{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline \n",
    "import torch \n",
    "#from IPython import display \n",
    "#from matplotlib import pyplot as plt\n",
    "import numpy as np \n",
    "import random\n",
    "import math\n",
    "#from time import time\n",
    "#from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatedata(noise,showpermutation=False,showtrue_w=False):\n",
    "    true_w2 = torch.from_numpy(np.random.normal(0, 1,(num_X2feature,1)))\n",
    "    if showtrue_w:\n",
    "        print('true_w2:',true_w2)\n",
    "    #X2_before_ =torch.from_numpy(np.random.normal(0, 1, (num_example, num_X2feature)))\n",
    "    X2_before_=torch.zeros(num_example, num_X2feature,dtype=torch.float64)\n",
    "    for i_1 in range(num_example):\n",
    "        for j_1 in range(num_X2feature):\n",
    "            X2_before_[i_1][j_1]=random.uniform(-5,5)\n",
    "    y_ = torch.mm(X2_before_,true_w2)\n",
    "    y_ += torch.from_numpy(np.random.normal(0, noise ,size=y_.size()))\n",
    "    P_array=np.random.permutation(num_example)\n",
    "    P=torch.zeros(num_example,num_example,dtype=torch.float64)\n",
    "    for i in range(num_example):\n",
    "        P[i][P_array[i]]=1\n",
    "    if showpermutation:\n",
    "        print('打乱X2的置换矩阵为',P)\n",
    "    X2_=torch.mm(P,X2_before_)\n",
    "    conditionnumber=np.linalg.cond(X2_.numpy())\n",
    "    #X2_=X2_before_\n",
    "    error_reg=(torch.norm(y_-torch.mm(X2_before_,true_w2))/torch.norm(y_))\n",
    "    return y_,X2_,true_w2,P,error_reg,conditionnumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateinitialw(method,showinitialw=False):\n",
    "    if method=='normal':\n",
    "        w2 = torch.from_numpy(np.random.normal(0, 1,(num_X2feature,1)))\n",
    "    if method=='zeros':\n",
    "        w2=torch.zeros(num_X2feature,1,dtype=torch.float64)\n",
    "    if showinitialw:\n",
    "        print('initial w2:',w2)\n",
    "    return w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinkhorn_stabilized(a, b, M, reg, numItermax=1000, tau=1e3, stopThr=1e-9,\n",
    "                        warmstart=None, verbose=False, print_period=20,\n",
    "                        log=False, **kwargs):\n",
    "\n",
    "#     a = np.asarray(a, dtype=np.float64)\n",
    "#     b = np.asarray(b, dtype=np.float64)\n",
    "#     M = np.asarray(M, dtype=np.float64)\n",
    "    a=a\n",
    "    b=b\n",
    "    M=M\n",
    "\n",
    "#     if len(a) == 0:\n",
    "#         a = np.ones((M.shape[0],), dtype=np.float64) / M.shape[0]\n",
    "#     if len(b) == 0:\n",
    "#         b = np.ones((M.shape[1],), dtype=np.float64) / M.shape[1]\n",
    "\n",
    "    # test if multiple target\n",
    "#     if len(b.shape) > 1:\n",
    "#         n_hists = b.shape[1]\n",
    "#         a = a[:, np.newaxis]\n",
    "#     else:\n",
    "#         n_hists = 0\n",
    "    n_hists = 0\n",
    "    # init data\n",
    "    dim_a = len(a)\n",
    "    dim_b = len(b)\n",
    "\n",
    "    cpt = 0\n",
    "    if log:\n",
    "        log = {'err': []}\n",
    "\n",
    "    # we assume that no distances are null except those of the diagonal of\n",
    "    # distances\n",
    "    if warmstart is None:\n",
    "        alpha, beta = torch.zeros(dim_a,1,dtype=torch.float64), torch.zeros(dim_b,1,dtype=torch.float64)\n",
    "    else:\n",
    "        alpha, beta = warmstart\n",
    "\n",
    "    if n_hists:\n",
    "        u = torch.ones((dim_a, n_hists)) / dim_a\n",
    "        v = torch.ones((dim_b, n_hists)) / dim_b\n",
    "    else:\n",
    "        u, v = torch.ones(dim_a,1,dtype=torch.float64) / dim_a, torch.ones(dim_b,1,dtype=torch.float64) / dim_b\n",
    "\n",
    "    def get_K(alpha, beta):\n",
    "        \"\"\"log space computation\"\"\"\n",
    "        return torch.exp(-(M - alpha.reshape((dim_a, 1))- beta.reshape((1, dim_b))) / reg)\n",
    "\n",
    "    def get_Gamma(alpha, beta, u, v):\n",
    "        \"\"\"log space gamma computation\"\"\"\n",
    "        return torch.exp(-(M - alpha.reshape((dim_a, 1)) - beta.reshape((1, dim_b)))\n",
    "                      / reg + torch.log(u.reshape((dim_a, 1))) + torch.log(v.reshape((1, dim_b))))\n",
    "\n",
    "    # print(np.min(K))\n",
    "\n",
    "    K = get_K(alpha, beta)\n",
    "    transp = K\n",
    "    loop = 1\n",
    "    cpt = 0\n",
    "    err = 1\n",
    "    while loop:\n",
    "\n",
    "        uprev = u\n",
    "        vprev = v\n",
    "        # sinkhornrn update\n",
    "        v = b / (torch.mm(K.transpose(1,0), u) + 1e-16)\n",
    "        u = a / (torch.mm(K, v) + 1e-16)\n",
    "        # remove numerical problems and store them in K\n",
    "        if torch.abs(u).max() > tau or torch.abs(v).max() > tau:\n",
    "            if n_hists:\n",
    "                alpha, beta = alpha + reg * \\\n",
    "                    torch.max(torch.log(u), 1), beta + reg * torch.max(np.log(v))\n",
    "            else:\n",
    "                alpha, beta = alpha + reg * torch.log(u), beta + reg * torch.log(v)\n",
    "                if n_hists:\n",
    "                    u, v = torch.ones((dim_a, n_hists)) / dim_a, torch.ones((dim_b, n_hists)) / dim_b\n",
    "                else:\n",
    "                    u, v = torch.ones(dim_a,1,dtype=torch.float64) / dim_a, torch.ones(dim_b,1,dtype=torch.float64) / dim_b\n",
    "            K = get_K(alpha, beta)\n",
    "            \n",
    "\n",
    "        if cpt % print_period == 0:\n",
    "            # we can speed up the process by checking for the error only all\n",
    "            # the 10th iterations\n",
    "            if n_hists:\n",
    "                err_u = abs(u - uprev).max()\n",
    "                err_u /= max(abs(u).max(), abs(uprev).max(), 1.)\n",
    "                err_v = abs(v - vprev).max()\n",
    "                err_v /= max(abs(v).max(), abs(vprev).max(), 1.)\n",
    "                err = 0.5 * (err_u + err_v)\n",
    "            else:\n",
    "                transp = get_Gamma(alpha, beta, u, v)\n",
    "                err = torch.norm((torch.sum(transp, axis=0) - b))\n",
    "            if log:\n",
    "                log['err'].append(err)\n",
    "\n",
    "            if verbose:\n",
    "                if cpt % (print_period * 20) == 0:\n",
    "                    print(\n",
    "                        '{:5s}|{:12s}'.format('It.', 'Err') + '\\n' + '-' * 19)\n",
    "                print('{:5d}|{:8e}|'.format(cpt, err))\n",
    "\n",
    "        if err <= stopThr:\n",
    "            loop = False\n",
    "\n",
    "        if cpt >= numItermax:\n",
    "            loop = False\n",
    "\n",
    "        if np.any(np.isnan(u.detach().numpy())) or np.any(np.isnan(v.detach().numpy())):\n",
    "            # we have reached the machine precision\n",
    "            # come back to previous solution and quit loop\n",
    "            print('Warning: numerical errors at iteration', cpt)\n",
    "            u = uprev\n",
    "            v = vprev\n",
    "            break\n",
    "\n",
    "        cpt = cpt + 1\n",
    "    #print(cpt)\n",
    "    if log:\n",
    "        if n_hists:\n",
    "            alpha = alpha[:, None]\n",
    "            beta = beta[:, None]\n",
    "        logu = alpha / reg + torch.log(u)\n",
    "        logv = beta / reg + torch.log(v)\n",
    "        log['logu'] = logu\n",
    "        log['logv'] = logv\n",
    "        log['alpha'] = alpha + reg * torch.log(u)\n",
    "        log['beta'] = beta + reg * torch.log(v)\n",
    "        log['warmstart'] = (log['alpha'], log['beta'])\n",
    "        if n_hists:\n",
    "            res = torch.zeros((n_hists))\n",
    "            for i in range(n_hists):\n",
    "                res[i] = torch.sum(get_Gamma(alpha, beta, u[:, i], v[:, i]) * M)\n",
    "            return res, log\n",
    "\n",
    "        else:\n",
    "            return get_Gamma(alpha, beta, u, v), log\n",
    "    else:\n",
    "        if n_hists:\n",
    "            res = torch.zeros((n_hists))\n",
    "            for i in range(n_hists):\n",
    "                res[i] = torch.sum(get_Gamma(alpha, beta, u[:, i], v[:, i]) * M)\n",
    "            return res\n",
    "        else:\n",
    "            return get_Gamma(alpha, beta, u, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinkhorn_epsilon_scaling(a, b, M, reg, numItermax=100, epsilon0=1e4,\n",
    "                             numInnerItermax=100, tau=1e3, stopThr=1e-9,\n",
    "                             warmstart=None, verbose=False, print_period=10,\n",
    "                             log=False, **kwargs):\n",
    "    #a = np.asarray(a, dtype=np.float64)\n",
    "    #b = np.asarray(b, dtype=np.float64)\n",
    "    #M = np.asarray(M, dtype=np.float64)\n",
    "    a=a\n",
    "    b=b\n",
    "    M=M\n",
    "#     if len(a) == 0:\n",
    "#         a = np.ones((M.shape[0],), dtype=np.float64) / M.shape[0]\n",
    "#     if len(b) == 0:\n",
    "#         b = np.ones((M.shape[1],), dtype=np.float64) / M.shape[1]\n",
    "\n",
    "    # init data\n",
    "    dim_a = len(a)\n",
    "    #dim_a=num_example\n",
    "    dim_b = len(b)\n",
    "    #dim_b=num_example\n",
    "    # nrelative umerical precision with 64 bits\n",
    "    numItermin = 35\n",
    "    numItermax = max(numItermin, numItermax)  # ensure that last velue is exact\n",
    "\n",
    "    cpt = 0\n",
    "    if log:\n",
    "        log = {'err': []}\n",
    "\n",
    "    # we assume that no distances are null except those of the diagonal of\n",
    "    # distances\n",
    "    if warmstart is None:\n",
    "        alpha, beta = torch.zeros(dim_a,1,dtype=torch.float64), torch.zeros(dim_b,1,dtype=torch.float64)\n",
    "    else:\n",
    "        alpha, beta = warmstart\n",
    "\n",
    "    def get_K(alpha, beta):\n",
    "        \"\"\"log space computation\"\"\"\n",
    "        return torch.exp(-(M - alpha.reshape((dim_a, 1))\n",
    "                        - beta.reshape((1, dim_b))) / reg)\n",
    "\n",
    "    # print(np.min(K))\n",
    "    def get_reg(n):  # exponential decreasing\n",
    "        return (epsilon0 - reg) * np.exp(-n) + reg\n",
    "\n",
    "    loop = 1\n",
    "    cpt = 0\n",
    "    err = 1\n",
    "    while loop:\n",
    "\n",
    "        regi = get_reg(cpt)\n",
    "\n",
    "        G, logi = sinkhorn_stabilized(a, b, M, regi,\n",
    "                                      numItermax=numInnerItermax, stopThr=1e-9,\n",
    "                                      warmstart=(alpha, beta), verbose=False,\n",
    "                                      print_period=20, tau=tau, log=True)\n",
    "\n",
    "        alpha = logi['alpha']\n",
    "        beta = logi['beta']\n",
    "\n",
    "        if cpt >= numItermax:\n",
    "            loop = False\n",
    "\n",
    "        if cpt % (print_period) == 0:  # spsion nearly converged\n",
    "            # we can speed up the process by checking for the error only all\n",
    "            # the 10th iterations\n",
    "            transp = G\n",
    "            err = torch.norm(\n",
    "                (torch.sum(transp, axis=0) - b))**2 + torch.norm((torch.sum(transp, axis=1) - a))**2\n",
    "            if log:\n",
    "                log['err'].append(err)\n",
    "\n",
    "            if verbose:\n",
    "                if cpt % (print_period * 10) == 0:\n",
    "                    print(\n",
    "                        '{:5s}|{:12s}'.format('It.', 'Err') + '\\n' + '-' * 19)\n",
    "                print('{:5d}|{:8e}|'.format(cpt, err))\n",
    "\n",
    "        if err <= stopThr and cpt > numItermin:\n",
    "            loop = False\n",
    "\n",
    "        cpt = cpt + 1\n",
    "    # print('err=',err,' cpt=',cpt)\n",
    "    if log:\n",
    "        log['alpha'] = alpha\n",
    "        log['beta'] = beta\n",
    "        log['warmstart'] = (log['alpha'], log['beta'])\n",
    "        return G, log\n",
    "    else:\n",
    "        return G\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0 = tensor(626.4322, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(626.2972, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(18.5380, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(12.6915, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(12.5361, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(12.4626, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(12.3786, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(12.2970, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(12.2500, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(12.2104, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(12.1376, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(12.0873, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(12.0739, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(12.0713, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(12.0647, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(12.0339, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(12.0113, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(11.9964, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(11.9957, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 19 = tensor(11.9957, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 20 = tensor(11.9957, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 2 100 平均相对误差2： tensor(1.6103, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.1526675637259225   2 100 置换矩阵误差： tensor(1.4036, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.1282, dtype=torch.float64)   实验回归误差 tensor(0.1384, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 98\n",
      "Loss 0 = tensor(406.7646, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(392.1237, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 36 = tensor(2.1512, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 37 = tensor(2.1019, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 38 = tensor(2.0732, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 39 = tensor(2.0434, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 40 = tensor(1.9742, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 41 = tensor(1.9301, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 42 = tensor(1.9177, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 43 = tensor(1.9104, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 44 = tensor(1.8991, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 45 = tensor(1.8953, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 46 = tensor(1.8942, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 47 = tensor(1.8941, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 48 = tensor(1.8941, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 49 = tensor(1.8941, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 2 100 平均相对误差2： tensor(0.0273, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.1114357830453288   2 100 置换矩阵误差： tensor(1.3115, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.1475, dtype=torch.float64)   实验回归误差 tensor(0.0682, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(1278.3624, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(1158.7323, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(7.2994, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(3.6512, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(2.9690, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(2.5779, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(2.3263, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(1.8773, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(1.6787, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(1.6062, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(1.5816, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(1.5715, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(1.5712, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(1.5712, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(1.5712, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(1.5712, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 2 100 平均相对误差2： tensor(0.0125, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.1131927866691653   2 100 置换矩阵误差： tensor(1.2490, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0779, dtype=torch.float64)   实验回归误差 tensor(0.0351, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(1014.0740, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(991.1259, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(151.9104, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(42.9521, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(25.3984, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(22.5999, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(22.1596, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(22.0907, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(22.0788, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(22.0764, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(22.0758, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(22.0757, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(22.0757, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(22.0757, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(22.0757, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 2 100 平均相对误差2： tensor(1.0940, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.2025359338792734   2 100 置换矩阵误差： tensor(1.4000, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0897, dtype=torch.float64)   实验回归误差 tensor(0.1475, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(4631.0470, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(4570.5721, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(22.6228, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(9.1531, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(8.3556, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(7.8881, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(6.5366, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(5.4042, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(4.7092, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(4.1064, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(3.8915, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(3.8443, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(3.7828, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(3.7590, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(3.7461, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(3.7461, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(3.7461, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 2 100 平均相对误差2： tensor(0.0059, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.0455557160884956   2 100 置换矩阵误差： tensor(1.1045, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0396, dtype=torch.float64)   实验回归误差 tensor(0.0284, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(147.3352, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(145.4501, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(3.8316, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(3.4453, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(3.0544, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(2.7610, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(2.4361, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(2.1607, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(1.9817, dtype=torch.float64, grad_fn=<PowBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 9 = tensor(1.8531, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(1.7397, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(1.7029, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(1.6639, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(1.6282, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(1.5805, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(1.5092, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(1.4361, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(1.3623, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(1.3290, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 19 = tensor(1.3217, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 20 = tensor(1.3096, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 21 = tensor(1.2967, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 22 = tensor(1.2909, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 23 = tensor(1.2897, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 24 = tensor(1.2886, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 25 = tensor(1.2808, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 26 = tensor(1.2743, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 27 = tensor(1.2741, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 28 = tensor(1.2741, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 29 = tensor(1.2741, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 30 = tensor(1.2741, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 2 100 平均相对误差2： tensor(1.2384, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.0816235785109976   2 100 置换矩阵误差： tensor(1.4000, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.2345, dtype=torch.float64)   实验回归误差 tensor(0.0930, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(798.8504, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(797.2379, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(43.8637, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(8.6710, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(6.9742, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(6.8850, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(6.8701, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(6.8601, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(6.8595, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(6.8584, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(6.8577, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(6.8565, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(6.8565, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(6.8565, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 2 100 平均相对误差2： tensor(1.4119, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.0842551465083592   2 100 置换矩阵误差： tensor(1.4071, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.1231, dtype=torch.float64)   实验回归误差 tensor(0.0926, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(4044.0618, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(4034.0032, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(144.8289, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(85.0371, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(82.8222, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(80.0154, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(75.7149, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(72.3109, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(71.0287, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(69.4568, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(69.0369, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(68.9786, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(68.9559, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(68.9540, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(68.9540, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(68.9540, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 2 100 平均相对误差2： tensor(1.1957, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.1236197657171143   2 100 置换矩阵误差： tensor(1.4000, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0422, dtype=torch.float64)   实验回归误差 tensor(0.1306, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(1082.0054, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(1010.3006, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(94.6294, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(17.6078, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(11.0008, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(10.3982, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(10.3208, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(10.3106, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(10.3095, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(10.3093, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(10.3093, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(10.3093, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 2 100 平均相对误差2： tensor(0.5700, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.1607100617421375   2 100 置换矩阵误差： tensor(1.3928, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0940, dtype=torch.float64)   实验回归误差 tensor(0.0976, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(3151.4433, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(3141.2307, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(475.2360, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(133.2265, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(81.1205, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(73.5489, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(72.4009, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(72.2248, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(72.1802, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(72.1584, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(72.1472, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(72.1445, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(72.1444, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(72.1444, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(72.1444, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 2 100 平均相对误差2： tensor(1.2352, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.1267736305464033   2 100 置换矩阵误差： tensor(1.4071, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0552, dtype=torch.float64)   实验回归误差 tensor(0.1513, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(1649.3786, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(1592.1727, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(248.3095, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(93.8677, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(70.4382, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(66.9405, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(66.0079, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(65.5696, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(65.0954, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(64.6950, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(63.7019, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(62.7079, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(61.6638, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(60.9998, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(60.6542, dtype=torch.float64, grad_fn=<PowBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 15 = tensor(60.4980, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(59.8886, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(58.9177, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(57.4408, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 19 = tensor(56.1890, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 20 = tensor(54.5585, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 21 = tensor(53.0101, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 22 = tensor(51.7421, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 23 = tensor(50.4639, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 24 = tensor(48.6661, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 25 = tensor(46.7662, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 26 = tensor(45.7873, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 27 = tensor(45.3366, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 28 = tensor(44.6273, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 29 = tensor(44.2366, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 30 = tensor(43.9125, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 31 = tensor(43.5208, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 32 = tensor(43.1833, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 33 = tensor(42.9223, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 34 = tensor(42.6859, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 35 = tensor(42.6307, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 36 = tensor(42.5661, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 37 = tensor(42.4315, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 38 = tensor(42.2182, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 39 = tensor(42.0712, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 40 = tensor(41.9665, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 41 = tensor(41.8904, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 42 = tensor(41.6498, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 43 = tensor(40.8158, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 44 = tensor(40.2655, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 45 = tensor(40.0423, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 46 = tensor(39.7801, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 47 = tensor(39.1892, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 48 = tensor(37.1139, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 49 = tensor(35.5455, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 50 = tensor(34.4699, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 51 = tensor(32.9560, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 52 = tensor(31.8682, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 53 = tensor(30.3962, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 54 = tensor(29.1755, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 55 = tensor(28.5141, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 56 = tensor(27.8902, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 57 = tensor(27.3717, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 58 = tensor(26.8701, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 59 = tensor(26.3690, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 60 = tensor(25.3272, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 61 = tensor(23.8388, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 62 = tensor(23.1096, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 63 = tensor(22.4285, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 64 = tensor(22.1181, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 65 = tensor(21.9905, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 66 = tensor(21.8819, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 67 = tensor(21.7019, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 68 = tensor(21.5860, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 69 = tensor(21.5458, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 70 = tensor(21.5295, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 71 = tensor(21.5251, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 72 = tensor(21.4980, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 73 = tensor(21.4238, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 74 = tensor(21.3863, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 75 = tensor(21.3588, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 76 = tensor(21.3523, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 77 = tensor(21.3471, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 78 = tensor(21.3457, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 79 = tensor(21.3456, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 80 = tensor(21.3456, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 81 = tensor(21.3456, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 5 100 平均相对误差2： tensor(1.0028, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.3479497225871686   5 100 置换矩阵误差： tensor(1.4000, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0723, dtype=torch.float64)   实验回归误差 tensor(0.1138, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(4205.8700, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(4205.1787, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(486.4223, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(133.0420, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(83.9524, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(73.3784, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(69.8652, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(68.6518, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(67.4357, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(65.6765, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(64.3676, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(62.6967, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(61.1900, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(59.7700, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(58.8153, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(57.8974, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(57.2908, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(56.4550, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(55.2611, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 19 = tensor(54.5098, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 20 = tensor(54.1051, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 21 = tensor(53.9211, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 22 = tensor(53.8502, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 23 = tensor(53.8447, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 24 = tensor(53.7998, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 25 = tensor(53.7549, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 26 = tensor(53.7195, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 27 = tensor(53.6988, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 28 = tensor(53.6932, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 29 = tensor(53.6916, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 30 = tensor(53.6916, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 31 = tensor(53.6916, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 5 100 平均相对误差2： tensor(1.1602, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.3209557428066203   5 100 置换矩阵误差： tensor(1.4000, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0499, dtype=torch.float64)   实验回归误差 tensor(0.1130, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(5563.3726, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(5384.0263, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(1821.5082, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(706.1969, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(326.7411, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(200.3169, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(155.4506, dtype=torch.float64, grad_fn=<PowBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 7 = tensor(137.4080, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(129.3093, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(123.3131, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(117.9117, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(107.1385, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(96.3112, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(85.0589, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(75.8117, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(69.3824, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(64.4599, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(61.9684, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(60.8942, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 19 = tensor(59.7434, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 20 = tensor(58.7017, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 21 = tensor(57.6068, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 22 = tensor(56.1403, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 23 = tensor(54.4654, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 24 = tensor(52.7599, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 25 = tensor(51.2986, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 26 = tensor(49.6825, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 27 = tensor(49.0814, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 28 = tensor(49.0056, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 29 = tensor(48.9984, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 30 = tensor(48.9953, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 31 = tensor(48.9790, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 32 = tensor(48.9471, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 33 = tensor(48.9317, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 34 = tensor(48.9301, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 35 = tensor(48.9300, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 36 = tensor(48.9300, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 37 = tensor(48.9300, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 5 100 平均相对误差2： tensor(1.0383, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.4326909269927262   5 100 置换矩阵误差： tensor(1.4071, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0368, dtype=torch.float64)   实验回归误差 tensor(0.0938, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(3502.5397, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(3248.9908, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(654.3696, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(324.2247, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(221.2968, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(192.5303, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(179.2901, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(168.1165, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(151.3500, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(140.4030, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(127.7369, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(113.0453, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(102.5159, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(96.6579, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(91.0120, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(86.4476, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(83.4241, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(81.3376, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(79.8662, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 19 = tensor(77.9181, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 20 = tensor(75.6218, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 21 = tensor(73.5580, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 22 = tensor(72.0523, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 23 = tensor(70.1031, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 24 = tensor(68.2083, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 25 = tensor(65.9476, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 26 = tensor(64.2368, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 27 = tensor(62.2965, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 28 = tensor(60.8878, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 29 = tensor(59.4453, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 30 = tensor(57.9144, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 31 = tensor(55.4671, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 32 = tensor(52.9873, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 33 = tensor(49.8407, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 34 = tensor(45.8167, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 35 = tensor(42.5348, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 36 = tensor(40.2249, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 37 = tensor(38.8194, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 38 = tensor(37.0667, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 39 = tensor(35.0077, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 40 = tensor(33.3969, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 41 = tensor(32.1734, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 42 = tensor(31.6650, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 43 = tensor(31.3503, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 44 = tensor(31.1333, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 45 = tensor(30.9808, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 46 = tensor(30.8269, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 47 = tensor(30.6839, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 48 = tensor(30.5396, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 49 = tensor(30.4209, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 50 = tensor(30.2223, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 51 = tensor(29.9589, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 52 = tensor(29.8753, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 53 = tensor(29.8278, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 54 = tensor(29.7893, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 55 = tensor(29.7673, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 56 = tensor(29.7098, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 57 = tensor(29.6802, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 58 = tensor(29.6764, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 59 = tensor(29.6664, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 60 = tensor(29.6238, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 61 = tensor(29.5958, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 62 = tensor(29.5633, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 63 = tensor(29.5550, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 64 = tensor(29.5541, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 65 = tensor(29.5539, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 66 = tensor(29.5537, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 67 = tensor(29.5537, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 68 = tensor(29.5537, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 69 = tensor(29.5536, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 70 = tensor(29.5536, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 71 = tensor(29.5536, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 72 = tensor(29.5536, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 73 = tensor(29.5536, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 5 100 平均相对误差2： tensor(1.5677, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.5623882906176672   5 100 置换矩阵误差： tensor(1.4071, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0498, dtype=torch.float64)   实验回归误差 tensor(0.0919, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(2590.0136, dtype=torch.float64, grad_fn=<PowBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 1 = tensor(2570.9980, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(122.0741, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(55.2386, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(49.1911, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(46.7846, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(45.9021, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(45.3146, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(44.7190, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(44.4535, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(44.3700, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(44.3345, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(44.2953, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(44.2858, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(44.2304, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(43.9209, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(43.7664, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(43.6667, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(43.6489, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 19 = tensor(43.6483, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 20 = tensor(43.6482, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 21 = tensor(43.6482, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 22 = tensor(43.6482, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 5 100 平均相对误差2： tensor(1.0268, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.2934515907996365   5 100 置换矩阵误差： tensor(1.4000, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0561, dtype=torch.float64)   实验回归误差 tensor(0.1298, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(10170.4631, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(8627.8874, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(1045.7238, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(506.2438, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(407.0346, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(378.3712, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(356.5652, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(330.2157, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(309.3882, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(280.3296, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(252.7546, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(229.1692, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(216.3726, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(207.8968, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(200.5087, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(189.4530, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(175.5643, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(160.4590, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(143.6619, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 19 = tensor(130.5932, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 20 = tensor(123.6103, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 21 = tensor(120.8450, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 22 = tensor(120.4872, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 23 = tensor(120.4301, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 24 = tensor(120.3624, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 25 = tensor(120.0196, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 26 = tensor(119.7059, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 27 = tensor(119.3326, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 28 = tensor(117.4194, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 29 = tensor(113.1930, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 30 = tensor(110.1101, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 31 = tensor(108.2428, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 32 = tensor(105.2708, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 33 = tensor(102.6173, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 34 = tensor(98.6073, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 35 = tensor(96.6402, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 36 = tensor(95.8922, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 37 = tensor(95.1117, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 38 = tensor(94.7393, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 39 = tensor(93.8458, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 40 = tensor(93.3664, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 41 = tensor(93.1230, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 42 = tensor(92.8348, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 43 = tensor(92.7086, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 44 = tensor(92.6453, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 45 = tensor(92.4924, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 46 = tensor(92.2255, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 47 = tensor(92.1674, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 48 = tensor(92.1628, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 49 = tensor(92.1604, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 50 = tensor(92.1546, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 51 = tensor(92.1543, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 52 = tensor(92.1543, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 53 = tensor(92.1543, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 5 100 平均相对误差2： tensor(1.2981, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.4811599678190852   5 100 置换矩阵误差： tensor(1.4071, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0299, dtype=torch.float64)   实验回归误差 tensor(0.0952, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(2064.5683, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(1996.8899, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(227.1972, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(66.3923, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(35.3441, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(29.9332, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(29.0467, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(28.8674, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(28.8075, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(28.7927, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(28.7898, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(28.7895, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(28.7894, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(28.7894, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(28.7894, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(28.7894, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(28.7894, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(28.7894, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 5 100 平均相对误差2： tensor(1.0063, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.4199828347746808   5 100 置换矩阵误差： tensor(1.4071, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0653, dtype=torch.float64)   实验回归误差 tensor(0.1181, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(621.1023, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(613.7728, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(140.5095, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(45.8844, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(24.8022, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(19.9640, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(18.2184, dtype=torch.float64, grad_fn=<PowBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 7 = tensor(17.5148, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(16.8795, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(16.5794, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(16.1907, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(15.7137, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(15.4278, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(15.2357, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(14.9483, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(14.6992, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(14.5698, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(14.5014, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(14.4200, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 19 = tensor(14.2972, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 20 = tensor(14.2556, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 21 = tensor(14.2365, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 22 = tensor(14.2048, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 23 = tensor(14.1551, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 24 = tensor(14.1349, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 25 = tensor(14.1003, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 26 = tensor(14.0683, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 27 = tensor(14.0466, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 28 = tensor(14.0446, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 29 = tensor(14.0252, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 30 = tensor(14.0170, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 31 = tensor(14.0131, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 32 = tensor(14.0068, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 33 = tensor(13.9920, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 34 = tensor(13.9696, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 35 = tensor(13.9560, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 36 = tensor(13.9502, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 37 = tensor(13.9413, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 38 = tensor(13.9328, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 39 = tensor(13.9316, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 40 = tensor(13.9315, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 41 = tensor(13.9315, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 42 = tensor(13.9315, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 43 = tensor(13.9315, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 5 100 平均相对误差2： tensor(1.3826, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.2994827850669735   5 100 置换矩阵误差： tensor(1.4142, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.1179, dtype=torch.float64)   实验回归误差 tensor(0.1498, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(2422.5854, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(2402.6546, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(89.1590, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(83.4546, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(78.9915, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(77.4617, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(76.0785, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(74.9749, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(74.2469, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(73.3826, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(72.9240, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(72.3598, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(71.3191, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(70.3284, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(69.8804, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(69.3244, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(69.1966, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(69.1671, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(69.0754, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 19 = tensor(69.0248, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 20 = tensor(69.0192, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 21 = tensor(69.0184, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 22 = tensor(69.0183, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 23 = tensor(69.0183, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 24 = tensor(69.0183, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 5 100 平均相对误差2： tensor(1.1277, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.424509418321146   5 100 置换矩阵误差： tensor(1.4142, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0656, dtype=torch.float64)   实验回归误差 tensor(0.1688, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(3260.3959, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(2726.7085, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(588.3727, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(291.2309, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(219.8560, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(193.6300, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(179.9463, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(163.7237, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(145.8564, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(132.5887, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(122.9421, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(115.6230, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(108.0727, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(101.2976, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(97.7517, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(93.7004, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(89.5721, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(86.1724, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(83.9554, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 19 = tensor(82.8900, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 20 = tensor(82.5711, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 21 = tensor(82.4632, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 22 = tensor(81.6223, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 23 = tensor(80.6725, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 24 = tensor(79.9425, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 25 = tensor(78.8199, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 26 = tensor(77.9330, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 27 = tensor(76.2664, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 28 = tensor(74.6722, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 29 = tensor(72.1152, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 30 = tensor(69.1759, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 31 = tensor(60.8128, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 32 = tensor(54.9998, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 33 = tensor(52.6576, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 34 = tensor(47.6915, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 35 = tensor(42.5165, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 36 = tensor(38.9247, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 37 = tensor(36.5633, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 38 = tensor(34.7919, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 39 = tensor(34.0973, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 40 = tensor(33.3218, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 41 = tensor(32.5526, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 42 = tensor(32.5126, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 43 = tensor(32.4901, dtype=torch.float64, grad_fn=<PowBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 44 = tensor(32.4441, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 45 = tensor(32.4272, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 46 = tensor(32.4224, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 47 = tensor(32.4221, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 48 = tensor(32.4221, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 49 = tensor(32.4221, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 50 = tensor(32.4221, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 5 100 平均相对误差2： tensor(1.6404, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.2759281302071592   5 100 置换矩阵误差： tensor(1.4000, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0521, dtype=torch.float64)   实验回归误差 tensor(0.0997, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(3676.5546, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(3563.5205, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(377.3363, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(202.1010, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(170.7942, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(150.8155, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(137.9948, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(128.7133, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(118.1248, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(105.0730, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(95.4150, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(89.3107, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(84.9352, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(82.7529, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(81.2570, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(77.5617, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(74.6965, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(73.2080, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(70.7693, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 19 = tensor(67.7324, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 20 = tensor(65.7138, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 21 = tensor(64.9662, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 22 = tensor(64.1037, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 23 = tensor(63.4667, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 24 = tensor(62.7695, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 25 = tensor(61.5980, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 26 = tensor(60.5400, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 27 = tensor(59.8312, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 28 = tensor(58.6400, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 29 = tensor(57.5946, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 30 = tensor(56.7335, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 31 = tensor(55.4999, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 32 = tensor(54.4524, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 33 = tensor(53.7250, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 34 = tensor(53.5608, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 35 = tensor(53.4535, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 36 = tensor(53.2931, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 37 = tensor(53.0914, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 38 = tensor(52.8236, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 39 = tensor(51.8232, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 40 = tensor(51.3775, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 41 = tensor(50.3286, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 42 = tensor(49.7183, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 43 = tensor(49.6026, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 44 = tensor(49.5695, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 45 = tensor(49.5620, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 46 = tensor(49.5600, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 47 = tensor(49.5146, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 48 = tensor(49.4779, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 49 = tensor(49.4603, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 50 = tensor(49.4571, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 51 = tensor(49.4566, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 52 = tensor(49.4551, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 53 = tensor(49.4550, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 54 = tensor(49.4550, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 55 = tensor(49.4550, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 10 100 平均相对误差2： tensor(1.0282, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.7627884903888236   10 100 置换矩阵误差： tensor(1.4000, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0511, dtype=torch.float64)   实验回归误差 tensor(0.1160, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(9235.6694, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(8651.0581, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(1281.9675, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(745.5257, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(616.9053, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(562.1375, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(522.0527, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(501.1406, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(490.9132, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(477.2140, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(419.4770, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(361.0713, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(324.5782, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(286.3146, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(261.6303, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(237.3671, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(212.9407, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(192.9394, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(182.3589, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 19 = tensor(177.3050, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 20 = tensor(164.1745, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 21 = tensor(147.4770, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 22 = tensor(131.2081, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 23 = tensor(115.1796, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 24 = tensor(104.6983, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 25 = tensor(97.2907, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 26 = tensor(91.9834, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 27 = tensor(89.7671, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 28 = tensor(88.1964, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 29 = tensor(87.6703, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 30 = tensor(87.5630, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 31 = tensor(87.5502, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 32 = tensor(87.5301, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 33 = tensor(87.5039, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 34 = tensor(87.5004, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 35 = tensor(87.4998, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 36 = tensor(87.4996, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 37 = tensor(87.4996, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 38 = tensor(87.4996, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 39 = tensor(87.4995, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 40 = tensor(87.4995, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 10 100 平均相对误差2： tensor(1.2370, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.6689775220876073   10 100 置换矩阵误差： tensor(1.4071, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0332, dtype=torch.float64)   实验回归误差 tensor(0.0973, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(4448.2816, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(4262.5478, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(1792.0556, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(963.0910, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(509.4670, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(344.9967, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(272.7443, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(234.7204, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(215.4375, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(205.4196, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(197.2461, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(189.5770, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(180.8853, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(171.5247, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(161.4884, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(150.7230, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(141.6585, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(133.9778, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(126.5462, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 19 = tensor(120.9693, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 20 = tensor(117.0885, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 21 = tensor(110.5248, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 22 = tensor(105.2961, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 23 = tensor(97.4252, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 24 = tensor(90.3567, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 25 = tensor(83.6605, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 26 = tensor(79.0064, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 27 = tensor(74.9577, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 28 = tensor(72.0199, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 29 = tensor(68.4867, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 30 = tensor(65.7429, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 31 = tensor(63.5964, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 32 = tensor(62.2834, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 33 = tensor(61.8108, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 34 = tensor(60.6245, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 35 = tensor(59.1251, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 36 = tensor(57.3872, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 37 = tensor(55.0632, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 38 = tensor(52.8626, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 39 = tensor(51.4192, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 40 = tensor(49.5621, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 41 = tensor(47.5402, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 42 = tensor(45.4046, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 43 = tensor(42.4358, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 44 = tensor(39.4365, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 45 = tensor(34.9431, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 46 = tensor(31.9430, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 47 = tensor(30.1054, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 48 = tensor(27.0144, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 49 = tensor(25.6095, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 50 = tensor(24.5588, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 51 = tensor(23.9825, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 52 = tensor(23.5663, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 53 = tensor(23.3905, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 54 = tensor(23.3201, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 55 = tensor(23.3038, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 56 = tensor(23.2213, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 57 = tensor(23.1304, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 58 = tensor(22.9711, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 59 = tensor(22.6048, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 60 = tensor(22.3018, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 61 = tensor(22.2874, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 62 = tensor(22.2780, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 63 = tensor(22.2776, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 64 = tensor(22.2774, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 65 = tensor(22.2774, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 66 = tensor(22.2773, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 67 = tensor(22.2773, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 68 = tensor(22.2773, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 69 = tensor(22.2773, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 70 = tensor(22.2773, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 71 = tensor(22.2773, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 72 = tensor(22.2773, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 10 100 平均相对误差2： tensor(1.3787, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.7415046941470451   10 100 置换矩阵误差： tensor(1.4071, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0464, dtype=torch.float64)   实验回归误差 tensor(0.0708, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(4903.7042, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(4146.1630, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(684.0183, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(307.6300, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(194.9954, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(164.4893, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(148.1081, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(141.4145, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(135.1306, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(123.6675, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(115.0328, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(110.6397, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(107.8096, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(104.4007, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(101.4859, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(95.1441, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(89.0701, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(82.9974, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(78.6244, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 19 = tensor(73.9086, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 20 = tensor(71.1120, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 21 = tensor(67.9709, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 22 = tensor(60.8899, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 23 = tensor(51.1138, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 24 = tensor(43.3831, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 25 = tensor(39.5014, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 26 = tensor(38.8626, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 27 = tensor(38.4754, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 28 = tensor(38.0405, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 29 = tensor(37.3665, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 30 = tensor(36.7331, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 31 = tensor(36.6272, dtype=torch.float64, grad_fn=<PowBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 32 = tensor(36.2880, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 33 = tensor(36.2280, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 34 = tensor(35.7409, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 35 = tensor(33.2211, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 36 = tensor(28.4750, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 37 = tensor(25.3792, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 38 = tensor(23.3053, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 39 = tensor(22.5173, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 40 = tensor(22.2006, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 41 = tensor(22.1172, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 42 = tensor(22.0842, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 43 = tensor(21.8589, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 44 = tensor(21.6579, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 45 = tensor(21.3200, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 46 = tensor(20.9545, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 47 = tensor(20.8946, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 48 = tensor(20.8856, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 49 = tensor(20.8846, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 50 = tensor(20.8845, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 51 = tensor(20.8845, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 52 = tensor(20.8845, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 53 = tensor(20.8845, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 54 = tensor(20.8845, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 55 = tensor(20.8845, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 10 100 平均相对误差2： tensor(1.0506, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.5534777011765386   10 100 置换矩阵误差： tensor(1.4000, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0398, dtype=torch.float64)   实验回归误差 tensor(0.0653, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(9072.6220, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(8169.5777, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(1024.2660, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(394.4451, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(253.9982, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(215.2314, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(194.2999, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(176.2827, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(160.0581, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(149.4655, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(141.9594, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(136.5918, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(126.4706, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(116.5360, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(109.4832, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(106.1437, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(104.9277, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(103.9744, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(99.4811, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 19 = tensor(95.7084, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 20 = tensor(94.1071, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 21 = tensor(92.9564, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 22 = tensor(89.7327, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 23 = tensor(86.7372, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 24 = tensor(81.1377, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 25 = tensor(76.9845, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 26 = tensor(74.3441, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 27 = tensor(71.5474, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 28 = tensor(68.7553, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 29 = tensor(66.4894, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 30 = tensor(62.9108, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 31 = tensor(57.9654, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 32 = tensor(54.3738, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 33 = tensor(48.6086, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 34 = tensor(45.8549, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 35 = tensor(44.0328, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 36 = tensor(41.5560, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 37 = tensor(39.5876, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 38 = tensor(38.5243, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 39 = tensor(37.7730, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 40 = tensor(37.3715, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 41 = tensor(37.0786, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 42 = tensor(36.9998, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 43 = tensor(36.9854, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 44 = tensor(36.9381, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 45 = tensor(36.9068, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 46 = tensor(36.7956, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 47 = tensor(36.7851, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 48 = tensor(36.7823, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 49 = tensor(36.7810, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 50 = tensor(36.7804, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 51 = tensor(36.7800, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 52 = tensor(36.7798, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 53 = tensor(36.7797, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 54 = tensor(36.7796, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 55 = tensor(36.7796, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 56 = tensor(36.7795, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 57 = tensor(36.7795, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 58 = tensor(36.7795, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 59 = tensor(36.7795, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 60 = tensor(36.7795, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 10 100 平均相对误差2： tensor(1.1476, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.7330010923822667   10 100 置换矩阵误差： tensor(1.4000, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0329, dtype=torch.float64)   实验回归误差 tensor(0.0637, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(2580.9596, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(2290.7725, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(582.0464, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(265.0594, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(167.7709, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(144.0571, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(136.4334, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(131.8591, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(125.0661, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(115.3294, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(105.5422, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(98.0756, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(88.3553, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(81.5502, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(76.3578, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(70.2499, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(65.8661, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(61.5371, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(58.1953, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 19 = tensor(54.8498, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 20 = tensor(51.5203, dtype=torch.float64, grad_fn=<PowBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 21 = tensor(48.7314, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 22 = tensor(45.5041, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 23 = tensor(42.1934, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 24 = tensor(40.5090, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 25 = tensor(39.5412, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 26 = tensor(38.0845, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 27 = tensor(37.1216, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 28 = tensor(36.6347, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 29 = tensor(35.9408, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 30 = tensor(35.0627, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 31 = tensor(33.9708, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 32 = tensor(32.9895, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 33 = tensor(32.2044, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 34 = tensor(31.5238, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 35 = tensor(31.0381, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 36 = tensor(30.4735, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 37 = tensor(30.1960, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 38 = tensor(29.7305, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 39 = tensor(29.4391, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 40 = tensor(29.2547, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 41 = tensor(29.1096, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 42 = tensor(28.6618, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 43 = tensor(28.2978, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 44 = tensor(27.8850, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 45 = tensor(27.3735, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 46 = tensor(27.1314, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 47 = tensor(26.9639, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 48 = tensor(26.6555, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 49 = tensor(26.5182, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 50 = tensor(26.4679, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 51 = tensor(26.4207, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 52 = tensor(26.3932, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 53 = tensor(26.3849, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 54 = tensor(26.3696, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 55 = tensor(26.1793, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 56 = tensor(25.8670, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 57 = tensor(25.4637, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 58 = tensor(24.8402, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 59 = tensor(24.4073, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 60 = tensor(24.2004, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 61 = tensor(24.0680, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 62 = tensor(23.9960, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 63 = tensor(23.9852, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 64 = tensor(23.9459, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 65 = tensor(23.8115, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 66 = tensor(23.7607, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 67 = tensor(23.7172, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 68 = tensor(23.6459, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 69 = tensor(23.5817, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 70 = tensor(23.5451, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 71 = tensor(23.5382, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 72 = tensor(23.5364, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 73 = tensor(23.5263, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 74 = tensor(23.5160, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 75 = tensor(23.5130, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 76 = tensor(23.5128, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 77 = tensor(23.5128, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 78 = tensor(23.5128, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 79 = tensor(23.5128, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 10 100 平均相对误差2： tensor(1.2782, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.6669050600709794   10 100 置换矩阵误差： tensor(1.4142, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0508, dtype=torch.float64)   实验回归误差 tensor(0.0954, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(7726.1975, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(7088.9545, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(1346.9682, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(648.8689, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(324.2641, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(216.1321, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(165.3179, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(137.8563, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(123.9272, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(112.6086, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(105.2660, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(96.7665, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(92.9775, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(90.9787, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(89.4355, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(88.0762, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(86.7989, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(85.4261, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(84.6302, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 19 = tensor(84.1280, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 20 = tensor(83.8931, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 21 = tensor(83.5741, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 22 = tensor(83.4312, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 23 = tensor(83.3403, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 24 = tensor(83.2811, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 25 = tensor(83.2529, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 26 = tensor(83.2503, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 27 = tensor(83.2499, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 28 = tensor(83.2498, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 29 = tensor(83.2498, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 30 = tensor(83.2497, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 31 = tensor(83.2497, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 10 100 平均相对误差2： tensor(0.8342, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.707076139855509   10 100 置换矩阵误差： tensor(1.3928, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0330, dtype=torch.float64)   实验回归误差 tensor(0.1038, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(5480.9419, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(5356.6410, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(1212.2848, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(502.8333, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(254.0508, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(193.5867, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(175.0836, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(168.4865, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(165.9226, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(164.9080, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(164.3107, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(163.3656, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(162.6846, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(162.2716, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(162.1461, dtype=torch.float64, grad_fn=<PowBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 15 = tensor(161.8969, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(161.3556, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(161.2414, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(161.2198, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 19 = tensor(161.2100, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 20 = tensor(161.2064, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 21 = tensor(161.2051, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 22 = tensor(161.2048, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 23 = tensor(161.2047, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 24 = tensor(161.2047, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 25 = tensor(161.2047, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 10 100 平均相对误差2： tensor(1.2902, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.9253390342579366   10 100 置换矩阵误差： tensor(1.4142, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0371, dtype=torch.float64)   实验回归误差 tensor(0.1715, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(14111.3434, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(13904.9795, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(2725.7614, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(1545.6334, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(1323.1960, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(1253.1587, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(1205.6935, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(1169.5287, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(1142.9549, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(1112.6202, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(1075.5193, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(1038.9634, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(995.9631, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(947.3458, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(882.7103, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(806.6108, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(750.5658, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(696.9957, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(626.4991, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 19 = tensor(548.4888, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 20 = tensor(504.6676, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 21 = tensor(462.3949, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 22 = tensor(415.6105, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 23 = tensor(381.0896, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 24 = tensor(349.7664, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 25 = tensor(329.4666, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 26 = tensor(307.5291, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 27 = tensor(279.7207, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 28 = tensor(260.1926, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 29 = tensor(226.5835, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 30 = tensor(186.6366, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 31 = tensor(160.0354, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 32 = tensor(142.9651, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 33 = tensor(128.9907, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 34 = tensor(117.4343, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 35 = tensor(108.7116, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 36 = tensor(101.6206, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 37 = tensor(98.2165, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 38 = tensor(96.6352, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 39 = tensor(94.6555, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 40 = tensor(92.4287, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 41 = tensor(90.1520, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 42 = tensor(87.4729, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 43 = tensor(80.6976, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 44 = tensor(76.1621, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 45 = tensor(74.0408, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 46 = tensor(73.2074, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 47 = tensor(73.0296, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 48 = tensor(72.9297, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 49 = tensor(72.8705, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 50 = tensor(72.1026, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 51 = tensor(71.1294, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 52 = tensor(71.0535, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 53 = tensor(71.0408, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 54 = tensor(71.0347, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 55 = tensor(71.0313, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 56 = tensor(71.0293, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 57 = tensor(71.0282, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 58 = tensor(71.0276, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 59 = tensor(71.0273, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 60 = tensor(71.0271, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 61 = tensor(71.0269, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 62 = tensor(71.0269, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 63 = tensor(71.0268, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 64 = tensor(71.0268, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 65 = tensor(71.0268, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 66 = tensor(71.0268, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 10 100 平均相对误差2： tensor(1.4452, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.6486412879817778   10 100 置换矩阵误差： tensor(1.4142, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0247, dtype=torch.float64)   实验回归误差 tensor(0.0709, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(12250.5281, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(12047.7117, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(3068.3304, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(1321.4333, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(855.1358, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(736.0630, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(695.8931, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(670.0609, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(657.2921, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(651.0476, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(643.9750, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(632.5688, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(620.4357, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(609.5675, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(600.2936, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(590.9943, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(585.0869, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(575.5379, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(567.4776, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 19 = tensor(561.6886, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 20 = tensor(557.9992, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 21 = tensor(555.0169, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 22 = tensor(552.7108, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 23 = tensor(551.2604, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 24 = tensor(549.8951, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 25 = tensor(548.0552, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 26 = tensor(546.8529, dtype=torch.float64, grad_fn=<PowBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 27 = tensor(544.1531, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 28 = tensor(543.4335, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 29 = tensor(540.8757, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 30 = tensor(534.3525, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 31 = tensor(530.8852, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 32 = tensor(525.6509, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 33 = tensor(515.9321, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 34 = tensor(507.1645, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 35 = tensor(503.6364, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 36 = tensor(500.7685, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 37 = tensor(499.2312, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 38 = tensor(498.8317, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 39 = tensor(498.5361, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 40 = tensor(497.8385, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 41 = tensor(496.5747, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 42 = tensor(495.4363, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 43 = tensor(494.0653, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 44 = tensor(493.4631, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 45 = tensor(492.2009, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 46 = tensor(490.3039, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 47 = tensor(488.5701, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 48 = tensor(486.7454, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 49 = tensor(483.9075, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 50 = tensor(481.5994, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 51 = tensor(480.9928, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 52 = tensor(479.2912, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 53 = tensor(477.2849, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 54 = tensor(475.3671, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 55 = tensor(474.6920, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 56 = tensor(474.0997, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 57 = tensor(473.1686, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 58 = tensor(472.2614, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 59 = tensor(471.6652, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 60 = tensor(471.5803, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 61 = tensor(471.1538, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 62 = tensor(470.8209, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 63 = tensor(470.7257, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 64 = tensor(470.7155, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 65 = tensor(470.7128, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 66 = tensor(470.7118, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 67 = tensor(470.7114, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 68 = tensor(470.7113, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 69 = tensor(470.7112, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 70 = tensor(470.7112, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 10 100 平均相对误差2： tensor(1.3519, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.7679871808083014   10 100 置换矩阵误差： tensor(1.3928, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0272, dtype=torch.float64)   实验回归误差 tensor(0.1960, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(15138.8496, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(13758.7966, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(9869.7621, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(8148.6872, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(3635.3962, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(2181.8904, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(1390.0048, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(1011.3228, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(798.2453, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(624.5654, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(492.1632, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(399.1683, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(349.1968, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(283.4837, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(250.7801, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(213.9960, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(183.0672, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(168.0573, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(151.2469, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 19 = tensor(143.1090, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 20 = tensor(134.1197, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 21 = tensor(126.3300, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 22 = tensor(120.9263, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 23 = tensor(114.8514, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 24 = tensor(109.4645, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 25 = tensor(107.0342, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 26 = tensor(105.3340, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 27 = tensor(103.5724, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 28 = tensor(102.2555, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 29 = tensor(100.4350, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 30 = tensor(99.4096, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 31 = tensor(98.6300, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 32 = tensor(97.7493, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 33 = tensor(96.6093, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 34 = tensor(95.5945, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 35 = tensor(95.1287, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 36 = tensor(94.4888, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 37 = tensor(94.0677, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 38 = tensor(93.5489, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 39 = tensor(93.1543, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 40 = tensor(92.4496, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 41 = tensor(92.2970, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 42 = tensor(92.1635, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 43 = tensor(92.0775, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 44 = tensor(91.9311, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 45 = tensor(91.7401, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 46 = tensor(91.6798, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 47 = tensor(91.6545, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 48 = tensor(91.6052, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 49 = tensor(91.5908, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 50 = tensor(91.5856, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 51 = tensor(91.4008, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 52 = tensor(91.3293, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 53 = tensor(91.3019, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 54 = tensor(91.3125, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 55 = tensor(91.3507, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 56 = tensor(91.4215, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 57 = tensor(91.5244, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 58 = tensor(91.5157, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 59 = tensor(91.6247, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 60 = tensor(91.5546, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 61 = tensor(91.6701, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 62 = tensor(91.5310, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 63 = tensor(91.5939, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 64 = tensor(91.5309, dtype=torch.float64, grad_fn=<PowBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 65 = tensor(91.6346, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 66 = tensor(91.5597, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 67 = tensor(91.6555, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 68 = tensor(91.6803, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 69 = tensor(91.8165, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 70 = tensor(91.7763, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 71 = tensor(91.7392, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 72 = tensor(91.4539, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 73 = tensor(91.3198, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 74 = tensor(91.2274, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 75 = tensor(91.2656, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 76 = tensor(91.3225, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 77 = tensor(91.4305, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 78 = tensor(91.3868, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 79 = tensor(90.7658, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 80 = tensor(90.4507, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 81 = tensor(90.0641, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 82 = tensor(89.7513, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 83 = tensor(89.6602, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 84 = tensor(89.3342, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 85 = tensor(89.2489, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 86 = tensor(89.2327, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 87 = tensor(89.2179, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 88 = tensor(89.2118, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 89 = tensor(89.2225, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 90 = tensor(89.2238, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 91 = tensor(89.2378, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 92 = tensor(89.2430, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 93 = tensor(89.2517, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 94 = tensor(89.2031, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 95 = tensor(89.2063, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 96 = tensor(89.1983, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 97 = tensor(89.2069, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 98 = tensor(89.2037, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 99 = tensor(89.2137, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 100 = tensor(89.2142, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 101 = tensor(89.2219, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 102 = tensor(89.2450, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 103 = tensor(89.2758, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 104 = tensor(89.2852, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 105 = tensor(89.2155, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 106 = tensor(89.1926, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 107 = tensor(89.2124, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 108 = tensor(89.2274, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 109 = tensor(89.2709, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 110 = tensor(89.3026, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 111 = tensor(89.2576, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 112 = tensor(89.2722, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 113 = tensor(89.3528, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 114 = tensor(89.3444, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 115 = tensor(89.3113, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 116 = tensor(89.3454, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 117 = tensor(89.3828, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 118 = tensor(89.3590, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 119 = tensor(89.3205, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 120 = tensor(89.3476, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 121 = tensor(89.3781, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 122 = tensor(89.4172, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 123 = tensor(89.4272, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 124 = tensor(89.4121, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 125 = tensor(89.4287, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 126 = tensor(89.4732, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 127 = tensor(89.4980, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 128 = tensor(89.4786, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 129 = tensor(89.3563, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 130 = tensor(89.3233, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 131 = tensor(89.3836, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 132 = tensor(89.4986, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 133 = tensor(89.4675, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 134 = tensor(89.4033, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 135 = tensor(89.3980, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 136 = tensor(89.4296, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 137 = tensor(89.4726, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 138 = tensor(89.4528, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 139 = tensor(89.3915, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 140 = tensor(89.3974, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 141 = tensor(89.3417, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 142 = tensor(89.3107, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 143 = tensor(89.3818, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 144 = tensor(89.4869, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 145 = tensor(89.4478, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 146 = tensor(89.3784, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 147 = tensor(89.4560, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 148 = tensor(89.4838, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 149 = tensor(89.4203, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 150 = tensor(89.3621, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 151 = tensor(89.3424, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 152 = tensor(89.3636, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 153 = tensor(89.3958, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 154 = tensor(89.4386, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 155 = tensor(89.4488, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 156 = tensor(89.4357, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 157 = tensor(89.3165, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 158 = tensor(89.2555, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 159 = tensor(89.2761, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 160 = tensor(89.3520, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 161 = tensor(89.4828, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 162 = tensor(89.6204, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 163 = tensor(89.5996, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 164 = tensor(89.5723, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 165 = tensor(89.6343, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 166 = tensor(89.6151, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 167 = tensor(89.4513, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 168 = tensor(89.4228, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 169 = tensor(89.4474, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 170 = tensor(89.4746, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 171 = tensor(89.5071, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 172 = tensor(89.4928, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 173 = tensor(89.5038, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 174 = tensor(89.4767, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 175 = tensor(89.5034, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 176 = tensor(89.6504, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 177 = tensor(89.6340, dtype=torch.float64, grad_fn=<PowBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 178 = tensor(89.5594, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 179 = tensor(89.5937, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 180 = tensor(89.6996, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 181 = tensor(89.5865, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 182 = tensor(89.4961, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 183 = tensor(89.4363, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 184 = tensor(89.4312, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 185 = tensor(89.4277, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 186 = tensor(89.3974, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 187 = tensor(89.3965, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 188 = tensor(89.5418, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 189 = tensor(89.5307, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 190 = tensor(88.0971, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 191 = tensor(87.6711, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 192 = tensor(87.0357, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 193 = tensor(86.4813, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 194 = tensor(86.3290, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 195 = tensor(86.2778, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 196 = tensor(86.0851, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 197 = tensor(85.4986, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 198 = tensor(85.3813, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 199 = tensor(84.7035, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 200 = tensor(84.3982, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "超过迭代上限\n",
      " 20 100 平均相对误差2： tensor(1.3704, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 2.42410597530402   20 100 置换矩阵误差： tensor(1.4142, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0231, dtype=torch.float64)   实验回归误差 tensor(0.0746, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(17512.6888, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(16181.0407, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(4151.7883, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(1900.3989, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(1143.8113, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(849.7417, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(711.0088, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(638.5228, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(593.5457, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(551.6220, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(535.2286, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(514.4173, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(487.9689, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(467.2580, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(438.8454, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(419.4524, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(398.3165, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(372.7456, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(349.7936, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 19 = tensor(326.4249, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 20 = tensor(315.2040, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 21 = tensor(287.8084, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 22 = tensor(273.1209, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 23 = tensor(265.3218, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 24 = tensor(250.0393, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 25 = tensor(233.1414, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 26 = tensor(214.7131, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 27 = tensor(192.8362, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 28 = tensor(174.2755, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 29 = tensor(156.8436, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 30 = tensor(142.2202, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 31 = tensor(129.8802, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 32 = tensor(121.6911, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 33 = tensor(110.3297, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 34 = tensor(98.0649, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 35 = tensor(87.0744, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 36 = tensor(81.2445, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 37 = tensor(78.2257, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 38 = tensor(76.7637, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 39 = tensor(74.8756, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 40 = tensor(73.8546, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 41 = tensor(72.1629, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 42 = tensor(71.2783, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 43 = tensor(70.4582, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 44 = tensor(67.9638, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 45 = tensor(66.0171, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 46 = tensor(63.9477, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 47 = tensor(62.6923, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 48 = tensor(58.8092, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 49 = tensor(57.1793, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 50 = tensor(56.2535, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 51 = tensor(55.7658, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 52 = tensor(55.7577, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 53 = tensor(55.9462, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 54 = tensor(55.9763, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 55 = tensor(54.1217, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 56 = tensor(52.9407, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 57 = tensor(51.9282, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 58 = tensor(50.3123, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 59 = tensor(49.0688, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 60 = tensor(48.5257, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 61 = tensor(47.7922, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 62 = tensor(47.7132, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 63 = tensor(47.6842, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 64 = tensor(47.6789, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 65 = tensor(47.6780, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 66 = tensor(47.6780, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 67 = tensor(47.6786, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 68 = tensor(47.6797, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 69 = tensor(47.6819, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 70 = tensor(47.6858, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 71 = tensor(47.6930, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 72 = tensor(47.7059, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 73 = tensor(47.7293, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 74 = tensor(47.7713, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 75 = tensor(47.8464, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 76 = tensor(47.9603, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 77 = tensor(48.1688, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 78 = tensor(48.2531, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 79 = tensor(48.4886, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 80 = tensor(48.6514, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 81 = tensor(48.9299, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 82 = tensor(49.1282, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 83 = tensor(49.4560, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 84 = tensor(48.5009, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 85 = tensor(48.1784, dtype=torch.float64, grad_fn=<PowBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 86 = tensor(48.2168, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 87 = tensor(48.3012, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 88 = tensor(48.5073, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 89 = tensor(48.3255, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 90 = tensor(48.4384, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 91 = tensor(48.3207, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 92 = tensor(48.2962, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 93 = tensor(48.3233, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 94 = tensor(48.2603, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 95 = tensor(48.2777, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 96 = tensor(48.1455, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 97 = tensor(48.1392, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 98 = tensor(48.0280, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 99 = tensor(47.9568, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 100 = tensor(47.9877, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 101 = tensor(48.0179, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 102 = tensor(47.9834, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 103 = tensor(47.9189, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 104 = tensor(47.9106, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 105 = tensor(47.9597, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 106 = tensor(48.0794, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 107 = tensor(48.1760, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 108 = tensor(48.2342, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 109 = tensor(48.3810, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 110 = tensor(48.4409, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 111 = tensor(48.6063, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 112 = tensor(47.7943, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 113 = tensor(47.5975, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 114 = tensor(47.6956, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 115 = tensor(47.7179, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 116 = tensor(47.8931, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 117 = tensor(47.9874, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 118 = tensor(48.0836, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 119 = tensor(48.1694, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 120 = tensor(48.2548, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 121 = tensor(48.3975, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 122 = tensor(48.4665, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 123 = tensor(48.6220, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 124 = tensor(47.8059, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 125 = tensor(47.6117, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 126 = tensor(47.7152, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 127 = tensor(47.7456, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 128 = tensor(47.9322, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 129 = tensor(47.9630, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 130 = tensor(47.9580, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 131 = tensor(47.9995, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 132 = tensor(48.0253, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 133 = tensor(48.0835, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 134 = tensor(48.1393, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 135 = tensor(48.2338, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 136 = tensor(48.2370, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 137 = tensor(48.3330, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 138 = tensor(48.3892, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 139 = tensor(48.5143, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 140 = tensor(48.5398, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 141 = tensor(48.7031, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 142 = tensor(47.8496, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 143 = tensor(47.6499, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 144 = tensor(47.6189, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 145 = tensor(47.6739, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 146 = tensor(47.8323, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 147 = tensor(47.9207, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 148 = tensor(48.0013, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 149 = tensor(48.0609, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 150 = tensor(48.1061, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 151 = tensor(48.1920, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 152 = tensor(48.1810, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 153 = tensor(48.2601, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 154 = tensor(48.4156, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 155 = tensor(48.6326, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 156 = tensor(47.8916, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 157 = tensor(47.7174, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 158 = tensor(47.7553, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 159 = tensor(47.8009, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 160 = tensor(47.9338, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 161 = tensor(47.9978, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 162 = tensor(48.2355, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 163 = tensor(48.3763, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 164 = tensor(48.4219, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 165 = tensor(48.5272, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 166 = tensor(48.4387, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 167 = tensor(48.5896, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 168 = tensor(47.8562, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 169 = tensor(47.6836, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 170 = tensor(47.8055, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 171 = tensor(47.8502, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 172 = tensor(48.0212, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 173 = tensor(48.0793, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 174 = tensor(48.1237, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 175 = tensor(48.2252, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 176 = tensor(48.2301, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 177 = tensor(48.3381, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 178 = tensor(48.2031, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 179 = tensor(48.2755, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 180 = tensor(48.3017, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 181 = tensor(48.4107, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 182 = tensor(48.4500, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 183 = tensor(48.6030, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 184 = tensor(47.7888, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 185 = tensor(47.5842, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 186 = tensor(47.6705, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 187 = tensor(47.7744, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 188 = tensor(47.8518, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 189 = tensor(47.8409, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 190 = tensor(47.9783, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 191 = tensor(48.0315, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 192 = tensor(48.0566, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 193 = tensor(48.1354, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 194 = tensor(48.2146, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 195 = tensor(48.3432, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 196 = tensor(48.3925, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 197 = tensor(48.5471, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 198 = tensor(47.7435, dtype=torch.float64, grad_fn=<PowBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 199 = tensor(47.5522, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 200 = tensor(47.6227, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "超过迭代上限\n",
      " 20 100 平均相对误差2： tensor(1.3774, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 2.1436198825340993   20 100 置换矩阵误差： tensor(1.4142, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0222, dtype=torch.float64)   实验回归误差 tensor(0.0523, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(19974.2152, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(17030.1713, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(10643.9964, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(7184.1682, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(4476.0389, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(3038.1207, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(2102.3527, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(1502.2242, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(1086.3527, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(719.3432, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(516.2810, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(372.6363, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(265.2580, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(184.5646, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(139.4264, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(114.6834, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(93.2235, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(81.7284, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(76.9717, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 19 = tensor(72.9238, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 20 = tensor(70.1374, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 21 = tensor(67.3360, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 22 = tensor(64.5439, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 23 = tensor(62.8649, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 24 = tensor(60.4662, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 25 = tensor(58.6635, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 26 = tensor(57.1009, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 27 = tensor(55.2078, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 28 = tensor(53.9345, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 29 = tensor(53.3279, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 30 = tensor(52.4685, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 31 = tensor(51.6495, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 32 = tensor(51.5233, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 33 = tensor(51.3143, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 34 = tensor(51.1284, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 35 = tensor(51.2155, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 36 = tensor(51.6002, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 37 = tensor(51.9880, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 38 = tensor(52.0913, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 39 = tensor(51.7191, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 40 = tensor(51.8808, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 41 = tensor(52.2593, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 42 = tensor(52.7342, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 43 = tensor(52.3901, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 44 = tensor(48.7899, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 45 = tensor(47.3876, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 46 = tensor(44.5746, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 47 = tensor(43.5610, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 48 = tensor(42.6312, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 49 = tensor(41.9895, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 50 = tensor(39.1091, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 51 = tensor(36.3736, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 52 = tensor(33.9960, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 53 = tensor(33.2115, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 54 = tensor(32.4275, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 55 = tensor(31.4403, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 56 = tensor(30.7242, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 57 = tensor(29.5382, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 58 = tensor(28.3001, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 59 = tensor(27.8084, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 60 = tensor(27.1678, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 61 = tensor(26.3243, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 62 = tensor(25.6071, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 63 = tensor(24.6100, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 64 = tensor(24.5083, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 65 = tensor(24.4663, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 66 = tensor(24.4436, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 67 = tensor(24.4444, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 68 = tensor(24.4489, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 69 = tensor(24.2450, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 70 = tensor(24.1772, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 71 = tensor(23.8388, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 72 = tensor(23.8235, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 73 = tensor(23.8429, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 74 = tensor(23.9122, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 75 = tensor(24.0095, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 76 = tensor(24.2044, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 77 = tensor(24.4833, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 78 = tensor(24.8507, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 79 = tensor(24.8889, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 80 = tensor(25.0984, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 81 = tensor(25.2973, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 82 = tensor(25.5960, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 83 = tensor(25.7613, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 84 = tensor(25.9322, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 85 = tensor(25.7766, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 86 = tensor(25.9316, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 87 = tensor(25.8464, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 88 = tensor(26.0131, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 89 = tensor(26.0895, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 90 = tensor(26.2974, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 91 = tensor(26.4438, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 92 = tensor(26.7612, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 93 = tensor(27.0188, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 94 = tensor(27.3667, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 95 = tensor(27.2279, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 96 = tensor(27.6128, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 97 = tensor(27.9022, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 98 = tensor(27.6404, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 99 = tensor(27.4410, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 100 = tensor(27.2707, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 101 = tensor(27.1055, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 102 = tensor(26.8118, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 103 = tensor(26.7840, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 104 = tensor(27.0682, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 105 = tensor(26.9916, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 106 = tensor(27.1010, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 107 = tensor(26.7794, dtype=torch.float64, grad_fn=<PowBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 108 = tensor(26.9047, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 109 = tensor(26.8044, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 110 = tensor(26.9464, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 111 = tensor(26.6463, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 112 = tensor(26.6936, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 113 = tensor(26.3782, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 114 = tensor(26.4494, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 115 = tensor(26.1373, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 116 = tensor(26.1662, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 117 = tensor(25.9638, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 118 = tensor(25.9615, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 119 = tensor(25.7198, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 120 = tensor(25.6183, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 121 = tensor(25.5892, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 122 = tensor(25.6732, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 123 = tensor(25.6682, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 124 = tensor(25.7163, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 125 = tensor(26.0200, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 126 = tensor(26.2447, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 127 = tensor(26.3970, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 128 = tensor(26.6093, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 129 = tensor(26.8023, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 130 = tensor(27.1791, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 131 = tensor(27.5273, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 132 = tensor(27.9334, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 133 = tensor(27.6590, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 134 = tensor(27.9515, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 135 = tensor(27.8281, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 136 = tensor(27.4789, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 137 = tensor(27.3525, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 138 = tensor(26.9676, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 139 = tensor(26.8896, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 140 = tensor(26.6826, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 141 = tensor(26.7062, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 142 = tensor(26.9680, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 143 = tensor(26.8922, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 144 = tensor(26.9818, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 145 = tensor(26.6404, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 146 = tensor(26.7318, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 147 = tensor(26.5861, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 148 = tensor(26.6667, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 149 = tensor(26.5406, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 150 = tensor(26.6301, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 151 = tensor(26.5184, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 152 = tensor(26.6187, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 153 = tensor(26.2686, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 154 = tensor(26.2550, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 155 = tensor(25.8654, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 156 = tensor(25.8243, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 157 = tensor(25.8193, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 158 = tensor(25.8301, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 159 = tensor(25.8351, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 160 = tensor(25.9171, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 161 = tensor(26.2720, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 162 = tensor(26.4980, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 163 = tensor(26.6833, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 164 = tensor(26.9706, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 165 = tensor(26.9324, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 166 = tensor(27.1818, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 167 = tensor(27.0081, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 168 = tensor(27.2811, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 169 = tensor(27.0841, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 170 = tensor(26.6396, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 171 = tensor(26.3925, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 172 = tensor(26.5149, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 173 = tensor(26.3398, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 174 = tensor(26.3939, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 175 = tensor(26.2044, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 176 = tensor(26.2120, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 177 = tensor(25.9934, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 178 = tensor(25.9597, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 179 = tensor(26.0184, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 180 = tensor(26.0794, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 181 = tensor(25.9970, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 182 = tensor(26.1592, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 183 = tensor(25.8884, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 184 = tensor(25.8394, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 185 = tensor(26.0969, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 186 = tensor(26.2381, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 187 = tensor(26.3118, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 188 = tensor(26.5304, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 189 = tensor(26.7080, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 190 = tensor(26.9062, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 191 = tensor(26.5154, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 192 = tensor(26.5970, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 193 = tensor(26.7118, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 194 = tensor(26.8521, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 195 = tensor(26.4962, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 196 = tensor(26.6130, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 197 = tensor(26.4649, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 198 = tensor(26.5860, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 199 = tensor(26.5090, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 200 = tensor(26.6311, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "超过迭代上限\n",
      " 20 100 平均相对误差2： tensor(1.3386, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 2.4160991090020016   20 100 置换矩阵误差： tensor(1.3928, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0206, dtype=torch.float64)   实验回归误差 tensor(0.0372, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(11981.9661, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(11291.9340, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(3189.5820, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(2064.4914, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(1135.0819, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(862.2208, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(663.8810, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(547.6881, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(466.9094, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(405.5153, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(372.1713, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(322.3017, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(279.3921, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(246.8722, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(233.6710, dtype=torch.float64, grad_fn=<PowBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 15 = tensor(214.8509, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(198.0809, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(182.2811, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(169.2558, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 19 = tensor(163.3645, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 20 = tensor(156.6472, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 21 = tensor(144.8947, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 22 = tensor(134.2672, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 23 = tensor(127.9494, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 24 = tensor(118.2404, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 25 = tensor(105.0652, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 26 = tensor(94.9449, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 27 = tensor(89.1488, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 28 = tensor(84.9975, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 29 = tensor(77.2445, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 30 = tensor(69.2075, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 31 = tensor(62.9591, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 32 = tensor(60.5405, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 33 = tensor(59.4527, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 34 = tensor(58.7528, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 35 = tensor(58.1975, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 36 = tensor(57.4314, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 37 = tensor(56.9128, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 38 = tensor(56.5211, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 39 = tensor(56.2048, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 40 = tensor(55.4072, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 41 = tensor(55.2181, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 42 = tensor(55.1807, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 43 = tensor(55.1880, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 44 = tensor(55.1805, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 45 = tensor(55.1901, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 46 = tensor(55.2095, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 47 = tensor(55.1957, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 48 = tensor(55.1882, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 49 = tensor(55.1610, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 50 = tensor(55.0520, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 51 = tensor(55.0360, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 52 = tensor(55.0182, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 53 = tensor(55.0073, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 54 = tensor(55.0078, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 55 = tensor(55.0186, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 56 = tensor(55.0301, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 57 = tensor(55.0285, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 58 = tensor(55.0358, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 59 = tensor(55.0337, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 60 = tensor(55.0399, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 61 = tensor(55.0376, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 62 = tensor(55.0437, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 63 = tensor(55.0415, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 64 = tensor(55.0478, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 65 = tensor(55.0459, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 66 = tensor(55.0527, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 67 = tensor(55.0513, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 68 = tensor(55.0588, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 69 = tensor(55.0583, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 70 = tensor(55.0667, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 71 = tensor(55.0675, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 72 = tensor(55.0776, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 73 = tensor(55.0803, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 74 = tensor(55.0917, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 75 = tensor(55.0859, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 76 = tensor(55.0971, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 77 = tensor(55.1018, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 78 = tensor(55.1155, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 79 = tensor(55.1056, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 80 = tensor(55.1163, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 81 = tensor(55.1231, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 82 = tensor(55.0990, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 83 = tensor(55.1104, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 84 = tensor(55.1381, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 85 = tensor(55.1259, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 86 = tensor(55.1135, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 87 = tensor(55.1258, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 88 = tensor(55.1535, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 89 = tensor(55.1859, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 90 = tensor(55.1864, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 91 = tensor(55.1498, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 92 = tensor(55.1268, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 93 = tensor(55.1187, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 94 = tensor(55.1360, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 95 = tensor(55.1361, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 96 = tensor(55.1535, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 97 = tensor(55.1467, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 98 = tensor(55.1204, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 99 = tensor(55.1312, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 100 = tensor(55.1577, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 101 = tensor(55.1450, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 102 = tensor(55.1309, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 103 = tensor(55.1403, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 104 = tensor(55.1641, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 105 = tensor(55.1913, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 106 = tensor(55.1945, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 107 = tensor(55.1607, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 108 = tensor(55.1758, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 109 = tensor(55.1665, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 110 = tensor(55.1577, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 111 = tensor(55.1528, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 112 = tensor(55.1475, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 113 = tensor(55.1520, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 114 = tensor(55.1319, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 115 = tensor(55.1443, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 116 = tensor(55.1725, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 117 = tensor(55.1603, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 118 = tensor(55.1482, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 119 = tensor(55.1610, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 120 = tensor(55.1895, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 121 = tensor(55.2225, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 122 = tensor(55.2245, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 123 = tensor(55.1832, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 124 = tensor(55.1997, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 125 = tensor(55.1931, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 126 = tensor(55.1863, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 127 = tensor(55.1926, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 128 = tensor(55.1703, dtype=torch.float64, grad_fn=<PowBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 129 = tensor(55.1854, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 130 = tensor(55.2159, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 131 = tensor(55.2047, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 132 = tensor(55.1747, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 133 = tensor(55.1879, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 134 = tensor(55.2192, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 135 = tensor(55.2075, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 136 = tensor(55.1767, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 137 = tensor(55.1894, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 138 = tensor(55.1966, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 139 = tensor(55.1824, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 140 = tensor(55.1710, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 141 = tensor(55.1860, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 142 = tensor(55.1936, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 143 = tensor(55.2269, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 144 = tensor(55.2277, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 145 = tensor(55.1870, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 146 = tensor(55.1668, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 147 = tensor(55.1824, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 148 = tensor(55.1902, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 149 = tensor(55.1765, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 150 = tensor(55.1430, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 151 = tensor(55.1523, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 152 = tensor(55.1822, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 153 = tensor(55.2181, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 154 = tensor(55.2188, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 155 = tensor(55.1779, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 156 = tensor(55.1951, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 157 = tensor(55.1874, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 158 = tensor(55.1444, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 159 = tensor(55.1539, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 160 = tensor(55.1827, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 161 = tensor(55.1716, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 162 = tensor(55.1614, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 163 = tensor(55.1768, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 164 = tensor(55.1841, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 165 = tensor(55.2169, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 166 = tensor(55.2176, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 167 = tensor(55.1768, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 168 = tensor(55.1942, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 169 = tensor(55.1868, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 170 = tensor(55.1437, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 171 = tensor(55.1526, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 172 = tensor(55.1809, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 173 = tensor(55.1694, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 174 = tensor(55.1581, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 175 = tensor(55.1722, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 176 = tensor(55.1776, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 177 = tensor(55.2078, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 178 = tensor(55.2092, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 179 = tensor(55.1670, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 180 = tensor(55.1828, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 181 = tensor(55.1758, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 182 = tensor(55.1685, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 183 = tensor(55.1738, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 184 = tensor(55.1930, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 185 = tensor(55.1896, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 186 = tensor(55.1745, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 187 = tensor(55.1962, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 188 = tensor(55.2021, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 189 = tensor(55.1662, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 190 = tensor(55.1797, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 191 = tensor(55.1688, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 192 = tensor(55.1422, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 193 = tensor(55.1416, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 194 = tensor(55.1594, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 195 = tensor(55.1571, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 196 = tensor(55.1376, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 197 = tensor(55.1524, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 198 = tensor(55.1814, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 199 = tensor(55.1703, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 200 = tensor(55.1393, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "超过迭代上限\n",
      " 20 100 平均相对误差2： tensor(1.3116, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 2.1644684265899707   20 100 置换矩阵误差： tensor(1.4071, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0267, dtype=torch.float64)   实验回归误差 tensor(0.0678, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(13967.5148, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(12826.8793, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(8114.5445, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(6602.3114, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(4034.2476, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(2751.4831, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(1715.8247, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(1123.8116, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(749.8872, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(541.6664, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(411.7984, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(327.3087, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(255.5245, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(206.8858, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(171.0870, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(140.1294, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(110.9228, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(88.1610, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(75.5689, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 19 = tensor(69.0226, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 20 = tensor(63.3533, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 21 = tensor(60.0518, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 22 = tensor(57.0538, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 23 = tensor(53.9101, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 24 = tensor(52.2485, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 25 = tensor(49.5332, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 26 = tensor(41.8907, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 27 = tensor(36.5025, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 28 = tensor(33.5901, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 29 = tensor(29.9747, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 30 = tensor(27.9819, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 31 = tensor(26.3875, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 32 = tensor(25.3585, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 33 = tensor(24.9623, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 34 = tensor(24.6689, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 35 = tensor(24.1561, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 36 = tensor(22.4950, dtype=torch.float64, grad_fn=<PowBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 37 = tensor(21.3779, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 38 = tensor(20.7837, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 39 = tensor(19.6260, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 40 = tensor(17.9182, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 41 = tensor(16.8694, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 42 = tensor(16.7250, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 43 = tensor(16.6802, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 44 = tensor(16.6446, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 45 = tensor(16.6296, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 46 = tensor(16.6159, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 47 = tensor(16.6182, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 48 = tensor(16.6540, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 49 = tensor(16.7084, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 50 = tensor(16.7582, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 51 = tensor(16.8363, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 52 = tensor(16.9278, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 53 = tensor(16.7379, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 54 = tensor(16.6113, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 55 = tensor(16.5653, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 56 = tensor(16.5571, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 57 = tensor(16.4096, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 58 = tensor(16.3219, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 59 = tensor(16.2443, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 60 = tensor(16.2234, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 61 = tensor(16.2457, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 62 = tensor(16.2812, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 63 = tensor(16.3283, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 64 = tensor(16.3218, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 65 = tensor(16.3225, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 66 = tensor(16.2972, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 67 = tensor(16.3445, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 68 = tensor(16.3417, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 69 = tensor(16.3467, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 70 = tensor(16.3286, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 71 = tensor(16.3859, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 72 = tensor(16.3679, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 73 = tensor(16.3727, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 74 = tensor(16.3594, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 75 = tensor(16.3222, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 76 = tensor(16.3686, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 77 = tensor(16.4174, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 78 = tensor(16.3676, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 79 = tensor(16.3786, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 80 = tensor(16.2879, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 81 = tensor(16.2844, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 82 = tensor(16.3203, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 83 = tensor(16.3501, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 84 = tensor(16.2997, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 85 = tensor(16.3269, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 86 = tensor(16.3653, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 87 = tensor(16.3946, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 88 = tensor(16.2935, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 89 = tensor(16.2756, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 90 = tensor(16.2681, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 91 = tensor(16.2341, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 92 = tensor(16.1378, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 93 = tensor(16.0459, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 94 = tensor(15.9870, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 95 = tensor(15.9289, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 96 = tensor(15.9218, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 97 = tensor(15.9375, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 98 = tensor(15.9351, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 99 = tensor(15.9569, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 100 = tensor(15.9606, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 101 = tensor(15.9542, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 102 = tensor(15.9232, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 103 = tensor(15.9222, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 104 = tensor(15.9440, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 105 = tensor(15.9735, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 106 = tensor(15.9703, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 107 = tensor(15.9752, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 108 = tensor(16.0078, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 109 = tensor(16.0441, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 110 = tensor(16.0071, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 111 = tensor(16.0155, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 112 = tensor(15.9750, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 113 = tensor(15.9749, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 114 = tensor(15.9902, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 115 = tensor(16.0156, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 116 = tensor(16.0563, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 117 = tensor(16.0938, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 118 = tensor(16.0669, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 119 = tensor(16.0661, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 120 = tensor(16.0593, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 121 = tensor(15.9791, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 122 = tensor(15.9750, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 123 = tensor(15.9886, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 124 = tensor(15.9753, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 125 = tensor(16.0042, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 126 = tensor(15.9758, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 127 = tensor(15.9791, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 128 = tensor(15.9959, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 129 = tensor(16.0285, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 130 = tensor(16.0108, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 131 = tensor(16.0241, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 132 = tensor(16.0599, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 133 = tensor(16.0995, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 134 = tensor(16.0561, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 135 = tensor(16.0655, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 136 = tensor(16.1076, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 137 = tensor(16.1609, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 138 = tensor(16.0721, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 139 = tensor(16.0562, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 140 = tensor(16.0841, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 141 = tensor(16.1224, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 142 = tensor(16.0808, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 143 = tensor(16.0892, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 144 = tensor(16.1343, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 145 = tensor(16.1832, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 146 = tensor(16.1127, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 147 = tensor(16.1316, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 148 = tensor(16.1932, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 149 = tensor(16.2496, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 150 = tensor(16.1636, dtype=torch.float64, grad_fn=<PowBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 151 = tensor(16.1683, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 152 = tensor(16.1384, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 153 = tensor(16.1718, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 154 = tensor(16.1051, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 155 = tensor(16.1199, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 156 = tensor(16.1825, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 157 = tensor(16.2361, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 158 = tensor(16.1467, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 159 = tensor(16.1620, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 160 = tensor(16.1067, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 161 = tensor(16.1055, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 162 = tensor(16.0917, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 163 = tensor(16.0055, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 164 = tensor(15.9846, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 165 = tensor(15.9870, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 166 = tensor(15.9698, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 167 = tensor(15.9680, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 168 = tensor(15.9931, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 169 = tensor(16.0291, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 170 = tensor(16.0134, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 171 = tensor(16.0289, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 172 = tensor(16.0603, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 173 = tensor(16.0990, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 174 = tensor(16.0542, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 175 = tensor(16.0492, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 176 = tensor(16.0416, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 177 = tensor(15.9610, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 178 = tensor(15.9551, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 179 = tensor(15.9675, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 180 = tensor(15.9693, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 181 = tensor(15.9806, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 182 = tensor(15.9611, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 183 = tensor(15.9622, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 184 = tensor(15.9909, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 185 = tensor(16.0288, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 186 = tensor(16.0134, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 187 = tensor(16.0266, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 188 = tensor(16.0549, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 189 = tensor(16.0943, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 190 = tensor(16.0488, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 191 = tensor(16.0419, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 192 = tensor(16.0335, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 193 = tensor(15.9534, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 194 = tensor(15.9269, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 195 = tensor(15.9131, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 196 = tensor(15.9083, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 197 = tensor(15.9176, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 198 = tensor(15.9392, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 199 = tensor(15.9631, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 200 = tensor(15.9940, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "超过迭代上限\n",
      " 20 100 平均相对误差2： tensor(1.1711, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 2.4221485718938247   20 100 置换矩阵误差： tensor(1.3928, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0253, dtype=torch.float64)   实验回归误差 tensor(0.0339, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(13610.6630, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(11314.3331, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(3348.8001, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(1854.0748, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(998.6151, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(627.9903, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(431.6933, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(323.6059, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(263.5651, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(233.4109, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(218.2565, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(208.0424, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(197.6697, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(188.4305, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(168.4499, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(154.9759, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(146.6658, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(142.7737, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(137.5361, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 19 = tensor(134.3858, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 20 = tensor(132.1774, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 21 = tensor(129.5823, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 22 = tensor(122.6804, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 23 = tensor(109.7852, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 24 = tensor(102.4745, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 25 = tensor(98.9709, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 26 = tensor(95.5032, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 27 = tensor(93.7520, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 28 = tensor(93.1301, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 29 = tensor(92.5254, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 30 = tensor(92.3238, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 31 = tensor(92.1081, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 32 = tensor(92.0769, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 33 = tensor(92.0222, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 34 = tensor(92.0152, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 35 = tensor(92.0134, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 36 = tensor(92.0130, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 37 = tensor(92.0134, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 38 = tensor(92.0141, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 39 = tensor(92.0151, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 40 = tensor(92.0164, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 41 = tensor(92.0179, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 42 = tensor(92.0196, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 43 = tensor(92.0217, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 44 = tensor(92.0241, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 45 = tensor(92.0268, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 46 = tensor(92.0288, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 47 = tensor(92.0321, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 48 = tensor(92.0349, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 49 = tensor(92.0390, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 50 = tensor(92.0426, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 51 = tensor(92.0461, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 52 = tensor(92.0501, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 53 = tensor(92.0544, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 54 = tensor(92.0593, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 55 = tensor(92.0647, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 56 = tensor(92.0707, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 57 = tensor(92.0774, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 58 = tensor(92.0849, dtype=torch.float64, grad_fn=<PowBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 59 = tensor(92.0933, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 60 = tensor(92.1027, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 61 = tensor(92.1132, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 62 = tensor(92.1250, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 63 = tensor(92.1383, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 64 = tensor(92.1531, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 65 = tensor(92.1698, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 66 = tensor(92.1883, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 67 = tensor(92.1982, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 68 = tensor(92.2204, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 69 = tensor(92.2299, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 70 = tensor(92.1422, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 71 = tensor(92.0459, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 72 = tensor(91.8687, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 73 = tensor(91.8270, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 74 = tensor(91.7699, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 75 = tensor(91.7365, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 76 = tensor(91.7310, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 77 = tensor(91.7290, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 78 = tensor(91.7295, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 79 = tensor(91.7306, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 80 = tensor(91.7321, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 81 = tensor(91.7340, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 82 = tensor(91.7361, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 83 = tensor(91.7386, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 84 = tensor(91.7409, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 85 = tensor(91.7437, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 86 = tensor(91.7414, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 87 = tensor(91.7413, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 88 = tensor(91.7435, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 89 = tensor(91.7465, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 90 = tensor(91.7501, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 91 = tensor(91.7539, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 92 = tensor(91.7523, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 93 = tensor(91.7533, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 94 = tensor(91.7569, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 95 = tensor(91.7613, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 96 = tensor(91.7660, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 97 = tensor(91.7709, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 98 = tensor(91.7702, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 99 = tensor(91.7719, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 100 = tensor(91.7760, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 101 = tensor(91.7799, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 102 = tensor(91.7798, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 103 = tensor(91.7825, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 104 = tensor(91.7884, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 105 = tensor(91.7932, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 106 = tensor(91.7938, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 107 = tensor(91.7961, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 108 = tensor(91.8036, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 109 = tensor(91.8093, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 110 = tensor(91.8110, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 111 = tensor(91.8147, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 112 = tensor(91.8164, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 113 = tensor(91.8194, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 114 = tensor(91.8276, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 115 = tensor(91.8170, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 116 = tensor(91.8113, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 117 = tensor(91.8143, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 118 = tensor(91.8178, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 119 = tensor(91.8231, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 120 = tensor(91.8221, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 121 = tensor(91.8236, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 122 = tensor(91.8232, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 123 = tensor(91.8241, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 124 = tensor(91.8277, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 125 = tensor(91.8334, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 126 = tensor(91.8329, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 127 = tensor(91.8360, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 128 = tensor(91.8353, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 129 = tensor(91.8375, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 130 = tensor(91.8409, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 131 = tensor(91.8292, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 132 = tensor(91.8244, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 133 = tensor(91.8284, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 134 = tensor(91.8331, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 135 = tensor(91.8393, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 136 = tensor(91.8391, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 137 = tensor(91.8413, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 138 = tensor(91.8414, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 139 = tensor(91.8432, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 140 = tensor(91.8472, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 141 = tensor(91.8359, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 142 = tensor(91.8306, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 143 = tensor(91.8315, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 144 = tensor(91.8363, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 145 = tensor(91.8427, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 146 = tensor(91.8428, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 147 = tensor(91.8469, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 148 = tensor(91.8471, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 149 = tensor(91.8505, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 150 = tensor(91.8503, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 151 = tensor(91.8501, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 152 = tensor(91.8495, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 153 = tensor(91.8524, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 154 = tensor(91.8524, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 20 100 平均相对误差2： tensor(1.1263, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 2.1990870936056806   20 100 置换矩阵误差： tensor(1.4142, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0262, dtype=torch.float64)   实验回归误差 tensor(0.0822, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(20388.9998, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(19559.5280, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(7651.1686, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(4878.5018, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(3349.1575, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(2245.7083, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(1562.2157, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(1016.3848, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(695.7439, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(485.0070, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(353.1037, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(263.5303, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(204.8404, dtype=torch.float64, grad_fn=<PowBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 13 = tensor(172.3821, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(154.1776, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(140.7678, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(127.2799, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(105.0347, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(85.4546, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 19 = tensor(71.6704, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 20 = tensor(62.4617, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 21 = tensor(51.9496, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 22 = tensor(47.4354, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 23 = tensor(46.5537, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 24 = tensor(45.1438, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 25 = tensor(43.7382, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 26 = tensor(43.2573, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 27 = tensor(43.1726, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 28 = tensor(42.9709, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 29 = tensor(42.8640, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 30 = tensor(42.6503, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 31 = tensor(42.5367, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 32 = tensor(42.5060, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 33 = tensor(42.4971, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 34 = tensor(42.4926, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 35 = tensor(42.4905, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 36 = tensor(42.4895, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 37 = tensor(42.4888, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 38 = tensor(42.4884, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 39 = tensor(42.4880, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 40 = tensor(42.4878, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 41 = tensor(42.4876, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 42 = tensor(42.4874, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 43 = tensor(42.4873, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 44 = tensor(42.4873, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 45 = tensor(42.4872, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 46 = tensor(42.4872, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 20 100 平均相对误差2： tensor(1.4616, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 2.2079076414776844   20 100 置换矩阵误差： tensor(1.4071, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0217, dtype=torch.float64)   实验回归误差 tensor(0.0456, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(3647.5813, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(3198.8669, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(1437.1093, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(906.1605, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(608.3122, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(379.9287, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(255.3374, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(170.0505, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(121.1672, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(91.6950, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(68.2389, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(54.0689, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(43.6016, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(39.0654, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(34.8704, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(32.1321, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(30.4289, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(29.6184, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(28.4775, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 19 = tensor(25.9565, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 20 = tensor(23.9077, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 21 = tensor(22.9103, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 22 = tensor(22.4809, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 23 = tensor(21.9769, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 24 = tensor(21.6454, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 25 = tensor(21.1903, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 26 = tensor(20.6834, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 27 = tensor(20.5535, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 28 = tensor(20.4855, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 29 = tensor(20.4596, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 30 = tensor(20.3779, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 31 = tensor(20.2348, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 32 = tensor(20.1875, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 33 = tensor(20.1792, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 34 = tensor(20.1765, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 35 = tensor(20.1751, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 36 = tensor(20.1746, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 37 = tensor(20.1743, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 38 = tensor(20.1742, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 39 = tensor(20.1742, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 40 = tensor(20.1742, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 41 = tensor(20.1744, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 42 = tensor(20.1748, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 43 = tensor(20.1755, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 44 = tensor(20.1762, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 45 = tensor(20.1776, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 46 = tensor(20.1796, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 47 = tensor(20.1828, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 48 = tensor(20.1875, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 49 = tensor(20.1919, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 50 = tensor(19.5559, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 51 = tensor(19.3155, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 52 = tensor(19.1177, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 53 = tensor(18.8509, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 54 = tensor(18.5958, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 55 = tensor(17.9070, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 56 = tensor(17.4091, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 57 = tensor(16.9680, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 58 = tensor(16.6672, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 59 = tensor(16.5064, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 60 = tensor(16.1309, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 61 = tensor(15.8633, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 62 = tensor(15.5342, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 63 = tensor(15.3303, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 64 = tensor(14.6526, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 65 = tensor(14.1764, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 66 = tensor(14.0677, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 67 = tensor(13.9467, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 68 = tensor(13.9167, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 69 = tensor(13.9215, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 70 = tensor(13.9211, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 71 = tensor(13.8709, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 72 = tensor(13.8591, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 73 = tensor(13.8570, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 74 = tensor(13.8575, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 75 = tensor(13.8591, dtype=torch.float64, grad_fn=<PowBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 76 = tensor(13.8621, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 77 = tensor(13.8656, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 78 = tensor(13.8699, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 79 = tensor(13.8192, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 80 = tensor(13.6929, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 81 = tensor(13.6039, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 82 = tensor(13.5892, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 83 = tensor(13.5808, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 84 = tensor(13.5712, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 85 = tensor(13.5692, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 86 = tensor(13.5722, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 87 = tensor(13.5773, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 88 = tensor(13.5768, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 89 = tensor(13.5836, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 90 = tensor(13.5843, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 91 = tensor(13.5765, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 92 = tensor(13.5773, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 93 = tensor(13.5678, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 94 = tensor(13.5673, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 95 = tensor(13.5656, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 96 = tensor(13.5679, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 97 = tensor(13.5671, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 98 = tensor(13.5690, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 99 = tensor(13.5623, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 100 = tensor(13.5590, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 101 = tensor(13.5591, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 102 = tensor(13.5599, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 103 = tensor(13.5612, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 104 = tensor(13.5634, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 105 = tensor(13.5669, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 106 = tensor(13.5698, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 107 = tensor(13.5637, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 108 = tensor(13.5606, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 109 = tensor(13.5607, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 110 = tensor(13.5605, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 111 = tensor(13.5617, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 112 = tensor(13.5639, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 113 = tensor(13.5674, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 114 = tensor(13.5704, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 115 = tensor(13.5643, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 116 = tensor(13.5612, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 117 = tensor(13.5613, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 118 = tensor(13.5611, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 119 = tensor(13.5624, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 120 = tensor(13.5649, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 121 = tensor(13.5686, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 122 = tensor(13.5707, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 123 = tensor(13.5639, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 124 = tensor(13.5609, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 125 = tensor(13.5613, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 126 = tensor(13.5614, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 127 = tensor(13.5630, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 128 = tensor(13.5658, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 129 = tensor(13.5642, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 130 = tensor(13.5662, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 131 = tensor(13.5648, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 132 = tensor(13.5671, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 133 = tensor(13.5662, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 134 = tensor(13.5682, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 135 = tensor(13.5620, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 136 = tensor(13.5587, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 137 = tensor(13.5585, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 138 = tensor(13.5588, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 139 = tensor(13.5593, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 140 = tensor(13.5603, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 141 = tensor(13.5618, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 142 = tensor(13.5641, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 143 = tensor(13.5677, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 144 = tensor(13.5707, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 145 = tensor(13.5645, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 146 = tensor(13.5615, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 147 = tensor(13.5617, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 148 = tensor(13.5617, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 149 = tensor(13.5632, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 150 = tensor(13.5660, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 151 = tensor(13.5643, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 152 = tensor(13.5662, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 153 = tensor(13.5647, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 154 = tensor(13.5668, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 155 = tensor(13.5656, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 156 = tensor(13.5679, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 157 = tensor(13.5621, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 158 = tensor(13.5587, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 159 = tensor(13.5584, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 160 = tensor(13.5583, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 161 = tensor(13.5585, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 162 = tensor(13.5588, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 163 = tensor(13.5595, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 164 = tensor(13.5606, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 165 = tensor(13.5622, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 166 = tensor(13.5648, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 167 = tensor(13.5686, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 168 = tensor(13.5714, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 169 = tensor(13.5650, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 170 = tensor(13.5622, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 171 = tensor(13.5628, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 172 = tensor(13.5632, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 173 = tensor(13.5655, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 174 = tensor(13.5689, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 175 = tensor(13.5680, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 176 = tensor(13.5703, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 177 = tensor(13.5642, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 178 = tensor(13.5609, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 179 = tensor(13.5607, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 180 = tensor(13.5602, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 181 = tensor(13.5609, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 182 = tensor(13.5625, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 183 = tensor(13.5649, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 184 = tensor(13.5683, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 185 = tensor(13.5673, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 186 = tensor(13.5696, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 187 = tensor(13.5637, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 188 = tensor(13.5603, dtype=torch.float64, grad_fn=<PowBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 189 = tensor(13.5601, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 190 = tensor(13.5593, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 191 = tensor(13.5597, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 192 = tensor(13.5607, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 193 = tensor(13.5622, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 194 = tensor(13.5646, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 195 = tensor(13.5683, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 196 = tensor(13.5703, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 197 = tensor(13.5636, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 198 = tensor(13.5606, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 199 = tensor(13.5609, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 200 = tensor(13.5609, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "超过迭代上限\n",
      " 20 100 平均相对误差2： tensor(1.4176, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 2.2909386467913566   20 100 置换矩阵误差： tensor(1.4071, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0448, dtype=torch.float64)   实验回归误差 tensor(0.0610, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(8277.4880, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(7827.0062, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(6403.3973, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(5424.0898, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(2212.3091, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(992.0241, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(484.1643, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(252.2443, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(151.4222, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(99.2902, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(71.4410, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(44.2778, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(35.3512, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(32.3682, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(30.4802, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(28.6774, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(26.9291, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(24.2814, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(22.7731, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 19 = tensor(22.2677, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 20 = tensor(21.8087, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 21 = tensor(21.3070, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 22 = tensor(20.7394, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 23 = tensor(20.0835, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 24 = tensor(19.4094, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 25 = tensor(18.7112, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 26 = tensor(18.2893, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 27 = tensor(17.7381, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 28 = tensor(17.2176, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 29 = tensor(16.3268, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 30 = tensor(15.9333, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 31 = tensor(15.7473, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 32 = tensor(15.6613, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 33 = tensor(15.6350, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 34 = tensor(15.6300, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 35 = tensor(15.6286, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 36 = tensor(15.6300, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 37 = tensor(15.6326, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 38 = tensor(15.6365, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 39 = tensor(15.6416, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 40 = tensor(15.6447, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 41 = tensor(15.6495, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 42 = tensor(15.6542, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 43 = tensor(15.6426, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 44 = tensor(15.6477, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 45 = tensor(15.6571, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 46 = tensor(15.6621, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 47 = tensor(15.6657, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 48 = tensor(15.6601, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 49 = tensor(15.6611, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 50 = tensor(15.6715, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 51 = tensor(15.6847, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 52 = tensor(15.6608, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 53 = tensor(15.6474, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 54 = tensor(15.6459, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 55 = tensor(15.6470, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 56 = tensor(15.6500, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 57 = tensor(15.6550, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 58 = tensor(15.6624, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 59 = tensor(15.6732, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 60 = tensor(15.6873, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 61 = tensor(15.6952, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 62 = tensor(15.6903, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 63 = tensor(15.6955, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 64 = tensor(15.7043, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 65 = tensor(15.7086, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 66 = tensor(15.6844, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 67 = tensor(15.6715, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 68 = tensor(15.6712, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 69 = tensor(15.6744, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 70 = tensor(15.6803, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 71 = tensor(15.6812, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 72 = tensor(15.6899, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 73 = tensor(15.7049, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 74 = tensor(15.7164, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 75 = tensor(15.7236, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 76 = tensor(15.7010, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 77 = tensor(15.6822, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 78 = tensor(15.6799, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 79 = tensor(15.6825, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 80 = tensor(15.6881, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 81 = tensor(15.6885, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 82 = tensor(15.6968, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 83 = tensor(15.7116, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 84 = tensor(15.7228, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 85 = tensor(15.7311, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 86 = tensor(15.7097, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 87 = tensor(15.6902, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 88 = tensor(15.6794, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 89 = tensor(15.6784, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 90 = tensor(15.6833, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 91 = tensor(15.6874, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 92 = tensor(15.6979, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 93 = tensor(15.7077, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 94 = tensor(15.7175, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 95 = tensor(15.7313, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 96 = tensor(15.7292, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 97 = tensor(15.7424, dtype=torch.float64, grad_fn=<PowBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 98 = tensor(15.7424, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 99 = tensor(15.7551, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 100 = tensor(15.7553, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 101 = tensor(15.7679, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 102 = tensor(15.7965, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 103 = tensor(15.8134, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 104 = tensor(15.7169, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 105 = tensor(15.7041, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 106 = tensor(15.7107, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 107 = tensor(15.7177, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 108 = tensor(15.7333, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 109 = tensor(15.7478, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 110 = tensor(15.7460, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 111 = tensor(15.7605, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 112 = tensor(15.7596, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 113 = tensor(15.7731, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 114 = tensor(15.7743, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 115 = tensor(15.7883, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 116 = tensor(15.7906, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 117 = tensor(15.8050, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 118 = tensor(15.7517, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 119 = tensor(15.7250, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 120 = tensor(15.6342, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 121 = tensor(15.5582, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 122 = tensor(15.3912, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 123 = tensor(15.3484, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 124 = tensor(15.3300, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 125 = tensor(15.2525, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 126 = tensor(15.2303, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 127 = tensor(15.2269, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 128 = tensor(15.2288, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 129 = tensor(15.2334, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 130 = tensor(15.2406, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 131 = tensor(15.2510, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 132 = tensor(15.2633, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 133 = tensor(15.2689, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 134 = tensor(15.2885, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 135 = tensor(15.3043, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 136 = tensor(15.2393, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 137 = tensor(15.2395, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 138 = tensor(15.2510, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 139 = tensor(15.2074, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 140 = tensor(15.1768, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 141 = tensor(15.1802, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 142 = tensor(15.1940, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 143 = tensor(15.2171, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 144 = tensor(15.2422, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 145 = tensor(15.2094, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 146 = tensor(15.1809, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 147 = tensor(15.1863, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 148 = tensor(15.2021, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 149 = tensor(15.2002, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 150 = tensor(15.1934, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 151 = tensor(15.1847, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 152 = tensor(15.2017, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 153 = tensor(15.2045, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 154 = tensor(15.2014, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 155 = tensor(15.2168, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 156 = tensor(15.2392, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 157 = tensor(15.2053, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 158 = tensor(15.1771, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 159 = tensor(15.1823, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 160 = tensor(15.1977, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 161 = tensor(15.1963, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 162 = tensor(15.1899, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 163 = tensor(15.2026, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 164 = tensor(15.2255, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 165 = tensor(15.2325, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 166 = tensor(15.2342, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 167 = tensor(15.2370, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 168 = tensor(15.2415, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 169 = tensor(15.2407, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 170 = tensor(15.2548, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 171 = tensor(15.2132, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 172 = tensor(15.1875, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 173 = tensor(15.1971, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 174 = tensor(15.2174, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 175 = tensor(15.2217, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 176 = tensor(15.2212, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 177 = tensor(15.2187, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 178 = tensor(15.2391, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 179 = tensor(15.2016, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 180 = tensor(15.0714, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 181 = tensor(15.0240, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 182 = tensor(15.0047, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 183 = tensor(14.9937, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 184 = tensor(14.9938, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 185 = tensor(14.9774, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 186 = tensor(14.9550, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 187 = tensor(14.9286, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 188 = tensor(14.9249, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 189 = tensor(14.9242, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 190 = tensor(14.9240, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 191 = tensor(14.9240, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 192 = tensor(14.9242, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 193 = tensor(14.9245, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 194 = tensor(14.9249, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 195 = tensor(14.9256, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 196 = tensor(14.9265, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 197 = tensor(14.9278, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 198 = tensor(14.9296, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 199 = tensor(14.9322, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 200 = tensor(14.9358, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "超过迭代上限\n",
      " 20 100 平均相对误差2： tensor(1.2181, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 2.3144706585063144   20 100 置换矩阵误差： tensor(1.4142, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0332, dtype=torch.float64)   实验回归误差 tensor(0.0425, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(29099.7741, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(28027.6903, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(14448.5424, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(10201.1065, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(5175.3684, dtype=torch.float64, grad_fn=<PowBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 5 = tensor(3454.2767, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(2551.3268, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(2008.0772, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(1680.7960, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(1366.3396, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(1178.6035, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(985.1701, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(886.4063, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(774.6874, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(664.9313, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(538.7772, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(452.6093, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(381.5527, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(311.2100, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 19 = tensor(257.1965, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 20 = tensor(229.3377, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 21 = tensor(205.3951, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 22 = tensor(182.0645, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 23 = tensor(155.2755, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 24 = tensor(136.1137, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 25 = tensor(115.5574, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 26 = tensor(106.6942, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 27 = tensor(102.1507, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 28 = tensor(97.6644, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 29 = tensor(93.6739, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 30 = tensor(89.8912, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 31 = tensor(87.0028, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 32 = tensor(85.1945, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 33 = tensor(84.7526, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 34 = tensor(83.5480, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 35 = tensor(81.8605, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 36 = tensor(81.0274, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 37 = tensor(80.0192, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 38 = tensor(79.8411, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 39 = tensor(79.7457, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 40 = tensor(79.5398, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 41 = tensor(79.4074, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 42 = tensor(79.3367, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 43 = tensor(79.3587, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 44 = tensor(79.3818, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 45 = tensor(79.3560, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 46 = tensor(79.3787, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 47 = tensor(79.4072, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 48 = tensor(78.8661, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 49 = tensor(78.8495, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 50 = tensor(78.9275, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 51 = tensor(79.0521, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 52 = tensor(79.1820, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 53 = tensor(79.3953, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 54 = tensor(79.4724, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 55 = tensor(79.7462, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 56 = tensor(79.8366, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 57 = tensor(80.0255, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 58 = tensor(80.2457, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 59 = tensor(80.7089, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 60 = tensor(80.9155, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 61 = tensor(80.9705, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 62 = tensor(81.1555, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 63 = tensor(81.3885, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 64 = tensor(81.5924, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 65 = tensor(81.9262, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 66 = tensor(81.3192, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 67 = tensor(80.7882, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 68 = tensor(80.2543, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 69 = tensor(79.9238, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 70 = tensor(79.2483, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 71 = tensor(78.8743, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 72 = tensor(78.3368, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 73 = tensor(78.1658, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 74 = tensor(78.3472, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 75 = tensor(78.3589, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 76 = tensor(78.5275, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 77 = tensor(78.4397, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 78 = tensor(78.5809, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 79 = tensor(78.5995, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 80 = tensor(78.6566, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 81 = tensor(78.5617, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 82 = tensor(78.5796, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 83 = tensor(78.5239, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 84 = tensor(78.5908, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 85 = tensor(78.4765, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 86 = tensor(78.4167, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 87 = tensor(78.2730, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 88 = tensor(78.4111, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 89 = tensor(78.1791, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 90 = tensor(78.1768, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 91 = tensor(78.2239, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 92 = tensor(78.3843, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 93 = tensor(78.1370, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 94 = tensor(78.1660, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 95 = tensor(77.9777, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 96 = tensor(78.0521, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 97 = tensor(78.0771, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 98 = tensor(78.3006, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 99 = tensor(78.2238, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 100 = tensor(78.4748, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 101 = tensor(78.4508, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 102 = tensor(78.6102, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 103 = tensor(78.3275, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 104 = tensor(78.3584, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 105 = tensor(78.1651, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 106 = tensor(78.3755, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 107 = tensor(78.3991, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 108 = tensor(78.5991, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 109 = tensor(78.5657, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 110 = tensor(78.5769, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 111 = tensor(78.5584, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 112 = tensor(78.5344, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 113 = tensor(78.4168, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 114 = tensor(78.5511, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 115 = tensor(78.3341, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 116 = tensor(78.3681, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 117 = tensor(78.2133, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 118 = tensor(78.3423, dtype=torch.float64, grad_fn=<PowBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 119 = tensor(78.0836, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 120 = tensor(78.0782, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 121 = tensor(78.0934, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 122 = tensor(78.2201, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 123 = tensor(77.9350, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 124 = tensor(77.9114, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 125 = tensor(77.9316, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 126 = tensor(78.1431, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 127 = tensor(78.0526, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 128 = tensor(78.2738, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 129 = tensor(78.1741, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 130 = tensor(78.3779, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 131 = tensor(78.2770, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 132 = tensor(78.4439, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 133 = tensor(78.3468, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 134 = tensor(78.5054, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 135 = tensor(78.5275, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 136 = tensor(78.6475, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 137 = tensor(78.6574, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 138 = tensor(78.8138, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 139 = tensor(78.6008, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 140 = tensor(78.6861, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 141 = tensor(78.5804, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 142 = tensor(78.8005, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 143 = tensor(78.7264, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 144 = tensor(78.6701, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 145 = tensor(78.4834, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 146 = tensor(78.5219, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 147 = tensor(78.4206, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 148 = tensor(78.4545, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 149 = tensor(78.3176, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 150 = tensor(78.5120, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 151 = tensor(78.4524, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 152 = tensor(78.5321, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 153 = tensor(78.5078, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 154 = tensor(78.6270, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 155 = tensor(78.3666, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 156 = tensor(78.3963, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 157 = tensor(78.2160, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 158 = tensor(78.3399, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 159 = tensor(78.2691, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 160 = tensor(78.3042, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 161 = tensor(78.2380, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 162 = tensor(78.4723, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 163 = tensor(78.4519, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 164 = tensor(78.6316, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 165 = tensor(78.4237, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 166 = tensor(78.4735, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 167 = tensor(78.3251, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 168 = tensor(78.4599, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 169 = tensor(78.2184, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 170 = tensor(78.2315, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 171 = tensor(78.2968, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 172 = tensor(78.4535, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 173 = tensor(78.1995, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 174 = tensor(78.2354, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 175 = tensor(78.1178, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 176 = tensor(78.2502, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 177 = tensor(77.9153, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 178 = tensor(77.8699, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 179 = tensor(77.7883, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 180 = tensor(77.8886, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 181 = tensor(77.8978, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 182 = tensor(78.1346, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 183 = tensor(78.1541, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 184 = tensor(78.4613, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 185 = tensor(78.5410, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 186 = tensor(78.6745, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 187 = tensor(78.6970, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 188 = tensor(78.8557, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 189 = tensor(78.6930, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 190 = tensor(78.8366, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 191 = tensor(78.8036, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 192 = tensor(78.8190, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 193 = tensor(78.7719, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 194 = tensor(79.0042, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 195 = tensor(78.8340, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 196 = tensor(78.9921, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 197 = tensor(78.9735, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 198 = tensor(79.0197, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 199 = tensor(78.9917, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 200 = tensor(79.2266, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "超过迭代上限\n",
      " 20 100 平均相对误差2： tensor(1.3457, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 2.2469333415921393   20 100 置换矩阵误差： tensor(1.4071, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0161, dtype=torch.float64)   实验回归误差 tensor(0.0523, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(499.0645, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(486.2154, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(7.5635, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(5.1930, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(5.1341, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(5.1280, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(5.1266, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(5.1265, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(5.1265, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(5.1265, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 2 100 平均相对误差2： tensor(1.2320, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.1604910113895837   2 100 置换矩阵误差： tensor(1.4071, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.1367, dtype=torch.float64)   实验回归误差 tensor(0.1014, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(167.1538, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(166.9686, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(7.9662, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(6.7645, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(6.6879, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(6.6493, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(6.6095, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(6.5186, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(6.4555, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(6.4336, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(6.4173, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(6.3837, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(6.3259, dtype=torch.float64, grad_fn=<PowBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 13 = tensor(6.2261, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(6.0685, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(5.9009, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(5.8421, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(5.8222, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(5.8176, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 19 = tensor(5.8148, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 20 = tensor(5.8144, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 21 = tensor(5.8140, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 22 = tensor(5.8140, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 23 = tensor(5.8140, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 2 100 平均相对误差2： tensor(1.3373, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.084420941705154   2 100 置换矩阵误差： tensor(1.4071, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.2621, dtype=torch.float64)   实验回归误差 tensor(0.1865, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(3881.7585, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(3547.4833, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(173.3454, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(76.9014, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(69.5646, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(65.1685, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(61.2074, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(55.8484, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(52.0324, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(48.1371, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(46.1650, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(43.8680, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(41.8114, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(40.8922, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(39.8833, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(38.8586, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(38.7466, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(38.7207, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(38.7174, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 19 = tensor(38.7119, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 20 = tensor(38.6546, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 21 = tensor(38.5788, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 22 = tensor(38.5378, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 23 = tensor(38.3926, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 24 = tensor(38.2464, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 25 = tensor(38.1781, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 26 = tensor(38.1771, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 27 = tensor(38.1771, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 28 = tensor(38.1771, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 2 100 平均相对误差2： tensor(0.3967, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.051364272321087   2 100 置换矩阵误差： tensor(1.3565, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0492, dtype=torch.float64)   实验回归误差 tensor(0.0992, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(372.2341, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(362.8905, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(52.0873, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(10.1662, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(4.2326, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(3.4132, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(3.2990, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(3.2829, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(3.2804, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(3.2801, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(3.2801, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(3.2801, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(3.2801, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(3.2801, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 2 100 平均相对误差2： tensor(0.2594, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.1972401331411562   2 100 置换矩阵误差： tensor(1.3711, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.1529, dtype=torch.float64)   实验回归误差 tensor(0.0939, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(1942.9372, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(1932.1030, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(43.2829, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(29.4846, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(27.7827, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(26.0384, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(25.1063, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(24.3766, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(24.0867, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(24.0102, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(23.9888, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(23.9871, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(23.9869, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(23.9869, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(23.9869, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(23.9869, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 2 100 平均相对误差2： tensor(1.2317, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.1413518005838945   2 100 置换矩阵误差： tensor(1.4000, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0699, dtype=torch.float64)   实验回归误差 tensor(0.1111, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(1289.3154, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(1182.1416, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(123.0118, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(117.0005, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(116.6740, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(116.3464, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(115.8448, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(115.3760, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(115.2926, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(115.2817, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(115.2790, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(115.2789, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(115.2789, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 2 100 平均相对误差2： tensor(1.0894, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.0750483637231505   2 100 置换矩阵误差： tensor(1.4000, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0864, dtype=torch.float64)   实验回归误差 tensor(0.2990, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(80.2664, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(80.2417, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(2.4201, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(2.3208, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(2.2785, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(2.2102, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(2.1937, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(2.1905, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(2.1815, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(2.1778, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(2.1777, dtype=torch.float64, grad_fn=<PowBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 11 = tensor(2.1777, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(2.1777, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 2 100 平均相对误差2： tensor(0.7125, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.165721233708948   2 100 置换矩阵误差： tensor(1.3928, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.3240, dtype=torch.float64)   实验回归误差 tensor(0.1647, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(1756.5026, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(1719.4676, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(67.2956, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(16.1144, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(8.1498, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(5.9777, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(5.1154, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(4.4271, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(3.7946, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(3.5088, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(3.4055, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(3.3993, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(3.3991, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(3.3984, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(3.3984, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(3.3984, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(3.3984, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(3.3984, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(3.3984, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 2 100 平均相对误差2： tensor(0.0976, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.2568623062754185   2 100 置换矩阵误差： tensor(1.3416, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0731, dtype=torch.float64)   实验回归误差 tensor(0.0440, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(4107.7068, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(4084.9543, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(228.9176, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(148.6849, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(134.4989, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(121.2181, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(101.4552, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(84.3307, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(71.3348, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(61.1958, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(56.4502, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(54.2825, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(52.1895, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(50.0278, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(47.6387, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(46.4229, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(44.7410, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(42.7906, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(40.3961, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 19 = tensor(38.9924, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 20 = tensor(38.5296, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 21 = tensor(38.4862, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 22 = tensor(38.4853, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 23 = tensor(38.4852, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 24 = tensor(38.4852, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 25 = tensor(38.4852, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 2 100 平均相对误差2： tensor(0.5250, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.110004616801656   2 100 置换矩阵误差： tensor(1.4071, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0557, dtype=torch.float64)   实验回归误差 tensor(0.0968, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(3922.5595, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(3917.8534, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(807.9158, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(356.6863, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(238.7649, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(179.8101, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(150.4141, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(135.0382, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(126.8832, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(122.3897, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(121.4769, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(120.8613, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(120.3335, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(119.6093, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(118.7141, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(118.3136, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(118.2668, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(118.1736, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(118.0920, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 19 = tensor(118.0539, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 20 = tensor(118.0193, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 21 = tensor(117.8130, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 22 = tensor(117.4962, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 23 = tensor(117.1842, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 24 = tensor(117.1186, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 25 = tensor(117.1183, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 26 = tensor(117.1183, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 2 100 平均相对误差2： tensor(1.4452, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.120135988878033   2 100 置换矩阵误差： tensor(1.4142, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0487, dtype=torch.float64)   实验回归误差 tensor(0.1728, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(3512.2494, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(3400.8630, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(517.1854, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(175.6912, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(117.8941, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(107.1668, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(103.3450, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(101.0629, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(99.6017, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(98.7982, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(98.4434, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(97.8775, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(97.4926, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(97.1874, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(96.7981, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(96.5601, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(96.1393, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(95.5693, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(94.1609, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 19 = tensor(93.2690, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 20 = tensor(92.8510, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 21 = tensor(92.3815, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 22 = tensor(91.7024, dtype=torch.float64, grad_fn=<PowBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 23 = tensor(91.3909, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 24 = tensor(91.3119, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 25 = tensor(91.0879, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 26 = tensor(90.4374, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 27 = tensor(89.7024, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 28 = tensor(89.4273, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 29 = tensor(89.2792, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 30 = tensor(89.2314, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 31 = tensor(89.2275, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 32 = tensor(89.2110, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 33 = tensor(89.2069, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 34 = tensor(89.2069, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 35 = tensor(89.2069, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 5 100 平均相对误差2： tensor(1.1232, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.3854364637955159   5 100 置换矩阵误差： tensor(1.4142, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0548, dtype=torch.float64)   实验回归误差 tensor(0.1594, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(8461.2903, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(8081.0963, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(1669.8092, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(475.2944, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(245.3664, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(194.0637, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(180.5150, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(176.9745, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(173.1285, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(171.5845, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(170.5762, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(167.9059, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(165.8315, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(162.6734, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(158.8613, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(154.6077, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(152.8649, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(151.6424, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(150.3810, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 19 = tensor(149.0740, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 20 = tensor(148.4992, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 21 = tensor(147.8696, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 22 = tensor(146.0066, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 23 = tensor(142.0911, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 24 = tensor(137.3550, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 25 = tensor(131.7987, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 26 = tensor(127.5210, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 27 = tensor(125.6922, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 28 = tensor(125.3439, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 29 = tensor(125.2730, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 30 = tensor(125.2689, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 31 = tensor(125.2472, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 32 = tensor(125.2427, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 33 = tensor(125.2425, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 34 = tensor(125.2425, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 5 100 平均相对误差2： tensor(0.9615, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.2702456468376666   5 100 置换矩阵误差： tensor(1.4071, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0315, dtype=torch.float64)   实验回归误差 tensor(0.1217, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(1655.2370, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(1589.3108, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(162.5634, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(125.2577, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(120.3385, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(116.0017, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(111.8779, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(105.3146, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(99.9910, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(94.6099, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(89.1049, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(83.4292, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(79.4722, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(75.0106, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(71.1699, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(68.7014, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(65.1051, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(59.1679, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(54.5042, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 19 = tensor(51.5841, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 20 = tensor(49.7157, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 21 = tensor(48.1067, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 22 = tensor(45.4734, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 23 = tensor(41.7254, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 24 = tensor(39.8608, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 25 = tensor(37.5886, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 26 = tensor(36.0420, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 27 = tensor(34.3055, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 28 = tensor(33.2600, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 29 = tensor(32.4624, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 30 = tensor(31.9387, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 31 = tensor(31.7412, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 32 = tensor(31.6352, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 33 = tensor(31.5044, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 34 = tensor(31.0879, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 35 = tensor(30.5514, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 36 = tensor(30.2404, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 37 = tensor(30.0865, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 38 = tensor(29.9712, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 39 = tensor(29.9128, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 40 = tensor(29.9009, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 41 = tensor(29.8971, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 42 = tensor(29.8522, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 43 = tensor(29.8471, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 44 = tensor(29.8463, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 45 = tensor(29.8463, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 46 = tensor(29.8463, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 47 = tensor(29.8463, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 5 100 平均相对误差2： tensor(1.2409, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.461708925832767   5 100 置换矩阵误差： tensor(1.4142, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0654, dtype=torch.float64)   实验回归误差 tensor(0.1343, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(2360.3362, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(2204.6253, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(75.0421, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(31.1571, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(27.0155, dtype=torch.float64, grad_fn=<PowBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 5 = tensor(24.1663, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(21.3181, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(18.6334, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(17.4555, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(16.9878, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(16.6886, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(16.5912, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(16.5812, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(16.5801, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(16.5793, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(16.5792, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(16.5792, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(16.5792, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(16.5792, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 5 100 平均相对误差2： tensor(0.9018, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.3835458897132744   5 100 置换矩阵误差： tensor(1.4000, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0612, dtype=torch.float64)   实验回归误差 tensor(0.0838, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(11103.2574, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(10500.8005, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 30 = tensor(193.4036, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 31 = tensor(189.2376, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 32 = tensor(183.4921, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 33 = tensor(179.9215, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 34 = tensor(177.6159, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 35 = tensor(174.5148, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 36 = tensor(172.4649, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 37 = tensor(170.4325, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 38 = tensor(167.3700, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 39 = tensor(165.3896, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 40 = tensor(164.2285, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 41 = tensor(164.0986, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 42 = tensor(164.0628, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 43 = tensor(164.0442, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 44 = tensor(164.0412, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 45 = tensor(164.0412, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 46 = tensor(164.0412, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 5 100 平均相对误差2： tensor(0.8036, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.3280612926848456   5 100 置换矩阵误差： tensor(1.4071, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0310, dtype=torch.float64)   实验回归误差 tensor(0.1215, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(5265.5296, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(5190.3899, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(791.3622, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(266.1540, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(185.9780, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(171.4483, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(165.8991, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(164.7168, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(164.4281, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(163.7995, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(162.1285, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(161.3709, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(161.0747, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(160.9300, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(160.6189, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(159.5504, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(157.3821, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(154.6748, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(153.6082, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 19 = tensor(153.2323, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 20 = tensor(153.1387, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 21 = tensor(152.8834, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 22 = tensor(152.4689, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 23 = tensor(152.3107, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 24 = tensor(151.9468, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 25 = tensor(151.4113, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 26 = tensor(150.5865, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 27 = tensor(149.5855, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 28 = tensor(147.9344, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 29 = tensor(146.1512, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 30 = tensor(144.3578, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 31 = tensor(142.8176, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 32 = tensor(140.1188, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 33 = tensor(138.3487, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 34 = tensor(136.9086, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 35 = tensor(135.6287, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 36 = tensor(131.1363, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 37 = tensor(128.1681, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 38 = tensor(125.5362, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 39 = tensor(124.2730, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 40 = tensor(123.6731, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 41 = tensor(123.5732, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 42 = tensor(123.5434, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 43 = tensor(123.5424, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 44 = tensor(123.5421, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 45 = tensor(123.5420, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 46 = tensor(123.5420, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 47 = tensor(123.5420, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 5 100 平均相对误差2： tensor(1.0973, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.3079058256832583   5 100 置换矩阵误差： tensor(1.4071, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0444, dtype=torch.float64)   实验回归误差 tensor(0.1532, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(2889.0555, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(2671.3620, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(569.0222, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(196.5675, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(112.6912, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(89.3792, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(76.4549, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(67.6984, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(60.1891, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(52.7421, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(46.8121, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(41.5817, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(38.6775, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(35.5118, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(33.2166, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(30.6043, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(28.8012, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(27.8022, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(26.7288, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 19 = tensor(26.1792, dtype=torch.float64, grad_fn=<PowBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 20 = tensor(25.7701, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 21 = tensor(25.4943, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 22 = tensor(25.3160, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 23 = tensor(24.9752, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 24 = tensor(24.3248, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 25 = tensor(23.9742, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 26 = tensor(23.1895, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 27 = tensor(22.8495, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 28 = tensor(22.7483, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 29 = tensor(22.7241, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 30 = tensor(22.7011, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 31 = tensor(22.6986, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 32 = tensor(22.6910, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 33 = tensor(22.6866, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 34 = tensor(22.6836, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 35 = tensor(22.6679, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 36 = tensor(22.3386, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 37 = tensor(21.7613, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 38 = tensor(21.4111, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 39 = tensor(20.9340, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 40 = tensor(20.7742, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 41 = tensor(20.6295, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 42 = tensor(20.4757, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 43 = tensor(20.2768, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 44 = tensor(20.1315, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 45 = tensor(20.0334, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 46 = tensor(19.9692, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 47 = tensor(19.9015, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 48 = tensor(19.8495, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 49 = tensor(19.8428, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 50 = tensor(19.8427, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 51 = tensor(19.8427, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 52 = tensor(19.8427, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 5 100 平均相对误差2： tensor(0.4847, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.287969566735625   5 100 置换矩阵误差： tensor(1.3856, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0565, dtype=torch.float64)   实验回归误差 tensor(0.0829, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(347.6833, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(343.2188, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(18.6154, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(5.3780, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(4.2956, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(4.1599, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(4.1142, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(4.0958, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(4.0848, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(4.0842, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(4.0828, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(4.0811, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(4.0809, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(4.0809, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(4.0809, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(4.0809, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(4.0809, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 5 100 平均相对误差2： tensor(1.4658, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.495823349940005   5 100 置换矩阵误差： tensor(1.4071, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.1823, dtype=torch.float64)   实验回归误差 tensor(0.1083, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(2958.5426, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(2949.2030, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(93.7818, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(82.3247, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(76.2731, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(70.9377, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(65.7855, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(64.2426, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(63.0626, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(62.4691, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(62.0920, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(61.2422, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(60.5826, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(60.2587, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(60.1480, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(60.1155, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(60.0937, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(60.0742, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(60.0715, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 19 = tensor(60.0705, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 20 = tensor(60.0705, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 21 = tensor(60.0705, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 5 100 平均相对误差2： tensor(1.5726, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.4050416353065336   5 100 置换矩阵误差： tensor(1.4142, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0552, dtype=torch.float64)   实验回归误差 tensor(0.1425, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(3317.4678, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(3214.0234, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(446.7626, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(182.2799, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(149.3611, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(143.3763, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(141.9511, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(140.2936, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(139.7522, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(139.5770, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(139.1506, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(138.9408, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(138.2372, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(137.4320, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(136.4209, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(136.1198, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(135.5872, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(135.2055, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(135.1217, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 19 = tensor(134.9389, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 20 = tensor(134.7540, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 21 = tensor(134.1988, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 22 = tensor(132.4290, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 23 = tensor(131.1400, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 24 = tensor(130.5917, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 25 = tensor(130.1383, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 26 = tensor(129.7725, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 27 = tensor(129.2204, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 28 = tensor(128.9359, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 29 = tensor(128.7298, dtype=torch.float64, grad_fn=<PowBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 30 = tensor(128.3692, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 31 = tensor(127.9219, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 32 = tensor(127.8827, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 33 = tensor(127.8588, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 34 = tensor(127.8129, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 35 = tensor(127.6867, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 36 = tensor(127.6100, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 37 = tensor(127.5881, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 38 = tensor(127.1554, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 39 = tensor(126.5763, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 40 = tensor(126.2888, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 41 = tensor(126.1184, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 42 = tensor(126.0745, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 43 = tensor(126.0706, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 44 = tensor(126.0704, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 45 = tensor(126.0704, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 46 = tensor(126.0703, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 5 100 平均相对误差2： tensor(0.8679, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.3614696099796186   5 100 置换矩阵误差： tensor(1.3928, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0446, dtype=torch.float64)   实验回归误差 tensor(0.1949, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(13009.9613, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(12954.7969, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(2413.6629, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(1201.1015, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(750.9775, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(607.5231, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(542.1721, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(504.4975, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(471.7049, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(446.6021, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(410.6839, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(377.6973, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(361.2881, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(349.9817, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(333.7497, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(317.1301, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(309.4843, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(301.7641, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(291.9962, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 19 = tensor(283.4110, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 20 = tensor(279.2969, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 21 = tensor(276.4287, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 22 = tensor(272.4088, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 23 = tensor(267.5552, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 24 = tensor(263.1180, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 25 = tensor(260.5565, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 26 = tensor(257.9664, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 27 = tensor(253.9827, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 28 = tensor(251.4408, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 29 = tensor(245.4803, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 30 = tensor(243.1658, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 31 = tensor(241.6734, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 32 = tensor(239.9563, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 33 = tensor(239.4076, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 34 = tensor(239.1554, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 35 = tensor(238.4517, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 36 = tensor(238.0001, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 37 = tensor(236.4974, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 38 = tensor(230.6559, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 39 = tensor(223.1509, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 40 = tensor(214.6931, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 41 = tensor(204.9815, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 42 = tensor(196.5606, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 43 = tensor(188.2692, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 44 = tensor(182.9183, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 45 = tensor(178.2734, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 46 = tensor(173.3078, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 47 = tensor(168.1402, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 48 = tensor(163.1885, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 49 = tensor(160.0526, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 50 = tensor(158.1745, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 51 = tensor(156.8033, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 52 = tensor(155.0221, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 53 = tensor(150.0846, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 54 = tensor(145.4540, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 55 = tensor(135.6443, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 56 = tensor(129.0242, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 57 = tensor(125.1223, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 58 = tensor(119.2790, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 59 = tensor(113.2872, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 60 = tensor(107.0100, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 61 = tensor(102.0301, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 62 = tensor(98.9126, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 63 = tensor(94.6538, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 64 = tensor(86.9720, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 65 = tensor(85.2816, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 66 = tensor(84.4534, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 67 = tensor(83.8851, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 68 = tensor(83.8233, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 69 = tensor(83.7133, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 70 = tensor(83.5091, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 71 = tensor(83.2888, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 72 = tensor(82.5074, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 73 = tensor(81.7390, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 74 = tensor(80.9093, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 75 = tensor(80.2815, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 76 = tensor(79.5493, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 77 = tensor(77.0793, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 78 = tensor(73.3082, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 79 = tensor(69.3314, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 80 = tensor(67.9064, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 81 = tensor(67.3197, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 82 = tensor(67.1876, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 83 = tensor(67.0761, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 84 = tensor(67.0368, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 85 = tensor(67.0298, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 86 = tensor(67.0290, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 87 = tensor(67.0287, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 88 = tensor(67.0286, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 89 = tensor(67.0284, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 90 = tensor(67.0283, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 91 = tensor(67.0282, dtype=torch.float64, grad_fn=<PowBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 92 = tensor(67.0281, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 93 = tensor(67.0281, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 94 = tensor(67.0280, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 95 = tensor(67.0280, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 96 = tensor(67.0279, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 97 = tensor(67.0279, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 98 = tensor(67.0279, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 99 = tensor(67.0278, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 100 = tensor(67.0278, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 101 = tensor(67.0278, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 102 = tensor(67.0278, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 103 = tensor(67.0278, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 104 = tensor(67.0277, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 105 = tensor(67.0277, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 106 = tensor(67.0277, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 107 = tensor(67.0277, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 108 = tensor(67.0277, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 10 100 平均相对误差2： tensor(1.1401, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.7105885046773979   10 100 置换矩阵误差： tensor(1.3856, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0267, dtype=torch.float64)   实验回归误差 tensor(0.0718, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(7713.3140, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(7127.2931, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(1808.4060, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(947.5747, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(645.7769, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 5 = tensor(533.7341, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 6 = tensor(469.2179, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 7 = tensor(416.6938, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 8 = tensor(377.7867, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 9 = tensor(338.4534, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 10 = tensor(295.6715, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 11 = tensor(254.5817, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 12 = tensor(220.2924, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 13 = tensor(179.8172, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 14 = tensor(167.7365, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 15 = tensor(160.3835, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 16 = tensor(153.3090, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 17 = tensor(145.4718, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 18 = tensor(141.2975, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 19 = tensor(137.3993, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 20 = tensor(134.4855, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 21 = tensor(131.9476, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 22 = tensor(123.4801, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 23 = tensor(116.8047, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 24 = tensor(108.5614, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 25 = tensor(102.4213, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 26 = tensor(94.1103, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 27 = tensor(85.6530, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 28 = tensor(73.1331, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 29 = tensor(64.9617, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 30 = tensor(56.1834, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 31 = tensor(50.0422, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 32 = tensor(44.2991, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 33 = tensor(41.7961, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 34 = tensor(41.0161, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 35 = tensor(40.9562, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 36 = tensor(40.8916, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 37 = tensor(40.7066, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 38 = tensor(40.6418, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 39 = tensor(40.6173, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 40 = tensor(40.5619, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 41 = tensor(40.5495, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 42 = tensor(40.5404, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 43 = tensor(40.5400, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 44 = tensor(40.5399, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 45 = tensor(40.5398, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 46 = tensor(40.5397, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 47 = tensor(40.5397, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 48 = tensor(40.5397, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 49 = tensor(40.5397, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 50 = tensor(40.5396, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 51 = tensor(40.5396, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 52 = tensor(40.5396, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 53 = tensor(40.5396, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 54 = tensor(40.5396, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 55 = tensor(40.5396, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 56 = tensor(40.5395, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 57 = tensor(40.5395, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 58 = tensor(40.5395, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 59 = tensor(40.5395, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 60 = tensor(40.5395, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 61 = tensor(40.5395, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 62 = tensor(40.5395, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 63 = tensor(40.5395, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 64 = tensor(40.5394, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 65 = tensor(40.5394, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 66 = tensor(40.5394, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 67 = tensor(40.5394, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 68 = tensor(40.5394, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 69 = tensor(40.5394, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 70 = tensor(40.5394, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 71 = tensor(40.5394, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 72 = tensor(40.5394, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 73 = tensor(40.5394, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 74 = tensor(40.5394, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 75 = tensor(40.5394, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 76 = tensor(40.5394, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 77 = tensor(40.5394, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 78 = tensor(40.5393, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 79 = tensor(40.5393, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 80 = tensor(40.5393, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      " 10 100 平均相对误差2： tensor(1.3253, dtype=torch.float64, grad_fn=<DivBackward0>)   X条件数 1.6554059064616   10 100 置换矩阵误差： tensor(1.4071, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0342, dtype=torch.float64)   实验回归误差 tensor(0.0725, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 100\n",
      "Loss 0 = tensor(13727.0253, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 1 = tensor(13719.0961, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 2 = tensor(4038.3398, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 3 = tensor(2476.8916, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#Loss 4 = tensor(1793.8155, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "#"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-d8540aaf1c69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mLoss\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                         \u001b[0mLoss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;31m#                         results_Loss.append(Loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m#                         for i_ in range(num_X1features):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gama_=1\n",
    "eta=0\n",
    "starts=1\n",
    "for i_____ in range(5):\n",
    "    for num_example in range(100,101,100): \n",
    "        for num_X2feature in [2,5,10,20]:\n",
    "            for i____ in range(10):\n",
    "                (y_,X2_,true_w2,true_P,error_reg1,conditionnumber)=generatedata(noise=0.3)\n",
    "                y=y_\n",
    "                X2=X2_\n",
    "                results_Loss = []\n",
    "                results_w2=[]\n",
    "                results_error=[]\n",
    "                for i__ in range(starts):\n",
    "    #                     P_array=np.random.permutation(num_example)\n",
    "    #                     P=torch.zeros(num_example,num_example,dtype=torch.float64)\n",
    "    #                     for i in range(num_example):\n",
    "    #                         P[i][P_array[i]]=1\n",
    "    #                     X_=torch.cat([X1,X2],1)\n",
    "    #                     X=torch.mm(P,X_)\n",
    "    #                     w=torch.mm(torch.mm(torch.tensor(np.linalg.inv(torch.mm(X.transpose(1,0),X))),X.transpose(1,0)),y)\n",
    "    #                     w1,w2=w.split([num_X1feature,num_X2feature],dim=0)\n",
    "    #                     w1=torch.from_numpy(np.random.normal(0, 0,(num_X1feature,1)))\n",
    "    #                     w2=torch.from_numpy(np.random.normal(0, 0,(num_X2feature,1)))\n",
    "                    w2=generateinitialw(method='zeros')\n",
    "                    #w2=true_w2\n",
    "                    w2.requires_grad_(requires_grad=True)\n",
    "    #                 results_Loss = []\n",
    "                    lr=0.0007\n",
    "                    results_S=[]\n",
    "                    t=0\n",
    "                    before1=0\n",
    "                    while True:                     \n",
    "                        Y1=y\n",
    "                        Y2=torch.mm(X2,w2)\n",
    "                        C=torch.zeros(num_example,num_example,dtype=torch.float64)\n",
    "                        for i in range(num_example):\n",
    "                            for j in range(num_example):\n",
    "                                C[i][j]=(Y1[i]-Y2[j])**2            \n",
    "\n",
    "                        #S=SinkhornIPOT(C)\n",
    "                        a=torch.ones(num_example,1,dtype=torch.float64)\n",
    "                        b=torch.ones(num_example,1,dtype=torch.float64)\n",
    "                        S=sinkhorn_epsilon_scaling(a, b, C, 0.00000001)\n",
    "                        #print(S.transpose(1,0).half())\n",
    "                        #results_S.append(S)\n",
    "                        #if t>0:\n",
    "                            #print('        S变化',(torch.norm(results_S[t]-results_S[t-1]))/(torch.norm(results_S[t-1])))\n",
    "                        #Loss=torch.sum(S*C)\n",
    "                        Loss=torch.norm(Y1-torch.mm(S,Y2))**2\n",
    "                        if Loss<1e-2:\n",
    "                            break\n",
    "                        Loss.backward()\n",
    "    #                         results_Loss.append(Loss)\n",
    "    #                         for i_ in range(num_X1features):\n",
    "    #                             results_w1[t][i_]=(w1[i_].data)\n",
    "    #                         for i_ in range(num_X2features):\n",
    "    #                             results_w2[t][i_]=(w2[i_].data)\n",
    "                        w2.data-=lr*(w2.grad+np.random.normal(0,np.sqrt(eta/(1+t)**gama_)))\n",
    "                        #print(w2.grad)\n",
    "    #                     if t==num_epochs-1:\n",
    "    #                         print('最终w1梯度：',w1.grad)\n",
    "    #                         print('最终w2梯度：',w2.grad)\n",
    "                        w2.grad.data.zero_() \n",
    "\n",
    "                        print('Loss',t,'=',Loss)\n",
    "    #                     if t%6==0:\n",
    "    #                         if torch.norm(Loss-before1)<1e-4:\n",
    "    #                             break\n",
    "    #                         before1=Loss\n",
    "                        if torch.norm(Loss-before1)/before1<1e-7:\n",
    "                            break\n",
    "                        before1=Loss\n",
    "                        if t>=200:\n",
    "                            print('超过迭代上限')\n",
    "                            break\n",
    "                        if math.isnan(Loss):\n",
    "                            break\n",
    "                        t+=1\n",
    "                        print('#',end='')\n",
    "\n",
    "\n",
    "\n",
    "                    print(' ',end='')\n",
    "                    error_each=(torch.norm(w2-true_w2))/torch.norm(true_w2)\n",
    "                    results_error.append(error_each)\n",
    "                    #results_Loss.append(Loss)\n",
    "                    #results_w1.append(w1.data)\n",
    "                    #results_w2.append(w2.data)\n",
    "\n",
    "\n",
    "                #w1=results_w1[results_Loss.index(min(results_Loss))]\n",
    "                #w2=results_w2[results_Loss.index(min(results_Loss))]\n",
    "\n",
    "    #                     for i_ in range(starts):\n",
    "    #                         results_w1[i_]=(w1[i_].data)\n",
    "    #                     for i_ in range(starts):\n",
    "    #                         results_w2[i_]=(w2[i_].data)\n",
    "\n",
    "\n",
    "                #error_w=((torch.norm(w1-true_w1))/(torch.norm(true_w1))+(torch.norm(w2-true_w2))/(torch.norm(true_w2)))/2\n",
    "                #print(num_X1feature,num_X2feature,num_example,'平均相对误差1：',error_w)\n",
    "                print(num_X2feature,num_example,'平均相对误差2：',np.min(results_error),end='   ')\n",
    "                print('X条件数',conditionnumber,end='   ')\n",
    "                #print('真实置换矩阵为：',true_P)\n",
    "                error_P=(torch.norm(S.transpose(1,0)-true_P))/(torch.norm(true_P))\n",
    "                print(num_X2feature,num_example,'置换矩阵误差：',error_P,end='   ')\n",
    "                error_reg2=(torch.norm(y_-torch.mm(torch.mm(S,X2_),w2))/torch.norm(y_))\n",
    "                print('真实回归误差',error_reg1,end='   ')\n",
    "                print('实验回归误差',error_reg2,end='   ')\n",
    "                matrix_count=0\n",
    "                for i_2 in range(num_example):\n",
    "                    for j_2 in range(num_example):\n",
    "                        if (abs(S[i_2][j_2]-1)<0.02):\n",
    "                            matrix_count+=1\n",
    "                print('离置换矩阵距离',matrix_count)\n",
    "                #print('双随机矩阵S为：',S.transpose(1,0).half())\n",
    "                #print(results)\n",
    "    #                 plt.figure(figsize=(6,6))\n",
    "    #                 plt.plot(results_w1_0,results_Loss, '-o',label='$w1[0]$')\n",
    "    #                 plt.plot(results_w1_1,results_Loss, '-o',label='$w1[1]$')\n",
    "    #                 plt.plot(results_w1_2,results_Loss, '-o',label='$w1[2]$')\n",
    "    #                 plt.plot(results_w2_0,results_Loss, '-o',label='$w2[0]$')\n",
    "    #                 plt.plot(results_w2_1,results_Loss, '-o',label='$w2[1]$')\n",
    "    #                 plt.plot(results_w2_2,results_Loss, '-o',label='$w2[2]$')\n",
    "    #                 plt.legend()\n",
    "    #                 plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
