{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from scipy.stats import norm\n",
    "\n",
    "def mse(x,y,w): #actually returns RMSE\n",
    "    assert x.dot(w).shape == y.shape\n",
    "    return np.sqrt(np.mean(np.square(x.dot(w)-y)))\n",
    "\n",
    "def log_prob_of_order(x,y,coefs,s,order):\n",
    "    eps = 1e-6\n",
    "    y_ = y[order]\n",
    "    log_prob = np.sum(-np.square(x.dot(coefs)-y_)/(2*(s+eps)**2))\n",
    "    return log_prob\n",
    "\n",
    "def calc_relative_error(w0, w):\n",
    "    w = np.array(w); w0 = np.array(w0)\n",
    "    w = w.flatten()\n",
    "    w0 = w0.flatten()\n",
    "    return np.linalg.norm(w-w0)/np.linalg.norm(w0)\n",
    "\n",
    "def calc_error(w0, w, multi=False):\n",
    "    w = np.array(w); w0 = np.array(w0)\n",
    "    if (multi):\n",
    "        w = w.reshape(w0.shape)\n",
    "        return np.linalg.norm(w-w0,axis=1)\n",
    "    else:\n",
    "        w = w.flatten()\n",
    "        w0 = w0.flatten()\n",
    "        return np.linalg.norm(w-w0)\n",
    "\n",
    "def calc_normalized_error(w0, w, multi=False):\n",
    "    w = np.array(w); w0 = np.array(w0)\n",
    "    d = w.flatten().shape\n",
    "    diff = w - w0\n",
    "    err = np.abs(diff)\n",
    "    err_total = np.sum(err)\n",
    "    return err_total/d\n",
    "\n",
    "def calc_rmse(y_,y):\n",
    "    return np.sqrt(np.mean((y.flatten() - y_.flatten())**2))\n",
    "\n",
    "def normalize(y):\n",
    "    return (y-np.min(y))/(np.max(y) - np.min(y))\n",
    "\n",
    "\n",
    "def shuffle_up_to_delta(y, eps, return_groups=False):\n",
    "    vals = np.linspace(np.min(y),np.max(y),(np.max(y)-np.min(y))/eps+1)\n",
    "    groups = np.copy(y)\n",
    "    #print(\"Actual delta:\",vals[1]-vals[0])\n",
    "    y_ = y.copy()\n",
    "    for i in range(len(vals)-1):\n",
    "        idx = np.where(np.logical_and(y>=vals[i], y<=vals[i+1]))\n",
    "        y_[idx] = np.random.permutation(y[idx])\n",
    "        groups[idx] = i\n",
    "    #plt.plot(y, y_,'.')\n",
    "    if (return_groups):\n",
    "        return y_, groups\n",
    "    return y_\n",
    "\n",
    "def enhanced_sort(x, w, groups):\n",
    "    for i in np.unique(groups):\n",
    "        idx = np.where(groups==i)[0]\n",
    "        order = np.argsort(x.dot(w).flatten()[idx])\n",
    "        x[idx] = x[idx][order]\n",
    "    return x\n",
    "\n",
    "def sorted_distance(y, y_):\n",
    "    y = np.sort(y.flatten())\n",
    "    y_ = np.sort(y_.flatten())\n",
    "    return np.linalg.norm(y-y_)\n",
    "\n",
    "def ols(x,y,alpha=0.01,fit_intercept=False):\n",
    "    if alpha==0:\n",
    "        lr =  LinearRegression(fit_intercept=fit_intercept)\n",
    "    else:\n",
    "        lr = Ridge(fit_intercept=fit_intercept, alpha=alpha)\n",
    "    lr.fit(x, y)\n",
    "    w = lr.coef_.T\n",
    "    return w\n",
    "\n",
    "\n",
    "def shuffle_within_num_groups_by_feature(features, labels, feature_index, n_clusters = 1, fraction_missorted=0, random_assignment=False):\n",
    "    n,d = features.shape\n",
    "    labels = labels.flatten()\n",
    "\n",
    "    cluster_vector = np.repeat(range(n_clusters), n//n_clusters)\n",
    "    padding = np.repeat([n_clusters-1],n%n_clusters)\n",
    "    cluster_vector = np.concatenate((cluster_vector, padding))\n",
    "\n",
    "    #Handle the missorts (they get randomly put into a bin ahead or behind)\n",
    "    missort_idx = np.random.permutation(n)[:int(fraction_missorted*n)]\n",
    "    missort = list()\n",
    "    for i in missort_idx:\n",
    "        if cluster_vector[i]==0:\n",
    "            missort.append(1)\n",
    "        elif cluster_vector[i]==n_clusters:\n",
    "            missort.append(-1)\n",
    "        else:\n",
    "            if np.random.random()<0.5:\n",
    "                missort.append(-1)\n",
    "            else:\n",
    "                missort.append(1)\n",
    "    cluster_vector[missort_idx] += np.array(missort, dtype=int)\n",
    "\n",
    "    #sort the features and labels\n",
    "    order = np.argsort(features[:,feature_index])\n",
    "    #if (random_assignment):\n",
    "        #order = np.random.permutation(order)\n",
    "\n",
    "    features = features[order]\n",
    "    labels = labels[order]\n",
    "\n",
    "\n",
    "    #randomize the label ordering\n",
    "    for i in range(n_clusters):\n",
    "        idx = np.where(cluster_vector==i)\n",
    "        labels[idx] = np.random.permutation(labels[idx])\n",
    "        features[idx] = np.random.permutation(features[idx])\n",
    "\n",
    "    return features, labels, cluster_vector\n",
    "\n",
    "def shuffle_within_num_groups(features, labels, n_clusters = 1, fraction_missorted=0, random_assignment=False):\n",
    "    n,d = features.shape\n",
    "    labels = labels.flatten()\n",
    "\n",
    "    cluster_vector = np.repeat(range(n_clusters), n//n_clusters)\n",
    "    padding = np.repeat([n_clusters-1],n%n_clusters)\n",
    "    cluster_vector = np.concatenate((cluster_vector, padding))\n",
    "\n",
    "    #Handle the missorts (they get randomly put into a bin ahead or behind)\n",
    "    missort_idx = np.random.permutation(n)[:int(fraction_missorted*n)]\n",
    "    missort = list()\n",
    "    for i in missort_idx:\n",
    "        if cluster_vector[i]==0:\n",
    "            missort.append(1)\n",
    "        elif cluster_vector[i]==n_clusters:\n",
    "            missort.append(-1)\n",
    "        else:\n",
    "            if np.random.random()<0.5:\n",
    "                missort.append(-1)\n",
    "            else:\n",
    "                missort.append(1)\n",
    "    cluster_vector[missort_idx] += np.array(missort, dtype=int)\n",
    "\n",
    "\n",
    "    #sort the features and labels\n",
    "    order = np.argsort(labels)\n",
    "    #if (random_assignment):\n",
    "        #order = np.random.permutation(order)\n",
    "\n",
    "    features = features[order]\n",
    "    labels = labels[order]\n",
    "\n",
    "\n",
    "    #randomize the label ordering\n",
    "    for i in range(n_clusters):\n",
    "        idx = np.where(cluster_vector==i)\n",
    "        labels[idx] = np.random.permutation(labels[idx])\n",
    "        features[idx] = np.random.permutation(features[idx])\n",
    "\n",
    "    return features, labels, cluster_vector\n",
    "\n",
    "def calc_angle(w0, w):\n",
    "    w = np.array(w); w0 = np.array(w0)\n",
    "    w = w.flatten()\n",
    "    w0 = w0.flatten()\n",
    "    return np.arccos(np.dot(w,w0)/(np.linalg.norm(w)*np.linalg.norm(w0)))\n",
    "\n",
    "\n",
    "def semi_mean_ols_y(features,labels, groups, alpha=0.01):\n",
    "    if alpha==0:\n",
    "        lr =  LinearRegression(fit_intercept=False)\n",
    "    else:\n",
    "        lr = Ridge(fit_intercept=False, alpha=alpha)\n",
    "\n",
    "    xs = list()\n",
    "    ys = list()\n",
    "    for i in np.unique(groups):\n",
    "        idxs = np.where(groups==i)[0]\n",
    "        y = np.mean(labels[idxs],axis=0)\n",
    "        for idx in idxs:\n",
    "            x = features[idx,:]\n",
    "            xs.append(x)\n",
    "            ys.append(y)\n",
    "    xs = np.array(xs)\n",
    "    ys = np.array(ys)\n",
    "    #print(xs.shape, ys.shape)\n",
    "    lr.fit(xs, ys)\n",
    "    return lr.coef_.T\n",
    "\n",
    "def semi_mean_ols_x(features,labels, groups, alpha=0.01):\n",
    "    if alpha==0:\n",
    "        lr =  LinearRegression(fit_intercept=False)\n",
    "    else:\n",
    "        lr = Ridge(fit_intercept=False, alpha=alpha)\n",
    "    xs = list()\n",
    "    ys = list()\n",
    "    for i in np.unique(groups):\n",
    "        idxs = np.where(groups==i)[0]\n",
    "        x = np.mean(features[idxs,:],axis=0)\n",
    "        for idx in idxs:\n",
    "            xs.append(x)\n",
    "            y = labels[idx]\n",
    "            ys.append(y)\n",
    "    xs = np.array(xs)\n",
    "    ys = np.array(ys)\n",
    "    #print(xs.shape, ys.shape)\n",
    "    lr.fit(xs, ys)\n",
    "    return lr.coef_.T\n",
    "\n",
    "def mean_ols(features,labels, groups, alpha=0.01):\n",
    "    if alpha==0:\n",
    "        lr =  LinearRegression(fit_intercept=False)\n",
    "    else:\n",
    "        lr = Ridge(fit_intercept=False, alpha=alpha)\n",
    "    xs = list()\n",
    "    ys = list()\n",
    "    for i in np.unique(groups):\n",
    "        idxs = np.where(groups==i)[0]\n",
    "        x = np.mean(features[idxs,:],axis=0)\n",
    "        y = np.mean(labels[idxs],axis=0)\n",
    "        for idx in idxs:\n",
    "            xs.append(x)\n",
    "            ys.append(y)\n",
    "    xs = np.array(xs)\n",
    "    ys = np.array(ys)\n",
    "    lr.fit(xs, ys)\n",
    "    return lr.coef_.T\n",
    "\n",
    "def mean_ols_with_noise(features,labels, groups, noise=0.01, alpha=0.01):\n",
    "    if alpha==0:\n",
    "        lr =  LinearRegression(fit_intercept=False)\n",
    "    else:\n",
    "        lr = Ridge(fit_intercept=False, alpha=alpha)\n",
    "    xs = list()\n",
    "    ys = list()\n",
    "    for i in np.unique(groups):\n",
    "        for _ in range(100):\n",
    "            idx = np.where(groups==i)[0]\n",
    "            x = np.mean(features[idx,:],axis=0)\n",
    "            xs.append(x)\n",
    "            y = np.mean(labels[idx],axis=0)\n",
    "            y = y + np.random.normal(0,noise,size=y.shape)\n",
    "            ys.append(y)\n",
    "    xs = np.array(xs)\n",
    "    ys = np.array(ys)\n",
    "    #print(xs.shape, ys.shape)\n",
    "    lr.fit(xs, ys)\n",
    "    return lr.coef_.T\n",
    "\n",
    "def generate_distribution(dim=2, n=100, noise=0, dist='normal', mean=0, var=1, WA=None, bias=False, n_clusters=None):\n",
    "    \"\"\"generates data of a given dimension and distribution with given parameters\n",
    "    WA -- if you would like to set the weight matrix, provide it here\n",
    "    \"\"\"\n",
    "    if (dist=='normal'):\n",
    "        X = np.random.normal(mean,var, size=[n, dim]);\n",
    "    elif (dist=='half-normal-uniform'):\n",
    "        X1 = np.random.rand(n, dim//2)-mean*0.5\n",
    "        X2 = np.random.normal(mean, var, size=[n, dim//2])\n",
    "        X = np.concatenate((X1, X2), axis=1)\n",
    "    elif (dist=='uniform'):\n",
    "        X = var*np.random.rand(n, dim)+mean\n",
    "    elif (dist=='2normals'):\n",
    "        X1 = np.random.normal(-mean,var, size=[n/2, dim])\n",
    "        X2 = np.random.normal(mean,var, size=[n-n/2, dim]);\n",
    "        X = np.concatenate((X1, X2), axis=0)\n",
    "    elif (dist=='exponential'):\n",
    "        X = np.random.exponential(var, size=[n, dim]);\n",
    "    else:\n",
    "        raise NameError('Invalid distribution: ' + str(dist))\n",
    "    if (bias):\n",
    "        X[:,0] = 1 #set the first column to be all 1s for the \"intercept\" term\n",
    "    if (WA is None):\n",
    "        WA = np.random.normal(0,1,size=[dim, 1]); #Actual weights\n",
    "    else:\n",
    "        WA = np.array(WA)\n",
    "        WA = WA.reshape(dim, 1)\n",
    "    y = np.dot(X,WA) + noise*np.random.normal(0,1,size=[n,1]); #Ordered labels\n",
    "    if (n_clusters is None):\n",
    "        return X, y, WA\n",
    "    else:\n",
    "        cluster_vector = np.tile(range(n_clusters), n//n_clusters)\n",
    "        cluster_vector = np.concatenate((cluster_vector, range(n%n_clusters)))\n",
    "        np.random.shuffle(cluster_vector)\n",
    "        return X, y, WA, cluster_vector\n",
    "\n",
    "def load_dataset_clusters(filename, normalize=True, n_clusters = 1):\n",
    "    data = np.genfromtxt(filename, delimiter=',',skip_header=2)\n",
    "    n,d = data.shape\n",
    "\n",
    "    cluster_vector = np.tile(range(n_clusters), n//n_clusters)\n",
    "    cluster_vector = np.concatenate((cluster_vector, range(n%n_clusters)))\n",
    "    np.random.shuffle(cluster_vector)\n",
    "\n",
    "    #normalize\n",
    "    if (normalize):\n",
    "        data = (data-np.min(data, axis=0))\n",
    "        data = data/(np.max(data, axis=0)+0.01)\n",
    "\n",
    "    labels = data[:,-1].copy()\n",
    "    features = data[:,:].copy()\n",
    "    features[:,-1] = 1 #add a bias column\n",
    "\n",
    "    return features, labels, cluster_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from scipy.stats import norm\n",
    "from utils import *\n",
    "\n",
    "# Stochastic EM Algorithm\n",
    "def em_mcmc(x,y,fit_intercept=False,steps=15,return_all_weights=False,verbose=False, enhanced=False, groups=None, mcmc_steps=None, interval_between_mcmc_steps=None):\n",
    "    import time\n",
    "\n",
    "    lr =  LinearRegression(fit_intercept=fit_intercept)\n",
    "    n, d = x.shape\n",
    "    lr.fit(x,y)\n",
    "    coefs = lr.coef_.T\n",
    "    s = np.sqrt(np.sum(np.square(y - x.dot(coefs)))/(n-d)) #RMS of residuals\n",
    "\n",
    "    ws = list()\n",
    "\n",
    "    for i in list(range(steps)):\n",
    "\n",
    "        order = np.arange(n)\n",
    "        y_mean = np.zeros(n)\n",
    "\n",
    "        if mcmc_steps is None:\n",
    "            mcmc_steps = np.max([int(n*np.log(n)),100])\n",
    "        if interval_between_mcmc_steps is None:\n",
    "            interval_between_mcmc_steps = n/10\n",
    "        burn_steps = int(mcmc_steps/2)\n",
    "        mean_step_counter = 0\n",
    "        interval_mcmc_counter = 0\n",
    "\n",
    "        for m_step in range(mcmc_steps):\n",
    "            order_ = np.copy(order)\n",
    "\n",
    "            i = np.random.randint(0,n)\n",
    "\n",
    "            if (enhanced):\n",
    "                if not(groups is None):\n",
    "                    indices_in_same_group = np.where(groups==groups[i])[0]\n",
    "                    j = np.random.choice(indices_in_same_group)\n",
    "                else:\n",
    "                    raise ValueError(\"Group Information Must Be Provided for Enhanced SLS\")\n",
    "            else:\n",
    "                j = np.random.randint(0,n)\n",
    "\n",
    "            order_[i] = order[j]\n",
    "            order_[j] = order[i]\n",
    "\n",
    "            p1 = log_prob_of_order(x,y,coefs,s,order)\n",
    "            p2 = log_prob_of_order(x,y,coefs,s,order_)\n",
    "\n",
    "            if p1 < p2:\n",
    "                order = order_\n",
    "            else:\n",
    "                if np.random.random() < np.exp(p2-p1): #since they're log probabilities\n",
    "                    order = order_\n",
    "\n",
    "            if m_step>=burn_steps:\n",
    "                interval_mcmc_counter += 1\n",
    "                if (interval_mcmc_counter>=interval_between_mcmc_steps):\n",
    "                    y_mean += y.flatten()[order]\n",
    "                    mean_step_counter += 1\n",
    "                    interval_mcmc_counter = 0\n",
    "\n",
    "        y = y_mean/mean_step_counter\n",
    "        y = y.reshape(-1,1)\n",
    "\n",
    "        lr.fit(x,y)\n",
    "        coefs = lr.coef_.T\n",
    "        s = np.sqrt(np.sum(np.square(y - x.dot(coefs)))/(n-d)) #RMS of residuals\n",
    "        ws.append(coefs)\n",
    "    residual=np.linalg.norm(y - x.dot(coefs))/np.linalg.norm(y)\n",
    "    \n",
    "    if (return_all_weights):\n",
    "        return ws\n",
    "    return coefs,residual\n",
    "\n",
    "# Hard EM Algorithm\n",
    "def sls(x, y, steps=15, alpha=0, w_initial=None, return_all_weights = False, enhanced=False, groups=None, fit_intercept=False, n_starts=1):\n",
    "    if alpha==0:\n",
    "        lr =  LinearRegression(fit_intercept=fit_intercept)\n",
    "    else:\n",
    "        lr = Ridge(fit_intercept=fit_intercept, alpha=alpha)\n",
    "\n",
    "    order = np.argsort(y.flatten())\n",
    "    y = y[order]\n",
    "    x = x[order]\n",
    "    errors = list()\n",
    "    optimal_score = float(\"-inf\")\n",
    "    optimal_ws = list()\n",
    "\n",
    "    for i_start in range(n_starts):\n",
    "        ws = list()\n",
    "        if w_initial is None and n_starts==1:\n",
    "            lr.fit(x, y)\n",
    "            w = lr.coef_.T\n",
    "        elif w_initial is None:\n",
    "            if i_start>0:\n",
    "                y_ = np.random.permutation(y)\n",
    "            elif i_start==0: #try the current permutation first\n",
    "                y_ = y\n",
    "            lr.fit(x, y_)\n",
    "            w = lr.coef_.T\n",
    "        elif w_initial=='mean':\n",
    "            y_ = np.copy(y)\n",
    "            for i in np.unique(groups):\n",
    "                idx = np.where(groups==i)[0]\n",
    "                y_[idx] = np.mean(y[idx])\n",
    "            lr.fit(x, y_)\n",
    "            w = lr.coef_.T\n",
    "        else:\n",
    "            w = w_initial\n",
    "\n",
    "        for _ in list(range(steps)):\n",
    "\n",
    "            if (enhanced):\n",
    "                if not(groups is None):\n",
    "                    x = enhanced_sort(x, w, groups)\n",
    "                else:\n",
    "                    raise ValueError(\"Group Information Must Be Provided for Enhanced SLS\")\n",
    "            else:\n",
    "                order = np.argsort(x.dot(w).flatten())\n",
    "                x = x[order]\n",
    "\n",
    "            lr.fit(x, y)\n",
    "            w = lr.coef_.T\n",
    "            ws.append(w)\n",
    "\n",
    "        if lr.score(x,y)>optimal_score:\n",
    "            optimal_score = lr.score(x,y)\n",
    "            optimal_ws = ws.copy()\n",
    "\n",
    "    if (return_all_weights):\n",
    "        return optimal_ws\n",
    "    return optimal_ws[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys, os;\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#from utils import *\n",
    "#from algorithms import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%matplotlib inline\n",
    "%autoreload 2\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "lr =  LinearRegression(fit_intercept=False)\n",
    "\n",
    "font = {'family' : 'sans-serif',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 18}\n",
    "\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatedata(noise,showpermutation=False,showtrue_w=False):\n",
    "    true_w2 = np.random.normal(0, 1,(num_X2feature,1))\n",
    "    X2_before_ =np.random.normal(0, 1, (num_example, num_X2feature))\n",
    "    X2_test_before=np.random.normal(0, 1, (num_example, num_X2feature))\n",
    "    y_ = np.matmul(X2_before_,true_w2)\n",
    "    y_test=np.matmul(X2_test_before,true_w2)\n",
    "    y_ += np.random.normal(0, noise ,size=(num_example,1))\n",
    "    y_test += np.random.normal(0, noise ,size=(num_example,1))\n",
    "    P_array=np.random.permutation(num_example)\n",
    "    P=np.zeros((num_example,num_example))\n",
    "    for i in range(num_example):\n",
    "        P[i][P_array[i]]=1\n",
    "    if showpermutation:\n",
    "        print('打乱X2的置换矩阵为',P)\n",
    "    P_arraytest=np.random.permutation(num_example)\n",
    "    P_test=np.zeros((num_example,num_example))\n",
    "    for i in range(num_example):\n",
    "        P_test[i][P_arraytest[i]]=1\n",
    "    X2_=np.matmul(P,X2_before_)\n",
    "    X2_test=np.matmul(P_test,X2_test_before)\n",
    "    conditionnumber=np.linalg.cond(X2_)\n",
    "    #X2_=X2_before_\n",
    "    error_reg=(np.linalg.norm(y_-np.matmul(X2_before_,true_w2))/np.linalg.norm(y_))\n",
    "    error_reg_test=(np.linalg.norm(y_test-np.matmul(X2_test_before,true_w2))/np.linalg.norm(y_test))\n",
    "    return y_,X2_,true_w2,P,error_reg,conditionnumber,y_test,X2_test,P_test,error_reg_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "0| 100 w相对误差 1.021444711137078 实验回归残差 0.358686249933205\n",
      "200 w相对误差 1.0403542034560562 实验回归残差 0.9079873409249418\n",
      "300 w相对误差 0.9987857849744898 实验回归残差 0.8561369989089445\n",
      "400 w相对误差 1.0299783585370452 实验回归残差 0.8443449332962878\n",
      "500 w相对误差 1.0069713813111547 实验回归残差 0.9512080763610316\n",
      "1| 100 w相对误差 1.0999613105379245 实验回归残差 0.35840551423508954\n",
      "200 w相对误差 0.9976921826961848 实验回归残差 0.7789241137476555\n",
      "300 w相对误差 0.9609557938326696 实验回归残差 0.8814305669767049\n",
      "400 w相对误差 0.9818042607481612 实验回归残差 0.8996292960872451\n",
      "500 w相对误差 0.9969350469401662 实验回归残差 0.9079419423098971\n",
      "2| 100 w相对误差 1.049945863807408 实验回归残差 0.6415475260949608\n",
      "200 w相对误差 0.9836203475395292 实验回归残差 0.8534880525765105\n",
      "300 w相对误差 0.9595798005398224 实验回归残差 0.832548090976611\n",
      "400 w相对误差 0.9829541409921443 实验回归残差 0.8879957979334031\n",
      "500 w相对误差 0.991604234751429 实验回归残差 0.927198590692457\n",
      "3| 100 w相对误差 1.2077684827720025 实验回归残差 0.33310834357994834\n",
      "200 w相对误差 1.001116874135875 实验回归残差 0.7455684695869936\n",
      "300 w相对误差 0.9982440653456299 实验回归残差 0.8821498610693846\n",
      "400 w相对误差 1.0051863522689697 实验回归残差 0.872173964569709\n",
      "500 w相对误差 0.9924994491278608 实验回归残差 0.8895110283216678\n",
      "4| 100 w相对误差 1.146886274798313 实验回归残差 0.6027678875878019\n",
      "200 w相对误差 1.0139747245651918 实验回归残差 0.7388305300083018\n",
      "300 w相对误差 1.0312235673316037 实验回归残差 0.8106112011884316\n",
      "400 w相对误差 1.0360221878033489 实验回归残差 0.8639663780801683\n",
      "500 w相对误差 1.0260955277863313 实验回归残差 0.9122598805923106\n"
     ]
    }
   ],
   "source": [
    "import sys, os;\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#from utils import *\n",
    "#from algorithms import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%matplotlib inline\n",
    "%autoreload 2\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "lr =  LinearRegression(fit_intercept=False)\n",
    "\n",
    "font = {'family' : 'sans-serif',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 18}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "d = 30\n",
    "noise = 1\n",
    "iters = 5\n",
    "ns = np.linspace(100,500,5,dtype=int)\n",
    "\n",
    "error_hard = np.zeros((iters,len(ns)))\n",
    "error_soft = np.zeros((iters,len(ns)))\n",
    "\n",
    "for i in range(iters):\n",
    "    print(i, end='| ')\n",
    "    x_, y__, w0_ = generate_distribution(n=np.max(ns), dim=d,  dist='normal', bias=False, noise=0)\n",
    "    y_ = y__ + np.random.normal(0,noise,y__.shape)\n",
    "    for n_i, n in enumerate(ns):\n",
    "        #print(n, end=' ')\n",
    "        y = y_[:n]; x = x_[:n]\n",
    "        y = np.random.permutation(y)\n",
    "        weights,residual = em_mcmc(x,y,steps=50,return_all_weights=False)\n",
    "        error = calc_error(w0_, weights)\n",
    "        error1=np.linalg.norm(weights-w0_)/np.linalg.norm(w0_)\n",
    "        print(n,'w相对误差',error1,'实验回归残差',residual)\n",
    "        error_soft[i,n_i] = error\n",
    "\n",
    "        #weights = sls(x,y,steps=50,return_all_weights=True, n_starts=n)\n",
    "        #error = calc_error(w0_, weights[-1])\n",
    "        #error_hard[i,n_i] = error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
