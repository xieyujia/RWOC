{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline \n",
    "import torch \n",
    "#from IPython import display \n",
    "#from matplotlib import pyplot as plt\n",
    "import numpy as np \n",
    "import random\n",
    "import math\n",
    "from time import time\n",
    "#from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatedata(noise,showpermutation=False,showtrue_w=False):\n",
    "    true_w2 = torch.from_numpy(np.random.normal(0, 1,(num_X2feature,1)))\n",
    "    if showtrue_w:\n",
    "        print('true_w2:',true_w2)\n",
    "    X2_before_ =torch.from_numpy(np.random.normal(0, 1, (num_example, num_X2feature)))\n",
    "    y_ = torch.mm(X2_before_,true_w2)\n",
    "    y_ += torch.from_numpy(np.random.normal(0, noise ,size=y_.size()))\n",
    "    P_array=np.random.permutation(num_example)\n",
    "    P=torch.zeros(num_example,num_example,dtype=torch.float64)\n",
    "    for i in range(num_example):\n",
    "        P[i][P_array[i]]=1\n",
    "    if showpermutation:\n",
    "        print('打乱X2的置换矩阵为',P)\n",
    "    X2_=torch.mm(P,X2_before_)\n",
    "    #X2_=X2_before_\n",
    "    error_reg=(torch.norm(y_-torch.mm(X2_before_,true_w2))/torch.norm(y_))\n",
    "    return y_,X2_,true_w2,P,error_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateinitialw(method,showinitialw=False):\n",
    "    if method=='normal':\n",
    "        w2 = torch.from_numpy(np.random.normal(0, 1,(num_X2feature,1)))\n",
    "    if method=='zeros':\n",
    "        w2=torch.zeros(num_X2feature,1,dtype=torch.float64)\n",
    "    if showinitialw:\n",
    "        print('initial w2:',w2)\n",
    "    return w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinkhorn_stabilized(a, b, M, reg, numItermax=1000, tau=1e3, stopThr=1e-9,\n",
    "                        warmstart=None, verbose=False, print_period=20,\n",
    "                        log=False, **kwargs):\n",
    "\n",
    "#     a = np.asarray(a, dtype=np.float64)\n",
    "#     b = np.asarray(b, dtype=np.float64)\n",
    "#     M = np.asarray(M, dtype=np.float64)\n",
    "    a=a\n",
    "    b=b\n",
    "    M=M\n",
    "\n",
    "#     if len(a) == 0:\n",
    "#         a = np.ones((M.shape[0],), dtype=np.float64) / M.shape[0]\n",
    "#     if len(b) == 0:\n",
    "#         b = np.ones((M.shape[1],), dtype=np.float64) / M.shape[1]\n",
    "\n",
    "    # test if multiple target\n",
    "#     if len(b.shape) > 1:\n",
    "#         n_hists = b.shape[1]\n",
    "#         a = a[:, np.newaxis]\n",
    "#     else:\n",
    "#         n_hists = 0\n",
    "    n_hists = 0\n",
    "    # init data\n",
    "    dim_a = len(a)\n",
    "    dim_b = len(b)\n",
    "\n",
    "    cpt = 0\n",
    "    if log:\n",
    "        log = {'err': []}\n",
    "\n",
    "    # we assume that no distances are null except those of the diagonal of\n",
    "    # distances\n",
    "    if warmstart is None:\n",
    "        alpha, beta = torch.zeros(dim_a,1,dtype=torch.float64), torch.zeros(dim_b,1,dtype=torch.float64)\n",
    "    else:\n",
    "        alpha, beta = warmstart\n",
    "\n",
    "    if n_hists:\n",
    "        u = torch.ones((dim_a, n_hists)) / dim_a\n",
    "        v = torch.ones((dim_b, n_hists)) / dim_b\n",
    "    else:\n",
    "        u, v = torch.ones(dim_a,1,dtype=torch.float64) / dim_a, torch.ones(dim_b,1,dtype=torch.float64) / dim_b\n",
    "\n",
    "    def get_K(alpha, beta):\n",
    "        \"\"\"log space computation\"\"\"\n",
    "        return torch.exp(-(M - alpha.reshape((dim_a, 1))- beta.reshape((1, dim_b))) / reg)\n",
    "\n",
    "    def get_Gamma(alpha, beta, u, v):\n",
    "        \"\"\"log space gamma computation\"\"\"\n",
    "        return torch.exp(-(M - alpha.reshape((dim_a, 1)) - beta.reshape((1, dim_b)))\n",
    "                      / reg + torch.log(u.reshape((dim_a, 1))) + torch.log(v.reshape((1, dim_b))))\n",
    "\n",
    "    # print(np.min(K))\n",
    "\n",
    "    K = get_K(alpha, beta)\n",
    "    transp = K\n",
    "    loop = 1\n",
    "    cpt = 0\n",
    "    err = 1\n",
    "    while loop:\n",
    "\n",
    "        uprev = u\n",
    "        vprev = v\n",
    "        # sinkhornrn update\n",
    "        v = b / (torch.mm(K.transpose(1,0), u) + 1e-16)\n",
    "        u = a / (torch.mm(K, v) + 1e-16)\n",
    "        # remove numerical problems and store them in K\n",
    "        if torch.abs(u).max() > tau or torch.abs(v).max() > tau:\n",
    "            if n_hists:\n",
    "                alpha, beta = alpha + reg * \\\n",
    "                    torch.max(torch.log(u), 1), beta + reg * torch.max(np.log(v))\n",
    "            else:\n",
    "                alpha, beta = alpha + reg * torch.log(u), beta + reg * torch.log(v)\n",
    "                if n_hists:\n",
    "                    u, v = torch.ones((dim_a, n_hists)) / dim_a, torch.ones((dim_b, n_hists)) / dim_b\n",
    "                else:\n",
    "                    u, v = torch.ones(dim_a,1,dtype=torch.float64) / dim_a, torch.ones(dim_b,1,dtype=torch.float64) / dim_b\n",
    "            K = get_K(alpha, beta)\n",
    "            \n",
    "\n",
    "        if cpt % print_period == 0:\n",
    "            # we can speed up the process by checking for the error only all\n",
    "            # the 10th iterations\n",
    "            if n_hists:\n",
    "                err_u = abs(u - uprev).max()\n",
    "                err_u /= max(abs(u).max(), abs(uprev).max(), 1.)\n",
    "                err_v = abs(v - vprev).max()\n",
    "                err_v /= max(abs(v).max(), abs(vprev).max(), 1.)\n",
    "                err = 0.5 * (err_u + err_v)\n",
    "            else:\n",
    "                transp = get_Gamma(alpha, beta, u, v)\n",
    "                err = torch.norm((torch.sum(transp, axis=0) - b))\n",
    "            if log:\n",
    "                log['err'].append(err)\n",
    "\n",
    "            if verbose:\n",
    "                if cpt % (print_period * 20) == 0:\n",
    "                    print(\n",
    "                        '{:5s}|{:12s}'.format('It.', 'Err') + '\\n' + '-' * 19)\n",
    "                print('{:5d}|{:8e}|'.format(cpt, err))\n",
    "\n",
    "        if err <= stopThr:\n",
    "            loop = False\n",
    "\n",
    "        if cpt >= numItermax:\n",
    "            loop = False\n",
    "\n",
    "        if np.any(np.isnan(u.detach().numpy())) or np.any(np.isnan(v.detach().numpy())):\n",
    "            # we have reached the machine precision\n",
    "            # come back to previous solution and quit loop\n",
    "            print('Warning: numerical errors at iteration', cpt)\n",
    "            u = uprev\n",
    "            v = vprev\n",
    "            break\n",
    "\n",
    "        cpt = cpt + 1\n",
    "    #print(cpt)\n",
    "    if log:\n",
    "        if n_hists:\n",
    "            alpha = alpha[:, None]\n",
    "            beta = beta[:, None]\n",
    "        logu = alpha / reg + torch.log(u)\n",
    "        logv = beta / reg + torch.log(v)\n",
    "        log['logu'] = logu\n",
    "        log['logv'] = logv\n",
    "        log['alpha'] = alpha + reg * torch.log(u)\n",
    "        log['beta'] = beta + reg * torch.log(v)\n",
    "        log['warmstart'] = (log['alpha'], log['beta'])\n",
    "        if n_hists:\n",
    "            res = torch.zeros((n_hists))\n",
    "            for i in range(n_hists):\n",
    "                res[i] = torch.sum(get_Gamma(alpha, beta, u[:, i], v[:, i]) * M)\n",
    "            return res, log\n",
    "\n",
    "        else:\n",
    "            return get_Gamma(alpha, beta, u, v), log\n",
    "    else:\n",
    "        if n_hists:\n",
    "            res = torch.zeros((n_hists))\n",
    "            for i in range(n_hists):\n",
    "                res[i] = torch.sum(get_Gamma(alpha, beta, u[:, i], v[:, i]) * M)\n",
    "            return res\n",
    "        else:\n",
    "            return get_Gamma(alpha, beta, u, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinkhorn_epsilon_scaling(a, b, M, reg, numItermax=100, epsilon0=1e4,\n",
    "                             numInnerItermax=100, tau=1e3, stopThr=1e-9,\n",
    "                             warmstart=None, verbose=False, print_period=10,\n",
    "                             log=False, **kwargs):\n",
    "    #a = np.asarray(a, dtype=np.float64)\n",
    "    #b = np.asarray(b, dtype=np.float64)\n",
    "    #M = np.asarray(M, dtype=np.float64)\n",
    "    a=a\n",
    "    b=b\n",
    "    M=M\n",
    "#     if len(a) == 0:\n",
    "#         a = np.ones((M.shape[0],), dtype=np.float64) / M.shape[0]\n",
    "#     if len(b) == 0:\n",
    "#         b = np.ones((M.shape[1],), dtype=np.float64) / M.shape[1]\n",
    "\n",
    "    # init data\n",
    "    dim_a = len(a)\n",
    "    #dim_a=num_example\n",
    "    dim_b = len(b)\n",
    "    #dim_b=num_example\n",
    "    # nrelative umerical precision with 64 bits\n",
    "    numItermin = 35\n",
    "    numItermax = max(numItermin, numItermax)  # ensure that last velue is exact\n",
    "\n",
    "    cpt = 0\n",
    "    if log:\n",
    "        log = {'err': []}\n",
    "\n",
    "    # we assume that no distances are null except those of the diagonal of\n",
    "    # distances\n",
    "    if warmstart is None:\n",
    "        alpha, beta = torch.zeros(dim_a,1,dtype=torch.float64), torch.zeros(dim_b,1,dtype=torch.float64)\n",
    "    else:\n",
    "        alpha, beta = warmstart\n",
    "\n",
    "    def get_K(alpha, beta):\n",
    "        \"\"\"log space computation\"\"\"\n",
    "        return torch.exp(-(M - alpha.reshape((dim_a, 1))\n",
    "                        - beta.reshape((1, dim_b))) / reg)\n",
    "\n",
    "    # print(np.min(K))\n",
    "    def get_reg(n):  # exponential decreasing\n",
    "        return (epsilon0 - reg) * np.exp(-n) + reg\n",
    "\n",
    "    loop = 1\n",
    "    cpt = 0\n",
    "    err = 1\n",
    "    while loop:\n",
    "\n",
    "        regi = get_reg(cpt)\n",
    "\n",
    "        G, logi = sinkhorn_stabilized(a, b, M, regi,\n",
    "                                      numItermax=numInnerItermax, stopThr=1e-9,\n",
    "                                      warmstart=(alpha, beta), verbose=False,\n",
    "                                      print_period=20, tau=tau, log=True)\n",
    "\n",
    "        alpha = logi['alpha']\n",
    "        beta = logi['beta']\n",
    "\n",
    "        if cpt >= numItermax:\n",
    "            loop = False\n",
    "\n",
    "        if cpt % (print_period) == 0:  # spsion nearly converged\n",
    "            # we can speed up the process by checking for the error only all\n",
    "            # the 10th iterations\n",
    "            transp = G\n",
    "            err = torch.norm(\n",
    "                (torch.sum(transp, axis=0) - b))**2 + torch.norm((torch.sum(transp, axis=1) - a))**2\n",
    "            if log:\n",
    "                log['err'].append(err)\n",
    "\n",
    "            if verbose:\n",
    "                if cpt % (print_period * 10) == 0:\n",
    "                    print(\n",
    "                        '{:5s}|{:12s}'.format('It.', 'Err') + '\\n' + '-' * 19)\n",
    "                print('{:5d}|{:8e}|'.format(cpt, err))\n",
    "\n",
    "        if err <= stopThr and cpt > numItermin:\n",
    "            loop = False\n",
    "\n",
    "        cpt = cpt + 1\n",
    "    # print('err=',err,' cpt=',cpt)\n",
    "    if log:\n",
    "        log['alpha'] = alpha\n",
    "        log['beta'] = beta\n",
    "        log['warmstart'] = (log['alpha'], log['beta'])\n",
    "        return G, log\n",
    "    else:\n",
    "        return G\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0 = tensor(3119.0879, dtype=torch.float64)\n",
      "#Loss 1 = tensor(3058.8860, dtype=torch.float64)\n",
      "#Loss 2 = tensor(214.5526, dtype=torch.float64)\n",
      "#Loss 3 = tensor(193.1970, dtype=torch.float64)\n",
      "#Loss 4 = tensor(179.5074, dtype=torch.float64)\n",
      "#Loss 5 = tensor(168.4188, dtype=torch.float64)\n",
      "#Loss 6 = tensor(160.0754, dtype=torch.float64)\n",
      "#Loss 7 = tensor(152.1518, dtype=torch.float64)\n",
      "#Loss 8 = tensor(144.4730, dtype=torch.float64)\n",
      "#Loss 9 = tensor(136.7875, dtype=torch.float64)\n",
      "#Loss 10 = tensor(129.4504, dtype=torch.float64)\n",
      "#Loss 11 = tensor(124.1337, dtype=torch.float64)\n",
      "#Loss 12 = tensor(119.8356, dtype=torch.float64)\n",
      "#Loss 13 = tensor(114.4960, dtype=torch.float64)\n",
      "#Loss 14 = tensor(109.2088, dtype=torch.float64)\n",
      "#Loss 15 = tensor(104.5247, dtype=torch.float64)\n",
      "#Loss 16 = tensor(99.2911, dtype=torch.float64)\n",
      "#Loss 17 = tensor(94.2866, dtype=torch.float64)\n",
      "#Loss 18 = tensor(89.5660, dtype=torch.float64)\n",
      "#Loss 19 = tensor(84.8250, dtype=torch.float64)\n",
      "#Loss 20 = tensor(78.5670, dtype=torch.float64)\n",
      "#Loss 21 = tensor(72.7489, dtype=torch.float64)\n",
      "#Loss 22 = tensor(67.6209, dtype=torch.float64)\n",
      "#Loss 23 = tensor(63.2481, dtype=torch.float64)\n",
      "#Loss 24 = tensor(59.6792, dtype=torch.float64)\n",
      "#Loss 25 = tensor(57.4226, dtype=torch.float64)\n",
      "#Loss 26 = tensor(55.1551, dtype=torch.float64)\n",
      "#Loss 27 = tensor(52.4650, dtype=torch.float64)\n",
      "#Loss 28 = tensor(49.5534, dtype=torch.float64)\n",
      "#Loss 29 = tensor(46.4593, dtype=torch.float64)\n",
      "#Loss 30 = tensor(43.3732, dtype=torch.float64)\n",
      "#Loss 31 = tensor(41.3114, dtype=torch.float64)\n",
      "#Loss 32 = tensor(39.9633, dtype=torch.float64)\n",
      "#Loss 33 = tensor(39.0165, dtype=torch.float64)\n",
      "#Loss 34 = tensor(38.3610, dtype=torch.float64)\n",
      "#Loss 35 = tensor(37.6970, dtype=torch.float64)\n",
      "#Loss 36 = tensor(37.3126, dtype=torch.float64)\n",
      "#Loss 37 = tensor(36.8783, dtype=torch.float64)\n",
      "#Loss 38 = tensor(36.4232, dtype=torch.float64)\n",
      "#Loss 39 = tensor(35.7250, dtype=torch.float64)\n",
      "#Loss 40 = tensor(35.1103, dtype=torch.float64)\n",
      "#Loss 41 = tensor(34.5243, dtype=torch.float64)\n",
      "#Loss 42 = tensor(33.8734, dtype=torch.float64)\n",
      "#Loss 43 = tensor(33.0177, dtype=torch.float64)\n",
      "#Loss 44 = tensor(32.3638, dtype=torch.float64)\n",
      "#Loss 45 = tensor(31.7529, dtype=torch.float64)\n",
      "#Loss 46 = tensor(31.4888, dtype=torch.float64)\n",
      "#Loss 47 = tensor(31.1582, dtype=torch.float64)\n",
      "#Loss 48 = tensor(30.8238, dtype=torch.float64)\n",
      "#Loss 49 = tensor(30.4265, dtype=torch.float64)\n",
      "#Loss 50 = tensor(29.9017, dtype=torch.float64)\n",
      "#Loss 51 = tensor(29.4466, dtype=torch.float64)\n",
      "#Loss 52 = tensor(29.0318, dtype=torch.float64)\n",
      "#Loss 53 = tensor(28.6632, dtype=torch.float64)\n",
      "#Loss 54 = tensor(28.4010, dtype=torch.float64)\n",
      "#Loss 55 = tensor(28.1312, dtype=torch.float64)\n",
      "#Loss 56 = tensor(27.7263, dtype=torch.float64)\n",
      "#Loss 57 = tensor(27.5083, dtype=torch.float64)\n",
      "#Loss 58 = tensor(27.2826, dtype=torch.float64)\n",
      "#Loss 59 = tensor(27.0438, dtype=torch.float64)\n",
      "#Loss 60 = tensor(26.7765, dtype=torch.float64)\n",
      "#Loss 61 = tensor(26.4287, dtype=torch.float64)\n",
      "#Loss 62 = tensor(26.0949, dtype=torch.float64)\n",
      "#Loss 63 = tensor(26.0017, dtype=torch.float64)\n",
      "#Loss 64 = tensor(25.9458, dtype=torch.float64)\n",
      "#Loss 65 = tensor(25.9170, dtype=torch.float64)\n",
      "#Loss 66 = tensor(25.8721, dtype=torch.float64)\n",
      "#Loss 67 = tensor(25.8547, dtype=torch.float64)\n",
      "#Loss 68 = tensor(25.8204, dtype=torch.float64)\n",
      "#Loss 69 = tensor(25.8125, dtype=torch.float64)\n",
      "#Loss 70 = tensor(25.8100, dtype=torch.float64)\n",
      "#Loss 71 = tensor(25.8090, dtype=torch.float64)\n",
      "#Loss 72 = tensor(25.8085, dtype=torch.float64)\n",
      "#Loss 73 = tensor(25.8083, dtype=torch.float64)\n",
      "#Loss 74 = tensor(25.8082, dtype=torch.float64)\n",
      "#Loss 75 = tensor(25.8082, dtype=torch.float64)\n",
      "#Loss 76 = tensor(25.8082, dtype=torch.float64)\n",
      "#Loss 77 = tensor(25.8082, dtype=torch.float64)\n",
      "#Loss 78 = tensor(25.8082, dtype=torch.float64)\n",
      "#Loss 79 = tensor(25.8081, dtype=torch.float64)\n",
      "#Loss 80 = tensor(25.8081, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(6.9323, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4095, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0658, dtype=torch.float64)   实验回归误差 tensor(0.0910, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(4320.7697, dtype=torch.float64)\n",
      "#Loss 1 = tensor(4186.2573, dtype=torch.float64)\n",
      "#Loss 2 = tensor(638.5375, dtype=torch.float64)\n",
      "#Loss 3 = tensor(494.8562, dtype=torch.float64)\n",
      "#Loss 4 = tensor(402.0486, dtype=torch.float64)\n",
      "#Loss 5 = tensor(311.2603, dtype=torch.float64)\n",
      "#Loss 6 = tensor(238.4867, dtype=torch.float64)\n",
      "#Loss 7 = tensor(180.3879, dtype=torch.float64)\n",
      "#Loss 8 = tensor(138.0190, dtype=torch.float64)\n",
      "#Loss 9 = tensor(102.6653, dtype=torch.float64)\n",
      "#Loss 10 = tensor(79.3259, dtype=torch.float64)\n",
      "#Loss 11 = tensor(61.5025, dtype=torch.float64)\n",
      "#Loss 12 = tensor(49.0691, dtype=torch.float64)\n",
      "#Loss 13 = tensor(39.4658, dtype=torch.float64)\n",
      "#Loss 14 = tensor(32.5938, dtype=torch.float64)\n",
      "#Loss 15 = tensor(28.4741, dtype=torch.float64)\n",
      "#Loss 16 = tensor(25.9683, dtype=torch.float64)\n",
      "#Loss 17 = tensor(23.5873, dtype=torch.float64)\n",
      "#Loss 18 = tensor(21.4872, dtype=torch.float64)\n",
      "#Loss 19 = tensor(20.0638, dtype=torch.float64)\n",
      "#Loss 20 = tensor(18.9033, dtype=torch.float64)\n",
      "#Loss 21 = tensor(17.3903, dtype=torch.float64)\n",
      "#Loss 22 = tensor(16.1953, dtype=torch.float64)\n",
      "#Loss 23 = tensor(15.3754, dtype=torch.float64)\n",
      "#Loss 24 = tensor(14.7667, dtype=torch.float64)\n",
      "#Loss 25 = tensor(14.1202, dtype=torch.float64)\n",
      "#Loss 26 = tensor(13.2135, dtype=torch.float64)\n",
      "#Loss 27 = tensor(12.0269, dtype=torch.float64)\n",
      "#Loss 28 = tensor(11.1333, dtype=torch.float64)\n",
      "#Loss 29 = tensor(10.2173, dtype=torch.float64)\n",
      "#Loss 30 = tensor(9.2980, dtype=torch.float64)\n",
      "#Loss 31 = tensor(8.4747, dtype=torch.float64)\n",
      "#Loss 32 = tensor(7.7583, dtype=torch.float64)\n",
      "#Loss 33 = tensor(7.3458, dtype=torch.float64)\n",
      "#Loss 34 = tensor(7.1903, dtype=torch.float64)\n",
      "#Loss 35 = tensor(7.0736, dtype=torch.float64)\n",
      "#Loss 36 = tensor(7.0242, dtype=torch.float64)\n",
      "#Loss 37 = tensor(6.9815, dtype=torch.float64)\n",
      "#Loss 38 = tensor(6.9502, dtype=torch.float64)\n",
      "#Loss 39 = tensor(6.8956, dtype=torch.float64)\n",
      "#Loss 40 = tensor(6.6551, dtype=torch.float64)\n",
      "#Loss 41 = tensor(6.4357, dtype=torch.float64)\n",
      "#Loss 42 = tensor(6.2458, dtype=torch.float64)\n",
      "#Loss 43 = tensor(6.1411, dtype=torch.float64)\n",
      "#Loss 44 = tensor(6.0608, dtype=torch.float64)\n",
      "#Loss 45 = tensor(5.9250, dtype=torch.float64)\n",
      "#Loss 46 = tensor(5.8779, dtype=torch.float64)\n",
      "#Loss 47 = tensor(5.8406, dtype=torch.float64)\n",
      "#Loss 48 = tensor(5.6734, dtype=torch.float64)\n",
      "#Loss 49 = tensor(5.5448, dtype=torch.float64)\n",
      "#Loss 50 = tensor(5.5156, dtype=torch.float64)\n",
      "#Loss 51 = tensor(5.5062, dtype=torch.float64)\n",
      "#Loss 52 = tensor(5.5036, dtype=torch.float64)\n",
      "#Loss 53 = tensor(5.5023, dtype=torch.float64)\n",
      "#Loss 54 = tensor(5.4844, dtype=torch.float64)\n",
      "#Loss 55 = tensor(5.4733, dtype=torch.float64)\n",
      "#Loss 56 = tensor(5.4550, dtype=torch.float64)\n",
      "#Loss 57 = tensor(5.4353, dtype=torch.float64)\n",
      "#Loss 58 = tensor(5.4195, dtype=torch.float64)\n",
      "#Loss 59 = tensor(5.3957, dtype=torch.float64)\n",
      "#Loss 60 = tensor(5.3489, dtype=torch.float64)\n",
      "#Loss 61 = tensor(5.3209, dtype=torch.float64)\n",
      "#Loss 62 = tensor(5.3089, dtype=torch.float64)\n",
      "#Loss 63 = tensor(5.3048, dtype=torch.float64)\n",
      "#Loss 64 = tensor(5.3026, dtype=torch.float64)\n",
      "#Loss 65 = tensor(5.3017, dtype=torch.float64)\n",
      "#Loss 66 = tensor(5.3013, dtype=torch.float64)\n",
      "#Loss 67 = tensor(5.3010, dtype=torch.float64)\n",
      "#Loss 68 = tensor(5.3009, dtype=torch.float64)\n",
      "#Loss 69 = tensor(5.3009, dtype=torch.float64)\n",
      "#Loss 70 = tensor(5.3008, dtype=torch.float64)\n",
      "#Loss 71 = tensor(5.3008, dtype=torch.float64)\n",
      "#Loss 72 = tensor(5.3008, dtype=torch.float64)\n",
      "#Loss 73 = tensor(5.3008, dtype=torch.float64)\n",
      "#Loss 74 = tensor(5.3008, dtype=torch.float64)\n",
      "#Loss 75 = tensor(5.3008, dtype=torch.float64)\n",
      "#Loss 76 = tensor(5.3008, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(7.0292, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4095, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0569, dtype=torch.float64)   实验回归误差 tensor(0.0350, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(5429.4740, dtype=torch.float64)\n",
      "#Loss 1 = tensor(4952.4424, dtype=torch.float64)\n",
      "#Loss 2 = tensor(375.2243, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 3 = tensor(277.4092, dtype=torch.float64)\n",
      "#Loss 4 = tensor(231.9813, dtype=torch.float64)\n",
      "#Loss 5 = tensor(199.0891, dtype=torch.float64)\n",
      "#Loss 6 = tensor(174.4242, dtype=torch.float64)\n",
      "#Loss 7 = tensor(151.3327, dtype=torch.float64)\n",
      "#Loss 8 = tensor(136.2763, dtype=torch.float64)\n",
      "#Loss 9 = tensor(122.2989, dtype=torch.float64)\n",
      "#Loss 10 = tensor(110.0395, dtype=torch.float64)\n",
      "#Loss 11 = tensor(101.0484, dtype=torch.float64)\n",
      "#Loss 12 = tensor(92.4008, dtype=torch.float64)\n",
      "#Loss 13 = tensor(85.1763, dtype=torch.float64)\n",
      "#Loss 14 = tensor(77.3370, dtype=torch.float64)\n",
      "#Loss 15 = tensor(70.6308, dtype=torch.float64)\n",
      "#Loss 16 = tensor(65.4989, dtype=torch.float64)\n",
      "#Loss 17 = tensor(61.2651, dtype=torch.float64)\n",
      "#Loss 18 = tensor(57.8708, dtype=torch.float64)\n",
      "#Loss 19 = tensor(55.1595, dtype=torch.float64)\n",
      "#Loss 20 = tensor(52.2021, dtype=torch.float64)\n",
      "#Loss 21 = tensor(49.2212, dtype=torch.float64)\n",
      "#Loss 22 = tensor(46.6838, dtype=torch.float64)\n",
      "#Loss 23 = tensor(43.9872, dtype=torch.float64)\n",
      "#Loss 24 = tensor(41.9071, dtype=torch.float64)\n",
      "#Loss 25 = tensor(40.2735, dtype=torch.float64)\n",
      "#Loss 26 = tensor(39.0856, dtype=torch.float64)\n",
      "#Loss 27 = tensor(37.6710, dtype=torch.float64)\n",
      "#Loss 28 = tensor(35.8827, dtype=torch.float64)\n",
      "#Loss 29 = tensor(34.6190, dtype=torch.float64)\n",
      "#Loss 30 = tensor(33.5577, dtype=torch.float64)\n",
      "#Loss 31 = tensor(31.4608, dtype=torch.float64)\n",
      "#Loss 32 = tensor(30.2746, dtype=torch.float64)\n",
      "#Loss 33 = tensor(29.3151, dtype=torch.float64)\n",
      "#Loss 34 = tensor(28.5845, dtype=torch.float64)\n",
      "#Loss 35 = tensor(28.0929, dtype=torch.float64)\n",
      "#Loss 36 = tensor(27.7189, dtype=torch.float64)\n",
      "#Loss 37 = tensor(27.2755, dtype=torch.float64)\n",
      "#Loss 38 = tensor(26.7930, dtype=torch.float64)\n",
      "#Loss 39 = tensor(26.4480, dtype=torch.float64)\n",
      "#Loss 40 = tensor(26.2255, dtype=torch.float64)\n",
      "#Loss 41 = tensor(25.8537, dtype=torch.float64)\n",
      "#Loss 42 = tensor(25.5435, dtype=torch.float64)\n",
      "#Loss 43 = tensor(25.3926, dtype=torch.float64)\n",
      "#Loss 44 = tensor(25.2033, dtype=torch.float64)\n",
      "#Loss 45 = tensor(24.9539, dtype=torch.float64)\n",
      "#Loss 46 = tensor(24.5853, dtype=torch.float64)\n",
      "#Loss 47 = tensor(24.3948, dtype=torch.float64)\n",
      "#Loss 48 = tensor(24.1514, dtype=torch.float64)\n",
      "#Loss 49 = tensor(23.7430, dtype=torch.float64)\n",
      "#Loss 50 = tensor(23.4842, dtype=torch.float64)\n",
      "#Loss 51 = tensor(23.2099, dtype=torch.float64)\n",
      "#Loss 52 = tensor(22.9320, dtype=torch.float64)\n",
      "#Loss 53 = tensor(22.7641, dtype=torch.float64)\n",
      "#Loss 54 = tensor(22.4645, dtype=torch.float64)\n",
      "#Loss 55 = tensor(22.2570, dtype=torch.float64)\n",
      "#Loss 56 = tensor(22.0133, dtype=torch.float64)\n",
      "#Loss 57 = tensor(21.7809, dtype=torch.float64)\n",
      "#Loss 58 = tensor(21.3473, dtype=torch.float64)\n",
      "#Loss 59 = tensor(21.0103, dtype=torch.float64)\n",
      "#Loss 60 = tensor(20.8488, dtype=torch.float64)\n",
      "#Loss 61 = tensor(20.7445, dtype=torch.float64)\n",
      "#Loss 62 = tensor(20.6625, dtype=torch.float64)\n",
      "#Loss 63 = tensor(20.6000, dtype=torch.float64)\n",
      "#Loss 64 = tensor(20.5719, dtype=torch.float64)\n",
      "#Loss 65 = tensor(20.4647, dtype=torch.float64)\n",
      "#Loss 66 = tensor(20.2830, dtype=torch.float64)\n",
      "#Loss 67 = tensor(20.0726, dtype=torch.float64)\n",
      "#Loss 68 = tensor(19.7617, dtype=torch.float64)\n",
      "#Loss 69 = tensor(19.5184, dtype=torch.float64)\n",
      "#Loss 70 = tensor(19.3092, dtype=torch.float64)\n",
      "#Loss 71 = tensor(19.2204, dtype=torch.float64)\n",
      "#Loss 72 = tensor(19.0944, dtype=torch.float64)\n",
      "#Loss 73 = tensor(19.0146, dtype=torch.float64)\n",
      "#Loss 74 = tensor(18.9471, dtype=torch.float64)\n",
      "#Loss 75 = tensor(18.8898, dtype=torch.float64)\n",
      "#Loss 76 = tensor(18.7925, dtype=torch.float64)\n",
      "#Loss 77 = tensor(18.6804, dtype=torch.float64)\n",
      "#Loss 78 = tensor(18.5470, dtype=torch.float64)\n",
      "#Loss 79 = tensor(18.3174, dtype=torch.float64)\n",
      "#Loss 80 = tensor(18.1528, dtype=torch.float64)\n",
      "#Loss 81 = tensor(18.0980, dtype=torch.float64)\n",
      "#Loss 82 = tensor(17.9901, dtype=torch.float64)\n",
      "#Loss 83 = tensor(17.7333, dtype=torch.float64)\n",
      "#Loss 84 = tensor(17.4463, dtype=torch.float64)\n",
      "#Loss 85 = tensor(17.1335, dtype=torch.float64)\n",
      "#Loss 86 = tensor(16.8779, dtype=torch.float64)\n",
      "#Loss 87 = tensor(16.7160, dtype=torch.float64)\n",
      "#Loss 88 = tensor(16.6256, dtype=torch.float64)\n",
      "#Loss 89 = tensor(16.5403, dtype=torch.float64)\n",
      "#Loss 90 = tensor(16.5011, dtype=torch.float64)\n",
      "#Loss 91 = tensor(16.4827, dtype=torch.float64)\n",
      "#Loss 92 = tensor(16.4708, dtype=torch.float64)\n",
      "#Loss 93 = tensor(16.4602, dtype=torch.float64)\n",
      "#Loss 94 = tensor(16.4551, dtype=torch.float64)\n",
      "#Loss 95 = tensor(16.4520, dtype=torch.float64)\n",
      "#Loss 96 = tensor(16.4492, dtype=torch.float64)\n",
      "#Loss 97 = tensor(16.4249, dtype=torch.float64)\n",
      "#Loss 98 = tensor(16.4103, dtype=torch.float64)\n",
      "#Loss 99 = tensor(16.3841, dtype=torch.float64)\n",
      "#Loss 100 = tensor(16.3737, dtype=torch.float64)\n",
      "#Loss 101 = tensor(16.3697, dtype=torch.float64)\n",
      "#Loss 102 = tensor(16.3679, dtype=torch.float64)\n",
      "#Loss 103 = tensor(16.3652, dtype=torch.float64)\n",
      "#Loss 104 = tensor(16.3638, dtype=torch.float64)\n",
      "#Loss 105 = tensor(16.3558, dtype=torch.float64)\n",
      "#Loss 106 = tensor(16.3525, dtype=torch.float64)\n",
      "#Loss 107 = tensor(16.3516, dtype=torch.float64)\n",
      "#Loss 108 = tensor(16.3512, dtype=torch.float64)\n",
      "#Loss 109 = tensor(16.3510, dtype=torch.float64)\n",
      "#Loss 110 = tensor(16.3509, dtype=torch.float64)\n",
      "#Loss 111 = tensor(16.3509, dtype=torch.float64)\n",
      "#Loss 112 = tensor(16.3508, dtype=torch.float64)\n",
      "#Loss 113 = tensor(16.3508, dtype=torch.float64)\n",
      "#Loss 114 = tensor(16.3508, dtype=torch.float64)\n",
      "#Loss 115 = tensor(16.3508, dtype=torch.float64)\n",
      "#Loss 116 = tensor(16.3508, dtype=torch.float64)\n",
      "#Loss 117 = tensor(16.3508, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(7.8527, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4095, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0512, dtype=torch.float64)   实验回归误差 tensor(0.0549, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(4718.4092, dtype=torch.float64)\n",
      "#Loss 1 = tensor(4658.6130, dtype=torch.float64)\n",
      "#Loss 2 = tensor(400.6769, dtype=torch.float64)\n",
      "#Loss 3 = tensor(340.9822, dtype=torch.float64)\n",
      "#Loss 4 = tensor(298.0492, dtype=torch.float64)\n",
      "#Loss 5 = tensor(259.9021, dtype=torch.float64)\n",
      "#Loss 6 = tensor(222.8322, dtype=torch.float64)\n",
      "#Loss 7 = tensor(192.4755, dtype=torch.float64)\n",
      "#Loss 8 = tensor(170.4320, dtype=torch.float64)\n",
      "#Loss 9 = tensor(151.1872, dtype=torch.float64)\n",
      "#Loss 10 = tensor(129.9477, dtype=torch.float64)\n",
      "#Loss 11 = tensor(114.4275, dtype=torch.float64)\n",
      "#Loss 12 = tensor(103.2040, dtype=torch.float64)\n",
      "#Loss 13 = tensor(93.3050, dtype=torch.float64)\n",
      "#Loss 14 = tensor(85.5771, dtype=torch.float64)\n",
      "#Loss 15 = tensor(78.0997, dtype=torch.float64)\n",
      "#Loss 16 = tensor(71.3676, dtype=torch.float64)\n",
      "#Loss 17 = tensor(65.5940, dtype=torch.float64)\n",
      "#Loss 18 = tensor(59.9223, dtype=torch.float64)\n",
      "#Loss 19 = tensor(55.1672, dtype=torch.float64)\n",
      "#Loss 20 = tensor(51.6971, dtype=torch.float64)\n",
      "#Loss 21 = tensor(48.8907, dtype=torch.float64)\n",
      "#Loss 22 = tensor(45.9252, dtype=torch.float64)\n",
      "#Loss 23 = tensor(42.9958, dtype=torch.float64)\n",
      "#Loss 24 = tensor(40.5442, dtype=torch.float64)\n",
      "#Loss 25 = tensor(37.8832, dtype=torch.float64)\n",
      "#Loss 26 = tensor(35.4964, dtype=torch.float64)\n",
      "#Loss 27 = tensor(33.4711, dtype=torch.float64)\n",
      "#Loss 28 = tensor(32.3025, dtype=torch.float64)\n",
      "#Loss 29 = tensor(31.2310, dtype=torch.float64)\n",
      "#Loss 30 = tensor(29.8197, dtype=torch.float64)\n",
      "#Loss 31 = tensor(28.6603, dtype=torch.float64)\n",
      "#Loss 32 = tensor(27.3945, dtype=torch.float64)\n",
      "#Loss 33 = tensor(26.2645, dtype=torch.float64)\n",
      "#Loss 34 = tensor(23.2304, dtype=torch.float64)\n",
      "#Loss 35 = tensor(21.2925, dtype=torch.float64)\n",
      "#Loss 36 = tensor(20.0194, dtype=torch.float64)\n",
      "#Loss 37 = tensor(18.5860, dtype=torch.float64)\n",
      "#Loss 38 = tensor(17.7945, dtype=torch.float64)\n",
      "#Loss 39 = tensor(17.3129, dtype=torch.float64)\n",
      "#Loss 40 = tensor(17.0920, dtype=torch.float64)\n",
      "#Loss 41 = tensor(16.8000, dtype=torch.float64)\n",
      "#Loss 42 = tensor(16.1995, dtype=torch.float64)\n",
      "#Loss 43 = tensor(15.5074, dtype=torch.float64)\n",
      "#Loss 44 = tensor(15.0336, dtype=torch.float64)\n",
      "#Loss 45 = tensor(14.5466, dtype=torch.float64)\n",
      "#Loss 46 = tensor(14.1594, dtype=torch.float64)\n",
      "#Loss 47 = tensor(13.7148, dtype=torch.float64)\n",
      "#Loss 48 = tensor(13.3075, dtype=torch.float64)\n",
      "#Loss 49 = tensor(12.8438, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 50 = tensor(12.5141, dtype=torch.float64)\n",
      "#Loss 51 = tensor(12.0972, dtype=torch.float64)\n",
      "#Loss 52 = tensor(11.6705, dtype=torch.float64)\n",
      "#Loss 53 = tensor(11.1726, dtype=torch.float64)\n",
      "#Loss 54 = tensor(10.7840, dtype=torch.float64)\n",
      "#Loss 55 = tensor(10.3023, dtype=torch.float64)\n",
      "#Loss 56 = tensor(9.7812, dtype=torch.float64)\n",
      "#Loss 57 = tensor(9.3522, dtype=torch.float64)\n",
      "#Loss 58 = tensor(8.9876, dtype=torch.float64)\n",
      "#Loss 59 = tensor(8.6495, dtype=torch.float64)\n",
      "#Loss 60 = tensor(8.3083, dtype=torch.float64)\n",
      "#Loss 61 = tensor(8.1315, dtype=torch.float64)\n",
      "#Loss 62 = tensor(7.9189, dtype=torch.float64)\n",
      "#Loss 63 = tensor(7.7102, dtype=torch.float64)\n",
      "#Loss 64 = tensor(7.4142, dtype=torch.float64)\n",
      "#Loss 65 = tensor(7.2235, dtype=torch.float64)\n",
      "#Loss 66 = tensor(7.0698, dtype=torch.float64)\n",
      "#Loss 67 = tensor(6.9655, dtype=torch.float64)\n",
      "#Loss 68 = tensor(6.8120, dtype=torch.float64)\n",
      "#Loss 69 = tensor(6.6858, dtype=torch.float64)\n",
      "#Loss 70 = tensor(6.5986, dtype=torch.float64)\n",
      "#Loss 71 = tensor(6.5377, dtype=torch.float64)\n",
      "#Loss 72 = tensor(6.4793, dtype=torch.float64)\n",
      "#Loss 73 = tensor(6.4417, dtype=torch.float64)\n",
      "#Loss 74 = tensor(6.4313, dtype=torch.float64)\n",
      "#Loss 75 = tensor(6.4278, dtype=torch.float64)\n",
      "#Loss 76 = tensor(6.4260, dtype=torch.float64)\n",
      "#Loss 77 = tensor(6.4226, dtype=torch.float64)\n",
      "#Loss 78 = tensor(6.4216, dtype=torch.float64)\n",
      "#Loss 79 = tensor(6.4211, dtype=torch.float64)\n",
      "#Loss 80 = tensor(6.4207, dtype=torch.float64)\n",
      "#Loss 81 = tensor(6.3875, dtype=torch.float64)\n",
      "#Loss 82 = tensor(6.3434, dtype=torch.float64)\n",
      "#Loss 83 = tensor(6.3298, dtype=torch.float64)\n",
      "#Loss 84 = tensor(6.3154, dtype=torch.float64)\n",
      "#Loss 85 = tensor(6.3120, dtype=torch.float64)\n",
      "#Loss 86 = tensor(6.3107, dtype=torch.float64)\n",
      "#Loss 87 = tensor(6.3102, dtype=torch.float64)\n",
      "#Loss 88 = tensor(6.3100, dtype=torch.float64)\n",
      "#Loss 89 = tensor(6.3099, dtype=torch.float64)\n",
      "#Loss 90 = tensor(6.3098, dtype=torch.float64)\n",
      "#Loss 91 = tensor(6.3098, dtype=torch.float64)\n",
      "#Loss 92 = tensor(6.3098, dtype=torch.float64)\n",
      "#Loss 93 = tensor(6.3098, dtype=torch.float64)\n",
      "#Loss 94 = tensor(6.3098, dtype=torch.float64)\n",
      "#Loss 95 = tensor(6.3098, dtype=torch.float64)\n",
      "#Loss 96 = tensor(6.3098, dtype=torch.float64)\n",
      "#Loss 97 = tensor(6.3098, dtype=torch.float64)\n",
      "#Loss 98 = tensor(6.3098, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(5.7628, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4000, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0508, dtype=torch.float64)   实验回归误差 tensor(0.0366, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(3724.8166, dtype=torch.float64)\n",
      "#Loss 1 = tensor(3397.3929, dtype=torch.float64)\n",
      "#Loss 2 = tensor(195.3102, dtype=torch.float64)\n",
      "#Loss 3 = tensor(167.6070, dtype=torch.float64)\n",
      "#Loss 4 = tensor(142.7370, dtype=torch.float64)\n",
      "#Loss 5 = tensor(120.6124, dtype=torch.float64)\n",
      "#Loss 6 = tensor(101.7071, dtype=torch.float64)\n",
      "#Loss 7 = tensor(86.0784, dtype=torch.float64)\n",
      "#Loss 8 = tensor(73.9267, dtype=torch.float64)\n",
      "#Loss 9 = tensor(63.5799, dtype=torch.float64)\n",
      "#Loss 10 = tensor(54.7828, dtype=torch.float64)\n",
      "#Loss 11 = tensor(47.2918, dtype=torch.float64)\n",
      "#Loss 12 = tensor(41.6926, dtype=torch.float64)\n",
      "#Loss 13 = tensor(36.2479, dtype=torch.float64)\n",
      "#Loss 14 = tensor(30.3675, dtype=torch.float64)\n",
      "#Loss 15 = tensor(26.5651, dtype=torch.float64)\n",
      "#Loss 16 = tensor(23.6183, dtype=torch.float64)\n",
      "#Loss 17 = tensor(21.4543, dtype=torch.float64)\n",
      "#Loss 18 = tensor(20.0370, dtype=torch.float64)\n",
      "#Loss 19 = tensor(18.7359, dtype=torch.float64)\n",
      "#Loss 20 = tensor(17.5363, dtype=torch.float64)\n",
      "#Loss 21 = tensor(16.4026, dtype=torch.float64)\n",
      "#Loss 22 = tensor(14.8856, dtype=torch.float64)\n",
      "#Loss 23 = tensor(13.1499, dtype=torch.float64)\n",
      "#Loss 24 = tensor(11.5899, dtype=torch.float64)\n",
      "#Loss 25 = tensor(10.2332, dtype=torch.float64)\n",
      "#Loss 26 = tensor(9.2268, dtype=torch.float64)\n",
      "#Loss 27 = tensor(8.5256, dtype=torch.float64)\n",
      "#Loss 28 = tensor(8.0271, dtype=torch.float64)\n",
      "#Loss 29 = tensor(7.6399, dtype=torch.float64)\n",
      "#Loss 30 = tensor(7.3217, dtype=torch.float64)\n",
      "#Loss 31 = tensor(7.0597, dtype=torch.float64)\n",
      "#Loss 32 = tensor(6.9342, dtype=torch.float64)\n",
      "#Loss 33 = tensor(6.7406, dtype=torch.float64)\n",
      "#Loss 34 = tensor(6.6051, dtype=torch.float64)\n",
      "#Loss 35 = tensor(6.5347, dtype=torch.float64)\n",
      "#Loss 36 = tensor(6.2989, dtype=torch.float64)\n",
      "#Loss 37 = tensor(6.0440, dtype=torch.float64)\n",
      "#Loss 38 = tensor(5.8760, dtype=torch.float64)\n",
      "#Loss 39 = tensor(5.5862, dtype=torch.float64)\n",
      "#Loss 40 = tensor(5.4360, dtype=torch.float64)\n",
      "#Loss 41 = tensor(5.3330, dtype=torch.float64)\n",
      "#Loss 42 = tensor(5.2145, dtype=torch.float64)\n",
      "#Loss 43 = tensor(4.9782, dtype=torch.float64)\n",
      "#Loss 44 = tensor(4.6967, dtype=torch.float64)\n",
      "#Loss 45 = tensor(4.4388, dtype=torch.float64)\n",
      "#Loss 46 = tensor(4.2926, dtype=torch.float64)\n",
      "#Loss 47 = tensor(4.1148, dtype=torch.float64)\n",
      "#Loss 48 = tensor(3.9822, dtype=torch.float64)\n",
      "#Loss 49 = tensor(3.8861, dtype=torch.float64)\n",
      "#Loss 50 = tensor(3.7961, dtype=torch.float64)\n",
      "#Loss 51 = tensor(3.7260, dtype=torch.float64)\n",
      "#Loss 52 = tensor(3.7101, dtype=torch.float64)\n",
      "#Loss 53 = tensor(3.6393, dtype=torch.float64)\n",
      "#Loss 54 = tensor(3.6082, dtype=torch.float64)\n",
      "#Loss 55 = tensor(3.5955, dtype=torch.float64)\n",
      "#Loss 56 = tensor(3.5433, dtype=torch.float64)\n",
      "#Loss 57 = tensor(3.5031, dtype=torch.float64)\n",
      "#Loss 58 = tensor(3.4907, dtype=torch.float64)\n",
      "#Loss 59 = tensor(3.4857, dtype=torch.float64)\n",
      "#Loss 60 = tensor(3.4835, dtype=torch.float64)\n",
      "#Loss 61 = tensor(3.4826, dtype=torch.float64)\n",
      "#Loss 62 = tensor(3.4822, dtype=torch.float64)\n",
      "#Loss 63 = tensor(3.4819, dtype=torch.float64)\n",
      "#Loss 64 = tensor(3.4818, dtype=torch.float64)\n",
      "#Loss 65 = tensor(3.4818, dtype=torch.float64)\n",
      "#Loss 66 = tensor(3.4817, dtype=torch.float64)\n",
      "#Loss 67 = tensor(3.4817, dtype=torch.float64)\n",
      "#Loss 68 = tensor(3.4817, dtype=torch.float64)\n",
      "#Loss 69 = tensor(3.4817, dtype=torch.float64)\n",
      "#Loss 70 = tensor(3.4817, dtype=torch.float64)\n",
      "#Loss 71 = tensor(3.4817, dtype=torch.float64)\n",
      "#Loss 72 = tensor(3.4817, dtype=torch.float64)\n",
      "#Loss 73 = tensor(3.4817, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(6.7288, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4048, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0564, dtype=torch.float64)   实验回归误差 tensor(0.0306, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(4286.7119, dtype=torch.float64)\n",
      "#Loss 1 = tensor(4100.1117, dtype=torch.float64)\n",
      "#Loss 2 = tensor(398.5794, dtype=torch.float64)\n",
      "#Loss 3 = tensor(304.7700, dtype=torch.float64)\n",
      "#Loss 4 = tensor(226.5877, dtype=torch.float64)\n",
      "#Loss 5 = tensor(171.3091, dtype=torch.float64)\n",
      "#Loss 6 = tensor(127.6976, dtype=torch.float64)\n",
      "#Loss 7 = tensor(98.0176, dtype=torch.float64)\n",
      "#Loss 8 = tensor(76.3487, dtype=torch.float64)\n",
      "#Loss 9 = tensor(62.2595, dtype=torch.float64)\n",
      "#Loss 10 = tensor(52.9666, dtype=torch.float64)\n",
      "#Loss 11 = tensor(43.5249, dtype=torch.float64)\n",
      "#Loss 12 = tensor(36.7618, dtype=torch.float64)\n",
      "#Loss 13 = tensor(31.2176, dtype=torch.float64)\n",
      "#Loss 14 = tensor(27.5376, dtype=torch.float64)\n",
      "#Loss 15 = tensor(23.0265, dtype=torch.float64)\n",
      "#Loss 16 = tensor(18.9280, dtype=torch.float64)\n",
      "#Loss 17 = tensor(15.4049, dtype=torch.float64)\n",
      "#Loss 18 = tensor(12.9161, dtype=torch.float64)\n",
      "#Loss 19 = tensor(10.9517, dtype=torch.float64)\n",
      "#Loss 20 = tensor(9.8731, dtype=torch.float64)\n",
      "#Loss 21 = tensor(9.2343, dtype=torch.float64)\n",
      "#Loss 22 = tensor(8.7997, dtype=torch.float64)\n",
      "#Loss 23 = tensor(8.3633, dtype=torch.float64)\n",
      "#Loss 24 = tensor(8.0221, dtype=torch.float64)\n",
      "#Loss 25 = tensor(7.7039, dtype=torch.float64)\n",
      "#Loss 26 = tensor(7.3367, dtype=torch.float64)\n",
      "#Loss 27 = tensor(7.1916, dtype=torch.float64)\n",
      "#Loss 28 = tensor(7.0899, dtype=torch.float64)\n",
      "#Loss 29 = tensor(7.0296, dtype=torch.float64)\n",
      "#Loss 30 = tensor(6.9868, dtype=torch.float64)\n",
      "#Loss 31 = tensor(6.9753, dtype=torch.float64)\n",
      "#Loss 32 = tensor(6.9698, dtype=torch.float64)\n",
      "#Loss 33 = tensor(6.9518, dtype=torch.float64)\n",
      "#Loss 34 = tensor(6.9188, dtype=torch.float64)\n",
      "#Loss 35 = tensor(6.8449, dtype=torch.float64)\n",
      "#Loss 36 = tensor(6.8288, dtype=torch.float64)\n",
      "#Loss 37 = tensor(6.8011, dtype=torch.float64)\n",
      "#Loss 38 = tensor(6.7665, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 39 = tensor(6.6974, dtype=torch.float64)\n",
      "#Loss 40 = tensor(6.4198, dtype=torch.float64)\n",
      "#Loss 41 = tensor(6.3123, dtype=torch.float64)\n",
      "#Loss 42 = tensor(6.1525, dtype=torch.float64)\n",
      "#Loss 43 = tensor(6.0564, dtype=torch.float64)\n",
      "#Loss 44 = tensor(5.9986, dtype=torch.float64)\n",
      "#Loss 45 = tensor(5.8787, dtype=torch.float64)\n",
      "#Loss 46 = tensor(5.7680, dtype=torch.float64)\n",
      "#Loss 47 = tensor(5.6996, dtype=torch.float64)\n",
      "#Loss 48 = tensor(5.6152, dtype=torch.float64)\n",
      "#Loss 49 = tensor(5.5335, dtype=torch.float64)\n",
      "#Loss 50 = tensor(5.4660, dtype=torch.float64)\n",
      "#Loss 51 = tensor(5.3594, dtype=torch.float64)\n",
      "#Loss 52 = tensor(5.3238, dtype=torch.float64)\n",
      "#Loss 53 = tensor(5.2515, dtype=torch.float64)\n",
      "#Loss 54 = tensor(5.1442, dtype=torch.float64)\n",
      "#Loss 55 = tensor(5.0416, dtype=torch.float64)\n",
      "#Loss 56 = tensor(5.0040, dtype=torch.float64)\n",
      "#Loss 57 = tensor(4.9585, dtype=torch.float64)\n",
      "#Loss 58 = tensor(4.9464, dtype=torch.float64)\n",
      "#Loss 59 = tensor(4.9299, dtype=torch.float64)\n",
      "#Loss 60 = tensor(4.8294, dtype=torch.float64)\n",
      "#Loss 61 = tensor(4.7333, dtype=torch.float64)\n",
      "#Loss 62 = tensor(4.6540, dtype=torch.float64)\n",
      "#Loss 63 = tensor(4.5969, dtype=torch.float64)\n",
      "#Loss 64 = tensor(4.5793, dtype=torch.float64)\n",
      "#Loss 65 = tensor(4.5731, dtype=torch.float64)\n",
      "#Loss 66 = tensor(4.5712, dtype=torch.float64)\n",
      "#Loss 67 = tensor(4.5705, dtype=torch.float64)\n",
      "#Loss 68 = tensor(4.5702, dtype=torch.float64)\n",
      "#Loss 69 = tensor(4.5701, dtype=torch.float64)\n",
      "#Loss 70 = tensor(4.5701, dtype=torch.float64)\n",
      "#Loss 71 = tensor(4.5700, dtype=torch.float64)\n",
      "#Loss 72 = tensor(4.5700, dtype=torch.float64)\n",
      "#Loss 73 = tensor(4.5700, dtype=torch.float64)\n",
      "#Loss 74 = tensor(4.5700, dtype=torch.float64)\n",
      "#Loss 75 = tensor(4.5700, dtype=torch.float64)\n",
      "#Loss 76 = tensor(4.5700, dtype=torch.float64)\n",
      "#Loss 77 = tensor(4.5700, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(6.1312, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4048, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0617, dtype=torch.float64)   实验回归误差 tensor(0.0327, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(4447.5363, dtype=torch.float64)\n",
      "#Loss 1 = tensor(4323.2613, dtype=torch.float64)\n",
      "#Loss 2 = tensor(557.9811, dtype=torch.float64)\n",
      "#Loss 3 = tensor(432.8495, dtype=torch.float64)\n",
      "#Loss 4 = tensor(326.6593, dtype=torch.float64)\n",
      "#Loss 5 = tensor(245.7901, dtype=torch.float64)\n",
      "#Loss 6 = tensor(184.0485, dtype=torch.float64)\n",
      "#Loss 7 = tensor(140.8781, dtype=torch.float64)\n",
      "#Loss 8 = tensor(110.5119, dtype=torch.float64)\n",
      "#Loss 9 = tensor(90.6491, dtype=torch.float64)\n",
      "#Loss 10 = tensor(74.5428, dtype=torch.float64)\n",
      "#Loss 11 = tensor(61.0783, dtype=torch.float64)\n",
      "#Loss 12 = tensor(48.9697, dtype=torch.float64)\n",
      "#Loss 13 = tensor(41.6313, dtype=torch.float64)\n",
      "#Loss 14 = tensor(34.7848, dtype=torch.float64)\n",
      "#Loss 15 = tensor(28.9684, dtype=torch.float64)\n",
      "#Loss 16 = tensor(25.2399, dtype=torch.float64)\n",
      "#Loss 17 = tensor(20.8677, dtype=torch.float64)\n",
      "#Loss 18 = tensor(17.1140, dtype=torch.float64)\n",
      "#Loss 19 = tensor(13.8681, dtype=torch.float64)\n",
      "#Loss 20 = tensor(11.8636, dtype=torch.float64)\n",
      "#Loss 21 = tensor(10.5967, dtype=torch.float64)\n",
      "#Loss 22 = tensor(9.7454, dtype=torch.float64)\n",
      "#Loss 23 = tensor(8.7994, dtype=torch.float64)\n",
      "#Loss 24 = tensor(8.4028, dtype=torch.float64)\n",
      "#Loss 25 = tensor(7.9873, dtype=torch.float64)\n",
      "#Loss 26 = tensor(7.6268, dtype=torch.float64)\n",
      "#Loss 27 = tensor(7.2426, dtype=torch.float64)\n",
      "#Loss 28 = tensor(6.9995, dtype=torch.float64)\n",
      "#Loss 29 = tensor(6.8543, dtype=torch.float64)\n",
      "#Loss 30 = tensor(6.5670, dtype=torch.float64)\n",
      "#Loss 31 = tensor(6.3747, dtype=torch.float64)\n",
      "#Loss 32 = tensor(6.2902, dtype=torch.float64)\n",
      "#Loss 33 = tensor(6.2379, dtype=torch.float64)\n",
      "#Loss 34 = tensor(6.1763, dtype=torch.float64)\n",
      "#Loss 35 = tensor(6.1287, dtype=torch.float64)\n",
      "#Loss 36 = tensor(6.0479, dtype=torch.float64)\n",
      "#Loss 37 = tensor(5.8242, dtype=torch.float64)\n",
      "#Loss 38 = tensor(5.6874, dtype=torch.float64)\n",
      "#Loss 39 = tensor(5.5606, dtype=torch.float64)\n",
      "#Loss 40 = tensor(5.4432, dtype=torch.float64)\n",
      "#Loss 41 = tensor(5.3748, dtype=torch.float64)\n",
      "#Loss 42 = tensor(5.3358, dtype=torch.float64)\n",
      "#Loss 43 = tensor(5.3025, dtype=torch.float64)\n",
      "#Loss 44 = tensor(5.1939, dtype=torch.float64)\n",
      "#Loss 45 = tensor(5.1511, dtype=torch.float64)\n",
      "#Loss 46 = tensor(5.1212, dtype=torch.float64)\n",
      "#Loss 47 = tensor(5.0996, dtype=torch.float64)\n",
      "#Loss 48 = tensor(5.0919, dtype=torch.float64)\n",
      "#Loss 49 = tensor(5.0682, dtype=torch.float64)\n",
      "#Loss 50 = tensor(5.0184, dtype=torch.float64)\n",
      "#Loss 51 = tensor(5.0024, dtype=torch.float64)\n",
      "#Loss 52 = tensor(4.9943, dtype=torch.float64)\n",
      "#Loss 53 = tensor(4.9779, dtype=torch.float64)\n",
      "#Loss 54 = tensor(4.9739, dtype=torch.float64)\n",
      "#Loss 55 = tensor(4.9294, dtype=torch.float64)\n",
      "#Loss 56 = tensor(4.8739, dtype=torch.float64)\n",
      "#Loss 57 = tensor(4.8446, dtype=torch.float64)\n",
      "#Loss 58 = tensor(4.8037, dtype=torch.float64)\n",
      "#Loss 59 = tensor(4.7903, dtype=torch.float64)\n",
      "#Loss 60 = tensor(4.7840, dtype=torch.float64)\n",
      "#Loss 61 = tensor(4.7441, dtype=torch.float64)\n",
      "#Loss 62 = tensor(4.7337, dtype=torch.float64)\n",
      "#Loss 63 = tensor(4.7307, dtype=torch.float64)\n",
      "#Loss 64 = tensor(4.7296, dtype=torch.float64)\n",
      "#Loss 65 = tensor(4.7291, dtype=torch.float64)\n",
      "#Loss 66 = tensor(4.7289, dtype=torch.float64)\n",
      "#Loss 67 = tensor(4.7288, dtype=torch.float64)\n",
      "#Loss 68 = tensor(4.7271, dtype=torch.float64)\n",
      "#Loss 69 = tensor(4.7202, dtype=torch.float64)\n",
      "#Loss 70 = tensor(4.7177, dtype=torch.float64)\n",
      "#Loss 71 = tensor(4.7173, dtype=torch.float64)\n",
      "#Loss 72 = tensor(4.7172, dtype=torch.float64)\n",
      "#Loss 73 = tensor(4.7171, dtype=torch.float64)\n",
      "#Loss 74 = tensor(4.7171, dtype=torch.float64)\n",
      "#Loss 75 = tensor(4.7171, dtype=torch.float64)\n",
      "#Loss 76 = tensor(4.7171, dtype=torch.float64)\n",
      "#Loss 77 = tensor(4.7171, dtype=torch.float64)\n",
      "#Loss 78 = tensor(4.7171, dtype=torch.float64)\n",
      "#Loss 79 = tensor(4.7171, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(6.5189, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4048, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0534, dtype=torch.float64)   实验回归误差 tensor(0.0326, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(3092.8870, dtype=torch.float64)\n",
      "#Loss 1 = tensor(2994.3512, dtype=torch.float64)\n",
      "#Loss 2 = tensor(271.5646, dtype=torch.float64)\n",
      "#Loss 3 = tensor(204.7939, dtype=torch.float64)\n",
      "#Loss 4 = tensor(185.1688, dtype=torch.float64)\n",
      "#Loss 5 = tensor(169.2847, dtype=torch.float64)\n",
      "#Loss 6 = tensor(154.8718, dtype=torch.float64)\n",
      "#Loss 7 = tensor(141.8982, dtype=torch.float64)\n",
      "#Loss 8 = tensor(131.6331, dtype=torch.float64)\n",
      "#Loss 9 = tensor(123.2124, dtype=torch.float64)\n",
      "#Loss 10 = tensor(116.0011, dtype=torch.float64)\n",
      "#Loss 11 = tensor(107.5516, dtype=torch.float64)\n",
      "#Loss 12 = tensor(101.0606, dtype=torch.float64)\n",
      "#Loss 13 = tensor(93.9162, dtype=torch.float64)\n",
      "#Loss 14 = tensor(86.9999, dtype=torch.float64)\n",
      "#Loss 15 = tensor(81.6887, dtype=torch.float64)\n",
      "#Loss 16 = tensor(75.7030, dtype=torch.float64)\n",
      "#Loss 17 = tensor(70.5424, dtype=torch.float64)\n",
      "#Loss 18 = tensor(62.6042, dtype=torch.float64)\n",
      "#Loss 19 = tensor(57.5160, dtype=torch.float64)\n",
      "#Loss 20 = tensor(53.0234, dtype=torch.float64)\n",
      "#Loss 21 = tensor(48.6863, dtype=torch.float64)\n",
      "#Loss 22 = tensor(44.7109, dtype=torch.float64)\n",
      "#Loss 23 = tensor(40.8900, dtype=torch.float64)\n",
      "#Loss 24 = tensor(37.6589, dtype=torch.float64)\n",
      "#Loss 25 = tensor(35.1780, dtype=torch.float64)\n",
      "#Loss 26 = tensor(33.1679, dtype=torch.float64)\n",
      "#Loss 27 = tensor(31.2764, dtype=torch.float64)\n",
      "#Loss 28 = tensor(29.7687, dtype=torch.float64)\n",
      "#Loss 29 = tensor(28.6219, dtype=torch.float64)\n",
      "#Loss 30 = tensor(27.8391, dtype=torch.float64)\n",
      "#Loss 31 = tensor(27.4250, dtype=torch.float64)\n",
      "#Loss 32 = tensor(26.7580, dtype=torch.float64)\n",
      "#Loss 33 = tensor(25.9563, dtype=torch.float64)\n",
      "#Loss 34 = tensor(24.6305, dtype=torch.float64)\n",
      "#Loss 35 = tensor(23.4808, dtype=torch.float64)\n",
      "#Loss 36 = tensor(21.9331, dtype=torch.float64)\n",
      "#Loss 37 = tensor(20.4462, dtype=torch.float64)\n",
      "#Loss 38 = tensor(18.5731, dtype=torch.float64)\n",
      "#Loss 39 = tensor(17.7859, dtype=torch.float64)\n",
      "#Loss 40 = tensor(16.7039, dtype=torch.float64)\n",
      "#Loss 41 = tensor(15.1284, dtype=torch.float64)\n",
      "#Loss 42 = tensor(14.0597, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 43 = tensor(13.2578, dtype=torch.float64)\n",
      "#Loss 44 = tensor(12.4165, dtype=torch.float64)\n",
      "#Loss 45 = tensor(11.7716, dtype=torch.float64)\n",
      "#Loss 46 = tensor(11.0806, dtype=torch.float64)\n",
      "#Loss 47 = tensor(10.6226, dtype=torch.float64)\n",
      "#Loss 48 = tensor(10.3237, dtype=torch.float64)\n",
      "#Loss 49 = tensor(10.0721, dtype=torch.float64)\n",
      "#Loss 50 = tensor(9.7535, dtype=torch.float64)\n",
      "#Loss 51 = tensor(9.5995, dtype=torch.float64)\n",
      "#Loss 52 = tensor(9.3307, dtype=torch.float64)\n",
      "#Loss 53 = tensor(8.8136, dtype=torch.float64)\n",
      "#Loss 54 = tensor(8.5081, dtype=torch.float64)\n",
      "#Loss 55 = tensor(8.2456, dtype=torch.float64)\n",
      "#Loss 56 = tensor(8.0053, dtype=torch.float64)\n",
      "#Loss 57 = tensor(7.7541, dtype=torch.float64)\n",
      "#Loss 58 = tensor(7.5751, dtype=torch.float64)\n",
      "#Loss 59 = tensor(7.3546, dtype=torch.float64)\n",
      "#Loss 60 = tensor(7.1207, dtype=torch.float64)\n",
      "#Loss 61 = tensor(7.0207, dtype=torch.float64)\n",
      "#Loss 62 = tensor(6.9022, dtype=torch.float64)\n",
      "#Loss 63 = tensor(6.8367, dtype=torch.float64)\n",
      "#Loss 64 = tensor(6.8065, dtype=torch.float64)\n",
      "#Loss 65 = tensor(6.7859, dtype=torch.float64)\n",
      "#Loss 66 = tensor(6.7803, dtype=torch.float64)\n",
      "#Loss 67 = tensor(6.7737, dtype=torch.float64)\n",
      "#Loss 68 = tensor(6.7649, dtype=torch.float64)\n",
      "#Loss 69 = tensor(6.7615, dtype=torch.float64)\n",
      "#Loss 70 = tensor(6.7602, dtype=torch.float64)\n",
      "#Loss 71 = tensor(6.7552, dtype=torch.float64)\n",
      "#Loss 72 = tensor(6.7530, dtype=torch.float64)\n",
      "#Loss 73 = tensor(6.7520, dtype=torch.float64)\n",
      "#Loss 74 = tensor(6.7515, dtype=torch.float64)\n",
      "#Loss 75 = tensor(6.7504, dtype=torch.float64)\n",
      "#Loss 76 = tensor(6.7501, dtype=torch.float64)\n",
      "#Loss 77 = tensor(6.7499, dtype=torch.float64)\n",
      "#Loss 78 = tensor(6.7499, dtype=torch.float64)\n",
      "#Loss 79 = tensor(6.7495, dtype=torch.float64)\n",
      "#Loss 80 = tensor(6.7494, dtype=torch.float64)\n",
      "#Loss 81 = tensor(6.7494, dtype=torch.float64)\n",
      "#Loss 82 = tensor(6.7493, dtype=torch.float64)\n",
      "#Loss 83 = tensor(6.7492, dtype=torch.float64)\n",
      "#Loss 84 = tensor(6.7492, dtype=torch.float64)\n",
      "#Loss 85 = tensor(6.7492, dtype=torch.float64)\n",
      "#Loss 86 = tensor(6.7492, dtype=torch.float64)\n",
      "#Loss 87 = tensor(6.7492, dtype=torch.float64)\n",
      "#Loss 88 = tensor(6.7492, dtype=torch.float64)\n",
      "#Loss 89 = tensor(6.7492, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(5.0885, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4142, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0603, dtype=torch.float64)   实验回归误差 tensor(0.0467, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(3564.3663, dtype=torch.float64)\n",
      "#Loss 1 = tensor(3452.7578, dtype=torch.float64)\n",
      "#Loss 2 = tensor(390.9452, dtype=torch.float64)\n",
      "#Loss 3 = tensor(325.5093, dtype=torch.float64)\n",
      "#Loss 4 = tensor(280.0448, dtype=torch.float64)\n",
      "#Loss 5 = tensor(238.7679, dtype=torch.float64)\n",
      "#Loss 6 = tensor(198.6821, dtype=torch.float64)\n",
      "#Loss 7 = tensor(167.4970, dtype=torch.float64)\n",
      "#Loss 8 = tensor(141.1317, dtype=torch.float64)\n",
      "#Loss 9 = tensor(122.3864, dtype=torch.float64)\n",
      "#Loss 10 = tensor(109.5333, dtype=torch.float64)\n",
      "#Loss 11 = tensor(94.8980, dtype=torch.float64)\n",
      "#Loss 12 = tensor(84.2219, dtype=torch.float64)\n",
      "#Loss 13 = tensor(77.1041, dtype=torch.float64)\n",
      "#Loss 14 = tensor(70.1026, dtype=torch.float64)\n",
      "#Loss 15 = tensor(63.8985, dtype=torch.float64)\n",
      "#Loss 16 = tensor(57.8669, dtype=torch.float64)\n",
      "#Loss 17 = tensor(54.4779, dtype=torch.float64)\n",
      "#Loss 18 = tensor(51.9352, dtype=torch.float64)\n",
      "#Loss 19 = tensor(48.8412, dtype=torch.float64)\n",
      "#Loss 20 = tensor(46.0584, dtype=torch.float64)\n",
      "#Loss 21 = tensor(43.1640, dtype=torch.float64)\n",
      "#Loss 22 = tensor(40.0271, dtype=torch.float64)\n",
      "#Loss 23 = tensor(37.7920, dtype=torch.float64)\n",
      "#Loss 24 = tensor(36.0289, dtype=torch.float64)\n",
      "#Loss 25 = tensor(33.5268, dtype=torch.float64)\n",
      "#Loss 26 = tensor(30.6635, dtype=torch.float64)\n",
      "#Loss 27 = tensor(27.8893, dtype=torch.float64)\n",
      "#Loss 28 = tensor(25.1349, dtype=torch.float64)\n",
      "#Loss 29 = tensor(23.0689, dtype=torch.float64)\n",
      "#Loss 30 = tensor(21.7717, dtype=torch.float64)\n",
      "#Loss 31 = tensor(20.1362, dtype=torch.float64)\n",
      "#Loss 32 = tensor(18.2125, dtype=torch.float64)\n",
      "#Loss 33 = tensor(16.7462, dtype=torch.float64)\n",
      "#Loss 34 = tensor(15.2861, dtype=torch.float64)\n",
      "#Loss 35 = tensor(14.4241, dtype=torch.float64)\n",
      "#Loss 36 = tensor(13.7241, dtype=torch.float64)\n",
      "#Loss 37 = tensor(13.0166, dtype=torch.float64)\n",
      "#Loss 38 = tensor(12.5856, dtype=torch.float64)\n",
      "#Loss 39 = tensor(12.2943, dtype=torch.float64)\n",
      "#Loss 40 = tensor(12.1060, dtype=torch.float64)\n",
      "#Loss 41 = tensor(11.9470, dtype=torch.float64)\n",
      "#Loss 42 = tensor(11.8413, dtype=torch.float64)\n",
      "#Loss 43 = tensor(11.7192, dtype=torch.float64)\n",
      "#Loss 44 = tensor(11.5889, dtype=torch.float64)\n",
      "#Loss 45 = tensor(11.4001, dtype=torch.float64)\n",
      "#Loss 46 = tensor(11.2030, dtype=torch.float64)\n",
      "#Loss 47 = tensor(11.0815, dtype=torch.float64)\n",
      "#Loss 48 = tensor(10.9991, dtype=torch.float64)\n",
      "#Loss 49 = tensor(10.9648, dtype=torch.float64)\n",
      "#Loss 50 = tensor(10.9451, dtype=torch.float64)\n",
      "#Loss 51 = tensor(10.8825, dtype=torch.float64)\n",
      "#Loss 52 = tensor(10.8604, dtype=torch.float64)\n",
      "#Loss 53 = tensor(10.8511, dtype=torch.float64)\n",
      "#Loss 54 = tensor(10.8446, dtype=torch.float64)\n",
      "#Loss 55 = tensor(10.8235, dtype=torch.float64)\n",
      "#Loss 56 = tensor(10.7989, dtype=torch.float64)\n",
      "#Loss 57 = tensor(10.7828, dtype=torch.float64)\n",
      "#Loss 58 = tensor(10.7626, dtype=torch.float64)\n",
      "#Loss 59 = tensor(10.5878, dtype=torch.float64)\n",
      "#Loss 60 = tensor(10.4737, dtype=torch.float64)\n",
      "#Loss 61 = tensor(10.3983, dtype=torch.float64)\n",
      "#Loss 62 = tensor(10.3488, dtype=torch.float64)\n",
      "#Loss 63 = tensor(10.3188, dtype=torch.float64)\n",
      "#Loss 64 = tensor(10.2835, dtype=torch.float64)\n",
      "#Loss 65 = tensor(10.2686, dtype=torch.float64)\n",
      "#Loss 66 = tensor(10.2581, dtype=torch.float64)\n",
      "#Loss 67 = tensor(10.2507, dtype=torch.float64)\n",
      "#Loss 68 = tensor(10.2411, dtype=torch.float64)\n",
      "#Loss 69 = tensor(10.2372, dtype=torch.float64)\n",
      "#Loss 70 = tensor(10.1955, dtype=torch.float64)\n",
      "#Loss 71 = tensor(10.1386, dtype=torch.float64)\n",
      "#Loss 72 = tensor(10.0644, dtype=torch.float64)\n",
      "#Loss 73 = tensor(9.8972, dtype=torch.float64)\n",
      "#Loss 74 = tensor(9.7793, dtype=torch.float64)\n",
      "#Loss 75 = tensor(9.6378, dtype=torch.float64)\n",
      "#Loss 76 = tensor(9.5240, dtype=torch.float64)\n",
      "#Loss 77 = tensor(9.4820, dtype=torch.float64)\n",
      "#Loss 78 = tensor(9.4559, dtype=torch.float64)\n",
      "#Loss 79 = tensor(9.4427, dtype=torch.float64)\n",
      "#Loss 80 = tensor(9.4288, dtype=torch.float64)\n",
      "#Loss 81 = tensor(9.4202, dtype=torch.float64)\n",
      "#Loss 82 = tensor(9.4105, dtype=torch.float64)\n",
      "#Loss 83 = tensor(9.4036, dtype=torch.float64)\n",
      "#Loss 84 = tensor(9.4017, dtype=torch.float64)\n",
      "#Loss 85 = tensor(9.3997, dtype=torch.float64)\n",
      "#Loss 86 = tensor(9.3988, dtype=torch.float64)\n",
      "#Loss 87 = tensor(9.3985, dtype=torch.float64)\n",
      "#Loss 88 = tensor(9.3984, dtype=torch.float64)\n",
      "#Loss 89 = tensor(9.3983, dtype=torch.float64)\n",
      "#Loss 90 = tensor(9.3982, dtype=torch.float64)\n",
      "#Loss 91 = tensor(9.3982, dtype=torch.float64)\n",
      "#Loss 92 = tensor(9.3982, dtype=torch.float64)\n",
      "#Loss 93 = tensor(9.3982, dtype=torch.float64)\n",
      "#Loss 94 = tensor(9.3982, dtype=torch.float64)\n",
      "#Loss 95 = tensor(9.3982, dtype=torch.float64)\n",
      "#Loss 96 = tensor(9.3982, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(5.9184, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4048, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0593, dtype=torch.float64)   实验回归误差 tensor(0.0513, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(3448.6364, dtype=torch.float64)\n",
      "#Loss 1 = tensor(3394.0340, dtype=torch.float64)\n",
      "#Loss 2 = tensor(435.9389, dtype=torch.float64)\n",
      "#Loss 3 = tensor(367.8317, dtype=torch.float64)\n",
      "#Loss 4 = tensor(324.9344, dtype=torch.float64)\n",
      "#Loss 5 = tensor(284.7701, dtype=torch.float64)\n",
      "#Loss 6 = tensor(248.5841, dtype=torch.float64)\n",
      "#Loss 7 = tensor(213.8228, dtype=torch.float64)\n",
      "#Loss 8 = tensor(184.5506, dtype=torch.float64)\n",
      "#Loss 9 = tensor(158.3918, dtype=torch.float64)\n",
      "#Loss 10 = tensor(135.0192, dtype=torch.float64)\n",
      "#Loss 11 = tensor(114.2639, dtype=torch.float64)\n",
      "#Loss 12 = tensor(98.2656, dtype=torch.float64)\n",
      "#Loss 13 = tensor(85.6437, dtype=torch.float64)\n",
      "#Loss 14 = tensor(75.8114, dtype=torch.float64)\n",
      "#Loss 15 = tensor(64.8393, dtype=torch.float64)\n",
      "#Loss 16 = tensor(56.3797, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 17 = tensor(48.8402, dtype=torch.float64)\n",
      "#Loss 18 = tensor(44.2236, dtype=torch.float64)\n",
      "#Loss 19 = tensor(40.8584, dtype=torch.float64)\n",
      "#Loss 20 = tensor(37.9444, dtype=torch.float64)\n",
      "#Loss 21 = tensor(34.2188, dtype=torch.float64)\n",
      "#Loss 22 = tensor(30.9394, dtype=torch.float64)\n",
      "#Loss 23 = tensor(28.1691, dtype=torch.float64)\n",
      "#Loss 24 = tensor(25.8325, dtype=torch.float64)\n",
      "#Loss 25 = tensor(23.4705, dtype=torch.float64)\n",
      "#Loss 26 = tensor(22.1390, dtype=torch.float64)\n",
      "#Loss 27 = tensor(20.2288, dtype=torch.float64)\n",
      "#Loss 28 = tensor(18.9027, dtype=torch.float64)\n",
      "#Loss 29 = tensor(18.0346, dtype=torch.float64)\n",
      "#Loss 30 = tensor(17.2195, dtype=torch.float64)\n",
      "#Loss 31 = tensor(16.2907, dtype=torch.float64)\n",
      "#Loss 32 = tensor(15.0730, dtype=torch.float64)\n",
      "#Loss 33 = tensor(14.1403, dtype=torch.float64)\n",
      "#Loss 34 = tensor(13.3100, dtype=torch.float64)\n",
      "#Loss 35 = tensor(12.8977, dtype=torch.float64)\n",
      "#Loss 36 = tensor(12.5674, dtype=torch.float64)\n",
      "#Loss 37 = tensor(12.3023, dtype=torch.float64)\n",
      "#Loss 38 = tensor(12.1270, dtype=torch.float64)\n",
      "#Loss 39 = tensor(11.9540, dtype=torch.float64)\n",
      "#Loss 40 = tensor(11.7390, dtype=torch.float64)\n",
      "#Loss 41 = tensor(11.3464, dtype=torch.float64)\n",
      "#Loss 42 = tensor(10.8790, dtype=torch.float64)\n",
      "#Loss 43 = tensor(10.4916, dtype=torch.float64)\n",
      "#Loss 44 = tensor(10.2662, dtype=torch.float64)\n",
      "#Loss 45 = tensor(10.0807, dtype=torch.float64)\n",
      "#Loss 46 = tensor(9.9100, dtype=torch.float64)\n",
      "#Loss 47 = tensor(9.6890, dtype=torch.float64)\n",
      "#Loss 48 = tensor(9.4007, dtype=torch.float64)\n",
      "#Loss 49 = tensor(9.0224, dtype=torch.float64)\n",
      "#Loss 50 = tensor(8.7114, dtype=torch.float64)\n",
      "#Loss 51 = tensor(8.4740, dtype=torch.float64)\n",
      "#Loss 52 = tensor(8.3283, dtype=torch.float64)\n",
      "#Loss 53 = tensor(8.2095, dtype=torch.float64)\n",
      "#Loss 54 = tensor(8.0795, dtype=torch.float64)\n",
      "#Loss 55 = tensor(7.9887, dtype=torch.float64)\n",
      "#Loss 56 = tensor(7.8782, dtype=torch.float64)\n",
      "#Loss 57 = tensor(7.8075, dtype=torch.float64)\n",
      "#Loss 58 = tensor(7.6940, dtype=torch.float64)\n",
      "#Loss 59 = tensor(7.6264, dtype=torch.float64)\n",
      "#Loss 60 = tensor(7.4538, dtype=torch.float64)\n",
      "#Loss 61 = tensor(7.3932, dtype=torch.float64)\n",
      "#Loss 62 = tensor(7.3576, dtype=torch.float64)\n",
      "#Loss 63 = tensor(7.3355, dtype=torch.float64)\n",
      "#Loss 64 = tensor(7.3130, dtype=torch.float64)\n",
      "#Loss 65 = tensor(7.2964, dtype=torch.float64)\n",
      "#Loss 66 = tensor(7.2807, dtype=torch.float64)\n",
      "#Loss 67 = tensor(7.2323, dtype=torch.float64)\n",
      "#Loss 68 = tensor(7.1560, dtype=torch.float64)\n",
      "#Loss 69 = tensor(7.0265, dtype=torch.float64)\n",
      "#Loss 70 = tensor(6.8638, dtype=torch.float64)\n",
      "#Loss 71 = tensor(6.7591, dtype=torch.float64)\n",
      "#Loss 72 = tensor(6.6882, dtype=torch.float64)\n",
      "#Loss 73 = tensor(6.5865, dtype=torch.float64)\n",
      "#Loss 74 = tensor(6.4291, dtype=torch.float64)\n",
      "#Loss 75 = tensor(6.3069, dtype=torch.float64)\n",
      "#Loss 76 = tensor(6.2571, dtype=torch.float64)\n",
      "#Loss 77 = tensor(6.1887, dtype=torch.float64)\n",
      "#Loss 78 = tensor(6.1691, dtype=torch.float64)\n",
      "#Loss 79 = tensor(6.1033, dtype=torch.float64)\n",
      "#Loss 80 = tensor(6.0793, dtype=torch.float64)\n",
      "#Loss 81 = tensor(6.0681, dtype=torch.float64)\n",
      "#Loss 82 = tensor(6.0620, dtype=torch.float64)\n",
      "#Loss 83 = tensor(5.9935, dtype=torch.float64)\n",
      "#Loss 84 = tensor(5.9388, dtype=torch.float64)\n",
      "#Loss 85 = tensor(5.9208, dtype=torch.float64)\n",
      "#Loss 86 = tensor(5.9128, dtype=torch.float64)\n",
      "#Loss 87 = tensor(5.9085, dtype=torch.float64)\n",
      "#Loss 88 = tensor(5.8807, dtype=torch.float64)\n",
      "#Loss 89 = tensor(5.7444, dtype=torch.float64)\n",
      "#Loss 90 = tensor(5.6534, dtype=torch.float64)\n",
      "#Loss 91 = tensor(5.6010, dtype=torch.float64)\n",
      "#Loss 92 = tensor(5.5718, dtype=torch.float64)\n",
      "#Loss 93 = tensor(5.5522, dtype=torch.float64)\n",
      "#Loss 94 = tensor(5.5383, dtype=torch.float64)\n",
      "#Loss 95 = tensor(5.5242, dtype=torch.float64)\n",
      "#Loss 96 = tensor(5.5196, dtype=torch.float64)\n",
      "#Loss 97 = tensor(5.5176, dtype=torch.float64)\n",
      "#Loss 98 = tensor(5.5164, dtype=torch.float64)\n",
      "#Loss 99 = tensor(5.5143, dtype=torch.float64)\n",
      "#Loss 100 = tensor(5.5136, dtype=torch.float64)\n",
      "#Loss 101 = tensor(5.5130, dtype=torch.float64)\n",
      "#Loss 102 = tensor(5.5128, dtype=torch.float64)\n",
      "#Loss 103 = tensor(5.5127, dtype=torch.float64)\n",
      "#Loss 104 = tensor(5.5127, dtype=torch.float64)\n",
      "#Loss 105 = tensor(5.5126, dtype=torch.float64)\n",
      "#Loss 106 = tensor(5.5126, dtype=torch.float64)\n",
      "#Loss 107 = tensor(5.5126, dtype=torch.float64)\n",
      "#Loss 108 = tensor(5.5126, dtype=torch.float64)\n",
      "#Loss 109 = tensor(5.5126, dtype=torch.float64)\n",
      "#Loss 110 = tensor(5.5126, dtype=torch.float64)\n",
      "#Loss 111 = tensor(5.5126, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(7.3877, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4142, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0599, dtype=torch.float64)   实验回归误差 tensor(0.0400, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(4002.1105, dtype=torch.float64)\n",
      "#Loss 1 = tensor(3729.0726, dtype=torch.float64)\n",
      "#Loss 2 = tensor(234.5433, dtype=torch.float64)\n",
      "#Loss 3 = tensor(197.6142, dtype=torch.float64)\n",
      "#Loss 4 = tensor(174.2317, dtype=torch.float64)\n",
      "#Loss 5 = tensor(153.2719, dtype=torch.float64)\n",
      "#Loss 6 = tensor(136.1995, dtype=torch.float64)\n",
      "#Loss 7 = tensor(121.0025, dtype=torch.float64)\n",
      "#Loss 8 = tensor(109.7130, dtype=torch.float64)\n",
      "#Loss 9 = tensor(99.6419, dtype=torch.float64)\n",
      "#Loss 10 = tensor(90.7403, dtype=torch.float64)\n",
      "#Loss 11 = tensor(84.2491, dtype=torch.float64)\n",
      "#Loss 12 = tensor(78.5818, dtype=torch.float64)\n",
      "#Loss 13 = tensor(74.1502, dtype=torch.float64)\n",
      "#Loss 14 = tensor(71.0986, dtype=torch.float64)\n",
      "#Loss 15 = tensor(66.6946, dtype=torch.float64)\n",
      "#Loss 16 = tensor(63.2264, dtype=torch.float64)\n",
      "#Loss 17 = tensor(59.4374, dtype=torch.float64)\n",
      "#Loss 18 = tensor(56.1984, dtype=torch.float64)\n",
      "#Loss 19 = tensor(53.2791, dtype=torch.float64)\n",
      "#Loss 20 = tensor(51.0134, dtype=torch.float64)\n",
      "#Loss 21 = tensor(48.8979, dtype=torch.float64)\n",
      "#Loss 22 = tensor(46.3130, dtype=torch.float64)\n",
      "#Loss 23 = tensor(43.7807, dtype=torch.float64)\n",
      "#Loss 24 = tensor(42.1133, dtype=torch.float64)\n",
      "#Loss 25 = tensor(40.7714, dtype=torch.float64)\n",
      "#Loss 26 = tensor(39.6363, dtype=torch.float64)\n",
      "#Loss 27 = tensor(38.6636, dtype=torch.float64)\n",
      "#Loss 28 = tensor(37.7821, dtype=torch.float64)\n",
      "#Loss 29 = tensor(36.7216, dtype=torch.float64)\n",
      "#Loss 30 = tensor(35.2438, dtype=torch.float64)\n",
      "#Loss 31 = tensor(34.1717, dtype=torch.float64)\n",
      "#Loss 32 = tensor(33.2022, dtype=torch.float64)\n",
      "#Loss 33 = tensor(32.5591, dtype=torch.float64)\n",
      "#Loss 34 = tensor(31.9632, dtype=torch.float64)\n",
      "#Loss 35 = tensor(31.0720, dtype=torch.float64)\n",
      "#Loss 36 = tensor(30.1269, dtype=torch.float64)\n",
      "#Loss 37 = tensor(29.0986, dtype=torch.float64)\n",
      "#Loss 38 = tensor(27.9456, dtype=torch.float64)\n",
      "#Loss 39 = tensor(27.1342, dtype=torch.float64)\n",
      "#Loss 40 = tensor(26.4826, dtype=torch.float64)\n",
      "#Loss 41 = tensor(25.8289, dtype=torch.float64)\n",
      "#Loss 42 = tensor(25.1492, dtype=torch.float64)\n",
      "#Loss 43 = tensor(24.6816, dtype=torch.float64)\n",
      "#Loss 44 = tensor(24.3465, dtype=torch.float64)\n",
      "#Loss 45 = tensor(23.8483, dtype=torch.float64)\n",
      "#Loss 46 = tensor(23.4447, dtype=torch.float64)\n",
      "#Loss 47 = tensor(23.1925, dtype=torch.float64)\n",
      "#Loss 48 = tensor(23.0147, dtype=torch.float64)\n",
      "#Loss 49 = tensor(22.8285, dtype=torch.float64)\n",
      "#Loss 50 = tensor(22.6468, dtype=torch.float64)\n",
      "#Loss 51 = tensor(22.2664, dtype=torch.float64)\n",
      "#Loss 52 = tensor(22.0721, dtype=torch.float64)\n",
      "#Loss 53 = tensor(21.8619, dtype=torch.float64)\n",
      "#Loss 54 = tensor(21.5457, dtype=torch.float64)\n",
      "#Loss 55 = tensor(21.3427, dtype=torch.float64)\n",
      "#Loss 56 = tensor(21.2011, dtype=torch.float64)\n",
      "#Loss 57 = tensor(20.9685, dtype=torch.float64)\n",
      "#Loss 58 = tensor(20.4291, dtype=torch.float64)\n",
      "#Loss 59 = tensor(19.9119, dtype=torch.float64)\n",
      "#Loss 60 = tensor(19.4734, dtype=torch.float64)\n",
      "#Loss 61 = tensor(19.0447, dtype=torch.float64)\n",
      "#Loss 62 = tensor(18.8219, dtype=torch.float64)\n",
      "#Loss 63 = tensor(18.7266, dtype=torch.float64)\n",
      "#Loss 64 = tensor(18.5595, dtype=torch.float64)\n",
      "#Loss 65 = tensor(18.4065, dtype=torch.float64)\n",
      "#Loss 66 = tensor(18.1501, dtype=torch.float64)\n",
      "#Loss 67 = tensor(18.0310, dtype=torch.float64)\n",
      "#Loss 68 = tensor(17.9339, dtype=torch.float64)\n",
      "#Loss 69 = tensor(17.8698, dtype=torch.float64)\n",
      "#Loss 70 = tensor(17.8046, dtype=torch.float64)\n",
      "#Loss 71 = tensor(17.7301, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 72 = tensor(17.6886, dtype=torch.float64)\n",
      "#Loss 73 = tensor(17.6770, dtype=torch.float64)\n",
      "#Loss 74 = tensor(17.6727, dtype=torch.float64)\n",
      "#Loss 75 = tensor(17.6716, dtype=torch.float64)\n",
      "#Loss 76 = tensor(17.6710, dtype=torch.float64)\n",
      "#Loss 77 = tensor(17.6697, dtype=torch.float64)\n",
      "#Loss 78 = tensor(17.6695, dtype=torch.float64)\n",
      "#Loss 79 = tensor(17.6694, dtype=torch.float64)\n",
      "#Loss 80 = tensor(17.6693, dtype=torch.float64)\n",
      "#Loss 81 = tensor(17.6690, dtype=torch.float64)\n",
      "#Loss 82 = tensor(17.6684, dtype=torch.float64)\n",
      "#Loss 83 = tensor(17.6684, dtype=torch.float64)\n",
      "#Loss 84 = tensor(17.6683, dtype=torch.float64)\n",
      "#Loss 85 = tensor(17.6683, dtype=torch.float64)\n",
      "#Loss 86 = tensor(17.6683, dtype=torch.float64)\n",
      "#Loss 87 = tensor(17.6683, dtype=torch.float64)\n",
      "#Loss 88 = tensor(17.6683, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(6.1077, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4000, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0565, dtype=torch.float64)   实验回归误差 tensor(0.0664, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(5296.6928, dtype=torch.float64)\n",
      "#Loss 1 = tensor(5075.3019, dtype=torch.float64)\n",
      "#Loss 2 = tensor(494.1169, dtype=torch.float64)\n",
      "#Loss 3 = tensor(418.0484, dtype=torch.float64)\n",
      "#Loss 4 = tensor(374.6672, dtype=torch.float64)\n",
      "#Loss 5 = tensor(330.5578, dtype=torch.float64)\n",
      "#Loss 6 = tensor(292.6445, dtype=torch.float64)\n",
      "#Loss 7 = tensor(257.4400, dtype=torch.float64)\n",
      "#Loss 8 = tensor(222.3624, dtype=torch.float64)\n",
      "#Loss 9 = tensor(193.3201, dtype=torch.float64)\n",
      "#Loss 10 = tensor(169.1409, dtype=torch.float64)\n",
      "#Loss 11 = tensor(149.2292, dtype=torch.float64)\n",
      "#Loss 12 = tensor(128.6567, dtype=torch.float64)\n",
      "#Loss 13 = tensor(108.9844, dtype=torch.float64)\n",
      "#Loss 14 = tensor(95.0744, dtype=torch.float64)\n",
      "#Loss 15 = tensor(84.2808, dtype=torch.float64)\n",
      "#Loss 16 = tensor(72.2303, dtype=torch.float64)\n",
      "#Loss 17 = tensor(61.7059, dtype=torch.float64)\n",
      "#Loss 18 = tensor(52.0255, dtype=torch.float64)\n",
      "#Loss 19 = tensor(45.2795, dtype=torch.float64)\n",
      "#Loss 20 = tensor(40.2242, dtype=torch.float64)\n",
      "#Loss 21 = tensor(36.9638, dtype=torch.float64)\n",
      "#Loss 22 = tensor(33.9679, dtype=torch.float64)\n",
      "#Loss 23 = tensor(31.8377, dtype=torch.float64)\n",
      "#Loss 24 = tensor(30.4988, dtype=torch.float64)\n",
      "#Loss 25 = tensor(29.2962, dtype=torch.float64)\n",
      "#Loss 26 = tensor(27.9041, dtype=torch.float64)\n",
      "#Loss 27 = tensor(26.4844, dtype=torch.float64)\n",
      "#Loss 28 = tensor(25.3156, dtype=torch.float64)\n",
      "#Loss 29 = tensor(24.5201, dtype=torch.float64)\n",
      "#Loss 30 = tensor(23.2201, dtype=torch.float64)\n",
      "#Loss 31 = tensor(22.3043, dtype=torch.float64)\n",
      "#Loss 32 = tensor(21.5163, dtype=torch.float64)\n",
      "#Loss 33 = tensor(21.0907, dtype=torch.float64)\n",
      "#Loss 34 = tensor(20.3407, dtype=torch.float64)\n",
      "#Loss 35 = tensor(19.8975, dtype=torch.float64)\n",
      "#Loss 36 = tensor(19.4540, dtype=torch.float64)\n",
      "#Loss 37 = tensor(18.8304, dtype=torch.float64)\n",
      "#Loss 38 = tensor(18.0751, dtype=torch.float64)\n",
      "#Loss 39 = tensor(17.1224, dtype=torch.float64)\n",
      "#Loss 40 = tensor(16.3700, dtype=torch.float64)\n",
      "#Loss 41 = tensor(15.9145, dtype=torch.float64)\n",
      "#Loss 42 = tensor(15.2753, dtype=torch.float64)\n",
      "#Loss 43 = tensor(14.6708, dtype=torch.float64)\n",
      "#Loss 44 = tensor(14.0675, dtype=torch.float64)\n",
      "#Loss 45 = tensor(13.2965, dtype=torch.float64)\n",
      "#Loss 46 = tensor(12.4602, dtype=torch.float64)\n",
      "#Loss 47 = tensor(11.9874, dtype=torch.float64)\n",
      "#Loss 48 = tensor(11.7950, dtype=torch.float64)\n",
      "#Loss 49 = tensor(11.6411, dtype=torch.float64)\n",
      "#Loss 50 = tensor(11.5303, dtype=torch.float64)\n",
      "#Loss 51 = tensor(11.4237, dtype=torch.float64)\n",
      "#Loss 52 = tensor(11.2069, dtype=torch.float64)\n",
      "#Loss 53 = tensor(11.1082, dtype=torch.float64)\n",
      "#Loss 54 = tensor(11.0092, dtype=torch.float64)\n",
      "#Loss 55 = tensor(10.9130, dtype=torch.float64)\n",
      "#Loss 56 = tensor(10.7948, dtype=torch.float64)\n",
      "#Loss 57 = tensor(10.5994, dtype=torch.float64)\n",
      "#Loss 58 = tensor(10.3947, dtype=torch.float64)\n",
      "#Loss 59 = tensor(10.2036, dtype=torch.float64)\n",
      "#Loss 60 = tensor(10.0540, dtype=torch.float64)\n",
      "#Loss 61 = tensor(9.9817, dtype=torch.float64)\n",
      "#Loss 62 = tensor(9.8541, dtype=torch.float64)\n",
      "#Loss 63 = tensor(9.7155, dtype=torch.float64)\n",
      "#Loss 64 = tensor(9.5624, dtype=torch.float64)\n",
      "#Loss 65 = tensor(9.4691, dtype=torch.float64)\n",
      "#Loss 66 = tensor(9.4305, dtype=torch.float64)\n",
      "#Loss 67 = tensor(9.3972, dtype=torch.float64)\n",
      "#Loss 68 = tensor(9.3795, dtype=torch.float64)\n",
      "#Loss 69 = tensor(9.3335, dtype=torch.float64)\n",
      "#Loss 70 = tensor(9.3106, dtype=torch.float64)\n",
      "#Loss 71 = tensor(9.2961, dtype=torch.float64)\n",
      "#Loss 72 = tensor(9.2845, dtype=torch.float64)\n",
      "#Loss 73 = tensor(9.2806, dtype=torch.float64)\n",
      "#Loss 74 = tensor(9.2789, dtype=torch.float64)\n",
      "#Loss 75 = tensor(9.2781, dtype=torch.float64)\n",
      "#Loss 76 = tensor(9.2777, dtype=torch.float64)\n",
      "#Loss 77 = tensor(9.2775, dtype=torch.float64)\n",
      "#Loss 78 = tensor(9.2774, dtype=torch.float64)\n",
      "#Loss 79 = tensor(9.2773, dtype=torch.float64)\n",
      "#Loss 80 = tensor(9.2773, dtype=torch.float64)\n",
      "#Loss 81 = tensor(9.2773, dtype=torch.float64)\n",
      "#Loss 82 = tensor(9.2773, dtype=torch.float64)\n",
      "#Loss 83 = tensor(9.2773, dtype=torch.float64)\n",
      "#Loss 84 = tensor(9.2773, dtype=torch.float64)\n",
      "#Loss 85 = tensor(9.2773, dtype=torch.float64)\n",
      "#Loss 86 = tensor(9.2773, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(5.9232, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4142, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0516, dtype=torch.float64)   实验回归误差 tensor(0.0419, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(6189.8775, dtype=torch.float64)\n",
      "#Loss 1 = tensor(6092.4421, dtype=torch.float64)\n",
      "#Loss 2 = tensor(1099.3732, dtype=torch.float64)\n",
      "#Loss 3 = tensor(882.9054, dtype=torch.float64)\n",
      "#Loss 4 = tensor(704.1676, dtype=torch.float64)\n",
      "#Loss 5 = tensor(545.7240, dtype=torch.float64)\n",
      "#Loss 6 = tensor(419.1631, dtype=torch.float64)\n",
      "#Loss 7 = tensor(324.3525, dtype=torch.float64)\n",
      "#Loss 8 = tensor(242.4135, dtype=torch.float64)\n",
      "#Loss 9 = tensor(191.3233, dtype=torch.float64)\n",
      "#Loss 10 = tensor(154.0125, dtype=torch.float64)\n",
      "#Loss 11 = tensor(121.3426, dtype=torch.float64)\n",
      "#Loss 12 = tensor(94.4608, dtype=torch.float64)\n",
      "#Loss 13 = tensor(73.1730, dtype=torch.float64)\n",
      "#Loss 14 = tensor(55.7622, dtype=torch.float64)\n",
      "#Loss 15 = tensor(45.7784, dtype=torch.float64)\n",
      "#Loss 16 = tensor(38.1771, dtype=torch.float64)\n",
      "#Loss 17 = tensor(32.7211, dtype=torch.float64)\n",
      "#Loss 18 = tensor(29.0919, dtype=torch.float64)\n",
      "#Loss 19 = tensor(26.1084, dtype=torch.float64)\n",
      "#Loss 20 = tensor(23.5366, dtype=torch.float64)\n",
      "#Loss 21 = tensor(21.0028, dtype=torch.float64)\n",
      "#Loss 22 = tensor(19.7058, dtype=torch.float64)\n",
      "#Loss 23 = tensor(18.6511, dtype=torch.float64)\n",
      "#Loss 24 = tensor(17.9312, dtype=torch.float64)\n",
      "#Loss 25 = tensor(17.5260, dtype=torch.float64)\n",
      "#Loss 26 = tensor(17.2101, dtype=torch.float64)\n",
      "#Loss 27 = tensor(17.0355, dtype=torch.float64)\n",
      "#Loss 28 = tensor(16.9890, dtype=torch.float64)\n",
      "#Loss 29 = tensor(16.8938, dtype=torch.float64)\n",
      "#Loss 30 = tensor(16.7858, dtype=torch.float64)\n",
      "#Loss 31 = tensor(16.6016, dtype=torch.float64)\n",
      "#Loss 32 = tensor(16.5233, dtype=torch.float64)\n",
      "#Loss 33 = tensor(16.4785, dtype=torch.float64)\n",
      "#Loss 34 = tensor(16.4609, dtype=torch.float64)\n",
      "#Loss 35 = tensor(16.3594, dtype=torch.float64)\n",
      "#Loss 36 = tensor(16.3325, dtype=torch.float64)\n",
      "#Loss 37 = tensor(16.3195, dtype=torch.float64)\n",
      "#Loss 38 = tensor(16.3119, dtype=torch.float64)\n",
      "#Loss 39 = tensor(16.3023, dtype=torch.float64)\n",
      "#Loss 40 = tensor(16.2995, dtype=torch.float64)\n",
      "#Loss 41 = tensor(16.2963, dtype=torch.float64)\n",
      "#Loss 42 = tensor(16.2888, dtype=torch.float64)\n",
      "#Loss 43 = tensor(16.2346, dtype=torch.float64)\n",
      "#Loss 44 = tensor(16.2251, dtype=torch.float64)\n",
      "#Loss 45 = tensor(16.2231, dtype=torch.float64)\n",
      "#Loss 46 = tensor(16.2222, dtype=torch.float64)\n",
      "#Loss 47 = tensor(16.2217, dtype=torch.float64)\n",
      "#Loss 48 = tensor(16.2215, dtype=torch.float64)\n",
      "#Loss 49 = tensor(16.2214, dtype=torch.float64)\n",
      "#Loss 50 = tensor(16.2213, dtype=torch.float64)\n",
      "#Loss 51 = tensor(16.2213, dtype=torch.float64)\n",
      "#Loss 52 = tensor(16.2213, dtype=torch.float64)\n",
      "#Loss 53 = tensor(16.2213, dtype=torch.float64)\n",
      "#Loss 54 = tensor(16.2213, dtype=torch.float64)\n",
      "#Loss 55 = tensor(16.2213, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(7.3219, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4095, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0516, dtype=torch.float64)   实验回归误差 tensor(0.0512, dtype=torch.float64, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0 = tensor(4266.7381, dtype=torch.float64)\n",
      "#Loss 1 = tensor(4194.1996, dtype=torch.float64)\n",
      "#Loss 2 = tensor(658.3940, dtype=torch.float64)\n",
      "#Loss 3 = tensor(474.3250, dtype=torch.float64)\n",
      "#Loss 4 = tensor(368.3488, dtype=torch.float64)\n",
      "#Loss 5 = tensor(296.4829, dtype=torch.float64)\n",
      "#Loss 6 = tensor(242.7323, dtype=torch.float64)\n",
      "#Loss 7 = tensor(194.7394, dtype=torch.float64)\n",
      "#Loss 8 = tensor(155.8858, dtype=torch.float64)\n",
      "#Loss 9 = tensor(121.2581, dtype=torch.float64)\n",
      "#Loss 10 = tensor(96.5038, dtype=torch.float64)\n",
      "#Loss 11 = tensor(75.5368, dtype=torch.float64)\n",
      "#Loss 12 = tensor(56.8774, dtype=torch.float64)\n",
      "#Loss 13 = tensor(46.1806, dtype=torch.float64)\n",
      "#Loss 14 = tensor(37.5892, dtype=torch.float64)\n",
      "#Loss 15 = tensor(30.3552, dtype=torch.float64)\n",
      "#Loss 16 = tensor(24.7586, dtype=torch.float64)\n",
      "#Loss 17 = tensor(19.9762, dtype=torch.float64)\n",
      "#Loss 18 = tensor(16.9885, dtype=torch.float64)\n",
      "#Loss 19 = tensor(15.5483, dtype=torch.float64)\n",
      "#Loss 20 = tensor(14.3286, dtype=torch.float64)\n",
      "#Loss 21 = tensor(13.5405, dtype=torch.float64)\n",
      "#Loss 22 = tensor(11.6170, dtype=torch.float64)\n",
      "#Loss 23 = tensor(10.2520, dtype=torch.float64)\n",
      "#Loss 24 = tensor(9.2586, dtype=torch.float64)\n",
      "#Loss 25 = tensor(8.6749, dtype=torch.float64)\n",
      "#Loss 26 = tensor(8.4279, dtype=torch.float64)\n",
      "#Loss 27 = tensor(8.2593, dtype=torch.float64)\n",
      "#Loss 28 = tensor(8.1048, dtype=torch.float64)\n",
      "#Loss 29 = tensor(7.7708, dtype=torch.float64)\n",
      "#Loss 30 = tensor(7.6253, dtype=torch.float64)\n",
      "#Loss 31 = tensor(7.5667, dtype=torch.float64)\n",
      "#Loss 32 = tensor(7.5342, dtype=torch.float64)\n",
      "#Loss 33 = tensor(7.5210, dtype=torch.float64)\n",
      "#Loss 34 = tensor(7.4927, dtype=torch.float64)\n",
      "#Loss 35 = tensor(7.4835, dtype=torch.float64)\n",
      "#Loss 36 = tensor(7.4776, dtype=torch.float64)\n",
      "#Loss 37 = tensor(7.4740, dtype=torch.float64)\n",
      "#Loss 38 = tensor(7.4525, dtype=torch.float64)\n",
      "#Loss 39 = tensor(7.4447, dtype=torch.float64)\n",
      "#Loss 40 = tensor(7.3959, dtype=torch.float64)\n",
      "#Loss 41 = tensor(7.3606, dtype=torch.float64)\n",
      "#Loss 42 = tensor(7.3052, dtype=torch.float64)\n",
      "#Loss 43 = tensor(7.2660, dtype=torch.float64)\n",
      "#Loss 44 = tensor(7.2173, dtype=torch.float64)\n",
      "#Loss 45 = tensor(7.1964, dtype=torch.float64)\n",
      "#Loss 46 = tensor(7.1900, dtype=torch.float64)\n",
      "#Loss 47 = tensor(7.1867, dtype=torch.float64)\n",
      "#Loss 48 = tensor(7.1779, dtype=torch.float64)\n",
      "#Loss 49 = tensor(7.1557, dtype=torch.float64)\n",
      "#Loss 50 = tensor(7.1372, dtype=torch.float64)\n",
      "#Loss 51 = tensor(7.1330, dtype=torch.float64)\n",
      "#Loss 52 = tensor(7.1295, dtype=torch.float64)\n",
      "#Loss 53 = tensor(7.1290, dtype=torch.float64)\n",
      "#Loss 54 = tensor(7.1288, dtype=torch.float64)\n",
      "#Loss 55 = tensor(7.1288, dtype=torch.float64)\n",
      "#Loss 56 = tensor(7.1287, dtype=torch.float64)\n",
      "#Loss 57 = tensor(7.1287, dtype=torch.float64)\n",
      "#Loss 58 = tensor(7.1287, dtype=torch.float64)\n",
      "#Loss 59 = tensor(7.1286, dtype=torch.float64)\n",
      "#Loss 60 = tensor(7.1286, dtype=torch.float64)\n",
      "#Loss 61 = tensor(7.1286, dtype=torch.float64)\n",
      "#Loss 62 = tensor(7.1286, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(6.0635, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4000, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0593, dtype=torch.float64)   实验回归误差 tensor(0.0409, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(5811.1118, dtype=torch.float64)\n",
      "#Loss 1 = tensor(5684.1638, dtype=torch.float64)\n",
      "#Loss 2 = tensor(458.8276, dtype=torch.float64)\n",
      "#Loss 3 = tensor(387.8514, dtype=torch.float64)\n",
      "#Loss 4 = tensor(347.6890, dtype=torch.float64)\n",
      "#Loss 5 = tensor(317.3894, dtype=torch.float64)\n",
      "#Loss 6 = tensor(292.0153, dtype=torch.float64)\n",
      "#Loss 7 = tensor(263.7677, dtype=torch.float64)\n",
      "#Loss 8 = tensor(233.2554, dtype=torch.float64)\n",
      "#Loss 9 = tensor(204.7561, dtype=torch.float64)\n",
      "#Loss 10 = tensor(186.9881, dtype=torch.float64)\n",
      "#Loss 11 = tensor(170.5498, dtype=torch.float64)\n",
      "#Loss 12 = tensor(156.6046, dtype=torch.float64)\n",
      "#Loss 13 = tensor(142.9073, dtype=torch.float64)\n",
      "#Loss 14 = tensor(131.5201, dtype=torch.float64)\n",
      "#Loss 15 = tensor(119.1015, dtype=torch.float64)\n",
      "#Loss 16 = tensor(109.3674, dtype=torch.float64)\n",
      "#Loss 17 = tensor(102.4496, dtype=torch.float64)\n",
      "#Loss 18 = tensor(95.0335, dtype=torch.float64)\n",
      "#Loss 19 = tensor(83.6380, dtype=torch.float64)\n",
      "#Loss 20 = tensor(75.2379, dtype=torch.float64)\n",
      "#Loss 21 = tensor(69.3990, dtype=torch.float64)\n",
      "#Loss 22 = tensor(65.1952, dtype=torch.float64)\n",
      "#Loss 23 = tensor(61.2582, dtype=torch.float64)\n",
      "#Loss 24 = tensor(55.3193, dtype=torch.float64)\n",
      "#Loss 25 = tensor(52.3214, dtype=torch.float64)\n",
      "#Loss 26 = tensor(49.2377, dtype=torch.float64)\n",
      "#Loss 27 = tensor(46.8485, dtype=torch.float64)\n",
      "#Loss 28 = tensor(44.9981, dtype=torch.float64)\n",
      "#Loss 29 = tensor(43.2100, dtype=torch.float64)\n",
      "#Loss 30 = tensor(40.8258, dtype=torch.float64)\n",
      "#Loss 31 = tensor(39.0291, dtype=torch.float64)\n",
      "#Loss 32 = tensor(37.7040, dtype=torch.float64)\n",
      "#Loss 33 = tensor(35.7982, dtype=torch.float64)\n",
      "#Loss 34 = tensor(34.1560, dtype=torch.float64)\n",
      "#Loss 35 = tensor(33.1177, dtype=torch.float64)\n",
      "#Loss 36 = tensor(31.9689, dtype=torch.float64)\n",
      "#Loss 37 = tensor(30.6805, dtype=torch.float64)\n",
      "#Loss 38 = tensor(29.4817, dtype=torch.float64)\n",
      "#Loss 39 = tensor(28.4432, dtype=torch.float64)\n",
      "#Loss 40 = tensor(27.7770, dtype=torch.float64)\n",
      "#Loss 41 = tensor(27.0386, dtype=torch.float64)\n",
      "#Loss 42 = tensor(26.4316, dtype=torch.float64)\n",
      "#Loss 43 = tensor(25.7341, dtype=torch.float64)\n",
      "#Loss 44 = tensor(25.0331, dtype=torch.float64)\n",
      "#Loss 45 = tensor(24.5525, dtype=torch.float64)\n",
      "#Loss 46 = tensor(24.1808, dtype=torch.float64)\n",
      "#Loss 47 = tensor(23.9513, dtype=torch.float64)\n",
      "#Loss 48 = tensor(23.8653, dtype=torch.float64)\n",
      "#Loss 49 = tensor(23.8088, dtype=torch.float64)\n",
      "#Loss 50 = tensor(23.7842, dtype=torch.float64)\n",
      "#Loss 51 = tensor(23.7769, dtype=torch.float64)\n",
      "#Loss 52 = tensor(23.7735, dtype=torch.float64)\n",
      "#Loss 53 = tensor(23.7720, dtype=torch.float64)\n",
      "#Loss 54 = tensor(23.7712, dtype=torch.float64)\n",
      "#Loss 55 = tensor(23.7709, dtype=torch.float64)\n",
      "#Loss 56 = tensor(23.7707, dtype=torch.float64)\n",
      "#Loss 57 = tensor(23.7706, dtype=torch.float64)\n",
      "#Loss 58 = tensor(23.7706, dtype=torch.float64)\n",
      "#Loss 59 = tensor(23.7705, dtype=torch.float64)\n",
      "#Loss 60 = tensor(23.7705, dtype=torch.float64)\n",
      "#Loss 61 = tensor(23.7705, dtype=torch.float64)\n",
      "#Loss 62 = tensor(23.7705, dtype=torch.float64)\n",
      "#Loss 63 = tensor(23.7705, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(7.8661, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4048, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0444, dtype=torch.float64)   实验回归误差 tensor(0.0640, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(5776.2301, dtype=torch.float64)\n",
      "#Loss 1 = tensor(5712.5290, dtype=torch.float64)\n",
      "#Loss 2 = tensor(549.7520, dtype=torch.float64)\n",
      "#Loss 3 = tensor(441.1834, dtype=torch.float64)\n",
      "#Loss 4 = tensor(382.8827, dtype=torch.float64)\n",
      "#Loss 5 = tensor(336.7797, dtype=torch.float64)\n",
      "#Loss 6 = tensor(297.6319, dtype=torch.float64)\n",
      "#Loss 7 = tensor(265.0716, dtype=torch.float64)\n",
      "#Loss 8 = tensor(237.6833, dtype=torch.float64)\n",
      "#Loss 9 = tensor(211.9290, dtype=torch.float64)\n",
      "#Loss 10 = tensor(194.0006, dtype=torch.float64)\n",
      "#Loss 11 = tensor(179.7065, dtype=torch.float64)\n",
      "#Loss 12 = tensor(164.7733, dtype=torch.float64)\n",
      "#Loss 13 = tensor(148.5777, dtype=torch.float64)\n",
      "#Loss 14 = tensor(132.9382, dtype=torch.float64)\n",
      "#Loss 15 = tensor(120.6290, dtype=torch.float64)\n",
      "#Loss 16 = tensor(109.6166, dtype=torch.float64)\n",
      "#Loss 17 = tensor(100.5472, dtype=torch.float64)\n",
      "#Loss 18 = tensor(93.1578, dtype=torch.float64)\n",
      "#Loss 19 = tensor(86.8528, dtype=torch.float64)\n",
      "#Loss 20 = tensor(80.5257, dtype=torch.float64)\n",
      "#Loss 21 = tensor(75.6523, dtype=torch.float64)\n",
      "#Loss 22 = tensor(71.0760, dtype=torch.float64)\n",
      "#Loss 23 = tensor(67.0334, dtype=torch.float64)\n",
      "#Loss 24 = tensor(63.2463, dtype=torch.float64)\n",
      "#Loss 25 = tensor(59.9530, dtype=torch.float64)\n",
      "#Loss 26 = tensor(56.9734, dtype=torch.float64)\n",
      "#Loss 27 = tensor(53.2634, dtype=torch.float64)\n",
      "#Loss 28 = tensor(50.8020, dtype=torch.float64)\n",
      "#Loss 29 = tensor(48.8007, dtype=torch.float64)\n",
      "#Loss 30 = tensor(46.4218, dtype=torch.float64)\n",
      "#Loss 31 = tensor(45.2279, dtype=torch.float64)\n",
      "#Loss 32 = tensor(44.1324, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 33 = tensor(42.6294, dtype=torch.float64)\n",
      "#Loss 34 = tensor(41.2817, dtype=torch.float64)\n",
      "#Loss 35 = tensor(40.2798, dtype=torch.float64)\n",
      "#Loss 36 = tensor(39.4142, dtype=torch.float64)\n",
      "#Loss 37 = tensor(38.7998, dtype=torch.float64)\n",
      "#Loss 38 = tensor(38.2122, dtype=torch.float64)\n",
      "#Loss 39 = tensor(37.5784, dtype=torch.float64)\n",
      "#Loss 40 = tensor(37.0222, dtype=torch.float64)\n",
      "#Loss 41 = tensor(36.2305, dtype=torch.float64)\n",
      "#Loss 42 = tensor(35.2632, dtype=torch.float64)\n",
      "#Loss 43 = tensor(34.4921, dtype=torch.float64)\n",
      "#Loss 44 = tensor(33.8341, dtype=torch.float64)\n",
      "#Loss 45 = tensor(33.3324, dtype=torch.float64)\n",
      "#Loss 46 = tensor(32.6147, dtype=torch.float64)\n",
      "#Loss 47 = tensor(32.1764, dtype=torch.float64)\n",
      "#Loss 48 = tensor(31.0178, dtype=torch.float64)\n",
      "#Loss 49 = tensor(29.8341, dtype=torch.float64)\n",
      "#Loss 50 = tensor(28.7659, dtype=torch.float64)\n",
      "#Loss 51 = tensor(28.0079, dtype=torch.float64)\n",
      "#Loss 52 = tensor(27.0494, dtype=torch.float64)\n",
      "#Loss 53 = tensor(26.4449, dtype=torch.float64)\n",
      "#Loss 54 = tensor(25.8404, dtype=torch.float64)\n",
      "#Loss 55 = tensor(25.3843, dtype=torch.float64)\n",
      "#Loss 56 = tensor(24.8671, dtype=torch.float64)\n",
      "#Loss 57 = tensor(23.9228, dtype=torch.float64)\n",
      "#Loss 58 = tensor(23.2228, dtype=torch.float64)\n",
      "#Loss 59 = tensor(22.8089, dtype=torch.float64)\n",
      "#Loss 60 = tensor(22.1244, dtype=torch.float64)\n",
      "#Loss 61 = tensor(20.9408, dtype=torch.float64)\n",
      "#Loss 62 = tensor(20.4475, dtype=torch.float64)\n",
      "#Loss 63 = tensor(19.8858, dtype=torch.float64)\n",
      "#Loss 64 = tensor(19.5086, dtype=torch.float64)\n",
      "#Loss 65 = tensor(19.3470, dtype=torch.float64)\n",
      "#Loss 66 = tensor(19.2864, dtype=torch.float64)\n",
      "#Loss 67 = tensor(19.2388, dtype=torch.float64)\n",
      "#Loss 68 = tensor(19.1550, dtype=torch.float64)\n",
      "#Loss 69 = tensor(19.0406, dtype=torch.float64)\n",
      "#Loss 70 = tensor(18.8968, dtype=torch.float64)\n",
      "#Loss 71 = tensor(18.8275, dtype=torch.float64)\n",
      "#Loss 72 = tensor(18.7723, dtype=torch.float64)\n",
      "#Loss 73 = tensor(18.7534, dtype=torch.float64)\n",
      "#Loss 74 = tensor(18.7440, dtype=torch.float64)\n",
      "#Loss 75 = tensor(18.7049, dtype=torch.float64)\n",
      "#Loss 76 = tensor(18.6953, dtype=torch.float64)\n",
      "#Loss 77 = tensor(18.6832, dtype=torch.float64)\n",
      "#Loss 78 = tensor(18.6723, dtype=torch.float64)\n",
      "#Loss 79 = tensor(18.6615, dtype=torch.float64)\n",
      "#Loss 80 = tensor(18.5459, dtype=torch.float64)\n",
      "#Loss 81 = tensor(18.4530, dtype=torch.float64)\n",
      "#Loss 82 = tensor(18.4215, dtype=torch.float64)\n",
      "#Loss 83 = tensor(18.4006, dtype=torch.float64)\n",
      "#Loss 84 = tensor(18.3897, dtype=torch.float64)\n",
      "#Loss 85 = tensor(18.3815, dtype=torch.float64)\n",
      "#Loss 86 = tensor(18.3778, dtype=torch.float64)\n",
      "#Loss 87 = tensor(18.3717, dtype=torch.float64)\n",
      "#Loss 88 = tensor(18.3685, dtype=torch.float64)\n",
      "#Loss 89 = tensor(18.3667, dtype=torch.float64)\n",
      "#Loss 90 = tensor(18.3654, dtype=torch.float64)\n",
      "#Loss 91 = tensor(18.3494, dtype=torch.float64)\n",
      "#Loss 92 = tensor(18.3460, dtype=torch.float64)\n",
      "#Loss 93 = tensor(18.2873, dtype=torch.float64)\n",
      "#Loss 94 = tensor(18.2589, dtype=torch.float64)\n",
      "#Loss 95 = tensor(18.2467, dtype=torch.float64)\n",
      "#Loss 96 = tensor(18.2377, dtype=torch.float64)\n",
      "#Loss 97 = tensor(18.2343, dtype=torch.float64)\n",
      "#Loss 98 = tensor(18.2327, dtype=torch.float64)\n",
      "#Loss 99 = tensor(18.2314, dtype=torch.float64)\n",
      "#Loss 100 = tensor(18.2307, dtype=torch.float64)\n",
      "#Loss 101 = tensor(18.2297, dtype=torch.float64)\n",
      "#Loss 102 = tensor(18.2294, dtype=torch.float64)\n",
      "#Loss 103 = tensor(18.2293, dtype=torch.float64)\n",
      "#Loss 104 = tensor(18.2291, dtype=torch.float64)\n",
      "#Loss 105 = tensor(18.2220, dtype=torch.float64)\n",
      "#Loss 106 = tensor(18.2189, dtype=torch.float64)\n",
      "#Loss 107 = tensor(18.2149, dtype=torch.float64)\n",
      "#Loss 108 = tensor(18.2140, dtype=torch.float64)\n",
      "#Loss 109 = tensor(18.2133, dtype=torch.float64)\n",
      "#Loss 110 = tensor(18.2005, dtype=torch.float64)\n",
      "#Loss 111 = tensor(18.1981, dtype=torch.float64)\n",
      "#Loss 112 = tensor(18.1793, dtype=torch.float64)\n",
      "#Loss 113 = tensor(18.1724, dtype=torch.float64)\n",
      "#Loss 114 = tensor(18.1701, dtype=torch.float64)\n",
      "#Loss 115 = tensor(18.1694, dtype=torch.float64)\n",
      "#Loss 116 = tensor(18.1691, dtype=torch.float64)\n",
      "#Loss 117 = tensor(18.1690, dtype=torch.float64)\n",
      "#Loss 118 = tensor(18.1690, dtype=torch.float64)\n",
      "#Loss 119 = tensor(18.1690, dtype=torch.float64)\n",
      "#Loss 120 = tensor(18.1690, dtype=torch.float64)\n",
      "#Loss 121 = tensor(18.1690, dtype=torch.float64)\n",
      "#Loss 122 = tensor(18.1690, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(8.9577, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4095, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0508, dtype=torch.float64)   实验回归误差 tensor(0.0561, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(7866.9457, dtype=torch.float64)\n",
      "#Loss 1 = tensor(6893.6748, dtype=torch.float64)\n",
      "#Loss 2 = tensor(540.6137, dtype=torch.float64)\n",
      "#Loss 3 = tensor(447.3746, dtype=torch.float64)\n",
      "#Loss 4 = tensor(363.5885, dtype=torch.float64)\n",
      "#Loss 5 = tensor(299.3395, dtype=torch.float64)\n",
      "#Loss 6 = tensor(249.7607, dtype=torch.float64)\n",
      "#Loss 7 = tensor(212.6930, dtype=torch.float64)\n",
      "#Loss 8 = tensor(176.0616, dtype=torch.float64)\n",
      "#Loss 9 = tensor(150.0442, dtype=torch.float64)\n",
      "#Loss 10 = tensor(128.8915, dtype=torch.float64)\n",
      "#Loss 11 = tensor(109.9456, dtype=torch.float64)\n",
      "#Loss 12 = tensor(94.7443, dtype=torch.float64)\n",
      "#Loss 13 = tensor(86.0158, dtype=torch.float64)\n",
      "#Loss 14 = tensor(79.4661, dtype=torch.float64)\n",
      "#Loss 15 = tensor(70.4418, dtype=torch.float64)\n",
      "#Loss 16 = tensor(63.5052, dtype=torch.float64)\n",
      "#Loss 17 = tensor(57.6435, dtype=torch.float64)\n",
      "#Loss 18 = tensor(51.3369, dtype=torch.float64)\n",
      "#Loss 19 = tensor(46.3157, dtype=torch.float64)\n",
      "#Loss 20 = tensor(42.2934, dtype=torch.float64)\n",
      "#Loss 21 = tensor(39.5484, dtype=torch.float64)\n",
      "#Loss 22 = tensor(35.9621, dtype=torch.float64)\n",
      "#Loss 23 = tensor(32.9369, dtype=torch.float64)\n",
      "#Loss 24 = tensor(31.0439, dtype=torch.float64)\n",
      "#Loss 25 = tensor(28.9591, dtype=torch.float64)\n",
      "#Loss 26 = tensor(26.1785, dtype=torch.float64)\n",
      "#Loss 27 = tensor(24.3347, dtype=torch.float64)\n",
      "#Loss 28 = tensor(23.0148, dtype=torch.float64)\n",
      "#Loss 29 = tensor(21.1982, dtype=torch.float64)\n",
      "#Loss 30 = tensor(20.0229, dtype=torch.float64)\n",
      "#Loss 31 = tensor(19.1879, dtype=torch.float64)\n",
      "#Loss 32 = tensor(18.4803, dtype=torch.float64)\n",
      "#Loss 33 = tensor(17.7597, dtype=torch.float64)\n",
      "#Loss 34 = tensor(16.6061, dtype=torch.float64)\n",
      "#Loss 35 = tensor(15.0487, dtype=torch.float64)\n",
      "#Loss 36 = tensor(14.2429, dtype=torch.float64)\n",
      "#Loss 37 = tensor(13.9508, dtype=torch.float64)\n",
      "#Loss 38 = tensor(13.8095, dtype=torch.float64)\n",
      "#Loss 39 = tensor(13.6489, dtype=torch.float64)\n",
      "#Loss 40 = tensor(13.5094, dtype=torch.float64)\n",
      "#Loss 41 = tensor(13.3697, dtype=torch.float64)\n",
      "#Loss 42 = tensor(13.0796, dtype=torch.float64)\n",
      "#Loss 43 = tensor(12.7592, dtype=torch.float64)\n",
      "#Loss 44 = tensor(12.5872, dtype=torch.float64)\n",
      "#Loss 45 = tensor(12.3998, dtype=torch.float64)\n",
      "#Loss 46 = tensor(12.2580, dtype=torch.float64)\n",
      "#Loss 47 = tensor(12.1850, dtype=torch.float64)\n",
      "#Loss 48 = tensor(12.1058, dtype=torch.float64)\n",
      "#Loss 49 = tensor(12.0784, dtype=torch.float64)\n",
      "#Loss 50 = tensor(12.0637, dtype=torch.float64)\n",
      "#Loss 51 = tensor(12.0327, dtype=torch.float64)\n",
      "#Loss 52 = tensor(11.9242, dtype=torch.float64)\n",
      "#Loss 53 = tensor(11.8347, dtype=torch.float64)\n",
      "#Loss 54 = tensor(11.7865, dtype=torch.float64)\n",
      "#Loss 55 = tensor(11.7189, dtype=torch.float64)\n",
      "#Loss 56 = tensor(11.6824, dtype=torch.float64)\n",
      "#Loss 57 = tensor(11.6600, dtype=torch.float64)\n",
      "#Loss 58 = tensor(11.4162, dtype=torch.float64)\n",
      "#Loss 59 = tensor(11.3078, dtype=torch.float64)\n",
      "#Loss 60 = tensor(11.2585, dtype=torch.float64)\n",
      "#Loss 61 = tensor(11.2328, dtype=torch.float64)\n",
      "#Loss 62 = tensor(11.2169, dtype=torch.float64)\n",
      "#Loss 63 = tensor(11.2113, dtype=torch.float64)\n",
      "#Loss 64 = tensor(11.2066, dtype=torch.float64)\n",
      "#Loss 65 = tensor(11.2055, dtype=torch.float64)\n",
      "#Loss 66 = tensor(11.2051, dtype=torch.float64)\n",
      "#Loss 67 = tensor(11.2050, dtype=torch.float64)\n",
      "#Loss 68 = tensor(11.2049, dtype=torch.float64)\n",
      "#Loss 69 = tensor(11.2049, dtype=torch.float64)\n",
      "#Loss 70 = tensor(11.2049, dtype=torch.float64)\n",
      "#Loss 71 = tensor(11.2049, dtype=torch.float64)\n",
      "#Loss 72 = tensor(11.2049, dtype=torch.float64)\n",
      "#Loss 73 = tensor(11.2049, dtype=torch.float64)\n",
      "#Loss 74 = tensor(11.2049, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(6.8405, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.3952, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0420, dtype=torch.float64)   实验回归误差 tensor(0.0377, dtype=torch.float64, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0 = tensor(4701.8423, dtype=torch.float64)\n",
      "#Loss 1 = tensor(4631.4964, dtype=torch.float64)\n",
      "#Loss 2 = tensor(584.3085, dtype=torch.float64)\n",
      "#Loss 3 = tensor(493.0110, dtype=torch.float64)\n",
      "#Loss 4 = tensor(429.8551, dtype=torch.float64)\n",
      "#Loss 5 = tensor(365.7196, dtype=torch.float64)\n",
      "#Loss 6 = tensor(308.0845, dtype=torch.float64)\n",
      "#Loss 7 = tensor(257.9520, dtype=torch.float64)\n",
      "#Loss 8 = tensor(217.9006, dtype=torch.float64)\n",
      "#Loss 9 = tensor(188.1410, dtype=torch.float64)\n",
      "#Loss 10 = tensor(165.2382, dtype=torch.float64)\n",
      "#Loss 11 = tensor(146.3856, dtype=torch.float64)\n",
      "#Loss 12 = tensor(129.7002, dtype=torch.float64)\n",
      "#Loss 13 = tensor(113.7616, dtype=torch.float64)\n",
      "#Loss 14 = tensor(101.4930, dtype=torch.float64)\n",
      "#Loss 15 = tensor(90.8127, dtype=torch.float64)\n",
      "#Loss 16 = tensor(80.1378, dtype=torch.float64)\n",
      "#Loss 17 = tensor(71.2836, dtype=torch.float64)\n",
      "#Loss 18 = tensor(63.5298, dtype=torch.float64)\n",
      "#Loss 19 = tensor(57.4985, dtype=torch.float64)\n",
      "#Loss 20 = tensor(52.6987, dtype=torch.float64)\n",
      "#Loss 21 = tensor(48.4444, dtype=torch.float64)\n",
      "#Loss 22 = tensor(44.7613, dtype=torch.float64)\n",
      "#Loss 23 = tensor(42.2311, dtype=torch.float64)\n",
      "#Loss 24 = tensor(40.1661, dtype=torch.float64)\n",
      "#Loss 25 = tensor(36.6166, dtype=torch.float64)\n",
      "#Loss 26 = tensor(34.4229, dtype=torch.float64)\n",
      "#Loss 27 = tensor(33.1061, dtype=torch.float64)\n",
      "#Loss 28 = tensor(32.0336, dtype=torch.float64)\n",
      "#Loss 29 = tensor(31.2034, dtype=torch.float64)\n",
      "#Loss 30 = tensor(30.0025, dtype=torch.float64)\n",
      "#Loss 31 = tensor(28.8195, dtype=torch.float64)\n",
      "#Loss 32 = tensor(27.4591, dtype=torch.float64)\n",
      "#Loss 33 = tensor(26.3327, dtype=torch.float64)\n",
      "#Loss 34 = tensor(25.4718, dtype=torch.float64)\n",
      "#Loss 35 = tensor(24.9315, dtype=torch.float64)\n",
      "#Loss 36 = tensor(24.3624, dtype=torch.float64)\n",
      "#Loss 37 = tensor(23.8226, dtype=torch.float64)\n",
      "#Loss 38 = tensor(23.4843, dtype=torch.float64)\n",
      "#Loss 39 = tensor(23.2681, dtype=torch.float64)\n",
      "#Loss 40 = tensor(22.8345, dtype=torch.float64)\n",
      "#Loss 41 = tensor(22.5081, dtype=torch.float64)\n",
      "#Loss 42 = tensor(22.1971, dtype=torch.float64)\n",
      "#Loss 43 = tensor(21.8298, dtype=torch.float64)\n",
      "#Loss 44 = tensor(21.5637, dtype=torch.float64)\n",
      "#Loss 45 = tensor(21.2594, dtype=torch.float64)\n",
      "#Loss 46 = tensor(20.9361, dtype=torch.float64)\n",
      "#Loss 47 = tensor(20.6776, dtype=torch.float64)\n",
      "#Loss 48 = tensor(20.2839, dtype=torch.float64)\n",
      "#Loss 49 = tensor(19.4159, dtype=torch.float64)\n",
      "#Loss 50 = tensor(18.6931, dtype=torch.float64)\n",
      "#Loss 51 = tensor(18.2114, dtype=torch.float64)\n",
      "#Loss 52 = tensor(17.8708, dtype=torch.float64)\n",
      "#Loss 53 = tensor(17.6519, dtype=torch.float64)\n",
      "#Loss 54 = tensor(17.4695, dtype=torch.float64)\n",
      "#Loss 55 = tensor(17.3333, dtype=torch.float64)\n",
      "#Loss 56 = tensor(17.1812, dtype=torch.float64)\n",
      "#Loss 57 = tensor(17.0721, dtype=torch.float64)\n",
      "#Loss 58 = tensor(17.0069, dtype=torch.float64)\n",
      "#Loss 59 = tensor(16.9631, dtype=torch.float64)\n",
      "#Loss 60 = tensor(16.9306, dtype=torch.float64)\n",
      "#Loss 61 = tensor(16.8648, dtype=torch.float64)\n",
      "#Loss 62 = tensor(16.7554, dtype=torch.float64)\n",
      "#Loss 63 = tensor(16.4993, dtype=torch.float64)\n",
      "#Loss 64 = tensor(16.3449, dtype=torch.float64)\n",
      "#Loss 65 = tensor(16.2210, dtype=torch.float64)\n",
      "#Loss 66 = tensor(16.0560, dtype=torch.float64)\n",
      "#Loss 67 = tensor(15.9369, dtype=torch.float64)\n",
      "#Loss 68 = tensor(15.2407, dtype=torch.float64)\n",
      "#Loss 69 = tensor(14.3804, dtype=torch.float64)\n",
      "#Loss 70 = tensor(13.9112, dtype=torch.float64)\n",
      "#Loss 71 = tensor(13.6884, dtype=torch.float64)\n",
      "#Loss 72 = tensor(13.4675, dtype=torch.float64)\n",
      "#Loss 73 = tensor(13.1699, dtype=torch.float64)\n",
      "#Loss 74 = tensor(12.8624, dtype=torch.float64)\n",
      "#Loss 75 = tensor(12.6617, dtype=torch.float64)\n",
      "#Loss 76 = tensor(12.5305, dtype=torch.float64)\n",
      "#Loss 77 = tensor(12.3169, dtype=torch.float64)\n",
      "#Loss 78 = tensor(12.2434, dtype=torch.float64)\n",
      "#Loss 79 = tensor(12.1931, dtype=torch.float64)\n",
      "#Loss 80 = tensor(12.1374, dtype=torch.float64)\n",
      "#Loss 81 = tensor(12.0933, dtype=torch.float64)\n",
      "#Loss 82 = tensor(12.0800, dtype=torch.float64)\n",
      "#Loss 83 = tensor(12.0743, dtype=torch.float64)\n",
      "#Loss 84 = tensor(12.0716, dtype=torch.float64)\n",
      "#Loss 85 = tensor(12.0702, dtype=torch.float64)\n",
      "#Loss 86 = tensor(12.0677, dtype=torch.float64)\n",
      "#Loss 87 = tensor(12.0204, dtype=torch.float64)\n",
      "#Loss 88 = tensor(11.9148, dtype=torch.float64)\n",
      "#Loss 89 = tensor(11.8808, dtype=torch.float64)\n",
      "#Loss 90 = tensor(11.8495, dtype=torch.float64)\n",
      "#Loss 91 = tensor(11.8262, dtype=torch.float64)\n",
      "#Loss 92 = tensor(11.7954, dtype=torch.float64)\n",
      "#Loss 93 = tensor(11.7695, dtype=torch.float64)\n",
      "#Loss 94 = tensor(11.7369, dtype=torch.float64)\n",
      "#Loss 95 = tensor(11.7296, dtype=torch.float64)\n",
      "#Loss 96 = tensor(11.7280, dtype=torch.float64)\n",
      "#Loss 97 = tensor(11.7275, dtype=torch.float64)\n",
      "#Loss 98 = tensor(11.7274, dtype=torch.float64)\n",
      "#Loss 99 = tensor(11.7273, dtype=torch.float64)\n",
      "#Loss 100 = tensor(11.7273, dtype=torch.float64)\n",
      "#Loss 101 = tensor(11.7273, dtype=torch.float64)\n",
      "#Loss 102 = tensor(11.7273, dtype=torch.float64)\n",
      "#Loss 103 = tensor(11.7271, dtype=torch.float64)\n",
      "#Loss 104 = tensor(11.7271, dtype=torch.float64)\n",
      "#Loss 105 = tensor(11.7270, dtype=torch.float64)\n",
      "#Loss 106 = tensor(11.7270, dtype=torch.float64)\n",
      "#Loss 107 = tensor(11.7270, dtype=torch.float64)\n",
      "#Loss 108 = tensor(11.7270, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(6.9908, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4142, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0596, dtype=torch.float64)   实验回归误差 tensor(0.0499, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(6241.3900, dtype=torch.float64)\n",
      "#Loss 1 = tensor(6052.6860, dtype=torch.float64)\n",
      "#Loss 2 = tensor(643.0589, dtype=torch.float64)\n",
      "#Loss 3 = tensor(462.8767, dtype=torch.float64)\n",
      "#Loss 4 = tensor(387.6732, dtype=torch.float64)\n",
      "#Loss 5 = tensor(335.5210, dtype=torch.float64)\n",
      "#Loss 6 = tensor(290.1899, dtype=torch.float64)\n",
      "#Loss 7 = tensor(245.1409, dtype=torch.float64)\n",
      "#Loss 8 = tensor(210.8000, dtype=torch.float64)\n",
      "#Loss 9 = tensor(180.9439, dtype=torch.float64)\n",
      "#Loss 10 = tensor(152.6182, dtype=torch.float64)\n",
      "#Loss 11 = tensor(134.2134, dtype=torch.float64)\n",
      "#Loss 12 = tensor(114.7219, dtype=torch.float64)\n",
      "#Loss 13 = tensor(100.9713, dtype=torch.float64)\n",
      "#Loss 14 = tensor(91.9829, dtype=torch.float64)\n",
      "#Loss 15 = tensor(84.1217, dtype=torch.float64)\n",
      "#Loss 16 = tensor(74.8351, dtype=torch.float64)\n",
      "#Loss 17 = tensor(62.5198, dtype=torch.float64)\n",
      "#Loss 18 = tensor(53.9178, dtype=torch.float64)\n",
      "#Loss 19 = tensor(47.8929, dtype=torch.float64)\n",
      "#Loss 20 = tensor(43.7306, dtype=torch.float64)\n",
      "#Loss 21 = tensor(39.6662, dtype=torch.float64)\n",
      "#Loss 22 = tensor(35.9522, dtype=torch.float64)\n",
      "#Loss 23 = tensor(33.1776, dtype=torch.float64)\n",
      "#Loss 24 = tensor(31.2003, dtype=torch.float64)\n",
      "#Loss 25 = tensor(29.8065, dtype=torch.float64)\n",
      "#Loss 26 = tensor(28.5897, dtype=torch.float64)\n",
      "#Loss 27 = tensor(27.6840, dtype=torch.float64)\n",
      "#Loss 28 = tensor(26.5412, dtype=torch.float64)\n",
      "#Loss 29 = tensor(25.3916, dtype=torch.float64)\n",
      "#Loss 30 = tensor(24.5513, dtype=torch.float64)\n",
      "#Loss 31 = tensor(24.1524, dtype=torch.float64)\n",
      "#Loss 32 = tensor(23.9252, dtype=torch.float64)\n",
      "#Loss 33 = tensor(23.6005, dtype=torch.float64)\n",
      "#Loss 34 = tensor(23.3788, dtype=torch.float64)\n",
      "#Loss 35 = tensor(23.2944, dtype=torch.float64)\n",
      "#Loss 36 = tensor(23.2236, dtype=torch.float64)\n",
      "#Loss 37 = tensor(23.1969, dtype=torch.float64)\n",
      "#Loss 38 = tensor(23.1861, dtype=torch.float64)\n",
      "#Loss 39 = tensor(23.0830, dtype=torch.float64)\n",
      "#Loss 40 = tensor(22.9889, dtype=torch.float64)\n",
      "#Loss 41 = tensor(22.4904, dtype=torch.float64)\n",
      "#Loss 42 = tensor(22.1320, dtype=torch.float64)\n",
      "#Loss 43 = tensor(21.6517, dtype=torch.float64)\n",
      "#Loss 44 = tensor(21.2588, dtype=torch.float64)\n",
      "#Loss 45 = tensor(20.9968, dtype=torch.float64)\n",
      "#Loss 46 = tensor(20.5836, dtype=torch.float64)\n",
      "#Loss 47 = tensor(19.8619, dtype=torch.float64)\n",
      "#Loss 48 = tensor(19.2076, dtype=torch.float64)\n",
      "#Loss 49 = tensor(18.5076, dtype=torch.float64)\n",
      "#Loss 50 = tensor(18.0784, dtype=torch.float64)\n",
      "#Loss 51 = tensor(17.4200, dtype=torch.float64)\n",
      "#Loss 52 = tensor(16.3520, dtype=torch.float64)\n",
      "#Loss 53 = tensor(15.6991, dtype=torch.float64)\n",
      "#Loss 54 = tensor(14.6045, dtype=torch.float64)\n",
      "#Loss 55 = tensor(13.6516, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 56 = tensor(12.6798, dtype=torch.float64)\n",
      "#Loss 57 = tensor(12.1793, dtype=torch.float64)\n",
      "#Loss 58 = tensor(11.8748, dtype=torch.float64)\n",
      "#Loss 59 = tensor(11.4217, dtype=torch.float64)\n",
      "#Loss 60 = tensor(10.8951, dtype=torch.float64)\n",
      "#Loss 61 = tensor(10.4527, dtype=torch.float64)\n",
      "#Loss 62 = tensor(10.2796, dtype=torch.float64)\n",
      "#Loss 63 = tensor(10.2005, dtype=torch.float64)\n",
      "#Loss 64 = tensor(10.1236, dtype=torch.float64)\n",
      "#Loss 65 = tensor(10.0868, dtype=torch.float64)\n",
      "#Loss 66 = tensor(10.0481, dtype=torch.float64)\n",
      "#Loss 67 = tensor(10.0234, dtype=torch.float64)\n",
      "#Loss 68 = tensor(10.0084, dtype=torch.float64)\n",
      "#Loss 69 = tensor(10.0037, dtype=torch.float64)\n",
      "#Loss 70 = tensor(10.0016, dtype=torch.float64)\n",
      "#Loss 71 = tensor(10.0006, dtype=torch.float64)\n",
      "#Loss 72 = tensor(10.0001, dtype=torch.float64)\n",
      "#Loss 73 = tensor(9.9998, dtype=torch.float64)\n",
      "#Loss 74 = tensor(9.9994, dtype=torch.float64)\n",
      "#Loss 75 = tensor(9.9927, dtype=torch.float64)\n",
      "#Loss 76 = tensor(9.9914, dtype=torch.float64)\n",
      "#Loss 77 = tensor(9.9910, dtype=torch.float64)\n",
      "#Loss 78 = tensor(9.9908, dtype=torch.float64)\n",
      "#Loss 79 = tensor(9.9908, dtype=torch.float64)\n",
      "#Loss 80 = tensor(9.9907, dtype=torch.float64)\n",
      "#Loss 81 = tensor(9.9907, dtype=torch.float64)\n",
      "#Loss 82 = tensor(9.9907, dtype=torch.float64)\n",
      "#Loss 83 = tensor(9.9907, dtype=torch.float64)\n",
      "#Loss 84 = tensor(9.9907, dtype=torch.float64)\n",
      "#Loss 85 = tensor(9.9907, dtype=torch.float64)\n",
      "#Loss 86 = tensor(9.9907, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(8.6751, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.3952, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0455, dtype=torch.float64)   实验回归误差 tensor(0.0400, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(6011.1545, dtype=torch.float64)\n",
      "#Loss 1 = tensor(5781.6459, dtype=torch.float64)\n",
      "#Loss 2 = tensor(380.5418, dtype=torch.float64)\n",
      "#Loss 3 = tensor(288.1601, dtype=torch.float64)\n",
      "#Loss 4 = tensor(231.0267, dtype=torch.float64)\n",
      "#Loss 5 = tensor(195.0118, dtype=torch.float64)\n",
      "#Loss 6 = tensor(170.2560, dtype=torch.float64)\n",
      "#Loss 7 = tensor(150.6588, dtype=torch.float64)\n",
      "#Loss 8 = tensor(135.9717, dtype=torch.float64)\n",
      "#Loss 9 = tensor(123.6194, dtype=torch.float64)\n",
      "#Loss 10 = tensor(111.7281, dtype=torch.float64)\n",
      "#Loss 11 = tensor(100.2762, dtype=torch.float64)\n",
      "#Loss 12 = tensor(90.0781, dtype=torch.float64)\n",
      "#Loss 13 = tensor(81.5410, dtype=torch.float64)\n",
      "#Loss 14 = tensor(73.2844, dtype=torch.float64)\n",
      "#Loss 15 = tensor(65.4083, dtype=torch.float64)\n",
      "#Loss 16 = tensor(57.3990, dtype=torch.float64)\n",
      "#Loss 17 = tensor(52.2456, dtype=torch.float64)\n",
      "#Loss 18 = tensor(48.3501, dtype=torch.float64)\n",
      "#Loss 19 = tensor(44.5759, dtype=torch.float64)\n",
      "#Loss 20 = tensor(41.6121, dtype=torch.float64)\n",
      "#Loss 21 = tensor(39.3046, dtype=torch.float64)\n",
      "#Loss 22 = tensor(36.6908, dtype=torch.float64)\n",
      "#Loss 23 = tensor(33.0575, dtype=torch.float64)\n",
      "#Loss 24 = tensor(29.9640, dtype=torch.float64)\n",
      "#Loss 25 = tensor(27.4508, dtype=torch.float64)\n",
      "#Loss 26 = tensor(25.4972, dtype=torch.float64)\n",
      "#Loss 27 = tensor(23.6126, dtype=torch.float64)\n",
      "#Loss 28 = tensor(22.7521, dtype=torch.float64)\n",
      "#Loss 29 = tensor(22.1223, dtype=torch.float64)\n",
      "#Loss 30 = tensor(21.7592, dtype=torch.float64)\n",
      "#Loss 31 = tensor(21.5873, dtype=torch.float64)\n",
      "#Loss 32 = tensor(21.4611, dtype=torch.float64)\n",
      "#Loss 33 = tensor(21.2551, dtype=torch.float64)\n",
      "#Loss 34 = tensor(20.9965, dtype=torch.float64)\n",
      "#Loss 35 = tensor(20.3513, dtype=torch.float64)\n",
      "#Loss 36 = tensor(19.6819, dtype=torch.float64)\n",
      "#Loss 37 = tensor(18.9875, dtype=torch.float64)\n",
      "#Loss 38 = tensor(18.3221, dtype=torch.float64)\n",
      "#Loss 39 = tensor(17.8289, dtype=torch.float64)\n",
      "#Loss 40 = tensor(17.5826, dtype=torch.float64)\n",
      "#Loss 41 = tensor(17.2584, dtype=torch.float64)\n",
      "#Loss 42 = tensor(16.9862, dtype=torch.float64)\n",
      "#Loss 43 = tensor(16.8946, dtype=torch.float64)\n",
      "#Loss 44 = tensor(16.8312, dtype=torch.float64)\n",
      "#Loss 45 = tensor(16.8061, dtype=torch.float64)\n",
      "#Loss 46 = tensor(16.7802, dtype=torch.float64)\n",
      "#Loss 47 = tensor(16.7656, dtype=torch.float64)\n",
      "#Loss 48 = tensor(16.7040, dtype=torch.float64)\n",
      "#Loss 49 = tensor(16.6511, dtype=torch.float64)\n",
      "#Loss 50 = tensor(16.6183, dtype=torch.float64)\n",
      "#Loss 51 = tensor(16.5921, dtype=torch.float64)\n",
      "#Loss 52 = tensor(16.5874, dtype=torch.float64)\n",
      "#Loss 53 = tensor(16.5859, dtype=torch.float64)\n",
      "#Loss 54 = tensor(16.5834, dtype=torch.float64)\n",
      "#Loss 55 = tensor(16.5827, dtype=torch.float64)\n",
      "#Loss 56 = tensor(16.5825, dtype=torch.float64)\n",
      "#Loss 57 = tensor(16.5824, dtype=torch.float64)\n",
      "#Loss 58 = tensor(16.5823, dtype=torch.float64)\n",
      "#Loss 59 = tensor(16.5822, dtype=torch.float64)\n",
      "#Loss 60 = tensor(16.5821, dtype=torch.float64)\n",
      "#Loss 61 = tensor(16.5821, dtype=torch.float64)\n",
      "#Loss 62 = tensor(16.5821, dtype=torch.float64)\n",
      "#Loss 63 = tensor(16.5821, dtype=torch.float64)\n",
      "#Loss 64 = tensor(16.5821, dtype=torch.float64)\n",
      "#Loss 65 = tensor(16.5821, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(6.6651, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4095, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0416, dtype=torch.float64)   实验回归误差 tensor(0.0525, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(2620.8432, dtype=torch.float64)\n",
      "#Loss 1 = tensor(2494.5521, dtype=torch.float64)\n",
      "#Loss 2 = tensor(292.7715, dtype=torch.float64)\n",
      "#Loss 3 = tensor(207.3085, dtype=torch.float64)\n",
      "#Loss 4 = tensor(172.3418, dtype=torch.float64)\n",
      "#Loss 5 = tensor(143.0451, dtype=torch.float64)\n",
      "#Loss 6 = tensor(119.5693, dtype=torch.float64)\n",
      "#Loss 7 = tensor(102.9300, dtype=torch.float64)\n",
      "#Loss 8 = tensor(86.5492, dtype=torch.float64)\n",
      "#Loss 9 = tensor(71.0180, dtype=torch.float64)\n",
      "#Loss 10 = tensor(58.6863, dtype=torch.float64)\n",
      "#Loss 11 = tensor(49.3616, dtype=torch.float64)\n",
      "#Loss 12 = tensor(41.3627, dtype=torch.float64)\n",
      "#Loss 13 = tensor(35.6480, dtype=torch.float64)\n",
      "#Loss 14 = tensor(30.1946, dtype=torch.float64)\n",
      "#Loss 15 = tensor(24.3944, dtype=torch.float64)\n",
      "#Loss 16 = tensor(20.7515, dtype=torch.float64)\n",
      "#Loss 17 = tensor(17.7414, dtype=torch.float64)\n",
      "#Loss 18 = tensor(15.6296, dtype=torch.float64)\n",
      "#Loss 19 = tensor(14.2874, dtype=torch.float64)\n",
      "#Loss 20 = tensor(13.1774, dtype=torch.float64)\n",
      "#Loss 21 = tensor(11.6659, dtype=torch.float64)\n",
      "#Loss 22 = tensor(9.4592, dtype=torch.float64)\n",
      "#Loss 23 = tensor(8.1648, dtype=torch.float64)\n",
      "#Loss 24 = tensor(7.3087, dtype=torch.float64)\n",
      "#Loss 25 = tensor(6.6469, dtype=torch.float64)\n",
      "#Loss 26 = tensor(6.0528, dtype=torch.float64)\n",
      "#Loss 27 = tensor(5.5377, dtype=torch.float64)\n",
      "#Loss 28 = tensor(5.2896, dtype=torch.float64)\n",
      "#Loss 29 = tensor(5.0970, dtype=torch.float64)\n",
      "#Loss 30 = tensor(4.8580, dtype=torch.float64)\n",
      "#Loss 31 = tensor(4.7251, dtype=torch.float64)\n",
      "#Loss 32 = tensor(4.4978, dtype=torch.float64)\n",
      "#Loss 33 = tensor(4.3270, dtype=torch.float64)\n",
      "#Loss 34 = tensor(4.1234, dtype=torch.float64)\n",
      "#Loss 35 = tensor(4.0091, dtype=torch.float64)\n",
      "#Loss 36 = tensor(3.9190, dtype=torch.float64)\n",
      "#Loss 37 = tensor(3.7955, dtype=torch.float64)\n",
      "#Loss 38 = tensor(3.6808, dtype=torch.float64)\n",
      "#Loss 39 = tensor(3.5816, dtype=torch.float64)\n",
      "#Loss 40 = tensor(3.4797, dtype=torch.float64)\n",
      "#Loss 41 = tensor(3.4427, dtype=torch.float64)\n",
      "#Loss 42 = tensor(3.4113, dtype=torch.float64)\n",
      "#Loss 43 = tensor(3.3807, dtype=torch.float64)\n",
      "#Loss 44 = tensor(3.3700, dtype=torch.float64)\n",
      "#Loss 45 = tensor(3.3642, dtype=torch.float64)\n",
      "#Loss 46 = tensor(3.3616, dtype=torch.float64)\n",
      "#Loss 47 = tensor(3.3352, dtype=torch.float64)\n",
      "#Loss 48 = tensor(3.2908, dtype=torch.float64)\n",
      "#Loss 49 = tensor(3.2596, dtype=torch.float64)\n",
      "#Loss 50 = tensor(3.2405, dtype=torch.float64)\n",
      "#Loss 51 = tensor(3.2257, dtype=torch.float64)\n",
      "#Loss 52 = tensor(3.2128, dtype=torch.float64)\n",
      "#Loss 53 = tensor(3.2088, dtype=torch.float64)\n",
      "#Loss 54 = tensor(3.2076, dtype=torch.float64)\n",
      "#Loss 55 = tensor(3.2072, dtype=torch.float64)\n",
      "#Loss 56 = tensor(3.2070, dtype=torch.float64)\n",
      "#Loss 57 = tensor(3.2069, dtype=torch.float64)\n",
      "#Loss 58 = tensor(3.2068, dtype=torch.float64)\n",
      "#Loss 59 = tensor(3.2068, dtype=torch.float64)\n",
      "#Loss 60 = tensor(3.2068, dtype=torch.float64)\n",
      "#Loss 61 = tensor(3.2068, dtype=torch.float64)\n",
      "#Loss 62 = tensor(3.2068, dtype=torch.float64)\n",
      "#Loss 63 = tensor(3.2068, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 64 = tensor(3.2068, dtype=torch.float64)\n",
      "#Loss 65 = tensor(3.2068, dtype=torch.float64)\n",
      "#Loss 66 = tensor(3.2068, dtype=torch.float64)\n",
      "#Loss 67 = tensor(3.2067, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(6.2281, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4000, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0741, dtype=torch.float64)   实验回归误差 tensor(0.0350, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(5646.5213, dtype=torch.float64)\n",
      "#Loss 1 = tensor(5612.8909, dtype=torch.float64)\n",
      "#Loss 2 = tensor(624.2116, dtype=torch.float64)\n",
      "#Loss 3 = tensor(544.5174, dtype=torch.float64)\n",
      "#Loss 4 = tensor(487.8401, dtype=torch.float64)\n",
      "#Loss 5 = tensor(446.7412, dtype=torch.float64)\n",
      "#Loss 6 = tensor(403.4308, dtype=torch.float64)\n",
      "#Loss 7 = tensor(365.0787, dtype=torch.float64)\n",
      "#Loss 8 = tensor(321.7094, dtype=torch.float64)\n",
      "#Loss 9 = tensor(280.5440, dtype=torch.float64)\n",
      "#Loss 10 = tensor(241.4827, dtype=torch.float64)\n",
      "#Loss 11 = tensor(207.8072, dtype=torch.float64)\n",
      "#Loss 12 = tensor(180.8784, dtype=torch.float64)\n",
      "#Loss 13 = tensor(162.2225, dtype=torch.float64)\n",
      "#Loss 14 = tensor(148.2718, dtype=torch.float64)\n",
      "#Loss 15 = tensor(137.1167, dtype=torch.float64)\n",
      "#Loss 16 = tensor(127.2797, dtype=torch.float64)\n",
      "#Loss 17 = tensor(117.0301, dtype=torch.float64)\n",
      "#Loss 18 = tensor(106.8536, dtype=torch.float64)\n",
      "#Loss 19 = tensor(99.1023, dtype=torch.float64)\n",
      "#Loss 20 = tensor(89.3462, dtype=torch.float64)\n",
      "#Loss 21 = tensor(78.3890, dtype=torch.float64)\n",
      "#Loss 22 = tensor(70.2565, dtype=torch.float64)\n",
      "#Loss 23 = tensor(64.6735, dtype=torch.float64)\n",
      "#Loss 24 = tensor(60.6940, dtype=torch.float64)\n",
      "#Loss 25 = tensor(55.5009, dtype=torch.float64)\n",
      "#Loss 26 = tensor(50.3264, dtype=torch.float64)\n",
      "#Loss 27 = tensor(45.9303, dtype=torch.float64)\n",
      "#Loss 28 = tensor(41.8863, dtype=torch.float64)\n",
      "#Loss 29 = tensor(38.7690, dtype=torch.float64)\n",
      "#Loss 30 = tensor(35.9949, dtype=torch.float64)\n",
      "#Loss 31 = tensor(33.9583, dtype=torch.float64)\n",
      "#Loss 32 = tensor(32.6368, dtype=torch.float64)\n",
      "#Loss 33 = tensor(31.5073, dtype=torch.float64)\n",
      "#Loss 34 = tensor(29.7769, dtype=torch.float64)\n",
      "#Loss 35 = tensor(27.5397, dtype=torch.float64)\n",
      "#Loss 36 = tensor(26.0841, dtype=torch.float64)\n",
      "#Loss 37 = tensor(24.9589, dtype=torch.float64)\n",
      "#Loss 38 = tensor(23.6471, dtype=torch.float64)\n",
      "#Loss 39 = tensor(22.7446, dtype=torch.float64)\n",
      "#Loss 40 = tensor(21.9512, dtype=torch.float64)\n",
      "#Loss 41 = tensor(20.9425, dtype=torch.float64)\n",
      "#Loss 42 = tensor(19.9066, dtype=torch.float64)\n",
      "#Loss 43 = tensor(19.3596, dtype=torch.float64)\n",
      "#Loss 44 = tensor(19.0901, dtype=torch.float64)\n",
      "#Loss 45 = tensor(18.5992, dtype=torch.float64)\n",
      "#Loss 46 = tensor(18.0204, dtype=torch.float64)\n",
      "#Loss 47 = tensor(17.6464, dtype=torch.float64)\n",
      "#Loss 48 = tensor(17.4137, dtype=torch.float64)\n",
      "#Loss 49 = tensor(17.2509, dtype=torch.float64)\n",
      "#Loss 50 = tensor(17.1213, dtype=torch.float64)\n",
      "#Loss 51 = tensor(16.9512, dtype=torch.float64)\n",
      "#Loss 52 = tensor(16.7367, dtype=torch.float64)\n",
      "#Loss 53 = tensor(16.5841, dtype=torch.float64)\n",
      "#Loss 54 = tensor(16.4864, dtype=torch.float64)\n",
      "#Loss 55 = tensor(16.4493, dtype=torch.float64)\n",
      "#Loss 56 = tensor(16.4099, dtype=torch.float64)\n",
      "#Loss 57 = tensor(16.3025, dtype=torch.float64)\n",
      "#Loss 58 = tensor(15.9262, dtype=torch.float64)\n",
      "#Loss 59 = tensor(15.3833, dtype=torch.float64)\n",
      "#Loss 60 = tensor(14.9755, dtype=torch.float64)\n",
      "#Loss 61 = tensor(14.7026, dtype=torch.float64)\n",
      "#Loss 62 = tensor(14.4991, dtype=torch.float64)\n",
      "#Loss 63 = tensor(14.3976, dtype=torch.float64)\n",
      "#Loss 64 = tensor(14.3286, dtype=torch.float64)\n",
      "#Loss 65 = tensor(14.2813, dtype=torch.float64)\n",
      "#Loss 66 = tensor(14.2102, dtype=torch.float64)\n",
      "#Loss 67 = tensor(14.1627, dtype=torch.float64)\n",
      "#Loss 68 = tensor(14.0944, dtype=torch.float64)\n",
      "#Loss 69 = tensor(14.0587, dtype=torch.float64)\n",
      "#Loss 70 = tensor(14.0413, dtype=torch.float64)\n",
      "#Loss 71 = tensor(13.9443, dtype=torch.float64)\n",
      "#Loss 72 = tensor(13.9006, dtype=torch.float64)\n",
      "#Loss 73 = tensor(13.8660, dtype=torch.float64)\n",
      "#Loss 74 = tensor(13.8380, dtype=torch.float64)\n",
      "#Loss 75 = tensor(13.7590, dtype=torch.float64)\n",
      "#Loss 76 = tensor(13.5717, dtype=torch.float64)\n",
      "#Loss 77 = tensor(13.5065, dtype=torch.float64)\n",
      "#Loss 78 = tensor(13.4678, dtype=torch.float64)\n",
      "#Loss 79 = tensor(13.4592, dtype=torch.float64)\n",
      "#Loss 80 = tensor(13.4462, dtype=torch.float64)\n",
      "#Loss 81 = tensor(13.4417, dtype=torch.float64)\n",
      "#Loss 82 = tensor(13.4369, dtype=torch.float64)\n",
      "#Loss 83 = tensor(13.3652, dtype=torch.float64)\n",
      "#Loss 84 = tensor(13.3442, dtype=torch.float64)\n",
      "#Loss 85 = tensor(13.2851, dtype=torch.float64)\n",
      "#Loss 86 = tensor(13.2375, dtype=torch.float64)\n",
      "#Loss 87 = tensor(13.2094, dtype=torch.float64)\n",
      "#Loss 88 = tensor(13.1999, dtype=torch.float64)\n",
      "#Loss 89 = tensor(13.1965, dtype=torch.float64)\n",
      "#Loss 90 = tensor(13.1950, dtype=torch.float64)\n",
      "#Loss 91 = tensor(13.1943, dtype=torch.float64)\n",
      "#Loss 92 = tensor(13.1935, dtype=torch.float64)\n",
      "#Loss 93 = tensor(13.1285, dtype=torch.float64)\n",
      "#Loss 94 = tensor(13.0554, dtype=torch.float64)\n",
      "#Loss 95 = tensor(13.0402, dtype=torch.float64)\n",
      "#Loss 96 = tensor(13.0288, dtype=torch.float64)\n",
      "#Loss 97 = tensor(13.0104, dtype=torch.float64)\n",
      "#Loss 98 = tensor(13.0034, dtype=torch.float64)\n",
      "#Loss 99 = tensor(13.0004, dtype=torch.float64)\n",
      "#Loss 100 = tensor(12.9983, dtype=torch.float64)\n",
      "#Loss 101 = tensor(12.9973, dtype=torch.float64)\n",
      "#Loss 102 = tensor(12.9967, dtype=torch.float64)\n",
      "#Loss 103 = tensor(12.9942, dtype=torch.float64)\n",
      "#Loss 104 = tensor(12.9936, dtype=torch.float64)\n",
      "#Loss 105 = tensor(12.9934, dtype=torch.float64)\n",
      "#Loss 106 = tensor(12.9933, dtype=torch.float64)\n",
      "#Loss 107 = tensor(12.9933, dtype=torch.float64)\n",
      "#Loss 108 = tensor(12.9932, dtype=torch.float64)\n",
      "#Loss 109 = tensor(12.9932, dtype=torch.float64)\n",
      "#Loss 110 = tensor(12.9932, dtype=torch.float64)\n",
      "#Loss 111 = tensor(12.9932, dtype=torch.float64)\n",
      "#Loss 112 = tensor(12.9932, dtype=torch.float64)\n",
      "#Loss 113 = tensor(12.9932, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(8.4138, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4095, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0516, dtype=torch.float64)   实验回归误差 tensor(0.0480, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(5230.7025, dtype=torch.float64)\n",
      "#Loss 1 = tensor(5224.9661, dtype=torch.float64)\n",
      "#Loss 2 = tensor(598.9730, dtype=torch.float64)\n",
      "#Loss 3 = tensor(542.4041, dtype=torch.float64)\n",
      "#Loss 4 = tensor(494.3109, dtype=torch.float64)\n",
      "#Loss 5 = tensor(453.2958, dtype=torch.float64)\n",
      "#Loss 6 = tensor(408.9954, dtype=torch.float64)\n",
      "#Loss 7 = tensor(368.2409, dtype=torch.float64)\n",
      "#Loss 8 = tensor(328.5069, dtype=torch.float64)\n",
      "#Loss 9 = tensor(293.3222, dtype=torch.float64)\n",
      "#Loss 10 = tensor(261.5136, dtype=torch.float64)\n",
      "#Loss 11 = tensor(232.5404, dtype=torch.float64)\n",
      "#Loss 12 = tensor(204.9827, dtype=torch.float64)\n",
      "#Loss 13 = tensor(180.1632, dtype=torch.float64)\n",
      "#Loss 14 = tensor(159.7702, dtype=torch.float64)\n",
      "#Loss 15 = tensor(141.4933, dtype=torch.float64)\n",
      "#Loss 16 = tensor(127.9234, dtype=torch.float64)\n",
      "#Loss 17 = tensor(117.7655, dtype=torch.float64)\n",
      "#Loss 18 = tensor(108.8528, dtype=torch.float64)\n",
      "#Loss 19 = tensor(102.1334, dtype=torch.float64)\n",
      "#Loss 20 = tensor(96.1437, dtype=torch.float64)\n",
      "#Loss 21 = tensor(90.1654, dtype=torch.float64)\n",
      "#Loss 22 = tensor(84.8136, dtype=torch.float64)\n",
      "#Loss 23 = tensor(80.6990, dtype=torch.float64)\n",
      "#Loss 24 = tensor(74.7599, dtype=torch.float64)\n",
      "#Loss 25 = tensor(68.7406, dtype=torch.float64)\n",
      "#Loss 26 = tensor(63.6780, dtype=torch.float64)\n",
      "#Loss 27 = tensor(58.4873, dtype=torch.float64)\n",
      "#Loss 28 = tensor(53.2180, dtype=torch.float64)\n",
      "#Loss 29 = tensor(49.1076, dtype=torch.float64)\n",
      "#Loss 30 = tensor(45.8976, dtype=torch.float64)\n",
      "#Loss 31 = tensor(42.3963, dtype=torch.float64)\n",
      "#Loss 32 = tensor(39.2419, dtype=torch.float64)\n",
      "#Loss 33 = tensor(35.7696, dtype=torch.float64)\n",
      "#Loss 34 = tensor(33.2581, dtype=torch.float64)\n",
      "#Loss 35 = tensor(31.0088, dtype=torch.float64)\n",
      "#Loss 36 = tensor(29.6802, dtype=torch.float64)\n",
      "#Loss 37 = tensor(28.4909, dtype=torch.float64)\n",
      "#Loss 38 = tensor(27.3858, dtype=torch.float64)\n",
      "#Loss 39 = tensor(25.7860, dtype=torch.float64)\n",
      "#Loss 40 = tensor(24.4185, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 41 = tensor(23.2707, dtype=torch.float64)\n",
      "#Loss 42 = tensor(21.8585, dtype=torch.float64)\n",
      "#Loss 43 = tensor(21.0685, dtype=torch.float64)\n",
      "#Loss 44 = tensor(20.2856, dtype=torch.float64)\n",
      "#Loss 45 = tensor(19.9161, dtype=torch.float64)\n",
      "#Loss 46 = tensor(19.6038, dtype=torch.float64)\n",
      "#Loss 47 = tensor(19.4120, dtype=torch.float64)\n",
      "#Loss 48 = tensor(19.2721, dtype=torch.float64)\n",
      "#Loss 49 = tensor(19.0298, dtype=torch.float64)\n",
      "#Loss 50 = tensor(18.2801, dtype=torch.float64)\n",
      "#Loss 51 = tensor(17.8672, dtype=torch.float64)\n",
      "#Loss 52 = tensor(17.3650, dtype=torch.float64)\n",
      "#Loss 53 = tensor(16.6494, dtype=torch.float64)\n",
      "#Loss 54 = tensor(16.1838, dtype=torch.float64)\n",
      "#Loss 55 = tensor(15.8101, dtype=torch.float64)\n",
      "#Loss 56 = tensor(15.6234, dtype=torch.float64)\n",
      "#Loss 57 = tensor(15.4123, dtype=torch.float64)\n",
      "#Loss 58 = tensor(15.1585, dtype=torch.float64)\n",
      "#Loss 59 = tensor(14.7498, dtype=torch.float64)\n",
      "#Loss 60 = tensor(14.3642, dtype=torch.float64)\n",
      "#Loss 61 = tensor(13.5584, dtype=torch.float64)\n",
      "#Loss 62 = tensor(13.0038, dtype=torch.float64)\n",
      "#Loss 63 = tensor(12.3507, dtype=torch.float64)\n",
      "#Loss 64 = tensor(11.5969, dtype=torch.float64)\n",
      "#Loss 65 = tensor(10.9124, dtype=torch.float64)\n",
      "#Loss 66 = tensor(10.5613, dtype=torch.float64)\n",
      "#Loss 67 = tensor(10.4374, dtype=torch.float64)\n",
      "#Loss 68 = tensor(10.3737, dtype=torch.float64)\n",
      "#Loss 69 = tensor(10.3030, dtype=torch.float64)\n",
      "#Loss 70 = tensor(10.2298, dtype=torch.float64)\n",
      "#Loss 71 = tensor(10.1801, dtype=torch.float64)\n",
      "#Loss 72 = tensor(10.1540, dtype=torch.float64)\n",
      "#Loss 73 = tensor(10.1217, dtype=torch.float64)\n",
      "#Loss 74 = tensor(10.0994, dtype=torch.float64)\n",
      "#Loss 75 = tensor(10.0912, dtype=torch.float64)\n",
      "#Loss 76 = tensor(10.0873, dtype=torch.float64)\n",
      "#Loss 77 = tensor(10.0849, dtype=torch.float64)\n",
      "#Loss 78 = tensor(10.0837, dtype=torch.float64)\n",
      "#Loss 79 = tensor(10.0832, dtype=torch.float64)\n",
      "#Loss 80 = tensor(10.0829, dtype=torch.float64)\n",
      "#Loss 81 = tensor(10.0828, dtype=torch.float64)\n",
      "#Loss 82 = tensor(10.0827, dtype=torch.float64)\n",
      "#Loss 83 = tensor(10.0827, dtype=torch.float64)\n",
      "#Loss 84 = tensor(10.0827, dtype=torch.float64)\n",
      "#Loss 85 = tensor(10.0827, dtype=torch.float64)\n",
      "#Loss 86 = tensor(10.0827, dtype=torch.float64)\n",
      "#Loss 87 = tensor(10.0827, dtype=torch.float64)\n",
      "#Loss 88 = tensor(10.0826, dtype=torch.float64)\n",
      "#Loss 89 = tensor(10.0826, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(8.7117, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4142, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0524, dtype=torch.float64)   实验回归误差 tensor(0.0439, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(3951.1757, dtype=torch.float64)\n",
      "#Loss 1 = tensor(3823.7604, dtype=torch.float64)\n",
      "#Loss 2 = tensor(433.5143, dtype=torch.float64)\n",
      "#Loss 3 = tensor(345.7430, dtype=torch.float64)\n",
      "#Loss 4 = tensor(288.1774, dtype=torch.float64)\n",
      "#Loss 5 = tensor(240.9128, dtype=torch.float64)\n",
      "#Loss 6 = tensor(206.5176, dtype=torch.float64)\n",
      "#Loss 7 = tensor(178.4802, dtype=torch.float64)\n",
      "#Loss 8 = tensor(159.0850, dtype=torch.float64)\n",
      "#Loss 9 = tensor(140.0826, dtype=torch.float64)\n",
      "#Loss 10 = tensor(118.5904, dtype=torch.float64)\n",
      "#Loss 11 = tensor(99.2735, dtype=torch.float64)\n",
      "#Loss 12 = tensor(84.8022, dtype=torch.float64)\n",
      "#Loss 13 = tensor(72.8606, dtype=torch.float64)\n",
      "#Loss 14 = tensor(61.0012, dtype=torch.float64)\n",
      "#Loss 15 = tensor(51.5020, dtype=torch.float64)\n",
      "#Loss 16 = tensor(43.2661, dtype=torch.float64)\n",
      "#Loss 17 = tensor(35.9072, dtype=torch.float64)\n",
      "#Loss 18 = tensor(29.9340, dtype=torch.float64)\n",
      "#Loss 19 = tensor(25.3369, dtype=torch.float64)\n",
      "#Loss 20 = tensor(22.0938, dtype=torch.float64)\n",
      "#Loss 21 = tensor(19.8360, dtype=torch.float64)\n",
      "#Loss 22 = tensor(18.2583, dtype=torch.float64)\n",
      "#Loss 23 = tensor(17.1051, dtype=torch.float64)\n",
      "#Loss 24 = tensor(16.2329, dtype=torch.float64)\n",
      "#Loss 25 = tensor(15.3294, dtype=torch.float64)\n",
      "#Loss 26 = tensor(14.7090, dtype=torch.float64)\n",
      "#Loss 27 = tensor(14.2140, dtype=torch.float64)\n",
      "#Loss 28 = tensor(13.7312, dtype=torch.float64)\n",
      "#Loss 29 = tensor(13.1874, dtype=torch.float64)\n",
      "#Loss 30 = tensor(12.9043, dtype=torch.float64)\n",
      "#Loss 31 = tensor(12.7053, dtype=torch.float64)\n",
      "#Loss 32 = tensor(12.5171, dtype=torch.float64)\n",
      "#Loss 33 = tensor(12.3897, dtype=torch.float64)\n",
      "#Loss 34 = tensor(12.2766, dtype=torch.float64)\n",
      "#Loss 35 = tensor(12.1975, dtype=torch.float64)\n",
      "#Loss 36 = tensor(12.0928, dtype=torch.float64)\n",
      "#Loss 37 = tensor(11.9833, dtype=torch.float64)\n",
      "#Loss 38 = tensor(11.8967, dtype=torch.float64)\n",
      "#Loss 39 = tensor(11.7974, dtype=torch.float64)\n",
      "#Loss 40 = tensor(11.7418, dtype=torch.float64)\n",
      "#Loss 41 = tensor(11.6791, dtype=torch.float64)\n",
      "#Loss 42 = tensor(11.6103, dtype=torch.float64)\n",
      "#Loss 43 = tensor(11.5749, dtype=torch.float64)\n",
      "#Loss 44 = tensor(11.4156, dtype=torch.float64)\n",
      "#Loss 45 = tensor(11.0747, dtype=torch.float64)\n",
      "#Loss 46 = tensor(10.5935, dtype=torch.float64)\n",
      "#Loss 47 = tensor(10.3655, dtype=torch.float64)\n",
      "#Loss 48 = tensor(10.1735, dtype=torch.float64)\n",
      "#Loss 49 = tensor(9.9553, dtype=torch.float64)\n",
      "#Loss 50 = tensor(9.7912, dtype=torch.float64)\n",
      "#Loss 51 = tensor(9.6985, dtype=torch.float64)\n",
      "#Loss 52 = tensor(9.5985, dtype=torch.float64)\n",
      "#Loss 53 = tensor(9.5172, dtype=torch.float64)\n",
      "#Loss 54 = tensor(9.4068, dtype=torch.float64)\n",
      "#Loss 55 = tensor(9.3159, dtype=torch.float64)\n",
      "#Loss 56 = tensor(9.2656, dtype=torch.float64)\n",
      "#Loss 57 = tensor(9.2288, dtype=torch.float64)\n",
      "#Loss 58 = tensor(9.1753, dtype=torch.float64)\n",
      "#Loss 59 = tensor(9.1520, dtype=torch.float64)\n",
      "#Loss 60 = tensor(9.1413, dtype=torch.float64)\n",
      "#Loss 61 = tensor(9.1332, dtype=torch.float64)\n",
      "#Loss 62 = tensor(9.1292, dtype=torch.float64)\n",
      "#Loss 63 = tensor(9.1257, dtype=torch.float64)\n",
      "#Loss 64 = tensor(9.1211, dtype=torch.float64)\n",
      "#Loss 65 = tensor(9.1201, dtype=torch.float64)\n",
      "#Loss 66 = tensor(9.1198, dtype=torch.float64)\n",
      "#Loss 67 = tensor(9.1197, dtype=torch.float64)\n",
      "#Loss 68 = tensor(9.1196, dtype=torch.float64)\n",
      "#Loss 69 = tensor(9.1196, dtype=torch.float64)\n",
      "#Loss 70 = tensor(9.1196, dtype=torch.float64)\n",
      "#Loss 71 = tensor(9.1196, dtype=torch.float64)\n",
      "#Loss 72 = tensor(9.1196, dtype=torch.float64)\n",
      "#Loss 73 = tensor(9.1196, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(6.4461, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4095, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0547, dtype=torch.float64)   实验回归误差 tensor(0.0480, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(4336.9740, dtype=torch.float64)\n",
      "#Loss 1 = tensor(4108.3745, dtype=torch.float64)\n",
      "#Loss 2 = tensor(362.5874, dtype=torch.float64)\n",
      "#Loss 3 = tensor(318.3850, dtype=torch.float64)\n",
      "#Loss 4 = tensor(282.5565, dtype=torch.float64)\n",
      "#Loss 5 = tensor(247.5788, dtype=torch.float64)\n",
      "#Loss 6 = tensor(215.8387, dtype=torch.float64)\n",
      "#Loss 7 = tensor(187.7815, dtype=torch.float64)\n",
      "#Loss 8 = tensor(162.8862, dtype=torch.float64)\n",
      "#Loss 9 = tensor(135.4115, dtype=torch.float64)\n",
      "#Loss 10 = tensor(113.1970, dtype=torch.float64)\n",
      "#Loss 11 = tensor(95.8808, dtype=torch.float64)\n",
      "#Loss 12 = tensor(80.2256, dtype=torch.float64)\n",
      "#Loss 13 = tensor(69.6730, dtype=torch.float64)\n",
      "#Loss 14 = tensor(61.0484, dtype=torch.float64)\n",
      "#Loss 15 = tensor(53.4207, dtype=torch.float64)\n",
      "#Loss 16 = tensor(44.2879, dtype=torch.float64)\n",
      "#Loss 17 = tensor(38.2041, dtype=torch.float64)\n",
      "#Loss 18 = tensor(33.0896, dtype=torch.float64)\n",
      "#Loss 19 = tensor(29.2208, dtype=torch.float64)\n",
      "#Loss 20 = tensor(25.9795, dtype=torch.float64)\n",
      "#Loss 21 = tensor(22.7522, dtype=torch.float64)\n",
      "#Loss 22 = tensor(20.4396, dtype=torch.float64)\n",
      "#Loss 23 = tensor(18.8465, dtype=torch.float64)\n",
      "#Loss 24 = tensor(17.7259, dtype=torch.float64)\n",
      "#Loss 25 = tensor(17.0460, dtype=torch.float64)\n",
      "#Loss 26 = tensor(16.6353, dtype=torch.float64)\n",
      "#Loss 27 = tensor(15.5719, dtype=torch.float64)\n",
      "#Loss 28 = tensor(14.6717, dtype=torch.float64)\n",
      "#Loss 29 = tensor(13.7474, dtype=torch.float64)\n",
      "#Loss 30 = tensor(12.6836, dtype=torch.float64)\n",
      "#Loss 31 = tensor(11.6820, dtype=torch.float64)\n",
      "#Loss 32 = tensor(10.9841, dtype=torch.float64)\n",
      "#Loss 33 = tensor(10.4339, dtype=torch.float64)\n",
      "#Loss 34 = tensor(10.1765, dtype=torch.float64)\n",
      "#Loss 35 = tensor(9.9460, dtype=torch.float64)\n",
      "#Loss 36 = tensor(9.7930, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 37 = tensor(9.4589, dtype=torch.float64)\n",
      "#Loss 38 = tensor(9.0511, dtype=torch.float64)\n",
      "#Loss 39 = tensor(8.6487, dtype=torch.float64)\n",
      "#Loss 40 = tensor(8.4332, dtype=torch.float64)\n",
      "#Loss 41 = tensor(8.2801, dtype=torch.float64)\n",
      "#Loss 42 = tensor(8.0953, dtype=torch.float64)\n",
      "#Loss 43 = tensor(7.8647, dtype=torch.float64)\n",
      "#Loss 44 = tensor(7.7686, dtype=torch.float64)\n",
      "#Loss 45 = tensor(7.6469, dtype=torch.float64)\n",
      "#Loss 46 = tensor(7.4566, dtype=torch.float64)\n",
      "#Loss 47 = tensor(7.3656, dtype=torch.float64)\n",
      "#Loss 48 = tensor(7.3242, dtype=torch.float64)\n",
      "#Loss 49 = tensor(7.2576, dtype=torch.float64)\n",
      "#Loss 50 = tensor(7.2299, dtype=torch.float64)\n",
      "#Loss 51 = tensor(7.2214, dtype=torch.float64)\n",
      "#Loss 52 = tensor(7.1996, dtype=torch.float64)\n",
      "#Loss 53 = tensor(7.1893, dtype=torch.float64)\n",
      "#Loss 54 = tensor(7.1563, dtype=torch.float64)\n",
      "#Loss 55 = tensor(7.1496, dtype=torch.float64)\n",
      "#Loss 56 = tensor(7.1466, dtype=torch.float64)\n",
      "#Loss 57 = tensor(7.1450, dtype=torch.float64)\n",
      "#Loss 58 = tensor(7.1444, dtype=torch.float64)\n",
      "#Loss 59 = tensor(7.1441, dtype=torch.float64)\n",
      "#Loss 60 = tensor(7.1440, dtype=torch.float64)\n",
      "#Loss 61 = tensor(7.1439, dtype=torch.float64)\n",
      "#Loss 62 = tensor(7.1439, dtype=torch.float64)\n",
      "#Loss 63 = tensor(7.1439, dtype=torch.float64)\n",
      "#Loss 64 = tensor(7.1439, dtype=torch.float64)\n",
      "#Loss 65 = tensor(7.1439, dtype=torch.float64)\n",
      "#Loss 66 = tensor(7.1439, dtype=torch.float64)\n",
      "#Loss 67 = tensor(7.1439, dtype=torch.float64)\n",
      "#Loss 68 = tensor(7.1439, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(7.0658, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4142, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0556, dtype=torch.float64)   实验回归误差 tensor(0.0406, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(5574.8406, dtype=torch.float64)\n",
      "#Loss 1 = tensor(4796.0884, dtype=torch.float64)\n",
      "#Loss 2 = tensor(423.4148, dtype=torch.float64)\n",
      "#Loss 3 = tensor(322.6385, dtype=torch.float64)\n",
      "#Loss 4 = tensor(276.8014, dtype=torch.float64)\n",
      "#Loss 5 = tensor(237.3777, dtype=torch.float64)\n",
      "#Loss 6 = tensor(207.2428, dtype=torch.float64)\n",
      "#Loss 7 = tensor(174.1605, dtype=torch.float64)\n",
      "#Loss 8 = tensor(147.8131, dtype=torch.float64)\n",
      "#Loss 9 = tensor(127.1189, dtype=torch.float64)\n",
      "#Loss 10 = tensor(110.1609, dtype=torch.float64)\n",
      "#Loss 11 = tensor(97.4365, dtype=torch.float64)\n",
      "#Loss 12 = tensor(86.7151, dtype=torch.float64)\n",
      "#Loss 13 = tensor(79.8520, dtype=torch.float64)\n",
      "#Loss 14 = tensor(74.5223, dtype=torch.float64)\n",
      "#Loss 15 = tensor(70.4684, dtype=torch.float64)\n",
      "#Loss 16 = tensor(67.2984, dtype=torch.float64)\n",
      "#Loss 17 = tensor(61.6295, dtype=torch.float64)\n",
      "#Loss 18 = tensor(56.5560, dtype=torch.float64)\n",
      "#Loss 19 = tensor(52.3919, dtype=torch.float64)\n",
      "#Loss 20 = tensor(49.3131, dtype=torch.float64)\n",
      "#Loss 21 = tensor(46.0688, dtype=torch.float64)\n",
      "#Loss 22 = tensor(42.0665, dtype=torch.float64)\n",
      "#Loss 23 = tensor(38.8427, dtype=torch.float64)\n",
      "#Loss 24 = tensor(35.6573, dtype=torch.float64)\n",
      "#Loss 25 = tensor(33.2821, dtype=torch.float64)\n",
      "#Loss 26 = tensor(32.0351, dtype=torch.float64)\n",
      "#Loss 27 = tensor(30.4999, dtype=torch.float64)\n",
      "#Loss 28 = tensor(28.9771, dtype=torch.float64)\n",
      "#Loss 29 = tensor(27.3387, dtype=torch.float64)\n",
      "#Loss 30 = tensor(26.1050, dtype=torch.float64)\n",
      "#Loss 31 = tensor(25.0776, dtype=torch.float64)\n",
      "#Loss 32 = tensor(24.4805, dtype=torch.float64)\n",
      "#Loss 33 = tensor(23.8588, dtype=torch.float64)\n",
      "#Loss 34 = tensor(23.4058, dtype=torch.float64)\n",
      "#Loss 35 = tensor(23.0558, dtype=torch.float64)\n",
      "#Loss 36 = tensor(22.6977, dtype=torch.float64)\n",
      "#Loss 37 = tensor(22.3930, dtype=torch.float64)\n",
      "#Loss 38 = tensor(22.2395, dtype=torch.float64)\n",
      "#Loss 39 = tensor(22.1431, dtype=torch.float64)\n",
      "#Loss 40 = tensor(22.0309, dtype=torch.float64)\n",
      "#Loss 41 = tensor(21.9908, dtype=torch.float64)\n",
      "#Loss 42 = tensor(21.9529, dtype=torch.float64)\n",
      "#Loss 43 = tensor(21.8538, dtype=torch.float64)\n",
      "#Loss 44 = tensor(21.7164, dtype=torch.float64)\n",
      "#Loss 45 = tensor(21.5749, dtype=torch.float64)\n",
      "#Loss 46 = tensor(21.1637, dtype=torch.float64)\n",
      "#Loss 47 = tensor(20.7849, dtype=torch.float64)\n",
      "#Loss 48 = tensor(20.3843, dtype=torch.float64)\n",
      "#Loss 49 = tensor(19.9592, dtype=torch.float64)\n",
      "#Loss 50 = tensor(19.6478, dtype=torch.float64)\n",
      "#Loss 51 = tensor(19.4704, dtype=torch.float64)\n",
      "#Loss 52 = tensor(19.2988, dtype=torch.float64)\n",
      "#Loss 53 = tensor(18.8970, dtype=torch.float64)\n",
      "#Loss 54 = tensor(18.2791, dtype=torch.float64)\n",
      "#Loss 55 = tensor(17.9028, dtype=torch.float64)\n",
      "#Loss 56 = tensor(17.5905, dtype=torch.float64)\n",
      "#Loss 57 = tensor(16.8850, dtype=torch.float64)\n",
      "#Loss 58 = tensor(16.5000, dtype=torch.float64)\n",
      "#Loss 59 = tensor(16.3409, dtype=torch.float64)\n",
      "#Loss 60 = tensor(16.1142, dtype=torch.float64)\n",
      "#Loss 61 = tensor(15.8325, dtype=torch.float64)\n",
      "#Loss 62 = tensor(15.4953, dtype=torch.float64)\n",
      "#Loss 63 = tensor(15.3275, dtype=torch.float64)\n",
      "#Loss 64 = tensor(15.1413, dtype=torch.float64)\n",
      "#Loss 65 = tensor(14.8246, dtype=torch.float64)\n",
      "#Loss 66 = tensor(14.5714, dtype=torch.float64)\n",
      "#Loss 67 = tensor(14.2602, dtype=torch.float64)\n",
      "#Loss 68 = tensor(14.1137, dtype=torch.float64)\n",
      "#Loss 69 = tensor(14.0341, dtype=torch.float64)\n",
      "#Loss 70 = tensor(13.9617, dtype=torch.float64)\n",
      "#Loss 71 = tensor(13.8673, dtype=torch.float64)\n",
      "#Loss 72 = tensor(13.8190, dtype=torch.float64)\n",
      "#Loss 73 = tensor(13.7912, dtype=torch.float64)\n",
      "#Loss 74 = tensor(13.7113, dtype=torch.float64)\n",
      "#Loss 75 = tensor(13.6521, dtype=torch.float64)\n",
      "#Loss 76 = tensor(13.5987, dtype=torch.float64)\n",
      "#Loss 77 = tensor(13.5448, dtype=torch.float64)\n",
      "#Loss 78 = tensor(13.5089, dtype=torch.float64)\n",
      "#Loss 79 = tensor(13.4945, dtype=torch.float64)\n",
      "#Loss 80 = tensor(13.4802, dtype=torch.float64)\n",
      "#Loss 81 = tensor(13.4248, dtype=torch.float64)\n",
      "#Loss 82 = tensor(13.3510, dtype=torch.float64)\n",
      "#Loss 83 = tensor(13.2798, dtype=torch.float64)\n",
      "#Loss 84 = tensor(13.0938, dtype=torch.float64)\n",
      "#Loss 85 = tensor(12.9618, dtype=torch.float64)\n",
      "#Loss 86 = tensor(12.8419, dtype=torch.float64)\n",
      "#Loss 87 = tensor(12.7874, dtype=torch.float64)\n",
      "#Loss 88 = tensor(12.7099, dtype=torch.float64)\n",
      "#Loss 89 = tensor(12.6252, dtype=torch.float64)\n",
      "#Loss 90 = tensor(12.3318, dtype=torch.float64)\n",
      "#Loss 91 = tensor(11.8962, dtype=torch.float64)\n",
      "#Loss 92 = tensor(11.4373, dtype=torch.float64)\n",
      "#Loss 93 = tensor(11.0993, dtype=torch.float64)\n",
      "#Loss 94 = tensor(10.9745, dtype=torch.float64)\n",
      "#Loss 95 = tensor(10.8560, dtype=torch.float64)\n",
      "#Loss 96 = tensor(10.7279, dtype=torch.float64)\n",
      "#Loss 97 = tensor(10.6389, dtype=torch.float64)\n",
      "#Loss 98 = tensor(10.5541, dtype=torch.float64)\n",
      "#Loss 99 = tensor(10.5360, dtype=torch.float64)\n",
      "#Loss 100 = tensor(10.5236, dtype=torch.float64)\n",
      "#Loss 101 = tensor(10.5198, dtype=torch.float64)\n",
      "#Loss 102 = tensor(10.3635, dtype=torch.float64)\n",
      "#Loss 103 = tensor(10.2854, dtype=torch.float64)\n",
      "#Loss 104 = tensor(10.2644, dtype=torch.float64)\n",
      "#Loss 105 = tensor(10.2587, dtype=torch.float64)\n",
      "#Loss 106 = tensor(10.2564, dtype=torch.float64)\n",
      "#Loss 107 = tensor(10.2555, dtype=torch.float64)\n",
      "#Loss 108 = tensor(10.2551, dtype=torch.float64)\n",
      "#Loss 109 = tensor(10.2549, dtype=torch.float64)\n",
      "#Loss 110 = tensor(10.2548, dtype=torch.float64)\n",
      "#Loss 111 = tensor(10.2547, dtype=torch.float64)\n",
      "#Loss 112 = tensor(10.2547, dtype=torch.float64)\n",
      "#Loss 113 = tensor(10.2546, dtype=torch.float64)\n",
      "#Loss 114 = tensor(10.2546, dtype=torch.float64)\n",
      "#Loss 115 = tensor(10.2546, dtype=torch.float64)\n",
      "#Loss 116 = tensor(10.2546, dtype=torch.float64)\n",
      "#Loss 117 = tensor(10.2546, dtype=torch.float64)\n",
      "#Loss 118 = tensor(10.2546, dtype=torch.float64)\n",
      "#Loss 119 = tensor(10.2546, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(6.7685, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4048, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0460, dtype=torch.float64)   实验回归误差 tensor(0.0429, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(6438.6550, dtype=torch.float64)\n",
      "#Loss 1 = tensor(6234.7651, dtype=torch.float64)\n",
      "#Loss 2 = tensor(1160.8701, dtype=torch.float64)\n",
      "#Loss 3 = tensor(841.8376, dtype=torch.float64)\n",
      "#Loss 4 = tensor(587.8347, dtype=torch.float64)\n",
      "#Loss 5 = tensor(409.3833, dtype=torch.float64)\n",
      "#Loss 6 = tensor(290.4032, dtype=torch.float64)\n",
      "#Loss 7 = tensor(206.6609, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 8 = tensor(138.8880, dtype=torch.float64)\n",
      "#Loss 9 = tensor(103.4864, dtype=torch.float64)\n",
      "#Loss 10 = tensor(76.3472, dtype=torch.float64)\n",
      "#Loss 11 = tensor(59.7820, dtype=torch.float64)\n",
      "#Loss 12 = tensor(51.5436, dtype=torch.float64)\n",
      "#Loss 13 = tensor(42.1354, dtype=torch.float64)\n",
      "#Loss 14 = tensor(35.4196, dtype=torch.float64)\n",
      "#Loss 15 = tensor(30.5443, dtype=torch.float64)\n",
      "#Loss 16 = tensor(26.2061, dtype=torch.float64)\n",
      "#Loss 17 = tensor(23.4104, dtype=torch.float64)\n",
      "#Loss 18 = tensor(21.4271, dtype=torch.float64)\n",
      "#Loss 19 = tensor(20.1249, dtype=torch.float64)\n",
      "#Loss 20 = tensor(19.1872, dtype=torch.float64)\n",
      "#Loss 21 = tensor(18.4164, dtype=torch.float64)\n",
      "#Loss 22 = tensor(17.5384, dtype=torch.float64)\n",
      "#Loss 23 = tensor(16.6056, dtype=torch.float64)\n",
      "#Loss 24 = tensor(15.7073, dtype=torch.float64)\n",
      "#Loss 25 = tensor(15.0212, dtype=torch.float64)\n",
      "#Loss 26 = tensor(14.2963, dtype=torch.float64)\n",
      "#Loss 27 = tensor(13.6728, dtype=torch.float64)\n",
      "#Loss 28 = tensor(13.3839, dtype=torch.float64)\n",
      "#Loss 29 = tensor(13.0674, dtype=torch.float64)\n",
      "#Loss 30 = tensor(12.8321, dtype=torch.float64)\n",
      "#Loss 31 = tensor(12.6410, dtype=torch.float64)\n",
      "#Loss 32 = tensor(12.3683, dtype=torch.float64)\n",
      "#Loss 33 = tensor(12.0016, dtype=torch.float64)\n",
      "#Loss 34 = tensor(11.6792, dtype=torch.float64)\n",
      "#Loss 35 = tensor(11.4696, dtype=torch.float64)\n",
      "#Loss 36 = tensor(11.3848, dtype=torch.float64)\n",
      "#Loss 37 = tensor(11.3438, dtype=torch.float64)\n",
      "#Loss 38 = tensor(11.3081, dtype=torch.float64)\n",
      "#Loss 39 = tensor(11.1155, dtype=torch.float64)\n",
      "#Loss 40 = tensor(11.0216, dtype=torch.float64)\n",
      "#Loss 41 = tensor(10.9898, dtype=torch.float64)\n",
      "#Loss 42 = tensor(10.9781, dtype=torch.float64)\n",
      "#Loss 43 = tensor(10.9551, dtype=torch.float64)\n",
      "#Loss 44 = tensor(10.8171, dtype=torch.float64)\n",
      "#Loss 45 = tensor(10.7105, dtype=torch.float64)\n",
      "#Loss 46 = tensor(10.5081, dtype=torch.float64)\n",
      "#Loss 47 = tensor(10.3223, dtype=torch.float64)\n",
      "#Loss 48 = tensor(10.1955, dtype=torch.float64)\n",
      "#Loss 49 = tensor(10.0299, dtype=torch.float64)\n",
      "#Loss 50 = tensor(9.0292, dtype=torch.float64)\n",
      "#Loss 51 = tensor(8.3178, dtype=torch.float64)\n",
      "#Loss 52 = tensor(7.8153, dtype=torch.float64)\n",
      "#Loss 53 = tensor(7.3591, dtype=torch.float64)\n",
      "#Loss 54 = tensor(7.1115, dtype=torch.float64)\n",
      "#Loss 55 = tensor(6.9482, dtype=torch.float64)\n",
      "#Loss 56 = tensor(6.8770, dtype=torch.float64)\n",
      "#Loss 57 = tensor(6.8468, dtype=torch.float64)\n",
      "#Loss 58 = tensor(6.8317, dtype=torch.float64)\n",
      "#Loss 59 = tensor(6.8244, dtype=torch.float64)\n",
      "#Loss 60 = tensor(6.8109, dtype=torch.float64)\n",
      "#Loss 61 = tensor(6.8064, dtype=torch.float64)\n",
      "#Loss 62 = tensor(6.8051, dtype=torch.float64)\n",
      "#Loss 63 = tensor(6.8045, dtype=torch.float64)\n",
      "#Loss 64 = tensor(6.8039, dtype=torch.float64)\n",
      "#Loss 65 = tensor(6.8035, dtype=torch.float64)\n",
      "#Loss 66 = tensor(6.8033, dtype=torch.float64)\n",
      "#Loss 67 = tensor(6.8004, dtype=torch.float64)\n",
      "#Loss 68 = tensor(6.7998, dtype=torch.float64)\n",
      "#Loss 69 = tensor(6.7996, dtype=torch.float64)\n",
      "#Loss 70 = tensor(6.7995, dtype=torch.float64)\n",
      "#Loss 71 = tensor(6.7994, dtype=torch.float64)\n",
      "#Loss 72 = tensor(6.7994, dtype=torch.float64)\n",
      "#Loss 73 = tensor(6.7994, dtype=torch.float64)\n",
      "#Loss 74 = tensor(6.7994, dtype=torch.float64)\n",
      "#Loss 75 = tensor(6.7994, dtype=torch.float64)\n",
      "#Loss 76 = tensor(6.7994, dtype=torch.float64)\n",
      "#Loss 77 = tensor(6.7994, dtype=torch.float64)\n",
      "#Loss 78 = tensor(6.7994, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(8.3367, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4095, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0478, dtype=torch.float64)   实验回归误差 tensor(0.0325, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(4160.2683, dtype=torch.float64)\n",
      "#Loss 1 = tensor(3824.6270, dtype=torch.float64)\n",
      "#Loss 2 = tensor(384.9951, dtype=torch.float64)\n",
      "#Loss 3 = tensor(319.8098, dtype=torch.float64)\n",
      "#Loss 4 = tensor(276.8233, dtype=torch.float64)\n",
      "#Loss 5 = tensor(238.2894, dtype=torch.float64)\n",
      "#Loss 6 = tensor(206.9042, dtype=torch.float64)\n",
      "#Loss 7 = tensor(177.9184, dtype=torch.float64)\n",
      "#Loss 8 = tensor(150.1330, dtype=torch.float64)\n",
      "#Loss 9 = tensor(126.5027, dtype=torch.float64)\n",
      "#Loss 10 = tensor(107.8933, dtype=torch.float64)\n",
      "#Loss 11 = tensor(91.2945, dtype=torch.float64)\n",
      "#Loss 12 = tensor(76.9064, dtype=torch.float64)\n",
      "#Loss 13 = tensor(62.1347, dtype=torch.float64)\n",
      "#Loss 14 = tensor(48.7210, dtype=torch.float64)\n",
      "#Loss 15 = tensor(39.5538, dtype=torch.float64)\n",
      "#Loss 16 = tensor(32.4692, dtype=torch.float64)\n",
      "#Loss 17 = tensor(27.5466, dtype=torch.float64)\n",
      "#Loss 18 = tensor(23.9055, dtype=torch.float64)\n",
      "#Loss 19 = tensor(20.2289, dtype=torch.float64)\n",
      "#Loss 20 = tensor(17.7579, dtype=torch.float64)\n",
      "#Loss 21 = tensor(16.1046, dtype=torch.float64)\n",
      "#Loss 22 = tensor(14.6331, dtype=torch.float64)\n",
      "#Loss 23 = tensor(13.6223, dtype=torch.float64)\n",
      "#Loss 24 = tensor(12.3082, dtype=torch.float64)\n",
      "#Loss 25 = tensor(11.1636, dtype=torch.float64)\n",
      "#Loss 26 = tensor(10.4114, dtype=torch.float64)\n",
      "#Loss 27 = tensor(9.9068, dtype=torch.float64)\n",
      "#Loss 28 = tensor(9.1717, dtype=torch.float64)\n",
      "#Loss 29 = tensor(8.7382, dtype=torch.float64)\n",
      "#Loss 30 = tensor(8.3632, dtype=torch.float64)\n",
      "#Loss 31 = tensor(7.7219, dtype=torch.float64)\n",
      "#Loss 32 = tensor(7.2174, dtype=torch.float64)\n",
      "#Loss 33 = tensor(7.0336, dtype=torch.float64)\n",
      "#Loss 34 = tensor(6.8602, dtype=torch.float64)\n",
      "#Loss 35 = tensor(6.7500, dtype=torch.float64)\n",
      "#Loss 36 = tensor(6.5904, dtype=torch.float64)\n",
      "#Loss 37 = tensor(6.5182, dtype=torch.float64)\n",
      "#Loss 38 = tensor(6.3639, dtype=torch.float64)\n",
      "#Loss 39 = tensor(6.2467, dtype=torch.float64)\n",
      "#Loss 40 = tensor(5.9265, dtype=torch.float64)\n",
      "#Loss 41 = tensor(5.5783, dtype=torch.float64)\n",
      "#Loss 42 = tensor(5.3094, dtype=torch.float64)\n",
      "#Loss 43 = tensor(5.0495, dtype=torch.float64)\n",
      "#Loss 44 = tensor(4.8613, dtype=torch.float64)\n",
      "#Loss 45 = tensor(4.7180, dtype=torch.float64)\n",
      "#Loss 46 = tensor(4.5408, dtype=torch.float64)\n",
      "#Loss 47 = tensor(4.3498, dtype=torch.float64)\n",
      "#Loss 48 = tensor(4.2296, dtype=torch.float64)\n",
      "#Loss 49 = tensor(4.1610, dtype=torch.float64)\n",
      "#Loss 50 = tensor(4.1304, dtype=torch.float64)\n",
      "#Loss 51 = tensor(4.1172, dtype=torch.float64)\n",
      "#Loss 52 = tensor(4.0920, dtype=torch.float64)\n",
      "#Loss 53 = tensor(4.0859, dtype=torch.float64)\n",
      "#Loss 54 = tensor(4.0834, dtype=torch.float64)\n",
      "#Loss 55 = tensor(4.0823, dtype=torch.float64)\n",
      "#Loss 56 = tensor(4.0819, dtype=torch.float64)\n",
      "#Loss 57 = tensor(4.0817, dtype=torch.float64)\n",
      "#Loss 58 = tensor(4.0587, dtype=torch.float64)\n",
      "#Loss 59 = tensor(4.0364, dtype=torch.float64)\n",
      "#Loss 60 = tensor(3.9879, dtype=torch.float64)\n",
      "#Loss 61 = tensor(3.9707, dtype=torch.float64)\n",
      "#Loss 62 = tensor(3.9617, dtype=torch.float64)\n",
      "#Loss 63 = tensor(3.9574, dtype=torch.float64)\n",
      "#Loss 64 = tensor(3.9559, dtype=torch.float64)\n",
      "#Loss 65 = tensor(3.9553, dtype=torch.float64)\n",
      "#Loss 66 = tensor(3.9550, dtype=torch.float64)\n",
      "#Loss 67 = tensor(3.9549, dtype=torch.float64)\n",
      "#Loss 68 = tensor(3.9549, dtype=torch.float64)\n",
      "#Loss 69 = tensor(3.9548, dtype=torch.float64)\n",
      "#Loss 70 = tensor(3.9548, dtype=torch.float64)\n",
      "#Loss 71 = tensor(3.9548, dtype=torch.float64)\n",
      "#Loss 72 = tensor(3.9548, dtype=torch.float64)\n",
      "#Loss 73 = tensor(3.9548, dtype=torch.float64)\n",
      "#Loss 74 = tensor(3.9548, dtype=torch.float64)\n",
      "#Loss 75 = tensor(3.9548, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(7.4235, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4142, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0539, dtype=torch.float64)   实验回归误差 tensor(0.0308, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(5703.3503, dtype=torch.float64)\n",
      "#Loss 1 = tensor(5592.1248, dtype=torch.float64)\n",
      "#Loss 2 = tensor(559.1150, dtype=torch.float64)\n",
      "#Loss 3 = tensor(416.6900, dtype=torch.float64)\n",
      "#Loss 4 = tensor(354.8873, dtype=torch.float64)\n",
      "#Loss 5 = tensor(306.6894, dtype=torch.float64)\n",
      "#Loss 6 = tensor(269.4111, dtype=torch.float64)\n",
      "#Loss 7 = tensor(236.5319, dtype=torch.float64)\n",
      "#Loss 8 = tensor(202.2828, dtype=torch.float64)\n",
      "#Loss 9 = tensor(172.7590, dtype=torch.float64)\n",
      "#Loss 10 = tensor(150.9292, dtype=torch.float64)\n",
      "#Loss 11 = tensor(133.1565, dtype=torch.float64)\n",
      "#Loss 12 = tensor(114.7165, dtype=torch.float64)\n",
      "#Loss 13 = tensor(97.0611, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 14 = tensor(82.6940, dtype=torch.float64)\n",
      "#Loss 15 = tensor(70.5341, dtype=torch.float64)\n",
      "#Loss 16 = tensor(61.9789, dtype=torch.float64)\n",
      "#Loss 17 = tensor(56.1664, dtype=torch.float64)\n",
      "#Loss 18 = tensor(52.2049, dtype=torch.float64)\n",
      "#Loss 19 = tensor(48.0587, dtype=torch.float64)\n",
      "#Loss 20 = tensor(44.2124, dtype=torch.float64)\n",
      "#Loss 21 = tensor(39.8188, dtype=torch.float64)\n",
      "#Loss 22 = tensor(36.1548, dtype=torch.float64)\n",
      "#Loss 23 = tensor(32.1581, dtype=torch.float64)\n",
      "#Loss 24 = tensor(28.0116, dtype=torch.float64)\n",
      "#Loss 25 = tensor(25.9741, dtype=torch.float64)\n",
      "#Loss 26 = tensor(23.8712, dtype=torch.float64)\n",
      "#Loss 27 = tensor(21.7523, dtype=torch.float64)\n",
      "#Loss 28 = tensor(19.2339, dtype=torch.float64)\n",
      "#Loss 29 = tensor(17.7333, dtype=torch.float64)\n",
      "#Loss 30 = tensor(16.5783, dtype=torch.float64)\n",
      "#Loss 31 = tensor(15.5692, dtype=torch.float64)\n",
      "#Loss 32 = tensor(15.0574, dtype=torch.float64)\n",
      "#Loss 33 = tensor(14.5754, dtype=torch.float64)\n",
      "#Loss 34 = tensor(14.1994, dtype=torch.float64)\n",
      "#Loss 35 = tensor(13.8546, dtype=torch.float64)\n",
      "#Loss 36 = tensor(13.2748, dtype=torch.float64)\n",
      "#Loss 37 = tensor(12.8860, dtype=torch.float64)\n",
      "#Loss 38 = tensor(12.4706, dtype=torch.float64)\n",
      "#Loss 39 = tensor(12.2985, dtype=torch.float64)\n",
      "#Loss 40 = tensor(12.0851, dtype=torch.float64)\n",
      "#Loss 41 = tensor(11.6428, dtype=torch.float64)\n",
      "#Loss 42 = tensor(11.1842, dtype=torch.float64)\n",
      "#Loss 43 = tensor(10.3902, dtype=torch.float64)\n",
      "#Loss 44 = tensor(9.8869, dtype=torch.float64)\n",
      "#Loss 45 = tensor(9.6946, dtype=torch.float64)\n",
      "#Loss 46 = tensor(9.5776, dtype=torch.float64)\n",
      "#Loss 47 = tensor(9.5230, dtype=torch.float64)\n",
      "#Loss 48 = tensor(9.4642, dtype=torch.float64)\n",
      "#Loss 49 = tensor(9.4339, dtype=torch.float64)\n",
      "#Loss 50 = tensor(9.4225, dtype=torch.float64)\n",
      "#Loss 51 = tensor(9.4196, dtype=torch.float64)\n",
      "#Loss 52 = tensor(9.4190, dtype=torch.float64)\n",
      "#Loss 53 = tensor(9.4188, dtype=torch.float64)\n",
      "#Loss 54 = tensor(9.4187, dtype=torch.float64)\n",
      "#Loss 55 = tensor(9.4186, dtype=torch.float64)\n",
      "#Loss 56 = tensor(9.4186, dtype=torch.float64)\n",
      "#Loss 57 = tensor(9.4186, dtype=torch.float64)\n",
      "#Loss 58 = tensor(9.4186, dtype=torch.float64)\n",
      "#Loss 59 = tensor(9.4186, dtype=torch.float64)\n",
      "#Loss 60 = tensor(9.4186, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(9.6748, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4142, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0487, dtype=torch.float64)   实验回归误差 tensor(0.0406, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(5452.4563, dtype=torch.float64)\n",
      "#Loss 1 = tensor(5451.6074, dtype=torch.float64)\n",
      "#Loss 2 = tensor(676.7565, dtype=torch.float64)\n",
      "#Loss 3 = tensor(493.1279, dtype=torch.float64)\n",
      "#Loss 4 = tensor(429.0841, dtype=torch.float64)\n",
      "#Loss 5 = tensor(384.2086, dtype=torch.float64)\n",
      "#Loss 6 = tensor(342.2909, dtype=torch.float64)\n",
      "#Loss 7 = tensor(302.8011, dtype=torch.float64)\n",
      "#Loss 8 = tensor(269.9406, dtype=torch.float64)\n",
      "#Loss 9 = tensor(237.2194, dtype=torch.float64)\n",
      "#Loss 10 = tensor(208.9036, dtype=torch.float64)\n",
      "#Loss 11 = tensor(185.6249, dtype=torch.float64)\n",
      "#Loss 12 = tensor(166.5435, dtype=torch.float64)\n",
      "#Loss 13 = tensor(151.6648, dtype=torch.float64)\n",
      "#Loss 14 = tensor(135.8336, dtype=torch.float64)\n",
      "#Loss 15 = tensor(120.7325, dtype=torch.float64)\n",
      "#Loss 16 = tensor(110.2311, dtype=torch.float64)\n",
      "#Loss 17 = tensor(101.8968, dtype=torch.float64)\n",
      "#Loss 18 = tensor(94.4210, dtype=torch.float64)\n",
      "#Loss 19 = tensor(86.4541, dtype=torch.float64)\n",
      "#Loss 20 = tensor(79.2778, dtype=torch.float64)\n",
      "#Loss 21 = tensor(73.6541, dtype=torch.float64)\n",
      "#Loss 22 = tensor(68.3122, dtype=torch.float64)\n",
      "#Loss 23 = tensor(60.7657, dtype=torch.float64)\n",
      "#Loss 24 = tensor(56.4388, dtype=torch.float64)\n",
      "#Loss 25 = tensor(53.7280, dtype=torch.float64)\n",
      "#Loss 26 = tensor(49.9595, dtype=torch.float64)\n",
      "#Loss 27 = tensor(45.3788, dtype=torch.float64)\n",
      "#Loss 28 = tensor(42.3686, dtype=torch.float64)\n",
      "#Loss 29 = tensor(40.3745, dtype=torch.float64)\n",
      "#Loss 30 = tensor(39.0663, dtype=torch.float64)\n",
      "#Loss 31 = tensor(37.8685, dtype=torch.float64)\n",
      "#Loss 32 = tensor(36.4348, dtype=torch.float64)\n",
      "#Loss 33 = tensor(35.1860, dtype=torch.float64)\n",
      "#Loss 34 = tensor(32.7480, dtype=torch.float64)\n",
      "#Loss 35 = tensor(30.4900, dtype=torch.float64)\n",
      "#Loss 36 = tensor(29.0387, dtype=torch.float64)\n",
      "#Loss 37 = tensor(28.1911, dtype=torch.float64)\n",
      "#Loss 38 = tensor(27.6458, dtype=torch.float64)\n",
      "#Loss 39 = tensor(27.3910, dtype=torch.float64)\n",
      "#Loss 40 = tensor(26.7589, dtype=torch.float64)\n",
      "#Loss 41 = tensor(26.4205, dtype=torch.float64)\n",
      "#Loss 42 = tensor(26.0677, dtype=torch.float64)\n",
      "#Loss 43 = tensor(25.8484, dtype=torch.float64)\n",
      "#Loss 44 = tensor(25.5038, dtype=torch.float64)\n",
      "#Loss 45 = tensor(25.1045, dtype=torch.float64)\n",
      "#Loss 46 = tensor(24.4924, dtype=torch.float64)\n",
      "#Loss 47 = tensor(24.2116, dtype=torch.float64)\n",
      "#Loss 48 = tensor(24.0241, dtype=torch.float64)\n",
      "#Loss 49 = tensor(23.7293, dtype=torch.float64)\n",
      "#Loss 50 = tensor(23.4497, dtype=torch.float64)\n",
      "#Loss 51 = tensor(23.0720, dtype=torch.float64)\n",
      "#Loss 52 = tensor(22.8955, dtype=torch.float64)\n",
      "#Loss 53 = tensor(22.7586, dtype=torch.float64)\n",
      "#Loss 54 = tensor(22.6187, dtype=torch.float64)\n",
      "#Loss 55 = tensor(22.4706, dtype=torch.float64)\n",
      "#Loss 56 = tensor(22.1894, dtype=torch.float64)\n",
      "#Loss 57 = tensor(21.9670, dtype=torch.float64)\n",
      "#Loss 58 = tensor(21.8066, dtype=torch.float64)\n",
      "#Loss 59 = tensor(21.7033, dtype=torch.float64)\n",
      "#Loss 60 = tensor(21.6552, dtype=torch.float64)\n",
      "#Loss 61 = tensor(21.5745, dtype=torch.float64)\n",
      "#Loss 62 = tensor(21.4949, dtype=torch.float64)\n",
      "#Loss 63 = tensor(21.3175, dtype=torch.float64)\n",
      "#Loss 64 = tensor(21.2256, dtype=torch.float64)\n",
      "#Loss 65 = tensor(21.2030, dtype=torch.float64)\n",
      "#Loss 66 = tensor(21.1866, dtype=torch.float64)\n",
      "#Loss 67 = tensor(21.1360, dtype=torch.float64)\n",
      "#Loss 68 = tensor(21.1164, dtype=torch.float64)\n",
      "#Loss 69 = tensor(21.1107, dtype=torch.float64)\n",
      "#Loss 70 = tensor(21.1035, dtype=torch.float64)\n",
      "#Loss 71 = tensor(21.0913, dtype=torch.float64)\n",
      "#Loss 72 = tensor(21.0892, dtype=torch.float64)\n",
      "#Loss 73 = tensor(21.0885, dtype=torch.float64)\n",
      "#Loss 74 = tensor(21.0882, dtype=torch.float64)\n",
      "#Loss 75 = tensor(21.0880, dtype=torch.float64)\n",
      "#Loss 76 = tensor(21.0879, dtype=torch.float64)\n",
      "#Loss 77 = tensor(21.0879, dtype=torch.float64)\n",
      "#Loss 78 = tensor(21.0879, dtype=torch.float64)\n",
      "#Loss 79 = tensor(21.0879, dtype=torch.float64)\n",
      "#Loss 80 = tensor(21.0878, dtype=torch.float64)\n",
      "#Loss 81 = tensor(21.0878, dtype=torch.float64)\n",
      "#Loss 82 = tensor(21.0878, dtype=torch.float64)\n",
      "#Loss 83 = tensor(21.0878, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(8.1675, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4048, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0491, dtype=torch.float64)   实验回归误差 tensor(0.0622, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(3311.7273, dtype=torch.float64)\n",
      "#Loss 1 = tensor(3194.9328, dtype=torch.float64)\n",
      "#Loss 2 = tensor(373.1692, dtype=torch.float64)\n",
      "#Loss 3 = tensor(304.3368, dtype=torch.float64)\n",
      "#Loss 4 = tensor(247.9070, dtype=torch.float64)\n",
      "#Loss 5 = tensor(202.2415, dtype=torch.float64)\n",
      "#Loss 6 = tensor(155.4176, dtype=torch.float64)\n",
      "#Loss 7 = tensor(120.1264, dtype=torch.float64)\n",
      "#Loss 8 = tensor(91.8851, dtype=torch.float64)\n",
      "#Loss 9 = tensor(73.7396, dtype=torch.float64)\n",
      "#Loss 10 = tensor(63.0674, dtype=torch.float64)\n",
      "#Loss 11 = tensor(53.1524, dtype=torch.float64)\n",
      "#Loss 12 = tensor(45.1726, dtype=torch.float64)\n",
      "#Loss 13 = tensor(38.2369, dtype=torch.float64)\n",
      "#Loss 14 = tensor(33.2507, dtype=torch.float64)\n",
      "#Loss 15 = tensor(29.7964, dtype=torch.float64)\n",
      "#Loss 16 = tensor(26.0397, dtype=torch.float64)\n",
      "#Loss 17 = tensor(21.7252, dtype=torch.float64)\n",
      "#Loss 18 = tensor(18.8107, dtype=torch.float64)\n",
      "#Loss 19 = tensor(17.1073, dtype=torch.float64)\n",
      "#Loss 20 = tensor(15.5555, dtype=torch.float64)\n",
      "#Loss 21 = tensor(14.1494, dtype=torch.float64)\n",
      "#Loss 22 = tensor(13.0978, dtype=torch.float64)\n",
      "#Loss 23 = tensor(12.2161, dtype=torch.float64)\n",
      "#Loss 24 = tensor(11.6908, dtype=torch.float64)\n",
      "#Loss 25 = tensor(11.3521, dtype=torch.float64)\n",
      "#Loss 26 = tensor(11.0122, dtype=torch.float64)\n",
      "#Loss 27 = tensor(10.7798, dtype=torch.float64)\n",
      "#Loss 28 = tensor(10.6379, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 29 = tensor(10.4376, dtype=torch.float64)\n",
      "#Loss 30 = tensor(10.2895, dtype=torch.float64)\n",
      "#Loss 31 = tensor(10.2047, dtype=torch.float64)\n",
      "#Loss 32 = tensor(9.9639, dtype=torch.float64)\n",
      "#Loss 33 = tensor(9.6658, dtype=torch.float64)\n",
      "#Loss 34 = tensor(9.2241, dtype=torch.float64)\n",
      "#Loss 35 = tensor(8.7838, dtype=torch.float64)\n",
      "#Loss 36 = tensor(8.4088, dtype=torch.float64)\n",
      "#Loss 37 = tensor(8.0430, dtype=torch.float64)\n",
      "#Loss 38 = tensor(7.7972, dtype=torch.float64)\n",
      "#Loss 39 = tensor(7.5250, dtype=torch.float64)\n",
      "#Loss 40 = tensor(7.3988, dtype=torch.float64)\n",
      "#Loss 41 = tensor(7.0985, dtype=torch.float64)\n",
      "#Loss 42 = tensor(6.8828, dtype=torch.float64)\n",
      "#Loss 43 = tensor(6.8144, dtype=torch.float64)\n",
      "#Loss 44 = tensor(6.7387, dtype=torch.float64)\n",
      "#Loss 45 = tensor(6.6210, dtype=torch.float64)\n",
      "#Loss 46 = tensor(6.5735, dtype=torch.float64)\n",
      "#Loss 47 = tensor(6.5416, dtype=torch.float64)\n",
      "#Loss 48 = tensor(6.5054, dtype=torch.float64)\n",
      "#Loss 49 = tensor(6.4660, dtype=torch.float64)\n",
      "#Loss 50 = tensor(6.4388, dtype=torch.float64)\n",
      "#Loss 51 = tensor(6.4181, dtype=torch.float64)\n",
      "#Loss 52 = tensor(6.3958, dtype=torch.float64)\n",
      "#Loss 53 = tensor(6.3893, dtype=torch.float64)\n",
      "#Loss 54 = tensor(6.3863, dtype=torch.float64)\n",
      "#Loss 55 = tensor(6.3847, dtype=torch.float64)\n",
      "#Loss 56 = tensor(6.3757, dtype=torch.float64)\n",
      "#Loss 57 = tensor(6.3696, dtype=torch.float64)\n",
      "#Loss 58 = tensor(6.3677, dtype=torch.float64)\n",
      "#Loss 59 = tensor(6.3627, dtype=torch.float64)\n",
      "#Loss 60 = tensor(6.3617, dtype=torch.float64)\n",
      "#Loss 61 = tensor(6.3613, dtype=torch.float64)\n",
      "#Loss 62 = tensor(6.3590, dtype=torch.float64)\n",
      "#Loss 63 = tensor(6.3586, dtype=torch.float64)\n",
      "#Loss 64 = tensor(6.3585, dtype=torch.float64)\n",
      "#Loss 65 = tensor(6.3584, dtype=torch.float64)\n",
      "#Loss 66 = tensor(6.3584, dtype=torch.float64)\n",
      "#Loss 67 = tensor(6.3584, dtype=torch.float64)\n",
      "#Loss 68 = tensor(6.3584, dtype=torch.float64)\n",
      "#Loss 69 = tensor(6.3584, dtype=torch.float64)\n",
      "#Loss 70 = tensor(6.3584, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(6.0529, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4095, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0673, dtype=torch.float64)   实验回归误差 tensor(0.0438, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(3882.8142, dtype=torch.float64)\n",
      "#Loss 1 = tensor(3801.5483, dtype=torch.float64)\n",
      "#Loss 2 = tensor(518.7506, dtype=torch.float64)\n",
      "#Loss 3 = tensor(410.4522, dtype=torch.float64)\n",
      "#Loss 4 = tensor(344.1523, dtype=torch.float64)\n",
      "#Loss 5 = tensor(278.0871, dtype=torch.float64)\n",
      "#Loss 6 = tensor(223.5704, dtype=torch.float64)\n",
      "#Loss 7 = tensor(179.7807, dtype=torch.float64)\n",
      "#Loss 8 = tensor(148.1839, dtype=torch.float64)\n",
      "#Loss 9 = tensor(126.0856, dtype=torch.float64)\n",
      "#Loss 10 = tensor(108.5496, dtype=torch.float64)\n",
      "#Loss 11 = tensor(93.0509, dtype=torch.float64)\n",
      "#Loss 12 = tensor(81.0956, dtype=torch.float64)\n",
      "#Loss 13 = tensor(71.3421, dtype=torch.float64)\n",
      "#Loss 14 = tensor(59.6680, dtype=torch.float64)\n",
      "#Loss 15 = tensor(48.5940, dtype=torch.float64)\n",
      "#Loss 16 = tensor(39.2439, dtype=torch.float64)\n",
      "#Loss 17 = tensor(32.8035, dtype=torch.float64)\n",
      "#Loss 18 = tensor(28.0007, dtype=torch.float64)\n",
      "#Loss 19 = tensor(24.4066, dtype=torch.float64)\n",
      "#Loss 20 = tensor(21.5212, dtype=torch.float64)\n",
      "#Loss 21 = tensor(19.4514, dtype=torch.float64)\n",
      "#Loss 22 = tensor(17.3966, dtype=torch.float64)\n",
      "#Loss 23 = tensor(15.6055, dtype=torch.float64)\n",
      "#Loss 24 = tensor(13.9944, dtype=torch.float64)\n",
      "#Loss 25 = tensor(12.4336, dtype=torch.float64)\n",
      "#Loss 26 = tensor(10.6028, dtype=torch.float64)\n",
      "#Loss 27 = tensor(8.8694, dtype=torch.float64)\n",
      "#Loss 28 = tensor(7.9390, dtype=torch.float64)\n",
      "#Loss 29 = tensor(6.9793, dtype=torch.float64)\n",
      "#Loss 30 = tensor(6.4139, dtype=torch.float64)\n",
      "#Loss 31 = tensor(5.9908, dtype=torch.float64)\n",
      "#Loss 32 = tensor(5.5285, dtype=torch.float64)\n",
      "#Loss 33 = tensor(5.1995, dtype=torch.float64)\n",
      "#Loss 34 = tensor(4.9452, dtype=torch.float64)\n",
      "#Loss 35 = tensor(4.8327, dtype=torch.float64)\n",
      "#Loss 36 = tensor(4.7852, dtype=torch.float64)\n",
      "#Loss 37 = tensor(4.7564, dtype=torch.float64)\n",
      "#Loss 38 = tensor(4.7267, dtype=torch.float64)\n",
      "#Loss 39 = tensor(4.6631, dtype=torch.float64)\n",
      "#Loss 40 = tensor(4.5365, dtype=torch.float64)\n",
      "#Loss 41 = tensor(4.4491, dtype=torch.float64)\n",
      "#Loss 42 = tensor(4.3674, dtype=torch.float64)\n",
      "#Loss 43 = tensor(4.2984, dtype=torch.float64)\n",
      "#Loss 44 = tensor(4.1692, dtype=torch.float64)\n",
      "#Loss 45 = tensor(4.0946, dtype=torch.float64)\n",
      "#Loss 46 = tensor(4.0693, dtype=torch.float64)\n",
      "#Loss 47 = tensor(4.0477, dtype=torch.float64)\n",
      "#Loss 48 = tensor(4.0344, dtype=torch.float64)\n",
      "#Loss 49 = tensor(4.0203, dtype=torch.float64)\n",
      "#Loss 50 = tensor(4.0161, dtype=torch.float64)\n",
      "#Loss 51 = tensor(4.0140, dtype=torch.float64)\n",
      "#Loss 52 = tensor(4.0135, dtype=torch.float64)\n",
      "#Loss 53 = tensor(4.0131, dtype=torch.float64)\n",
      "#Loss 54 = tensor(4.0120, dtype=torch.float64)\n",
      "#Loss 55 = tensor(4.0117, dtype=torch.float64)\n",
      "#Loss 56 = tensor(4.0117, dtype=torch.float64)\n",
      "#Loss 57 = tensor(4.0116, dtype=torch.float64)\n",
      "#Loss 58 = tensor(4.0116, dtype=torch.float64)\n",
      "#Loss 59 = tensor(4.0116, dtype=torch.float64)\n",
      "#Loss 60 = tensor(4.0116, dtype=torch.float64)\n",
      "#Loss 61 = tensor(4.0116, dtype=torch.float64)\n",
      "#Loss 62 = tensor(4.0116, dtype=torch.float64)\n",
      "#Loss 63 = tensor(4.0116, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(7.5149, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4000, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0585, dtype=torch.float64)   实验回归误差 tensor(0.0321, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(6428.3941, dtype=torch.float64)\n",
      "#Loss 1 = tensor(6124.1521, dtype=torch.float64)\n",
      "#Loss 2 = tensor(1313.9529, dtype=torch.float64)\n",
      "#Loss 3 = tensor(748.7780, dtype=torch.float64)\n",
      "#Loss 4 = tensor(514.9765, dtype=torch.float64)\n",
      "#Loss 5 = tensor(368.6835, dtype=torch.float64)\n",
      "#Loss 6 = tensor(268.8098, dtype=torch.float64)\n",
      "#Loss 7 = tensor(193.9382, dtype=torch.float64)\n",
      "#Loss 8 = tensor(143.0683, dtype=torch.float64)\n",
      "#Loss 9 = tensor(105.7237, dtype=torch.float64)\n",
      "#Loss 10 = tensor(80.9678, dtype=torch.float64)\n",
      "#Loss 11 = tensor(65.9783, dtype=torch.float64)\n",
      "#Loss 12 = tensor(52.1767, dtype=torch.float64)\n",
      "#Loss 13 = tensor(42.0788, dtype=torch.float64)\n",
      "#Loss 14 = tensor(35.7190, dtype=torch.float64)\n",
      "#Loss 15 = tensor(31.0199, dtype=torch.float64)\n",
      "#Loss 16 = tensor(27.2260, dtype=torch.float64)\n",
      "#Loss 17 = tensor(23.0930, dtype=torch.float64)\n",
      "#Loss 18 = tensor(19.9694, dtype=torch.float64)\n",
      "#Loss 19 = tensor(18.0550, dtype=torch.float64)\n",
      "#Loss 20 = tensor(15.9612, dtype=torch.float64)\n",
      "#Loss 21 = tensor(14.9416, dtype=torch.float64)\n",
      "#Loss 22 = tensor(13.7770, dtype=torch.float64)\n",
      "#Loss 23 = tensor(12.8189, dtype=torch.float64)\n",
      "#Loss 24 = tensor(12.2236, dtype=torch.float64)\n",
      "#Loss 25 = tensor(11.9909, dtype=torch.float64)\n",
      "#Loss 26 = tensor(11.8306, dtype=torch.float64)\n",
      "#Loss 27 = tensor(11.7365, dtype=torch.float64)\n",
      "#Loss 28 = tensor(11.6757, dtype=torch.float64)\n",
      "#Loss 29 = tensor(11.6207, dtype=torch.float64)\n",
      "#Loss 30 = tensor(11.6036, dtype=torch.float64)\n",
      "#Loss 31 = tensor(11.5919, dtype=torch.float64)\n",
      "#Loss 32 = tensor(11.5577, dtype=torch.float64)\n",
      "#Loss 33 = tensor(11.5210, dtype=torch.float64)\n",
      "#Loss 34 = tensor(11.4754, dtype=torch.float64)\n",
      "#Loss 35 = tensor(11.4572, dtype=torch.float64)\n",
      "#Loss 36 = tensor(11.3830, dtype=torch.float64)\n",
      "#Loss 37 = tensor(10.8162, dtype=torch.float64)\n",
      "#Loss 38 = tensor(10.6359, dtype=torch.float64)\n",
      "#Loss 39 = tensor(10.5467, dtype=torch.float64)\n",
      "#Loss 40 = tensor(10.3964, dtype=torch.float64)\n",
      "#Loss 41 = tensor(10.1632, dtype=torch.float64)\n",
      "#Loss 42 = tensor(9.8868, dtype=torch.float64)\n",
      "#Loss 43 = tensor(9.7556, dtype=torch.float64)\n",
      "#Loss 44 = tensor(9.7075, dtype=torch.float64)\n",
      "#Loss 45 = tensor(9.6832, dtype=torch.float64)\n",
      "#Loss 46 = tensor(9.6671, dtype=torch.float64)\n",
      "#Loss 47 = tensor(9.6596, dtype=torch.float64)\n",
      "#Loss 48 = tensor(9.5996, dtype=torch.float64)\n",
      "#Loss 49 = tensor(9.5797, dtype=torch.float64)\n",
      "#Loss 50 = tensor(9.5721, dtype=torch.float64)\n",
      "#Loss 51 = tensor(9.5697, dtype=torch.float64)\n",
      "#Loss 52 = tensor(9.5688, dtype=torch.float64)\n",
      "#Loss 53 = tensor(9.5620, dtype=torch.float64)\n",
      "#Loss 54 = tensor(9.5561, dtype=torch.float64)\n",
      "#Loss 55 = tensor(9.5534, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 56 = tensor(9.5528, dtype=torch.float64)\n",
      "#Loss 57 = tensor(9.5525, dtype=torch.float64)\n",
      "#Loss 58 = tensor(9.5524, dtype=torch.float64)\n",
      "#Loss 59 = tensor(9.5524, dtype=torch.float64)\n",
      "#Loss 60 = tensor(9.5524, dtype=torch.float64)\n",
      "#Loss 61 = tensor(9.5523, dtype=torch.float64)\n",
      "#Loss 62 = tensor(9.5523, dtype=torch.float64)\n",
      "#Loss 63 = tensor(9.5523, dtype=torch.float64)\n",
      "#Loss 64 = tensor(9.5523, dtype=torch.float64)\n",
      "#Loss 65 = tensor(9.5523, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(7.4719, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4048, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0455, dtype=torch.float64)   实验回归误差 tensor(0.0385, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(5172.8043, dtype=torch.float64)\n",
      "#Loss 1 = tensor(4692.4116, dtype=torch.float64)\n",
      "#Loss 2 = tensor(437.6261, dtype=torch.float64)\n",
      "#Loss 3 = tensor(330.9589, dtype=torch.float64)\n",
      "#Loss 4 = tensor(285.0509, dtype=torch.float64)\n",
      "#Loss 5 = tensor(247.8648, dtype=torch.float64)\n",
      "#Loss 6 = tensor(211.1697, dtype=torch.float64)\n",
      "#Loss 7 = tensor(184.3341, dtype=torch.float64)\n",
      "#Loss 8 = tensor(160.0916, dtype=torch.float64)\n",
      "#Loss 9 = tensor(138.5478, dtype=torch.float64)\n",
      "#Loss 10 = tensor(122.7652, dtype=torch.float64)\n",
      "#Loss 11 = tensor(108.9893, dtype=torch.float64)\n",
      "#Loss 12 = tensor(97.1388, dtype=torch.float64)\n",
      "#Loss 13 = tensor(86.3763, dtype=torch.float64)\n",
      "#Loss 14 = tensor(78.0478, dtype=torch.float64)\n",
      "#Loss 15 = tensor(68.4726, dtype=torch.float64)\n",
      "#Loss 16 = tensor(62.1620, dtype=torch.float64)\n",
      "#Loss 17 = tensor(57.0719, dtype=torch.float64)\n",
      "#Loss 18 = tensor(50.9541, dtype=torch.float64)\n",
      "#Loss 19 = tensor(44.8232, dtype=torch.float64)\n",
      "#Loss 20 = tensor(40.0499, dtype=torch.float64)\n",
      "#Loss 21 = tensor(36.3041, dtype=torch.float64)\n",
      "#Loss 22 = tensor(32.9749, dtype=torch.float64)\n",
      "#Loss 23 = tensor(30.7759, dtype=torch.float64)\n",
      "#Loss 24 = tensor(29.0766, dtype=torch.float64)\n",
      "#Loss 25 = tensor(26.5360, dtype=torch.float64)\n",
      "#Loss 26 = tensor(23.9934, dtype=torch.float64)\n",
      "#Loss 27 = tensor(21.4677, dtype=torch.float64)\n",
      "#Loss 28 = tensor(19.6729, dtype=torch.float64)\n",
      "#Loss 29 = tensor(17.4928, dtype=torch.float64)\n",
      "#Loss 30 = tensor(16.0288, dtype=torch.float64)\n",
      "#Loss 31 = tensor(14.8677, dtype=torch.float64)\n",
      "#Loss 32 = tensor(13.9076, dtype=torch.float64)\n",
      "#Loss 33 = tensor(12.5985, dtype=torch.float64)\n",
      "#Loss 34 = tensor(11.6064, dtype=torch.float64)\n",
      "#Loss 35 = tensor(10.5809, dtype=torch.float64)\n",
      "#Loss 36 = tensor(10.0228, dtype=torch.float64)\n",
      "#Loss 37 = tensor(9.5785, dtype=torch.float64)\n",
      "#Loss 38 = tensor(9.0285, dtype=torch.float64)\n",
      "#Loss 39 = tensor(8.7273, dtype=torch.float64)\n",
      "#Loss 40 = tensor(8.3888, dtype=torch.float64)\n",
      "#Loss 41 = tensor(8.1805, dtype=torch.float64)\n",
      "#Loss 42 = tensor(8.0340, dtype=torch.float64)\n",
      "#Loss 43 = tensor(7.9849, dtype=torch.float64)\n",
      "#Loss 44 = tensor(7.9639, dtype=torch.float64)\n",
      "#Loss 45 = tensor(7.9143, dtype=torch.float64)\n",
      "#Loss 46 = tensor(7.8083, dtype=torch.float64)\n",
      "#Loss 47 = tensor(7.7818, dtype=torch.float64)\n",
      "#Loss 48 = tensor(7.7751, dtype=torch.float64)\n",
      "#Loss 49 = tensor(7.7634, dtype=torch.float64)\n",
      "#Loss 50 = tensor(7.7589, dtype=torch.float64)\n",
      "#Loss 51 = tensor(7.7571, dtype=torch.float64)\n",
      "#Loss 52 = tensor(7.7433, dtype=torch.float64)\n",
      "#Loss 53 = tensor(7.7402, dtype=torch.float64)\n",
      "#Loss 54 = tensor(7.7307, dtype=torch.float64)\n",
      "#Loss 55 = tensor(7.6668, dtype=torch.float64)\n",
      "#Loss 56 = tensor(7.6234, dtype=torch.float64)\n",
      "#Loss 57 = tensor(7.5957, dtype=torch.float64)\n",
      "#Loss 58 = tensor(7.5549, dtype=torch.float64)\n",
      "#Loss 59 = tensor(7.4970, dtype=torch.float64)\n",
      "#Loss 60 = tensor(7.4814, dtype=torch.float64)\n",
      "#Loss 61 = tensor(7.4733, dtype=torch.float64)\n",
      "#Loss 62 = tensor(7.4673, dtype=torch.float64)\n",
      "#Loss 63 = tensor(7.4617, dtype=torch.float64)\n",
      "#Loss 64 = tensor(7.4609, dtype=torch.float64)\n",
      "#Loss 65 = tensor(7.4606, dtype=torch.float64)\n",
      "#Loss 66 = tensor(7.4605, dtype=torch.float64)\n",
      "#Loss 67 = tensor(7.4604, dtype=torch.float64)\n",
      "#Loss 68 = tensor(7.4253, dtype=torch.float64)\n",
      "#Loss 69 = tensor(7.4187, dtype=torch.float64)\n",
      "#Loss 70 = tensor(7.4172, dtype=torch.float64)\n",
      "#Loss 71 = tensor(7.4166, dtype=torch.float64)\n",
      "#Loss 72 = tensor(7.4164, dtype=torch.float64)\n",
      "#Loss 73 = tensor(7.4163, dtype=torch.float64)\n",
      "#Loss 74 = tensor(7.4162, dtype=torch.float64)\n",
      "#Loss 75 = tensor(7.4162, dtype=torch.float64)\n",
      "#Loss 76 = tensor(7.4162, dtype=torch.float64)\n",
      "#Loss 77 = tensor(7.4162, dtype=torch.float64)\n",
      "#Loss 78 = tensor(7.4162, dtype=torch.float64)\n",
      "#Loss 79 = tensor(7.4162, dtype=torch.float64)\n",
      "#Loss 80 = tensor(7.4162, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(8.1786, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4142, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0508, dtype=torch.float64)   实验回归误差 tensor(0.0379, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(4353.2054, dtype=torch.float64)\n",
      "#Loss 1 = tensor(4076.1038, dtype=torch.float64)\n",
      "#Loss 2 = tensor(310.4686, dtype=torch.float64)\n",
      "#Loss 3 = tensor(255.3143, dtype=torch.float64)\n",
      "#Loss 4 = tensor(233.6881, dtype=torch.float64)\n",
      "#Loss 5 = tensor(212.7604, dtype=torch.float64)\n",
      "#Loss 6 = tensor(193.4125, dtype=torch.float64)\n",
      "#Loss 7 = tensor(172.6036, dtype=torch.float64)\n",
      "#Loss 8 = tensor(155.9975, dtype=torch.float64)\n",
      "#Loss 9 = tensor(137.2736, dtype=torch.float64)\n",
      "#Loss 10 = tensor(120.5081, dtype=torch.float64)\n",
      "#Loss 11 = tensor(106.3555, dtype=torch.float64)\n",
      "#Loss 12 = tensor(95.1832, dtype=torch.float64)\n",
      "#Loss 13 = tensor(86.2657, dtype=torch.float64)\n",
      "#Loss 14 = tensor(78.2835, dtype=torch.float64)\n",
      "#Loss 15 = tensor(70.1781, dtype=torch.float64)\n",
      "#Loss 16 = tensor(62.4296, dtype=torch.float64)\n",
      "#Loss 17 = tensor(56.4776, dtype=torch.float64)\n",
      "#Loss 18 = tensor(52.3145, dtype=torch.float64)\n",
      "#Loss 19 = tensor(47.3193, dtype=torch.float64)\n",
      "#Loss 20 = tensor(43.7818, dtype=torch.float64)\n",
      "#Loss 21 = tensor(40.0740, dtype=torch.float64)\n",
      "#Loss 22 = tensor(38.0913, dtype=torch.float64)\n",
      "#Loss 23 = tensor(36.3138, dtype=torch.float64)\n",
      "#Loss 24 = tensor(34.7608, dtype=torch.float64)\n",
      "#Loss 25 = tensor(32.9366, dtype=torch.float64)\n",
      "#Loss 26 = tensor(31.8221, dtype=torch.float64)\n",
      "#Loss 27 = tensor(29.8569, dtype=torch.float64)\n",
      "#Loss 28 = tensor(28.1219, dtype=torch.float64)\n",
      "#Loss 29 = tensor(26.4180, dtype=torch.float64)\n",
      "#Loss 30 = tensor(24.8073, dtype=torch.float64)\n",
      "#Loss 31 = tensor(23.2395, dtype=torch.float64)\n",
      "#Loss 32 = tensor(21.9944, dtype=torch.float64)\n",
      "#Loss 33 = tensor(21.1944, dtype=torch.float64)\n",
      "#Loss 34 = tensor(20.1816, dtype=torch.float64)\n",
      "#Loss 35 = tensor(19.2488, dtype=torch.float64)\n",
      "#Loss 36 = tensor(18.8035, dtype=torch.float64)\n",
      "#Loss 37 = tensor(18.4296, dtype=torch.float64)\n",
      "#Loss 38 = tensor(17.9950, dtype=torch.float64)\n",
      "#Loss 39 = tensor(17.5404, dtype=torch.float64)\n",
      "#Loss 40 = tensor(16.9535, dtype=torch.float64)\n",
      "#Loss 41 = tensor(16.3165, dtype=torch.float64)\n",
      "#Loss 42 = tensor(15.6089, dtype=torch.float64)\n",
      "#Loss 43 = tensor(15.0874, dtype=torch.float64)\n",
      "#Loss 44 = tensor(14.7360, dtype=torch.float64)\n",
      "#Loss 45 = tensor(14.4570, dtype=torch.float64)\n",
      "#Loss 46 = tensor(14.0925, dtype=torch.float64)\n",
      "#Loss 47 = tensor(13.5779, dtype=torch.float64)\n",
      "#Loss 48 = tensor(12.9445, dtype=torch.float64)\n",
      "#Loss 49 = tensor(12.4096, dtype=torch.float64)\n",
      "#Loss 50 = tensor(12.1751, dtype=torch.float64)\n",
      "#Loss 51 = tensor(11.9636, dtype=torch.float64)\n",
      "#Loss 52 = tensor(11.6108, dtype=torch.float64)\n",
      "#Loss 53 = tensor(11.2426, dtype=torch.float64)\n",
      "#Loss 54 = tensor(11.0400, dtype=torch.float64)\n",
      "#Loss 55 = tensor(10.9489, dtype=torch.float64)\n",
      "#Loss 56 = tensor(10.8906, dtype=torch.float64)\n",
      "#Loss 57 = tensor(10.8178, dtype=torch.float64)\n",
      "#Loss 58 = tensor(10.7839, dtype=torch.float64)\n",
      "#Loss 59 = tensor(10.7397, dtype=torch.float64)\n",
      "#Loss 60 = tensor(10.7074, dtype=torch.float64)\n",
      "#Loss 61 = tensor(10.6020, dtype=torch.float64)\n",
      "#Loss 62 = tensor(10.4589, dtype=torch.float64)\n",
      "#Loss 63 = tensor(10.3582, dtype=torch.float64)\n",
      "#Loss 64 = tensor(10.2286, dtype=torch.float64)\n",
      "#Loss 65 = tensor(10.0626, dtype=torch.float64)\n",
      "#Loss 66 = tensor(9.8561, dtype=torch.float64)\n",
      "#Loss 67 = tensor(9.7368, dtype=torch.float64)\n",
      "#Loss 68 = tensor(9.6794, dtype=torch.float64)\n",
      "#Loss 69 = tensor(9.5803, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 70 = tensor(9.4033, dtype=torch.float64)\n",
      "#Loss 71 = tensor(8.9234, dtype=torch.float64)\n",
      "#Loss 72 = tensor(8.6166, dtype=torch.float64)\n",
      "#Loss 73 = tensor(8.4614, dtype=torch.float64)\n",
      "#Loss 74 = tensor(8.3842, dtype=torch.float64)\n",
      "#Loss 75 = tensor(8.3618, dtype=torch.float64)\n",
      "#Loss 76 = tensor(8.3495, dtype=torch.float64)\n",
      "#Loss 77 = tensor(8.3436, dtype=torch.float64)\n",
      "#Loss 78 = tensor(8.3259, dtype=torch.float64)\n",
      "#Loss 79 = tensor(8.3081, dtype=torch.float64)\n",
      "#Loss 80 = tensor(8.2942, dtype=torch.float64)\n",
      "#Loss 81 = tensor(8.2786, dtype=torch.float64)\n",
      "#Loss 82 = tensor(8.2736, dtype=torch.float64)\n",
      "#Loss 83 = tensor(8.2710, dtype=torch.float64)\n",
      "#Loss 84 = tensor(8.2601, dtype=torch.float64)\n",
      "#Loss 85 = tensor(8.2527, dtype=torch.float64)\n",
      "#Loss 86 = tensor(8.2463, dtype=torch.float64)\n",
      "#Loss 87 = tensor(8.2441, dtype=torch.float64)\n",
      "#Loss 88 = tensor(8.2430, dtype=torch.float64)\n",
      "#Loss 89 = tensor(8.2425, dtype=torch.float64)\n",
      "#Loss 90 = tensor(8.2422, dtype=torch.float64)\n",
      "#Loss 91 = tensor(8.2420, dtype=torch.float64)\n",
      "#Loss 92 = tensor(8.2419, dtype=torch.float64)\n",
      "#Loss 93 = tensor(8.2418, dtype=torch.float64)\n",
      "#Loss 94 = tensor(8.2418, dtype=torch.float64)\n",
      "#Loss 95 = tensor(8.2417, dtype=torch.float64)\n",
      "#Loss 96 = tensor(8.2417, dtype=torch.float64)\n",
      "#Loss 97 = tensor(8.2417, dtype=torch.float64)\n",
      "#Loss 98 = tensor(8.2417, dtype=torch.float64)\n",
      "#Loss 99 = tensor(8.2417, dtype=torch.float64)\n",
      "#Loss 100 = tensor(8.2417, dtype=torch.float64)\n",
      "#Loss 101 = tensor(8.2417, dtype=torch.float64)\n",
      "#Loss 102 = tensor(8.2417, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(7.1446, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4142, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0576, dtype=torch.float64)   实验回归误差 tensor(0.0435, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(5262.2327, dtype=torch.float64)\n",
      "#Loss 1 = tensor(4981.0985, dtype=torch.float64)\n",
      "#Loss 2 = tensor(483.5801, dtype=torch.float64)\n",
      "#Loss 3 = tensor(416.5418, dtype=torch.float64)\n",
      "#Loss 4 = tensor(361.3331, dtype=torch.float64)\n",
      "#Loss 5 = tensor(319.3065, dtype=torch.float64)\n",
      "#Loss 6 = tensor(284.3380, dtype=torch.float64)\n",
      "#Loss 7 = tensor(244.4194, dtype=torch.float64)\n",
      "#Loss 8 = tensor(206.6591, dtype=torch.float64)\n",
      "#Loss 9 = tensor(175.4181, dtype=torch.float64)\n",
      "#Loss 10 = tensor(146.2145, dtype=torch.float64)\n",
      "#Loss 11 = tensor(123.5896, dtype=torch.float64)\n",
      "#Loss 12 = tensor(107.2219, dtype=torch.float64)\n",
      "#Loss 13 = tensor(92.1298, dtype=torch.float64)\n",
      "#Loss 14 = tensor(79.8399, dtype=torch.float64)\n",
      "#Loss 15 = tensor(70.4764, dtype=torch.float64)\n",
      "#Loss 16 = tensor(61.3201, dtype=torch.float64)\n",
      "#Loss 17 = tensor(53.1315, dtype=torch.float64)\n",
      "#Loss 18 = tensor(47.3111, dtype=torch.float64)\n",
      "#Loss 19 = tensor(43.4175, dtype=torch.float64)\n",
      "#Loss 20 = tensor(40.5665, dtype=torch.float64)\n",
      "#Loss 21 = tensor(38.2260, dtype=torch.float64)\n",
      "#Loss 22 = tensor(36.2825, dtype=torch.float64)\n",
      "#Loss 23 = tensor(35.1264, dtype=torch.float64)\n",
      "#Loss 24 = tensor(34.1685, dtype=torch.float64)\n",
      "#Loss 25 = tensor(32.8893, dtype=torch.float64)\n",
      "#Loss 26 = tensor(31.2811, dtype=torch.float64)\n",
      "#Loss 27 = tensor(30.4037, dtype=torch.float64)\n",
      "#Loss 28 = tensor(29.1055, dtype=torch.float64)\n",
      "#Loss 29 = tensor(27.9345, dtype=torch.float64)\n",
      "#Loss 30 = tensor(27.1074, dtype=torch.float64)\n",
      "#Loss 31 = tensor(26.4561, dtype=torch.float64)\n",
      "#Loss 32 = tensor(25.9196, dtype=torch.float64)\n",
      "#Loss 33 = tensor(25.4068, dtype=torch.float64)\n",
      "#Loss 34 = tensor(25.1237, dtype=torch.float64)\n",
      "#Loss 35 = tensor(24.9644, dtype=torch.float64)\n",
      "#Loss 36 = tensor(24.4816, dtype=torch.float64)\n",
      "#Loss 37 = tensor(23.9871, dtype=torch.float64)\n",
      "#Loss 38 = tensor(23.6331, dtype=torch.float64)\n",
      "#Loss 39 = tensor(23.3496, dtype=torch.float64)\n",
      "#Loss 40 = tensor(22.8029, dtype=torch.float64)\n",
      "#Loss 41 = tensor(22.3694, dtype=torch.float64)\n",
      "#Loss 42 = tensor(22.0971, dtype=torch.float64)\n",
      "#Loss 43 = tensor(21.9134, dtype=torch.float64)\n",
      "#Loss 44 = tensor(21.8007, dtype=torch.float64)\n",
      "#Loss 45 = tensor(21.5494, dtype=torch.float64)\n",
      "#Loss 46 = tensor(21.3971, dtype=torch.float64)\n",
      "#Loss 47 = tensor(21.3171, dtype=torch.float64)\n",
      "#Loss 48 = tensor(21.2224, dtype=torch.float64)\n",
      "#Loss 49 = tensor(20.8067, dtype=torch.float64)\n",
      "#Loss 50 = tensor(20.6277, dtype=torch.float64)\n",
      "#Loss 51 = tensor(20.5189, dtype=torch.float64)\n",
      "#Loss 52 = tensor(20.3959, dtype=torch.float64)\n",
      "#Loss 53 = tensor(20.2495, dtype=torch.float64)\n",
      "#Loss 54 = tensor(20.1592, dtype=torch.float64)\n",
      "#Loss 55 = tensor(20.1146, dtype=torch.float64)\n",
      "#Loss 56 = tensor(20.0904, dtype=torch.float64)\n",
      "#Loss 57 = tensor(20.0623, dtype=torch.float64)\n",
      "#Loss 58 = tensor(19.9797, dtype=torch.float64)\n",
      "#Loss 59 = tensor(19.8232, dtype=torch.float64)\n",
      "#Loss 60 = tensor(19.7029, dtype=torch.float64)\n",
      "#Loss 61 = tensor(19.5674, dtype=torch.float64)\n",
      "#Loss 62 = tensor(19.5176, dtype=torch.float64)\n",
      "#Loss 63 = tensor(19.4543, dtype=torch.float64)\n",
      "#Loss 64 = tensor(19.3885, dtype=torch.float64)\n",
      "#Loss 65 = tensor(19.3563, dtype=torch.float64)\n",
      "#Loss 66 = tensor(19.3385, dtype=torch.float64)\n",
      "#Loss 67 = tensor(19.3045, dtype=torch.float64)\n",
      "#Loss 68 = tensor(19.2504, dtype=torch.float64)\n",
      "#Loss 69 = tensor(19.1701, dtype=torch.float64)\n",
      "#Loss 70 = tensor(19.0819, dtype=torch.float64)\n",
      "#Loss 71 = tensor(18.9879, dtype=torch.float64)\n",
      "#Loss 72 = tensor(18.8798, dtype=torch.float64)\n",
      "#Loss 73 = tensor(18.8349, dtype=torch.float64)\n",
      "#Loss 74 = tensor(18.8089, dtype=torch.float64)\n",
      "#Loss 75 = tensor(18.8024, dtype=torch.float64)\n",
      "#Loss 76 = tensor(18.8001, dtype=torch.float64)\n",
      "#Loss 77 = tensor(18.7991, dtype=torch.float64)\n",
      "#Loss 78 = tensor(18.7987, dtype=torch.float64)\n",
      "#Loss 79 = tensor(18.7985, dtype=torch.float64)\n",
      "#Loss 80 = tensor(18.7984, dtype=torch.float64)\n",
      "#Loss 81 = tensor(18.7983, dtype=torch.float64)\n",
      "#Loss 82 = tensor(18.7983, dtype=torch.float64)\n",
      "#Loss 83 = tensor(18.7983, dtype=torch.float64)\n",
      "#Loss 84 = tensor(18.7983, dtype=torch.float64)\n",
      "#Loss 85 = tensor(18.7982, dtype=torch.float64)\n",
      "#Loss 86 = tensor(18.7982, dtype=torch.float64)\n",
      "#Loss 87 = tensor(18.7982, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(6.7452, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4142, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0526, dtype=torch.float64)   实验回归误差 tensor(0.0598, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(6337.5110, dtype=torch.float64)\n",
      "#Loss 1 = tensor(5937.0899, dtype=torch.float64)\n",
      "#Loss 2 = tensor(727.4575, dtype=torch.float64)\n",
      "#Loss 3 = tensor(593.6749, dtype=torch.float64)\n",
      "#Loss 4 = tensor(493.0303, dtype=torch.float64)\n",
      "#Loss 5 = tensor(413.3970, dtype=torch.float64)\n",
      "#Loss 6 = tensor(337.4336, dtype=torch.float64)\n",
      "#Loss 7 = tensor(280.1552, dtype=torch.float64)\n",
      "#Loss 8 = tensor(238.5669, dtype=torch.float64)\n",
      "#Loss 9 = tensor(204.1820, dtype=torch.float64)\n",
      "#Loss 10 = tensor(179.2215, dtype=torch.float64)\n",
      "#Loss 11 = tensor(161.3177, dtype=torch.float64)\n",
      "#Loss 12 = tensor(143.9325, dtype=torch.float64)\n",
      "#Loss 13 = tensor(124.3641, dtype=torch.float64)\n",
      "#Loss 14 = tensor(109.7539, dtype=torch.float64)\n",
      "#Loss 15 = tensor(96.2116, dtype=torch.float64)\n",
      "#Loss 16 = tensor(85.1191, dtype=torch.float64)\n",
      "#Loss 17 = tensor(74.6932, dtype=torch.float64)\n",
      "#Loss 18 = tensor(66.0302, dtype=torch.float64)\n",
      "#Loss 19 = tensor(59.5234, dtype=torch.float64)\n",
      "#Loss 20 = tensor(55.2526, dtype=torch.float64)\n",
      "#Loss 21 = tensor(52.6780, dtype=torch.float64)\n",
      "#Loss 22 = tensor(50.5761, dtype=torch.float64)\n",
      "#Loss 23 = tensor(48.9876, dtype=torch.float64)\n",
      "#Loss 24 = tensor(47.0609, dtype=torch.float64)\n",
      "#Loss 25 = tensor(45.0677, dtype=torch.float64)\n",
      "#Loss 26 = tensor(43.3521, dtype=torch.float64)\n",
      "#Loss 27 = tensor(40.9240, dtype=torch.float64)\n",
      "#Loss 28 = tensor(39.2019, dtype=torch.float64)\n",
      "#Loss 29 = tensor(38.2831, dtype=torch.float64)\n",
      "#Loss 30 = tensor(37.6073, dtype=torch.float64)\n",
      "#Loss 31 = tensor(36.8307, dtype=torch.float64)\n",
      "#Loss 32 = tensor(35.9489, dtype=torch.float64)\n",
      "#Loss 33 = tensor(35.0031, dtype=torch.float64)\n",
      "#Loss 34 = tensor(34.2858, dtype=torch.float64)\n",
      "#Loss 35 = tensor(33.9036, dtype=torch.float64)\n",
      "#Loss 36 = tensor(33.6869, dtype=torch.float64)\n",
      "#Loss 37 = tensor(33.3140, dtype=torch.float64)\n",
      "#Loss 38 = tensor(32.7244, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 39 = tensor(32.0651, dtype=torch.float64)\n",
      "#Loss 40 = tensor(31.4822, dtype=torch.float64)\n",
      "#Loss 41 = tensor(31.1831, dtype=torch.float64)\n",
      "#Loss 42 = tensor(30.9616, dtype=torch.float64)\n",
      "#Loss 43 = tensor(30.6268, dtype=torch.float64)\n",
      "#Loss 44 = tensor(30.0115, dtype=torch.float64)\n",
      "#Loss 45 = tensor(29.2822, dtype=torch.float64)\n",
      "#Loss 46 = tensor(28.6642, dtype=torch.float64)\n",
      "#Loss 47 = tensor(28.2849, dtype=torch.float64)\n",
      "#Loss 48 = tensor(27.2227, dtype=torch.float64)\n",
      "#Loss 49 = tensor(26.5925, dtype=torch.float64)\n",
      "#Loss 50 = tensor(26.1229, dtype=torch.float64)\n",
      "#Loss 51 = tensor(25.8054, dtype=torch.float64)\n",
      "#Loss 52 = tensor(25.6786, dtype=torch.float64)\n",
      "#Loss 53 = tensor(25.6172, dtype=torch.float64)\n",
      "#Loss 54 = tensor(25.4002, dtype=torch.float64)\n",
      "#Loss 55 = tensor(24.9777, dtype=torch.float64)\n",
      "#Loss 56 = tensor(24.7675, dtype=torch.float64)\n",
      "#Loss 57 = tensor(24.6539, dtype=torch.float64)\n",
      "#Loss 58 = tensor(24.4199, dtype=torch.float64)\n",
      "#Loss 59 = tensor(24.1439, dtype=torch.float64)\n",
      "#Loss 60 = tensor(23.8860, dtype=torch.float64)\n",
      "#Loss 61 = tensor(23.4495, dtype=torch.float64)\n",
      "#Loss 62 = tensor(23.2495, dtype=torch.float64)\n",
      "#Loss 63 = tensor(23.0122, dtype=torch.float64)\n",
      "#Loss 64 = tensor(22.8736, dtype=torch.float64)\n",
      "#Loss 65 = tensor(22.6049, dtype=torch.float64)\n",
      "#Loss 66 = tensor(22.3598, dtype=torch.float64)\n",
      "#Loss 67 = tensor(22.2575, dtype=torch.float64)\n",
      "#Loss 68 = tensor(22.1990, dtype=torch.float64)\n",
      "#Loss 69 = tensor(22.1581, dtype=torch.float64)\n",
      "#Loss 70 = tensor(22.1434, dtype=torch.float64)\n",
      "#Loss 71 = tensor(22.1203, dtype=torch.float64)\n",
      "#Loss 72 = tensor(22.1040, dtype=torch.float64)\n",
      "#Loss 73 = tensor(22.0899, dtype=torch.float64)\n",
      "#Loss 74 = tensor(22.0849, dtype=torch.float64)\n",
      "#Loss 75 = tensor(22.0825, dtype=torch.float64)\n",
      "#Loss 76 = tensor(22.0542, dtype=torch.float64)\n",
      "#Loss 77 = tensor(21.9923, dtype=torch.float64)\n",
      "#Loss 78 = tensor(21.9584, dtype=torch.float64)\n",
      "#Loss 79 = tensor(21.9474, dtype=torch.float64)\n",
      "#Loss 80 = tensor(21.9243, dtype=torch.float64)\n",
      "#Loss 81 = tensor(21.8961, dtype=torch.float64)\n",
      "#Loss 82 = tensor(21.7260, dtype=torch.float64)\n",
      "#Loss 83 = tensor(21.6535, dtype=torch.float64)\n",
      "#Loss 84 = tensor(21.6033, dtype=torch.float64)\n",
      "#Loss 85 = tensor(21.5662, dtype=torch.float64)\n",
      "#Loss 86 = tensor(21.5504, dtype=torch.float64)\n",
      "#Loss 87 = tensor(21.5455, dtype=torch.float64)\n",
      "#Loss 88 = tensor(21.5434, dtype=torch.float64)\n",
      "#Loss 89 = tensor(21.5423, dtype=torch.float64)\n",
      "#Loss 90 = tensor(21.5418, dtype=torch.float64)\n",
      "#Loss 91 = tensor(21.5415, dtype=torch.float64)\n",
      "#Loss 92 = tensor(21.5414, dtype=torch.float64)\n",
      "#Loss 93 = tensor(21.5413, dtype=torch.float64)\n",
      "#Loss 94 = tensor(21.5412, dtype=torch.float64)\n",
      "#Loss 95 = tensor(21.5412, dtype=torch.float64)\n",
      "#Loss 96 = tensor(21.5412, dtype=torch.float64)\n",
      "#Loss 97 = tensor(21.5412, dtype=torch.float64)\n",
      "#Loss 98 = tensor(21.5412, dtype=torch.float64)\n",
      "#Loss 99 = tensor(21.5412, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(8.5955, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4142, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0479, dtype=torch.float64)   实验回归误差 tensor(0.0583, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(5070.9251, dtype=torch.float64)\n",
      "#Loss 1 = tensor(4967.8518, dtype=torch.float64)\n",
      "#Loss 2 = tensor(410.4028, dtype=torch.float64)\n",
      "#Loss 3 = tensor(349.5009, dtype=torch.float64)\n",
      "#Loss 4 = tensor(325.9745, dtype=torch.float64)\n",
      "#Loss 5 = tensor(307.9411, dtype=torch.float64)\n",
      "#Loss 6 = tensor(291.2621, dtype=torch.float64)\n",
      "#Loss 7 = tensor(272.4542, dtype=torch.float64)\n",
      "#Loss 8 = tensor(254.3702, dtype=torch.float64)\n",
      "#Loss 9 = tensor(234.4901, dtype=torch.float64)\n",
      "#Loss 10 = tensor(218.9376, dtype=torch.float64)\n",
      "#Loss 11 = tensor(205.1083, dtype=torch.float64)\n",
      "#Loss 12 = tensor(191.5312, dtype=torch.float64)\n",
      "#Loss 13 = tensor(177.7183, dtype=torch.float64)\n",
      "#Loss 14 = tensor(164.7890, dtype=torch.float64)\n",
      "#Loss 15 = tensor(153.1940, dtype=torch.float64)\n",
      "#Loss 16 = tensor(144.1486, dtype=torch.float64)\n",
      "#Loss 17 = tensor(130.5337, dtype=torch.float64)\n",
      "#Loss 18 = tensor(119.2468, dtype=torch.float64)\n",
      "#Loss 19 = tensor(110.8500, dtype=torch.float64)\n",
      "#Loss 20 = tensor(103.2931, dtype=torch.float64)\n",
      "#Loss 21 = tensor(96.6382, dtype=torch.float64)\n",
      "#Loss 22 = tensor(89.3793, dtype=torch.float64)\n",
      "#Loss 23 = tensor(82.1621, dtype=torch.float64)\n",
      "#Loss 24 = tensor(75.4707, dtype=torch.float64)\n",
      "#Loss 25 = tensor(64.9605, dtype=torch.float64)\n",
      "#Loss 26 = tensor(56.5484, dtype=torch.float64)\n",
      "#Loss 27 = tensor(50.9850, dtype=torch.float64)\n",
      "#Loss 28 = tensor(47.1550, dtype=torch.float64)\n",
      "#Loss 29 = tensor(45.1429, dtype=torch.float64)\n",
      "#Loss 30 = tensor(43.6308, dtype=torch.float64)\n",
      "#Loss 31 = tensor(41.4986, dtype=torch.float64)\n",
      "#Loss 32 = tensor(38.9696, dtype=torch.float64)\n",
      "#Loss 33 = tensor(36.3737, dtype=torch.float64)\n",
      "#Loss 34 = tensor(34.3319, dtype=torch.float64)\n",
      "#Loss 35 = tensor(31.6880, dtype=torch.float64)\n",
      "#Loss 36 = tensor(28.9966, dtype=torch.float64)\n",
      "#Loss 37 = tensor(27.0393, dtype=torch.float64)\n",
      "#Loss 38 = tensor(25.6274, dtype=torch.float64)\n",
      "#Loss 39 = tensor(24.2981, dtype=torch.float64)\n",
      "#Loss 40 = tensor(23.1682, dtype=torch.float64)\n",
      "#Loss 41 = tensor(21.9189, dtype=torch.float64)\n",
      "#Loss 42 = tensor(20.5773, dtype=torch.float64)\n",
      "#Loss 43 = tensor(18.4103, dtype=torch.float64)\n",
      "#Loss 44 = tensor(16.6914, dtype=torch.float64)\n",
      "#Loss 45 = tensor(15.5470, dtype=torch.float64)\n",
      "#Loss 46 = tensor(14.9872, dtype=torch.float64)\n",
      "#Loss 47 = tensor(14.5685, dtype=torch.float64)\n",
      "#Loss 48 = tensor(13.7962, dtype=torch.float64)\n",
      "#Loss 49 = tensor(12.9789, dtype=torch.float64)\n",
      "#Loss 50 = tensor(12.2619, dtype=torch.float64)\n",
      "#Loss 51 = tensor(11.7851, dtype=torch.float64)\n",
      "#Loss 52 = tensor(11.5229, dtype=torch.float64)\n",
      "#Loss 53 = tensor(11.0534, dtype=torch.float64)\n",
      "#Loss 54 = tensor(10.7182, dtype=torch.float64)\n",
      "#Loss 55 = tensor(10.4885, dtype=torch.float64)\n",
      "#Loss 56 = tensor(10.1140, dtype=torch.float64)\n",
      "#Loss 57 = tensor(9.7739, dtype=torch.float64)\n",
      "#Loss 58 = tensor(9.6312, dtype=torch.float64)\n",
      "#Loss 59 = tensor(9.4665, dtype=torch.float64)\n",
      "#Loss 60 = tensor(9.3243, dtype=torch.float64)\n",
      "#Loss 61 = tensor(9.2726, dtype=torch.float64)\n",
      "#Loss 62 = tensor(9.2230, dtype=torch.float64)\n",
      "#Loss 63 = tensor(9.1375, dtype=torch.float64)\n",
      "#Loss 64 = tensor(9.0750, dtype=torch.float64)\n",
      "#Loss 65 = tensor(8.9995, dtype=torch.float64)\n",
      "#Loss 66 = tensor(8.9761, dtype=torch.float64)\n",
      "#Loss 67 = tensor(8.9662, dtype=torch.float64)\n",
      "#Loss 68 = tensor(8.9230, dtype=torch.float64)\n",
      "#Loss 69 = tensor(8.9135, dtype=torch.float64)\n",
      "#Loss 70 = tensor(8.9075, dtype=torch.float64)\n",
      "#Loss 71 = tensor(8.8998, dtype=torch.float64)\n",
      "#Loss 72 = tensor(8.8977, dtype=torch.float64)\n",
      "#Loss 73 = tensor(8.8965, dtype=torch.float64)\n",
      "#Loss 74 = tensor(8.8805, dtype=torch.float64)\n",
      "#Loss 75 = tensor(8.8701, dtype=torch.float64)\n",
      "#Loss 76 = tensor(8.8672, dtype=torch.float64)\n",
      "#Loss 77 = tensor(8.8652, dtype=torch.float64)\n",
      "#Loss 78 = tensor(8.8646, dtype=torch.float64)\n",
      "#Loss 79 = tensor(8.8644, dtype=torch.float64)\n",
      "#Loss 80 = tensor(8.8642, dtype=torch.float64)\n",
      "#Loss 81 = tensor(8.8642, dtype=torch.float64)\n",
      "#Loss 82 = tensor(8.8642, dtype=torch.float64)\n",
      "#Loss 83 = tensor(8.8641, dtype=torch.float64)\n",
      "#Loss 84 = tensor(8.8641, dtype=torch.float64)\n",
      "#Loss 85 = tensor(8.8641, dtype=torch.float64)\n",
      "#Loss 86 = tensor(8.8641, dtype=torch.float64)\n",
      "#Loss 87 = tensor(8.8641, dtype=torch.float64)\n",
      "#Loss 88 = tensor(8.8641, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(6.9450, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4000, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0534, dtype=torch.float64)   实验回归误差 tensor(0.0418, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(5019.2689, dtype=torch.float64)\n",
      "#Loss 1 = tensor(4837.8648, dtype=torch.float64)\n",
      "#Loss 2 = tensor(781.1300, dtype=torch.float64)\n",
      "#Loss 3 = tensor(623.2191, dtype=torch.float64)\n",
      "#Loss 4 = tensor(501.4119, dtype=torch.float64)\n",
      "#Loss 5 = tensor(390.5321, dtype=torch.float64)\n",
      "#Loss 6 = tensor(303.1725, dtype=torch.float64)\n",
      "#Loss 7 = tensor(243.0723, dtype=torch.float64)\n",
      "#Loss 8 = tensor(200.6554, dtype=torch.float64)\n",
      "#Loss 9 = tensor(155.3664, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 10 = tensor(122.2215, dtype=torch.float64)\n",
      "#Loss 11 = tensor(102.0259, dtype=torch.float64)\n",
      "#Loss 12 = tensor(88.9183, dtype=torch.float64)\n",
      "#Loss 13 = tensor(78.1024, dtype=torch.float64)\n",
      "#Loss 14 = tensor(69.0128, dtype=torch.float64)\n",
      "#Loss 15 = tensor(60.9815, dtype=torch.float64)\n",
      "#Loss 16 = tensor(54.9097, dtype=torch.float64)\n",
      "#Loss 17 = tensor(46.7754, dtype=torch.float64)\n",
      "#Loss 18 = tensor(40.2014, dtype=torch.float64)\n",
      "#Loss 19 = tensor(34.3872, dtype=torch.float64)\n",
      "#Loss 20 = tensor(31.3875, dtype=torch.float64)\n",
      "#Loss 21 = tensor(29.5602, dtype=torch.float64)\n",
      "#Loss 22 = tensor(27.3977, dtype=torch.float64)\n",
      "#Loss 23 = tensor(23.7727, dtype=torch.float64)\n",
      "#Loss 24 = tensor(21.1666, dtype=torch.float64)\n",
      "#Loss 25 = tensor(19.5861, dtype=torch.float64)\n",
      "#Loss 26 = tensor(17.9508, dtype=torch.float64)\n",
      "#Loss 27 = tensor(16.2354, dtype=torch.float64)\n",
      "#Loss 28 = tensor(14.0856, dtype=torch.float64)\n",
      "#Loss 29 = tensor(12.0486, dtype=torch.float64)\n",
      "#Loss 30 = tensor(10.5261, dtype=torch.float64)\n",
      "#Loss 31 = tensor(9.5806, dtype=torch.float64)\n",
      "#Loss 32 = tensor(9.0197, dtype=torch.float64)\n",
      "#Loss 33 = tensor(8.7298, dtype=torch.float64)\n",
      "#Loss 34 = tensor(8.5415, dtype=torch.float64)\n",
      "#Loss 35 = tensor(8.4380, dtype=torch.float64)\n",
      "#Loss 36 = tensor(7.9798, dtype=torch.float64)\n",
      "#Loss 37 = tensor(7.7406, dtype=torch.float64)\n",
      "#Loss 38 = tensor(7.4305, dtype=torch.float64)\n",
      "#Loss 39 = tensor(7.1570, dtype=torch.float64)\n",
      "#Loss 40 = tensor(6.9883, dtype=torch.float64)\n",
      "#Loss 41 = tensor(6.7836, dtype=torch.float64)\n",
      "#Loss 42 = tensor(6.6116, dtype=torch.float64)\n",
      "#Loss 43 = tensor(6.3420, dtype=torch.float64)\n",
      "#Loss 44 = tensor(6.2161, dtype=torch.float64)\n",
      "#Loss 45 = tensor(6.0981, dtype=torch.float64)\n",
      "#Loss 46 = tensor(5.9179, dtype=torch.float64)\n",
      "#Loss 47 = tensor(5.7533, dtype=torch.float64)\n",
      "#Loss 48 = tensor(5.5821, dtype=torch.float64)\n",
      "#Loss 49 = tensor(5.4826, dtype=torch.float64)\n",
      "#Loss 50 = tensor(5.4588, dtype=torch.float64)\n",
      "#Loss 51 = tensor(5.4471, dtype=torch.float64)\n",
      "#Loss 52 = tensor(5.4413, dtype=torch.float64)\n",
      "#Loss 53 = tensor(5.4388, dtype=torch.float64)\n",
      "#Loss 54 = tensor(5.4346, dtype=torch.float64)\n",
      "#Loss 55 = tensor(5.4211, dtype=torch.float64)\n",
      "#Loss 56 = tensor(5.4175, dtype=torch.float64)\n",
      "#Loss 57 = tensor(5.4163, dtype=torch.float64)\n",
      "#Loss 58 = tensor(5.4141, dtype=torch.float64)\n",
      "#Loss 59 = tensor(5.4134, dtype=torch.float64)\n",
      "#Loss 60 = tensor(5.4131, dtype=torch.float64)\n",
      "#Loss 61 = tensor(5.4116, dtype=torch.float64)\n",
      "#Loss 62 = tensor(5.4113, dtype=torch.float64)\n",
      "#Loss 63 = tensor(5.4111, dtype=torch.float64)\n",
      "#Loss 64 = tensor(5.4111, dtype=torch.float64)\n",
      "#Loss 65 = tensor(5.4110, dtype=torch.float64)\n",
      "#Loss 66 = tensor(5.4110, dtype=torch.float64)\n",
      "#Loss 67 = tensor(5.4110, dtype=torch.float64)\n",
      "#Loss 68 = tensor(5.4110, dtype=torch.float64)\n",
      "#Loss 69 = tensor(5.4110, dtype=torch.float64)\n",
      "#Loss 70 = tensor(5.4110, dtype=torch.float64)\n",
      "#Loss 71 = tensor(5.4110, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(8.2148, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4095, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0496, dtype=torch.float64)   实验回归误差 tensor(0.0328, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(3850.0225, dtype=torch.float64)\n",
      "#Loss 1 = tensor(3763.5056, dtype=torch.float64)\n",
      "#Loss 2 = tensor(296.0555, dtype=torch.float64)\n",
      "#Loss 3 = tensor(245.2758, dtype=torch.float64)\n",
      "#Loss 4 = tensor(215.5406, dtype=torch.float64)\n",
      "#Loss 5 = tensor(190.5645, dtype=torch.float64)\n",
      "#Loss 6 = tensor(169.1795, dtype=torch.float64)\n",
      "#Loss 7 = tensor(152.4375, dtype=torch.float64)\n",
      "#Loss 8 = tensor(139.6233, dtype=torch.float64)\n",
      "#Loss 9 = tensor(130.1978, dtype=torch.float64)\n",
      "#Loss 10 = tensor(121.5187, dtype=torch.float64)\n",
      "#Loss 11 = tensor(112.2318, dtype=torch.float64)\n",
      "#Loss 12 = tensor(104.8385, dtype=torch.float64)\n",
      "#Loss 13 = tensor(96.1114, dtype=torch.float64)\n",
      "#Loss 14 = tensor(88.6576, dtype=torch.float64)\n",
      "#Loss 15 = tensor(82.1885, dtype=torch.float64)\n",
      "#Loss 16 = tensor(76.4992, dtype=torch.float64)\n",
      "#Loss 17 = tensor(70.9339, dtype=torch.float64)\n",
      "#Loss 18 = tensor(60.9926, dtype=torch.float64)\n",
      "#Loss 19 = tensor(53.7056, dtype=torch.float64)\n",
      "#Loss 20 = tensor(48.7156, dtype=torch.float64)\n",
      "#Loss 21 = tensor(45.2696, dtype=torch.float64)\n",
      "#Loss 22 = tensor(42.6417, dtype=torch.float64)\n",
      "#Loss 23 = tensor(39.6705, dtype=torch.float64)\n",
      "#Loss 24 = tensor(37.6781, dtype=torch.float64)\n",
      "#Loss 25 = tensor(35.9678, dtype=torch.float64)\n",
      "#Loss 26 = tensor(34.6916, dtype=torch.float64)\n",
      "#Loss 27 = tensor(32.7721, dtype=torch.float64)\n",
      "#Loss 28 = tensor(31.1732, dtype=torch.float64)\n",
      "#Loss 29 = tensor(29.7071, dtype=torch.float64)\n",
      "#Loss 30 = tensor(28.7331, dtype=torch.float64)\n",
      "#Loss 31 = tensor(28.0863, dtype=torch.float64)\n",
      "#Loss 32 = tensor(27.5000, dtype=torch.float64)\n",
      "#Loss 33 = tensor(27.0060, dtype=torch.float64)\n",
      "#Loss 34 = tensor(26.5959, dtype=torch.float64)\n",
      "#Loss 35 = tensor(26.1772, dtype=torch.float64)\n",
      "#Loss 36 = tensor(25.9530, dtype=torch.float64)\n",
      "#Loss 37 = tensor(25.6944, dtype=torch.float64)\n",
      "#Loss 38 = tensor(25.2067, dtype=torch.float64)\n",
      "#Loss 39 = tensor(24.6830, dtype=torch.float64)\n",
      "#Loss 40 = tensor(24.1456, dtype=torch.float64)\n",
      "#Loss 41 = tensor(23.7429, dtype=torch.float64)\n",
      "#Loss 42 = tensor(23.5203, dtype=torch.float64)\n",
      "#Loss 43 = tensor(23.3439, dtype=torch.float64)\n",
      "#Loss 44 = tensor(23.1413, dtype=torch.float64)\n",
      "#Loss 45 = tensor(22.8923, dtype=torch.float64)\n",
      "#Loss 46 = tensor(22.4649, dtype=torch.float64)\n",
      "#Loss 47 = tensor(22.1578, dtype=torch.float64)\n",
      "#Loss 48 = tensor(21.9986, dtype=torch.float64)\n",
      "#Loss 49 = tensor(21.7666, dtype=torch.float64)\n",
      "#Loss 50 = tensor(21.1736, dtype=torch.float64)\n",
      "#Loss 51 = tensor(20.8016, dtype=torch.float64)\n",
      "#Loss 52 = tensor(19.2842, dtype=torch.float64)\n",
      "#Loss 53 = tensor(18.2701, dtype=torch.float64)\n",
      "#Loss 54 = tensor(17.4485, dtype=torch.float64)\n",
      "#Loss 55 = tensor(16.4385, dtype=torch.float64)\n",
      "#Loss 56 = tensor(15.5484, dtype=torch.float64)\n",
      "#Loss 57 = tensor(14.9303, dtype=torch.float64)\n",
      "#Loss 58 = tensor(14.3225, dtype=torch.float64)\n",
      "#Loss 59 = tensor(13.8695, dtype=torch.float64)\n",
      "#Loss 60 = tensor(13.5236, dtype=torch.float64)\n",
      "#Loss 61 = tensor(13.4274, dtype=torch.float64)\n",
      "#Loss 62 = tensor(13.0247, dtype=torch.float64)\n",
      "#Loss 63 = tensor(12.6741, dtype=torch.float64)\n",
      "#Loss 64 = tensor(12.4127, dtype=torch.float64)\n",
      "#Loss 65 = tensor(12.2205, dtype=torch.float64)\n",
      "#Loss 66 = tensor(12.1459, dtype=torch.float64)\n",
      "#Loss 67 = tensor(12.0345, dtype=torch.float64)\n",
      "#Loss 68 = tensor(11.9527, dtype=torch.float64)\n",
      "#Loss 69 = tensor(11.7881, dtype=torch.float64)\n",
      "#Loss 70 = tensor(11.6778, dtype=torch.float64)\n",
      "#Loss 71 = tensor(11.5518, dtype=torch.float64)\n",
      "#Loss 72 = tensor(11.4816, dtype=torch.float64)\n",
      "#Loss 73 = tensor(11.4438, dtype=torch.float64)\n",
      "#Loss 74 = tensor(11.4147, dtype=torch.float64)\n",
      "#Loss 75 = tensor(11.3968, dtype=torch.float64)\n",
      "#Loss 76 = tensor(11.3753, dtype=torch.float64)\n",
      "#Loss 77 = tensor(11.3429, dtype=torch.float64)\n",
      "#Loss 78 = tensor(11.2909, dtype=torch.float64)\n",
      "#Loss 79 = tensor(11.1515, dtype=torch.float64)\n",
      "#Loss 80 = tensor(10.7953, dtype=torch.float64)\n",
      "#Loss 81 = tensor(10.6061, dtype=torch.float64)\n",
      "#Loss 82 = tensor(10.4216, dtype=torch.float64)\n",
      "#Loss 83 = tensor(10.2476, dtype=torch.float64)\n",
      "#Loss 84 = tensor(10.0885, dtype=torch.float64)\n",
      "#Loss 85 = tensor(10.0143, dtype=torch.float64)\n",
      "#Loss 86 = tensor(9.9663, dtype=torch.float64)\n",
      "#Loss 87 = tensor(9.9545, dtype=torch.float64)\n",
      "#Loss 88 = tensor(9.9419, dtype=torch.float64)\n",
      "#Loss 89 = tensor(9.9358, dtype=torch.float64)\n",
      "#Loss 90 = tensor(9.9288, dtype=torch.float64)\n",
      "#Loss 91 = tensor(9.9263, dtype=torch.float64)\n",
      "#Loss 92 = tensor(9.9232, dtype=torch.float64)\n",
      "#Loss 93 = tensor(9.9223, dtype=torch.float64)\n",
      "#Loss 94 = tensor(9.9218, dtype=torch.float64)\n",
      "#Loss 95 = tensor(9.9216, dtype=torch.float64)\n",
      "#Loss 96 = tensor(9.9216, dtype=torch.float64)\n",
      "#Loss 97 = tensor(9.9215, dtype=torch.float64)\n",
      "#Loss 98 = tensor(9.9215, dtype=torch.float64)\n",
      "#Loss 99 = tensor(9.9215, dtype=torch.float64)\n",
      "#Loss 100 = tensor(9.9215, dtype=torch.float64)\n",
      "#Loss 101 = tensor(9.9215, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(7.3690, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4048, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0612, dtype=torch.float64)   实验回归误差 tensor(0.0508, dtype=torch.float64, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0 = tensor(2876.6086, dtype=torch.float64)\n",
      "#Loss 1 = tensor(2825.2097, dtype=torch.float64)\n",
      "#Loss 2 = tensor(362.9398, dtype=torch.float64)\n",
      "#Loss 3 = tensor(284.5695, dtype=torch.float64)\n",
      "#Loss 4 = tensor(243.1051, dtype=torch.float64)\n",
      "#Loss 5 = tensor(208.1102, dtype=torch.float64)\n",
      "#Loss 6 = tensor(177.4558, dtype=torch.float64)\n",
      "#Loss 7 = tensor(149.0420, dtype=torch.float64)\n",
      "#Loss 8 = tensor(129.8700, dtype=torch.float64)\n",
      "#Loss 9 = tensor(113.0946, dtype=torch.float64)\n",
      "#Loss 10 = tensor(98.2560, dtype=torch.float64)\n",
      "#Loss 11 = tensor(86.5801, dtype=torch.float64)\n",
      "#Loss 12 = tensor(76.0090, dtype=torch.float64)\n",
      "#Loss 13 = tensor(66.8007, dtype=torch.float64)\n",
      "#Loss 14 = tensor(60.9096, dtype=torch.float64)\n",
      "#Loss 15 = tensor(57.5648, dtype=torch.float64)\n",
      "#Loss 16 = tensor(55.3072, dtype=torch.float64)\n",
      "#Loss 17 = tensor(52.7697, dtype=torch.float64)\n",
      "#Loss 18 = tensor(50.0362, dtype=torch.float64)\n",
      "#Loss 19 = tensor(48.1045, dtype=torch.float64)\n",
      "#Loss 20 = tensor(46.6252, dtype=torch.float64)\n",
      "#Loss 21 = tensor(43.8627, dtype=torch.float64)\n",
      "#Loss 22 = tensor(41.3336, dtype=torch.float64)\n",
      "#Loss 23 = tensor(39.3697, dtype=torch.float64)\n",
      "#Loss 24 = tensor(37.6577, dtype=torch.float64)\n",
      "#Loss 25 = tensor(35.6705, dtype=torch.float64)\n",
      "#Loss 26 = tensor(34.0422, dtype=torch.float64)\n",
      "#Loss 27 = tensor(32.5672, dtype=torch.float64)\n",
      "#Loss 28 = tensor(31.4674, dtype=torch.float64)\n",
      "#Loss 29 = tensor(30.5060, dtype=torch.float64)\n",
      "#Loss 30 = tensor(29.9381, dtype=torch.float64)\n",
      "#Loss 31 = tensor(29.3418, dtype=torch.float64)\n",
      "#Loss 32 = tensor(28.8095, dtype=torch.float64)\n",
      "#Loss 33 = tensor(28.5215, dtype=torch.float64)\n",
      "#Loss 34 = tensor(27.8785, dtype=torch.float64)\n",
      "#Loss 35 = tensor(26.9116, dtype=torch.float64)\n",
      "#Loss 36 = tensor(26.2645, dtype=torch.float64)\n",
      "#Loss 37 = tensor(25.1334, dtype=torch.float64)\n",
      "#Loss 38 = tensor(23.8850, dtype=torch.float64)\n",
      "#Loss 39 = tensor(22.1876, dtype=torch.float64)\n",
      "#Loss 40 = tensor(21.0634, dtype=torch.float64)\n",
      "#Loss 41 = tensor(20.2732, dtype=torch.float64)\n",
      "#Loss 42 = tensor(19.5209, dtype=torch.float64)\n",
      "#Loss 43 = tensor(18.8971, dtype=torch.float64)\n",
      "#Loss 44 = tensor(18.4600, dtype=torch.float64)\n",
      "#Loss 45 = tensor(18.2506, dtype=torch.float64)\n",
      "#Loss 46 = tensor(18.0702, dtype=torch.float64)\n",
      "#Loss 47 = tensor(17.8956, dtype=torch.float64)\n",
      "#Loss 48 = tensor(17.7050, dtype=torch.float64)\n",
      "#Loss 49 = tensor(17.3126, dtype=torch.float64)\n",
      "#Loss 50 = tensor(16.9643, dtype=torch.float64)\n",
      "#Loss 51 = tensor(16.6857, dtype=torch.float64)\n",
      "#Loss 52 = tensor(16.5220, dtype=torch.float64)\n",
      "#Loss 53 = tensor(16.3430, dtype=torch.float64)\n",
      "#Loss 54 = tensor(16.1413, dtype=torch.float64)\n",
      "#Loss 55 = tensor(15.8845, dtype=torch.float64)\n",
      "#Loss 56 = tensor(15.6396, dtype=torch.float64)\n",
      "#Loss 57 = tensor(15.3790, dtype=torch.float64)\n",
      "#Loss 58 = tensor(15.0492, dtype=torch.float64)\n",
      "#Loss 59 = tensor(14.8585, dtype=torch.float64)\n",
      "#Loss 60 = tensor(14.4699, dtype=torch.float64)\n",
      "#Loss 61 = tensor(14.1840, dtype=torch.float64)\n",
      "#Loss 62 = tensor(13.9559, dtype=torch.float64)\n",
      "#Loss 63 = tensor(13.6764, dtype=torch.float64)\n",
      "#Loss 64 = tensor(13.4177, dtype=torch.float64)\n",
      "#Loss 65 = tensor(13.2118, dtype=torch.float64)\n",
      "#Loss 66 = tensor(13.0501, dtype=torch.float64)\n",
      "#Loss 67 = tensor(12.9058, dtype=torch.float64)\n",
      "#Loss 68 = tensor(12.8029, dtype=torch.float64)\n",
      "#Loss 69 = tensor(12.7418, dtype=torch.float64)\n",
      "#Loss 70 = tensor(12.7098, dtype=torch.float64)\n",
      "#Loss 71 = tensor(12.6887, dtype=torch.float64)\n",
      "#Loss 72 = tensor(12.6635, dtype=torch.float64)\n",
      "#Loss 73 = tensor(12.6315, dtype=torch.float64)\n",
      "#Loss 74 = tensor(12.5885, dtype=torch.float64)\n",
      "#Loss 75 = tensor(12.5712, dtype=torch.float64)\n",
      "#Loss 76 = tensor(12.5648, dtype=torch.float64)\n",
      "#Loss 77 = tensor(12.5625, dtype=torch.float64)\n",
      "#Loss 78 = tensor(12.5610, dtype=torch.float64)\n",
      "#Loss 79 = tensor(12.5600, dtype=torch.float64)\n",
      "#Loss 80 = tensor(12.5596, dtype=torch.float64)\n",
      "#Loss 81 = tensor(12.5589, dtype=torch.float64)\n",
      "#Loss 82 = tensor(12.5432, dtype=torch.float64)\n",
      "#Loss 83 = tensor(12.5382, dtype=torch.float64)\n",
      "#Loss 84 = tensor(12.5366, dtype=torch.float64)\n",
      "#Loss 85 = tensor(12.5359, dtype=torch.float64)\n",
      "#Loss 86 = tensor(12.5357, dtype=torch.float64)\n",
      "#Loss 87 = tensor(12.5356, dtype=torch.float64)\n",
      "#Loss 88 = tensor(12.5353, dtype=torch.float64)\n",
      "#Loss 89 = tensor(12.5270, dtype=torch.float64)\n",
      "#Loss 90 = tensor(12.5169, dtype=torch.float64)\n",
      "#Loss 91 = tensor(12.4706, dtype=torch.float64)\n",
      "#Loss 92 = tensor(12.4390, dtype=torch.float64)\n",
      "#Loss 93 = tensor(12.3655, dtype=torch.float64)\n",
      "#Loss 94 = tensor(12.2282, dtype=torch.float64)\n",
      "#Loss 95 = tensor(11.9375, dtype=torch.float64)\n",
      "#Loss 96 = tensor(11.8255, dtype=torch.float64)\n",
      "#Loss 97 = tensor(11.7543, dtype=torch.float64)\n",
      "#Loss 98 = tensor(11.6772, dtype=torch.float64)\n",
      "#Loss 99 = tensor(11.6416, dtype=torch.float64)\n",
      "#Loss 100 = tensor(11.6123, dtype=torch.float64)\n",
      "#Loss 101 = tensor(11.5892, dtype=torch.float64)\n",
      "#Loss 102 = tensor(11.5745, dtype=torch.float64)\n",
      "#Loss 103 = tensor(11.5696, dtype=torch.float64)\n",
      "#Loss 104 = tensor(11.5671, dtype=torch.float64)\n",
      "#Loss 105 = tensor(11.5560, dtype=torch.float64)\n",
      "#Loss 106 = tensor(11.5216, dtype=torch.float64)\n",
      "#Loss 107 = tensor(11.4470, dtype=torch.float64)\n",
      "#Loss 108 = tensor(11.3875, dtype=torch.float64)\n",
      "#Loss 109 = tensor(11.3398, dtype=torch.float64)\n",
      "#Loss 110 = tensor(11.3250, dtype=torch.float64)\n",
      "#Loss 111 = tensor(11.3128, dtype=torch.float64)\n",
      "#Loss 112 = tensor(11.2976, dtype=torch.float64)\n",
      "#Loss 113 = tensor(11.2802, dtype=torch.float64)\n",
      "#Loss 114 = tensor(11.2755, dtype=torch.float64)\n",
      "#Loss 115 = tensor(11.2731, dtype=torch.float64)\n",
      "#Loss 116 = tensor(11.2718, dtype=torch.float64)\n",
      "#Loss 117 = tensor(11.2711, dtype=torch.float64)\n",
      "#Loss 118 = tensor(11.2701, dtype=torch.float64)\n",
      "#Loss 119 = tensor(11.2696, dtype=torch.float64)\n",
      "#Loss 120 = tensor(11.2539, dtype=torch.float64)\n",
      "#Loss 121 = tensor(11.2340, dtype=torch.float64)\n",
      "#Loss 122 = tensor(11.2094, dtype=torch.float64)\n",
      "#Loss 123 = tensor(11.1759, dtype=torch.float64)\n",
      "#Loss 124 = tensor(11.1373, dtype=torch.float64)\n",
      "#Loss 125 = tensor(11.1264, dtype=torch.float64)\n",
      "#Loss 126 = tensor(11.0932, dtype=torch.float64)\n",
      "#Loss 127 = tensor(11.0253, dtype=torch.float64)\n",
      "#Loss 128 = tensor(10.9234, dtype=torch.float64)\n",
      "#Loss 129 = tensor(10.7838, dtype=torch.float64)\n",
      "#Loss 130 = tensor(10.7398, dtype=torch.float64)\n",
      "#Loss 131 = tensor(10.7061, dtype=torch.float64)\n",
      "#Loss 132 = tensor(10.6821, dtype=torch.float64)\n",
      "#Loss 133 = tensor(10.6682, dtype=torch.float64)\n",
      "#Loss 134 = tensor(10.6529, dtype=torch.float64)\n",
      "#Loss 135 = tensor(10.5885, dtype=torch.float64)\n",
      "#Loss 136 = tensor(10.5587, dtype=torch.float64)\n",
      "#Loss 137 = tensor(10.5484, dtype=torch.float64)\n",
      "#Loss 138 = tensor(10.5376, dtype=torch.float64)\n",
      "#Loss 139 = tensor(10.5332, dtype=torch.float64)\n",
      "#Loss 140 = tensor(10.5021, dtype=torch.float64)\n",
      "#Loss 141 = tensor(10.4906, dtype=torch.float64)\n",
      "#Loss 142 = tensor(10.4720, dtype=torch.float64)\n",
      "#Loss 143 = tensor(10.4576, dtype=torch.float64)\n",
      "#Loss 144 = tensor(10.4487, dtype=torch.float64)\n",
      "#Loss 145 = tensor(10.4439, dtype=torch.float64)\n",
      "#Loss 146 = tensor(10.4334, dtype=torch.float64)\n",
      "#Loss 147 = tensor(10.4257, dtype=torch.float64)\n",
      "#Loss 148 = tensor(10.4224, dtype=torch.float64)\n",
      "#Loss 149 = tensor(10.4210, dtype=torch.float64)\n",
      "#Loss 150 = tensor(10.4205, dtype=torch.float64)\n",
      "#Loss 151 = tensor(10.4199, dtype=torch.float64)\n",
      "#Loss 152 = tensor(10.4198, dtype=torch.float64)\n",
      "#Loss 153 = tensor(10.4197, dtype=torch.float64)\n",
      "#Loss 154 = tensor(10.4197, dtype=torch.float64)\n",
      "#Loss 155 = tensor(10.4197, dtype=torch.float64)\n",
      "#Loss 156 = tensor(10.4196, dtype=torch.float64)\n",
      "#Loss 157 = tensor(10.4196, dtype=torch.float64)\n",
      "#Loss 158 = tensor(10.4196, dtype=torch.float64)\n",
      "#Loss 159 = tensor(10.4196, dtype=torch.float64)\n",
      "#Loss 160 = tensor(10.4196, dtype=torch.float64)\n",
      "#Loss 161 = tensor(10.4196, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(6.2964, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4095, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0704, dtype=torch.float64)   实验回归误差 tensor(0.0602, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(3880.3422, dtype=torch.float64)\n",
      "#Loss 1 = tensor(3870.9318, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 2 = tensor(558.3925, dtype=torch.float64)\n",
      "#Loss 3 = tensor(460.9618, dtype=torch.float64)\n",
      "#Loss 4 = tensor(391.1160, dtype=torch.float64)\n",
      "#Loss 5 = tensor(321.9297, dtype=torch.float64)\n",
      "#Loss 6 = tensor(260.2871, dtype=torch.float64)\n",
      "#Loss 7 = tensor(210.6620, dtype=torch.float64)\n",
      "#Loss 8 = tensor(170.5316, dtype=torch.float64)\n",
      "#Loss 9 = tensor(139.7664, dtype=torch.float64)\n",
      "#Loss 10 = tensor(115.6211, dtype=torch.float64)\n",
      "#Loss 11 = tensor(98.2049, dtype=torch.float64)\n",
      "#Loss 12 = tensor(86.1559, dtype=torch.float64)\n",
      "#Loss 13 = tensor(74.6476, dtype=torch.float64)\n",
      "#Loss 14 = tensor(64.1036, dtype=torch.float64)\n",
      "#Loss 15 = tensor(56.5076, dtype=torch.float64)\n",
      "#Loss 16 = tensor(50.8314, dtype=torch.float64)\n",
      "#Loss 17 = tensor(44.8986, dtype=torch.float64)\n",
      "#Loss 18 = tensor(39.3652, dtype=torch.float64)\n",
      "#Loss 19 = tensor(35.4789, dtype=torch.float64)\n",
      "#Loss 20 = tensor(31.3335, dtype=torch.float64)\n",
      "#Loss 21 = tensor(27.8747, dtype=torch.float64)\n",
      "#Loss 22 = tensor(25.1295, dtype=torch.float64)\n",
      "#Loss 23 = tensor(22.6067, dtype=torch.float64)\n",
      "#Loss 24 = tensor(21.0586, dtype=torch.float64)\n",
      "#Loss 25 = tensor(19.9908, dtype=torch.float64)\n",
      "#Loss 26 = tensor(19.1698, dtype=torch.float64)\n",
      "#Loss 27 = tensor(18.6404, dtype=torch.float64)\n",
      "#Loss 28 = tensor(18.1955, dtype=torch.float64)\n",
      "#Loss 29 = tensor(17.6165, dtype=torch.float64)\n",
      "#Loss 30 = tensor(17.1717, dtype=torch.float64)\n",
      "#Loss 31 = tensor(16.5946, dtype=torch.float64)\n",
      "#Loss 32 = tensor(15.8897, dtype=torch.float64)\n",
      "#Loss 33 = tensor(15.6190, dtype=torch.float64)\n",
      "#Loss 34 = tensor(15.3753, dtype=torch.float64)\n",
      "#Loss 35 = tensor(15.2212, dtype=torch.float64)\n",
      "#Loss 36 = tensor(15.1500, dtype=torch.float64)\n",
      "#Loss 37 = tensor(15.0580, dtype=torch.float64)\n",
      "#Loss 38 = tensor(14.8055, dtype=torch.float64)\n",
      "#Loss 39 = tensor(14.4952, dtype=torch.float64)\n",
      "#Loss 40 = tensor(14.1262, dtype=torch.float64)\n",
      "#Loss 41 = tensor(13.8927, dtype=torch.float64)\n",
      "#Loss 42 = tensor(13.7478, dtype=torch.float64)\n",
      "#Loss 43 = tensor(13.4746, dtype=torch.float64)\n",
      "#Loss 44 = tensor(13.2404, dtype=torch.float64)\n",
      "#Loss 45 = tensor(13.0928, dtype=torch.float64)\n",
      "#Loss 46 = tensor(13.0219, dtype=torch.float64)\n",
      "#Loss 47 = tensor(12.9541, dtype=torch.float64)\n",
      "#Loss 48 = tensor(12.8348, dtype=torch.float64)\n",
      "#Loss 49 = tensor(12.6868, dtype=torch.float64)\n",
      "#Loss 50 = tensor(12.5424, dtype=torch.float64)\n",
      "#Loss 51 = tensor(12.4265, dtype=torch.float64)\n",
      "#Loss 52 = tensor(12.3952, dtype=torch.float64)\n",
      "#Loss 53 = tensor(12.3431, dtype=torch.float64)\n",
      "#Loss 54 = tensor(12.2430, dtype=torch.float64)\n",
      "#Loss 55 = tensor(12.0906, dtype=torch.float64)\n",
      "#Loss 56 = tensor(11.9547, dtype=torch.float64)\n",
      "#Loss 57 = tensor(11.8007, dtype=torch.float64)\n",
      "#Loss 58 = tensor(11.7223, dtype=torch.float64)\n",
      "#Loss 59 = tensor(11.6657, dtype=torch.float64)\n",
      "#Loss 60 = tensor(11.5680, dtype=torch.float64)\n",
      "#Loss 61 = tensor(11.4204, dtype=torch.float64)\n",
      "#Loss 62 = tensor(11.3588, dtype=torch.float64)\n",
      "#Loss 63 = tensor(11.3326, dtype=torch.float64)\n",
      "#Loss 64 = tensor(11.2928, dtype=torch.float64)\n",
      "#Loss 65 = tensor(11.2527, dtype=torch.float64)\n",
      "#Loss 66 = tensor(11.2313, dtype=torch.float64)\n",
      "#Loss 67 = tensor(11.2203, dtype=torch.float64)\n",
      "#Loss 68 = tensor(11.2136, dtype=torch.float64)\n",
      "#Loss 69 = tensor(11.1886, dtype=torch.float64)\n",
      "#Loss 70 = tensor(11.1664, dtype=torch.float64)\n",
      "#Loss 71 = tensor(11.0522, dtype=torch.float64)\n",
      "#Loss 72 = tensor(11.0107, dtype=torch.float64)\n",
      "#Loss 73 = tensor(10.8880, dtype=torch.float64)\n",
      "#Loss 74 = tensor(10.7905, dtype=torch.float64)\n",
      "#Loss 75 = tensor(10.7399, dtype=torch.float64)\n",
      "#Loss 76 = tensor(10.7271, dtype=torch.float64)\n",
      "#Loss 77 = tensor(10.7220, dtype=torch.float64)\n",
      "#Loss 78 = tensor(10.7139, dtype=torch.float64)\n",
      "#Loss 79 = tensor(10.7054, dtype=torch.float64)\n",
      "#Loss 80 = tensor(10.6720, dtype=torch.float64)\n",
      "#Loss 81 = tensor(10.6026, dtype=torch.float64)\n",
      "#Loss 82 = tensor(10.5616, dtype=torch.float64)\n",
      "#Loss 83 = tensor(10.5239, dtype=torch.float64)\n",
      "#Loss 84 = tensor(10.4697, dtype=torch.float64)\n",
      "#Loss 85 = tensor(10.3976, dtype=torch.float64)\n",
      "#Loss 86 = tensor(10.2696, dtype=torch.float64)\n",
      "#Loss 87 = tensor(10.1712, dtype=torch.float64)\n",
      "#Loss 88 = tensor(10.1287, dtype=torch.float64)\n",
      "#Loss 89 = tensor(10.0975, dtype=torch.float64)\n",
      "#Loss 90 = tensor(10.0867, dtype=torch.float64)\n",
      "#Loss 91 = tensor(10.0836, dtype=torch.float64)\n",
      "#Loss 92 = tensor(10.0788, dtype=torch.float64)\n",
      "#Loss 93 = tensor(10.0778, dtype=torch.float64)\n",
      "#Loss 94 = tensor(10.0774, dtype=torch.float64)\n",
      "#Loss 95 = tensor(10.0765, dtype=torch.float64)\n",
      "#Loss 96 = tensor(10.0756, dtype=torch.float64)\n",
      "#Loss 97 = tensor(10.0753, dtype=torch.float64)\n",
      "#Loss 98 = tensor(10.0752, dtype=torch.float64)\n",
      "#Loss 99 = tensor(10.0752, dtype=torch.float64)\n",
      "#Loss 100 = tensor(10.0752, dtype=torch.float64)\n",
      "#Loss 101 = tensor(10.0752, dtype=torch.float64)\n",
      "#Loss 102 = tensor(10.0752, dtype=torch.float64)\n",
      "#Loss 103 = tensor(10.0752, dtype=torch.float64)\n",
      "#Loss 104 = tensor(10.0752, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(7.3355, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4120, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0566, dtype=torch.float64)   实验回归误差 tensor(0.0510, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(5997.3632, dtype=torch.float64)\n",
      "#Loss 1 = tensor(5915.0497, dtype=torch.float64)\n",
      "#Loss 2 = tensor(886.2344, dtype=torch.float64)\n",
      "#Loss 3 = tensor(700.4519, dtype=torch.float64)\n",
      "#Loss 4 = tensor(594.8237, dtype=torch.float64)\n",
      "#Loss 5 = tensor(508.5682, dtype=torch.float64)\n",
      "#Loss 6 = tensor(427.8473, dtype=torch.float64)\n",
      "#Loss 7 = tensor(364.3692, dtype=torch.float64)\n",
      "#Loss 8 = tensor(309.1498, dtype=torch.float64)\n",
      "#Loss 9 = tensor(268.3961, dtype=torch.float64)\n",
      "#Loss 10 = tensor(235.8830, dtype=torch.float64)\n",
      "#Loss 11 = tensor(202.5302, dtype=torch.float64)\n",
      "#Loss 12 = tensor(174.4086, dtype=torch.float64)\n",
      "#Loss 13 = tensor(145.0833, dtype=torch.float64)\n",
      "#Loss 14 = tensor(119.2396, dtype=torch.float64)\n",
      "#Loss 15 = tensor(101.2897, dtype=torch.float64)\n",
      "#Loss 16 = tensor(91.1614, dtype=torch.float64)\n",
      "#Loss 17 = tensor(81.0097, dtype=torch.float64)\n",
      "#Loss 18 = tensor(72.7367, dtype=torch.float64)\n",
      "#Loss 19 = tensor(64.5550, dtype=torch.float64)\n",
      "#Loss 20 = tensor(57.4137, dtype=torch.float64)\n",
      "#Loss 21 = tensor(50.8306, dtype=torch.float64)\n",
      "#Loss 22 = tensor(45.0068, dtype=torch.float64)\n",
      "#Loss 23 = tensor(40.5955, dtype=torch.float64)\n",
      "#Loss 24 = tensor(36.3008, dtype=torch.float64)\n",
      "#Loss 25 = tensor(32.7180, dtype=torch.float64)\n",
      "#Loss 26 = tensor(29.3520, dtype=torch.float64)\n",
      "#Loss 27 = tensor(25.7771, dtype=torch.float64)\n",
      "#Loss 28 = tensor(23.3805, dtype=torch.float64)\n",
      "#Loss 29 = tensor(20.6412, dtype=torch.float64)\n",
      "#Loss 30 = tensor(18.8652, dtype=torch.float64)\n",
      "#Loss 31 = tensor(17.9313, dtype=torch.float64)\n",
      "#Loss 32 = tensor(17.3562, dtype=torch.float64)\n",
      "#Loss 33 = tensor(17.0074, dtype=torch.float64)\n",
      "#Loss 34 = tensor(16.7309, dtype=torch.float64)\n",
      "#Loss 35 = tensor(16.4939, dtype=torch.float64)\n",
      "#Loss 36 = tensor(16.0944, dtype=torch.float64)\n",
      "#Loss 37 = tensor(15.6787, dtype=torch.float64)\n",
      "#Loss 38 = tensor(15.0909, dtype=torch.float64)\n",
      "#Loss 39 = tensor(14.7363, dtype=torch.float64)\n",
      "#Loss 40 = tensor(14.4854, dtype=torch.float64)\n",
      "#Loss 41 = tensor(14.3010, dtype=torch.float64)\n",
      "#Loss 42 = tensor(14.0766, dtype=torch.float64)\n",
      "#Loss 43 = tensor(13.5798, dtype=torch.float64)\n",
      "#Loss 44 = tensor(13.1636, dtype=torch.float64)\n",
      "#Loss 45 = tensor(12.9687, dtype=torch.float64)\n",
      "#Loss 46 = tensor(12.8585, dtype=torch.float64)\n",
      "#Loss 47 = tensor(12.8264, dtype=torch.float64)\n",
      "#Loss 48 = tensor(12.8159, dtype=torch.float64)\n",
      "#Loss 49 = tensor(12.8111, dtype=torch.float64)\n",
      "#Loss 50 = tensor(12.8058, dtype=torch.float64)\n",
      "#Loss 51 = tensor(12.8040, dtype=torch.float64)\n",
      "#Loss 52 = tensor(12.8033, dtype=torch.float64)\n",
      "#Loss 53 = tensor(12.8029, dtype=torch.float64)\n",
      "#Loss 54 = tensor(12.8027, dtype=torch.float64)\n",
      "#Loss 55 = tensor(12.8026, dtype=torch.float64)\n",
      "#Loss 56 = tensor(12.8026, dtype=torch.float64)\n",
      "#Loss 57 = tensor(12.8026, dtype=torch.float64)\n",
      "#Loss 58 = tensor(12.8026, dtype=torch.float64)\n",
      "#Loss 59 = tensor(12.8026, dtype=torch.float64)\n",
      "#Loss 60 = tensor(12.8026, dtype=torch.float64)\n",
      "#Loss 61 = tensor(12.8026, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(7.4193, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4048, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0506, dtype=torch.float64)   实验回归误差 tensor(0.0462, dtype=torch.float64, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0 = tensor(5565.2014, dtype=torch.float64)\n",
      "#Loss 1 = tensor(5448.7715, dtype=torch.float64)\n",
      "#Loss 2 = tensor(595.9290, dtype=torch.float64)\n",
      "#Loss 3 = tensor(514.6246, dtype=torch.float64)\n",
      "#Loss 4 = tensor(439.1465, dtype=torch.float64)\n",
      "#Loss 5 = tensor(371.3500, dtype=torch.float64)\n",
      "#Loss 6 = tensor(319.0733, dtype=torch.float64)\n",
      "#Loss 7 = tensor(270.3551, dtype=torch.float64)\n",
      "#Loss 8 = tensor(232.6454, dtype=torch.float64)\n",
      "#Loss 9 = tensor(192.0392, dtype=torch.float64)\n",
      "#Loss 10 = tensor(158.2352, dtype=torch.float64)\n",
      "#Loss 11 = tensor(131.4624, dtype=torch.float64)\n",
      "#Loss 12 = tensor(107.9064, dtype=torch.float64)\n",
      "#Loss 13 = tensor(89.1072, dtype=torch.float64)\n",
      "#Loss 14 = tensor(74.1116, dtype=torch.float64)\n",
      "#Loss 15 = tensor(62.0867, dtype=torch.float64)\n",
      "#Loss 16 = tensor(53.1918, dtype=torch.float64)\n",
      "#Loss 17 = tensor(44.5462, dtype=torch.float64)\n",
      "#Loss 18 = tensor(37.5360, dtype=torch.float64)\n",
      "#Loss 19 = tensor(31.7049, dtype=torch.float64)\n",
      "#Loss 20 = tensor(27.1002, dtype=torch.float64)\n",
      "#Loss 21 = tensor(24.0115, dtype=torch.float64)\n",
      "#Loss 22 = tensor(21.0947, dtype=torch.float64)\n",
      "#Loss 23 = tensor(19.0824, dtype=torch.float64)\n",
      "#Loss 24 = tensor(18.0159, dtype=torch.float64)\n",
      "#Loss 25 = tensor(17.3916, dtype=torch.float64)\n",
      "#Loss 26 = tensor(15.9959, dtype=torch.float64)\n",
      "#Loss 27 = tensor(14.8429, dtype=torch.float64)\n",
      "#Loss 28 = tensor(14.1915, dtype=torch.float64)\n",
      "#Loss 29 = tensor(13.2632, dtype=torch.float64)\n",
      "#Loss 30 = tensor(12.0954, dtype=torch.float64)\n",
      "#Loss 31 = tensor(11.0057, dtype=torch.float64)\n",
      "#Loss 32 = tensor(10.2819, dtype=torch.float64)\n",
      "#Loss 33 = tensor(9.8446, dtype=torch.float64)\n",
      "#Loss 34 = tensor(9.2955, dtype=torch.float64)\n",
      "#Loss 35 = tensor(8.9103, dtype=torch.float64)\n",
      "#Loss 36 = tensor(8.5449, dtype=torch.float64)\n",
      "#Loss 37 = tensor(8.2824, dtype=torch.float64)\n",
      "#Loss 38 = tensor(8.1313, dtype=torch.float64)\n",
      "#Loss 39 = tensor(8.0266, dtype=torch.float64)\n",
      "#Loss 40 = tensor(7.9340, dtype=torch.float64)\n",
      "#Loss 41 = tensor(7.8420, dtype=torch.float64)\n",
      "#Loss 42 = tensor(7.7560, dtype=torch.float64)\n",
      "#Loss 43 = tensor(7.7292, dtype=torch.float64)\n",
      "#Loss 44 = tensor(7.7179, dtype=torch.float64)\n",
      "#Loss 45 = tensor(7.7133, dtype=torch.float64)\n",
      "#Loss 46 = tensor(7.7106, dtype=torch.float64)\n",
      "#Loss 47 = tensor(7.7094, dtype=torch.float64)\n",
      "#Loss 48 = tensor(7.7089, dtype=torch.float64)\n",
      "#Loss 49 = tensor(7.7086, dtype=torch.float64)\n",
      "#Loss 50 = tensor(7.7085, dtype=torch.float64)\n",
      "#Loss 51 = tensor(7.7084, dtype=torch.float64)\n",
      "#Loss 52 = tensor(7.7084, dtype=torch.float64)\n",
      "#Loss 53 = tensor(7.7084, dtype=torch.float64)\n",
      "#Loss 54 = tensor(7.7083, dtype=torch.float64)\n",
      "#Loss 55 = tensor(7.7083, dtype=torch.float64)\n",
      "#Loss 56 = tensor(7.7083, dtype=torch.float64)\n",
      "#Loss 57 = tensor(7.7083, dtype=torch.float64)\n",
      "#Loss 58 = tensor(7.7083, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(7.1868, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4095, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0459, dtype=torch.float64)   实验回归误差 tensor(0.0372, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(3387.1901, dtype=torch.float64)\n",
      "#Loss 1 = tensor(3211.0340, dtype=torch.float64)\n",
      "#Loss 2 = tensor(386.4810, dtype=torch.float64)\n",
      "#Loss 3 = tensor(320.3127, dtype=torch.float64)\n",
      "#Loss 4 = tensor(279.1294, dtype=torch.float64)\n",
      "#Loss 5 = tensor(243.0329, dtype=torch.float64)\n",
      "#Loss 6 = tensor(211.0321, dtype=torch.float64)\n",
      "#Loss 7 = tensor(185.0574, dtype=torch.float64)\n",
      "#Loss 8 = tensor(160.6559, dtype=torch.float64)\n",
      "#Loss 9 = tensor(138.9362, dtype=torch.float64)\n",
      "#Loss 10 = tensor(119.9788, dtype=torch.float64)\n",
      "#Loss 11 = tensor(103.4729, dtype=torch.float64)\n",
      "#Loss 12 = tensor(90.4556, dtype=torch.float64)\n",
      "#Loss 13 = tensor(76.7531, dtype=torch.float64)\n",
      "#Loss 14 = tensor(64.9427, dtype=torch.float64)\n",
      "#Loss 15 = tensor(56.3244, dtype=torch.float64)\n",
      "#Loss 16 = tensor(46.8291, dtype=torch.float64)\n",
      "#Loss 17 = tensor(40.5782, dtype=torch.float64)\n",
      "#Loss 18 = tensor(36.5420, dtype=torch.float64)\n",
      "#Loss 19 = tensor(33.1704, dtype=torch.float64)\n",
      "#Loss 20 = tensor(29.8025, dtype=torch.float64)\n",
      "#Loss 21 = tensor(27.4067, dtype=torch.float64)\n",
      "#Loss 22 = tensor(24.9127, dtype=torch.float64)\n",
      "#Loss 23 = tensor(22.8816, dtype=torch.float64)\n",
      "#Loss 24 = tensor(21.0231, dtype=torch.float64)\n",
      "#Loss 25 = tensor(18.8896, dtype=torch.float64)\n",
      "#Loss 26 = tensor(16.1796, dtype=torch.float64)\n",
      "#Loss 27 = tensor(14.7115, dtype=torch.float64)\n",
      "#Loss 28 = tensor(12.8024, dtype=torch.float64)\n",
      "#Loss 29 = tensor(11.5340, dtype=torch.float64)\n",
      "#Loss 30 = tensor(10.5485, dtype=torch.float64)\n",
      "#Loss 31 = tensor(9.6785, dtype=torch.float64)\n",
      "#Loss 32 = tensor(9.3707, dtype=torch.float64)\n",
      "#Loss 33 = tensor(9.2151, dtype=torch.float64)\n",
      "#Loss 34 = tensor(8.8850, dtype=torch.float64)\n",
      "#Loss 35 = tensor(8.6842, dtype=torch.float64)\n",
      "#Loss 36 = tensor(8.5003, dtype=torch.float64)\n",
      "#Loss 37 = tensor(8.3805, dtype=torch.float64)\n",
      "#Loss 38 = tensor(8.0808, dtype=torch.float64)\n",
      "#Loss 39 = tensor(7.8606, dtype=torch.float64)\n",
      "#Loss 40 = tensor(7.7432, dtype=torch.float64)\n",
      "#Loss 41 = tensor(7.6301, dtype=torch.float64)\n",
      "#Loss 42 = tensor(7.5452, dtype=torch.float64)\n",
      "#Loss 43 = tensor(7.4275, dtype=torch.float64)\n",
      "#Loss 44 = tensor(7.3687, dtype=torch.float64)\n",
      "#Loss 45 = tensor(7.3214, dtype=torch.float64)\n",
      "#Loss 46 = tensor(7.2675, dtype=torch.float64)\n",
      "#Loss 47 = tensor(7.1355, dtype=torch.float64)\n",
      "#Loss 48 = tensor(6.9897, dtype=torch.float64)\n",
      "#Loss 49 = tensor(6.8660, dtype=torch.float64)\n",
      "#Loss 50 = tensor(6.8011, dtype=torch.float64)\n",
      "#Loss 51 = tensor(6.7528, dtype=torch.float64)\n",
      "#Loss 52 = tensor(6.7028, dtype=torch.float64)\n",
      "#Loss 53 = tensor(6.6323, dtype=torch.float64)\n",
      "#Loss 54 = tensor(6.1898, dtype=torch.float64)\n",
      "#Loss 55 = tensor(6.0875, dtype=torch.float64)\n",
      "#Loss 56 = tensor(5.9895, dtype=torch.float64)\n",
      "#Loss 57 = tensor(5.8641, dtype=torch.float64)\n",
      "#Loss 58 = tensor(5.7185, dtype=torch.float64)\n",
      "#Loss 59 = tensor(5.5662, dtype=torch.float64)\n",
      "#Loss 60 = tensor(5.4453, dtype=torch.float64)\n",
      "#Loss 61 = tensor(5.3671, dtype=torch.float64)\n",
      "#Loss 62 = tensor(5.1838, dtype=torch.float64)\n",
      "#Loss 63 = tensor(4.8081, dtype=torch.float64)\n",
      "#Loss 64 = tensor(4.3896, dtype=torch.float64)\n",
      "#Loss 65 = tensor(4.1950, dtype=torch.float64)\n",
      "#Loss 66 = tensor(4.0583, dtype=torch.float64)\n",
      "#Loss 67 = tensor(3.9419, dtype=torch.float64)\n",
      "#Loss 68 = tensor(3.8201, dtype=torch.float64)\n",
      "#Loss 69 = tensor(3.7451, dtype=torch.float64)\n",
      "#Loss 70 = tensor(3.7014, dtype=torch.float64)\n",
      "#Loss 71 = tensor(3.6777, dtype=torch.float64)\n",
      "#Loss 72 = tensor(3.6706, dtype=torch.float64)\n",
      "#Loss 73 = tensor(3.6665, dtype=torch.float64)\n",
      "#Loss 74 = tensor(3.6622, dtype=torch.float64)\n",
      "#Loss 75 = tensor(3.6603, dtype=torch.float64)\n",
      "#Loss 76 = tensor(3.6597, dtype=torch.float64)\n",
      "#Loss 77 = tensor(3.6594, dtype=torch.float64)\n",
      "#Loss 78 = tensor(3.6581, dtype=torch.float64)\n",
      "#Loss 79 = tensor(3.6578, dtype=torch.float64)\n",
      "#Loss 80 = tensor(3.6577, dtype=torch.float64)\n",
      "#Loss 81 = tensor(3.6576, dtype=torch.float64)\n",
      "#Loss 82 = tensor(3.6576, dtype=torch.float64)\n",
      "#Loss 83 = tensor(3.6576, dtype=torch.float64)\n",
      "#Loss 84 = tensor(3.6576, dtype=torch.float64)\n",
      "#Loss 85 = tensor(3.6576, dtype=torch.float64)\n",
      "#Loss 86 = tensor(3.6576, dtype=torch.float64)\n",
      "#Loss 87 = tensor(3.6576, dtype=torch.float64)\n",
      "#Loss 88 = tensor(3.6576, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(6.3945, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4095, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0637, dtype=torch.float64)   实验回归误差 tensor(0.0329, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(5776.4447, dtype=torch.float64)\n",
      "#Loss 1 = tensor(5565.1539, dtype=torch.float64)\n",
      "#Loss 2 = tensor(547.6621, dtype=torch.float64)\n",
      "#Loss 3 = tensor(450.6849, dtype=torch.float64)\n",
      "#Loss 4 = tensor(386.5630, dtype=torch.float64)\n",
      "#Loss 5 = tensor(335.6864, dtype=torch.float64)\n",
      "#Loss 6 = tensor(291.3231, dtype=torch.float64)\n",
      "#Loss 7 = tensor(254.4682, dtype=torch.float64)\n",
      "#Loss 8 = tensor(226.0618, dtype=torch.float64)\n",
      "#Loss 9 = tensor(204.1928, dtype=torch.float64)\n",
      "#Loss 10 = tensor(185.1894, dtype=torch.float64)\n",
      "#Loss 11 = tensor(167.3759, dtype=torch.float64)\n",
      "#Loss 12 = tensor(152.9703, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 13 = tensor(140.9746, dtype=torch.float64)\n",
      "#Loss 14 = tensor(130.5768, dtype=torch.float64)\n",
      "#Loss 15 = tensor(117.6145, dtype=torch.float64)\n",
      "#Loss 16 = tensor(104.9357, dtype=torch.float64)\n",
      "#Loss 17 = tensor(94.1492, dtype=torch.float64)\n",
      "#Loss 18 = tensor(84.1461, dtype=torch.float64)\n",
      "#Loss 19 = tensor(76.2109, dtype=torch.float64)\n",
      "#Loss 20 = tensor(69.3863, dtype=torch.float64)\n",
      "#Loss 21 = tensor(63.6514, dtype=torch.float64)\n",
      "#Loss 22 = tensor(59.2621, dtype=torch.float64)\n",
      "#Loss 23 = tensor(54.3573, dtype=torch.float64)\n",
      "#Loss 24 = tensor(50.3811, dtype=torch.float64)\n",
      "#Loss 25 = tensor(47.2249, dtype=torch.float64)\n",
      "#Loss 26 = tensor(43.2716, dtype=torch.float64)\n",
      "#Loss 27 = tensor(39.9589, dtype=torch.float64)\n",
      "#Loss 28 = tensor(37.7335, dtype=torch.float64)\n",
      "#Loss 29 = tensor(36.3879, dtype=torch.float64)\n",
      "#Loss 30 = tensor(35.3143, dtype=torch.float64)\n",
      "#Loss 31 = tensor(34.5531, dtype=torch.float64)\n",
      "#Loss 32 = tensor(33.6690, dtype=torch.float64)\n",
      "#Loss 33 = tensor(32.8275, dtype=torch.float64)\n",
      "#Loss 34 = tensor(31.2817, dtype=torch.float64)\n",
      "#Loss 35 = tensor(30.1600, dtype=torch.float64)\n",
      "#Loss 36 = tensor(28.8919, dtype=torch.float64)\n",
      "#Loss 37 = tensor(28.0104, dtype=torch.float64)\n",
      "#Loss 38 = tensor(27.0775, dtype=torch.float64)\n",
      "#Loss 39 = tensor(26.3831, dtype=torch.float64)\n",
      "#Loss 40 = tensor(25.8105, dtype=torch.float64)\n",
      "#Loss 41 = tensor(25.1127, dtype=torch.float64)\n",
      "#Loss 42 = tensor(24.1146, dtype=torch.float64)\n",
      "#Loss 43 = tensor(23.5033, dtype=torch.float64)\n",
      "#Loss 44 = tensor(23.2398, dtype=torch.float64)\n",
      "#Loss 45 = tensor(23.0947, dtype=torch.float64)\n",
      "#Loss 46 = tensor(22.9906, dtype=torch.float64)\n",
      "#Loss 47 = tensor(22.9040, dtype=torch.float64)\n",
      "#Loss 48 = tensor(22.8008, dtype=torch.float64)\n",
      "#Loss 49 = tensor(22.4792, dtype=torch.float64)\n",
      "#Loss 50 = tensor(22.1560, dtype=torch.float64)\n",
      "#Loss 51 = tensor(21.5682, dtype=torch.float64)\n",
      "#Loss 52 = tensor(20.9987, dtype=torch.float64)\n",
      "#Loss 53 = tensor(20.8591, dtype=torch.float64)\n",
      "#Loss 54 = tensor(20.7991, dtype=torch.float64)\n",
      "#Loss 55 = tensor(20.7160, dtype=torch.float64)\n",
      "#Loss 56 = tensor(20.6159, dtype=torch.float64)\n",
      "#Loss 57 = tensor(20.5458, dtype=torch.float64)\n",
      "#Loss 58 = tensor(20.4812, dtype=torch.float64)\n",
      "#Loss 59 = tensor(20.4216, dtype=torch.float64)\n",
      "#Loss 60 = tensor(20.3295, dtype=torch.float64)\n",
      "#Loss 61 = tensor(20.2112, dtype=torch.float64)\n",
      "#Loss 62 = tensor(19.9437, dtype=torch.float64)\n",
      "#Loss 63 = tensor(19.7959, dtype=torch.float64)\n",
      "#Loss 64 = tensor(19.7016, dtype=torch.float64)\n",
      "#Loss 65 = tensor(19.3422, dtype=torch.float64)\n",
      "#Loss 66 = tensor(19.0951, dtype=torch.float64)\n",
      "#Loss 67 = tensor(18.9214, dtype=torch.float64)\n",
      "#Loss 68 = tensor(18.7479, dtype=torch.float64)\n",
      "#Loss 69 = tensor(18.5478, dtype=torch.float64)\n",
      "#Loss 70 = tensor(18.4148, dtype=torch.float64)\n",
      "#Loss 71 = tensor(18.3179, dtype=torch.float64)\n",
      "#Loss 72 = tensor(18.1759, dtype=torch.float64)\n",
      "#Loss 73 = tensor(18.0999, dtype=torch.float64)\n",
      "#Loss 74 = tensor(18.0355, dtype=torch.float64)\n",
      "#Loss 75 = tensor(18.0097, dtype=torch.float64)\n",
      "#Loss 76 = tensor(17.9854, dtype=torch.float64)\n",
      "#Loss 77 = tensor(17.9208, dtype=torch.float64)\n",
      "#Loss 78 = tensor(17.8037, dtype=torch.float64)\n",
      "#Loss 79 = tensor(17.7625, dtype=torch.float64)\n",
      "#Loss 80 = tensor(17.7179, dtype=torch.float64)\n",
      "#Loss 81 = tensor(17.6883, dtype=torch.float64)\n",
      "#Loss 82 = tensor(17.6619, dtype=torch.float64)\n",
      "#Loss 83 = tensor(17.6535, dtype=torch.float64)\n",
      "#Loss 84 = tensor(17.6465, dtype=torch.float64)\n",
      "#Loss 85 = tensor(17.6339, dtype=torch.float64)\n",
      "#Loss 86 = tensor(17.6266, dtype=torch.float64)\n",
      "#Loss 87 = tensor(17.6237, dtype=torch.float64)\n",
      "#Loss 88 = tensor(17.6230, dtype=torch.float64)\n",
      "#Loss 89 = tensor(17.6228, dtype=torch.float64)\n",
      "#Loss 90 = tensor(17.6226, dtype=torch.float64)\n",
      "#Loss 91 = tensor(17.6226, dtype=torch.float64)\n",
      "#Loss 92 = tensor(17.6226, dtype=torch.float64)\n",
      "#Loss 93 = tensor(17.6226, dtype=torch.float64)\n",
      "#Loss 94 = tensor(17.6225, dtype=torch.float64)\n",
      "#Loss 95 = tensor(17.6225, dtype=torch.float64)\n",
      "#Loss 96 = tensor(17.6225, dtype=torch.float64)\n",
      "#Loss 97 = tensor(17.6225, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(7.8121, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4048, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0480, dtype=torch.float64)   实验回归误差 tensor(0.0552, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(4150.8849, dtype=torch.float64)\n",
      "#Loss 1 = tensor(3728.8604, dtype=torch.float64)\n",
      "#Loss 2 = tensor(445.8297, dtype=torch.float64)\n",
      "#Loss 3 = tensor(263.5798, dtype=torch.float64)\n",
      "#Loss 4 = tensor(216.5293, dtype=torch.float64)\n",
      "#Loss 5 = tensor(187.3941, dtype=torch.float64)\n",
      "#Loss 6 = tensor(164.5430, dtype=torch.float64)\n",
      "#Loss 7 = tensor(147.3161, dtype=torch.float64)\n",
      "#Loss 8 = tensor(132.0882, dtype=torch.float64)\n",
      "#Loss 9 = tensor(119.7645, dtype=torch.float64)\n",
      "#Loss 10 = tensor(110.0091, dtype=torch.float64)\n",
      "#Loss 11 = tensor(98.4771, dtype=torch.float64)\n",
      "#Loss 12 = tensor(90.1533, dtype=torch.float64)\n",
      "#Loss 13 = tensor(83.9847, dtype=torch.float64)\n",
      "#Loss 14 = tensor(76.9912, dtype=torch.float64)\n",
      "#Loss 15 = tensor(70.0108, dtype=torch.float64)\n",
      "#Loss 16 = tensor(64.3978, dtype=torch.float64)\n",
      "#Loss 17 = tensor(59.2259, dtype=torch.float64)\n",
      "#Loss 18 = tensor(54.7776, dtype=torch.float64)\n",
      "#Loss 19 = tensor(48.6640, dtype=torch.float64)\n",
      "#Loss 20 = tensor(43.2982, dtype=torch.float64)\n",
      "#Loss 21 = tensor(39.1711, dtype=torch.float64)\n",
      "#Loss 22 = tensor(34.6698, dtype=torch.float64)\n",
      "#Loss 23 = tensor(31.0961, dtype=torch.float64)\n",
      "#Loss 24 = tensor(27.5040, dtype=torch.float64)\n",
      "#Loss 25 = tensor(24.8331, dtype=torch.float64)\n",
      "#Loss 26 = tensor(23.2605, dtype=torch.float64)\n",
      "#Loss 27 = tensor(21.4016, dtype=torch.float64)\n",
      "#Loss 28 = tensor(19.5929, dtype=torch.float64)\n",
      "#Loss 29 = tensor(18.1724, dtype=torch.float64)\n",
      "#Loss 30 = tensor(16.8435, dtype=torch.float64)\n",
      "#Loss 31 = tensor(15.4901, dtype=torch.float64)\n",
      "#Loss 32 = tensor(14.7128, dtype=torch.float64)\n",
      "#Loss 33 = tensor(14.1013, dtype=torch.float64)\n",
      "#Loss 34 = tensor(13.1319, dtype=torch.float64)\n",
      "#Loss 35 = tensor(12.0763, dtype=torch.float64)\n",
      "#Loss 36 = tensor(11.3715, dtype=torch.float64)\n",
      "#Loss 37 = tensor(10.8896, dtype=torch.float64)\n",
      "#Loss 38 = tensor(10.2589, dtype=torch.float64)\n",
      "#Loss 39 = tensor(9.7621, dtype=torch.float64)\n",
      "#Loss 40 = tensor(9.5009, dtype=torch.float64)\n",
      "#Loss 41 = tensor(9.3037, dtype=torch.float64)\n",
      "#Loss 42 = tensor(9.0251, dtype=torch.float64)\n",
      "#Loss 43 = tensor(8.7811, dtype=torch.float64)\n",
      "#Loss 44 = tensor(8.5700, dtype=torch.float64)\n",
      "#Loss 45 = tensor(8.3013, dtype=torch.float64)\n",
      "#Loss 46 = tensor(8.2116, dtype=torch.float64)\n",
      "#Loss 47 = tensor(8.1872, dtype=torch.float64)\n",
      "#Loss 48 = tensor(8.1508, dtype=torch.float64)\n",
      "#Loss 49 = tensor(8.1039, dtype=torch.float64)\n",
      "#Loss 50 = tensor(8.0880, dtype=torch.float64)\n",
      "#Loss 51 = tensor(8.0774, dtype=torch.float64)\n",
      "#Loss 52 = tensor(8.0718, dtype=torch.float64)\n",
      "#Loss 53 = tensor(8.0702, dtype=torch.float64)\n",
      "#Loss 54 = tensor(8.0695, dtype=torch.float64)\n",
      "#Loss 55 = tensor(8.0689, dtype=torch.float64)\n",
      "#Loss 56 = tensor(8.0687, dtype=torch.float64)\n",
      "#Loss 57 = tensor(8.0686, dtype=torch.float64)\n",
      "#Loss 58 = tensor(8.0686, dtype=torch.float64)\n",
      "#Loss 59 = tensor(8.0685, dtype=torch.float64)\n",
      "#Loss 60 = tensor(8.0685, dtype=torch.float64)\n",
      "#Loss 61 = tensor(8.0685, dtype=torch.float64)\n",
      "#Loss 62 = tensor(8.0685, dtype=torch.float64)\n",
      "#Loss 63 = tensor(8.0685, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(6.9074, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4048, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0610, dtype=torch.float64)   实验回归误差 tensor(0.0441, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(3905.2519, dtype=torch.float64)\n",
      "#Loss 1 = tensor(3727.6548, dtype=torch.float64)\n",
      "#Loss 2 = tensor(273.4787, dtype=torch.float64)\n",
      "#Loss 3 = tensor(243.5193, dtype=torch.float64)\n",
      "#Loss 4 = tensor(220.4974, dtype=torch.float64)\n",
      "#Loss 5 = tensor(201.1859, dtype=torch.float64)\n",
      "#Loss 6 = tensor(185.8549, dtype=torch.float64)\n",
      "#Loss 7 = tensor(172.8196, dtype=torch.float64)\n",
      "#Loss 8 = tensor(159.5242, dtype=torch.float64)\n",
      "#Loss 9 = tensor(145.1641, dtype=torch.float64)\n",
      "#Loss 10 = tensor(130.3807, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 11 = tensor(118.2864, dtype=torch.float64)\n",
      "#Loss 12 = tensor(104.6817, dtype=torch.float64)\n",
      "#Loss 13 = tensor(90.3347, dtype=torch.float64)\n",
      "#Loss 14 = tensor(80.2921, dtype=torch.float64)\n",
      "#Loss 15 = tensor(72.5967, dtype=torch.float64)\n",
      "#Loss 16 = tensor(63.7610, dtype=torch.float64)\n",
      "#Loss 17 = tensor(57.1346, dtype=torch.float64)\n",
      "#Loss 18 = tensor(52.9285, dtype=torch.float64)\n",
      "#Loss 19 = tensor(49.0968, dtype=torch.float64)\n",
      "#Loss 20 = tensor(45.0905, dtype=torch.float64)\n",
      "#Loss 21 = tensor(41.6071, dtype=torch.float64)\n",
      "#Loss 22 = tensor(38.9161, dtype=torch.float64)\n",
      "#Loss 23 = tensor(36.4066, dtype=torch.float64)\n",
      "#Loss 24 = tensor(34.9034, dtype=torch.float64)\n",
      "#Loss 25 = tensor(33.4970, dtype=torch.float64)\n",
      "#Loss 26 = tensor(32.2919, dtype=torch.float64)\n",
      "#Loss 27 = tensor(30.4696, dtype=torch.float64)\n",
      "#Loss 28 = tensor(28.3404, dtype=torch.float64)\n",
      "#Loss 29 = tensor(26.2762, dtype=torch.float64)\n",
      "#Loss 30 = tensor(24.3320, dtype=torch.float64)\n",
      "#Loss 31 = tensor(23.0128, dtype=torch.float64)\n",
      "#Loss 32 = tensor(22.1550, dtype=torch.float64)\n",
      "#Loss 33 = tensor(21.3060, dtype=torch.float64)\n",
      "#Loss 34 = tensor(20.3969, dtype=torch.float64)\n",
      "#Loss 35 = tensor(18.7828, dtype=torch.float64)\n",
      "#Loss 36 = tensor(17.3077, dtype=torch.float64)\n",
      "#Loss 37 = tensor(16.1051, dtype=torch.float64)\n",
      "#Loss 38 = tensor(15.1208, dtype=torch.float64)\n",
      "#Loss 39 = tensor(14.2509, dtype=torch.float64)\n",
      "#Loss 40 = tensor(13.7130, dtype=torch.float64)\n",
      "#Loss 41 = tensor(12.7242, dtype=torch.float64)\n",
      "#Loss 42 = tensor(11.7457, dtype=torch.float64)\n",
      "#Loss 43 = tensor(11.1249, dtype=torch.float64)\n",
      "#Loss 44 = tensor(10.7456, dtype=torch.float64)\n",
      "#Loss 45 = tensor(10.1042, dtype=torch.float64)\n",
      "#Loss 46 = tensor(9.1810, dtype=torch.float64)\n",
      "#Loss 47 = tensor(8.4805, dtype=torch.float64)\n",
      "#Loss 48 = tensor(8.0696, dtype=torch.float64)\n",
      "#Loss 49 = tensor(7.8299, dtype=torch.float64)\n",
      "#Loss 50 = tensor(7.7123, dtype=torch.float64)\n",
      "#Loss 51 = tensor(7.6017, dtype=torch.float64)\n",
      "#Loss 52 = tensor(7.4955, dtype=torch.float64)\n",
      "#Loss 53 = tensor(7.4247, dtype=torch.float64)\n",
      "#Loss 54 = tensor(7.3973, dtype=torch.float64)\n",
      "#Loss 55 = tensor(7.3870, dtype=torch.float64)\n",
      "#Loss 56 = tensor(7.3838, dtype=torch.float64)\n",
      "#Loss 57 = tensor(7.3791, dtype=torch.float64)\n",
      "#Loss 58 = tensor(7.3769, dtype=torch.float64)\n",
      "#Loss 59 = tensor(7.3762, dtype=torch.float64)\n",
      "#Loss 60 = tensor(7.3759, dtype=torch.float64)\n",
      "#Loss 61 = tensor(7.3757, dtype=torch.float64)\n",
      "#Loss 62 = tensor(7.3757, dtype=torch.float64)\n",
      "#Loss 63 = tensor(7.3756, dtype=torch.float64)\n",
      "#Loss 64 = tensor(7.3756, dtype=torch.float64)\n",
      "#Loss 65 = tensor(7.3756, dtype=torch.float64)\n",
      "#Loss 66 = tensor(7.3756, dtype=torch.float64)\n",
      "#Loss 67 = tensor(7.3756, dtype=torch.float64)\n",
      "#Loss 68 = tensor(7.3756, dtype=torch.float64)\n",
      "#Loss 69 = tensor(7.3756, dtype=torch.float64)\n",
      "#Loss 70 = tensor(7.3756, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(5.7812, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4142, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0598, dtype=torch.float64)   实验回归误差 tensor(0.0435, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(4926.8137, dtype=torch.float64)\n",
      "#Loss 1 = tensor(4592.2433, dtype=torch.float64)\n",
      "#Loss 2 = tensor(781.6231, dtype=torch.float64)\n",
      "#Loss 3 = tensor(372.1577, dtype=torch.float64)\n",
      "#Loss 4 = tensor(255.0191, dtype=torch.float64)\n",
      "#Loss 5 = tensor(208.0422, dtype=torch.float64)\n",
      "#Loss 6 = tensor(178.4071, dtype=torch.float64)\n",
      "#Loss 7 = tensor(156.9825, dtype=torch.float64)\n",
      "#Loss 8 = tensor(138.3742, dtype=torch.float64)\n",
      "#Loss 9 = tensor(123.7378, dtype=torch.float64)\n",
      "#Loss 10 = tensor(109.4356, dtype=torch.float64)\n",
      "#Loss 11 = tensor(96.7509, dtype=torch.float64)\n",
      "#Loss 12 = tensor(87.4686, dtype=torch.float64)\n",
      "#Loss 13 = tensor(80.2221, dtype=torch.float64)\n",
      "#Loss 14 = tensor(72.6379, dtype=torch.float64)\n",
      "#Loss 15 = tensor(65.9651, dtype=torch.float64)\n",
      "#Loss 16 = tensor(60.2712, dtype=torch.float64)\n",
      "#Loss 17 = tensor(55.4866, dtype=torch.float64)\n",
      "#Loss 18 = tensor(51.2995, dtype=torch.float64)\n",
      "#Loss 19 = tensor(47.9680, dtype=torch.float64)\n",
      "#Loss 20 = tensor(44.5999, dtype=torch.float64)\n",
      "#Loss 21 = tensor(41.4092, dtype=torch.float64)\n",
      "#Loss 22 = tensor(38.6298, dtype=torch.float64)\n",
      "#Loss 23 = tensor(35.4498, dtype=torch.float64)\n",
      "#Loss 24 = tensor(32.9809, dtype=torch.float64)\n",
      "#Loss 25 = tensor(30.0828, dtype=torch.float64)\n",
      "#Loss 26 = tensor(27.8469, dtype=torch.float64)\n",
      "#Loss 27 = tensor(25.6238, dtype=torch.float64)\n",
      "#Loss 28 = tensor(23.5546, dtype=torch.float64)\n",
      "#Loss 29 = tensor(21.9005, dtype=torch.float64)\n",
      "#Loss 30 = tensor(20.8992, dtype=torch.float64)\n",
      "#Loss 31 = tensor(20.1638, dtype=torch.float64)\n",
      "#Loss 32 = tensor(19.3494, dtype=torch.float64)\n",
      "#Loss 33 = tensor(18.7645, dtype=torch.float64)\n",
      "#Loss 34 = tensor(18.2016, dtype=torch.float64)\n",
      "#Loss 35 = tensor(17.7127, dtype=torch.float64)\n",
      "#Loss 36 = tensor(17.3915, dtype=torch.float64)\n",
      "#Loss 37 = tensor(17.0557, dtype=torch.float64)\n",
      "#Loss 38 = tensor(16.6999, dtype=torch.float64)\n",
      "#Loss 39 = tensor(16.2384, dtype=torch.float64)\n",
      "#Loss 40 = tensor(15.6967, dtype=torch.float64)\n",
      "#Loss 41 = tensor(15.1918, dtype=torch.float64)\n",
      "#Loss 42 = tensor(14.6678, dtype=torch.float64)\n",
      "#Loss 43 = tensor(14.2427, dtype=torch.float64)\n",
      "#Loss 44 = tensor(13.9312, dtype=torch.float64)\n",
      "#Loss 45 = tensor(13.7097, dtype=torch.float64)\n",
      "#Loss 46 = tensor(13.5525, dtype=torch.float64)\n",
      "#Loss 47 = tensor(13.4839, dtype=torch.float64)\n",
      "#Loss 48 = tensor(13.4121, dtype=torch.float64)\n",
      "#Loss 49 = tensor(13.2420, dtype=torch.float64)\n",
      "#Loss 50 = tensor(13.1764, dtype=torch.float64)\n",
      "#Loss 51 = tensor(13.0609, dtype=torch.float64)\n",
      "#Loss 52 = tensor(12.9586, dtype=torch.float64)\n",
      "#Loss 53 = tensor(12.9253, dtype=torch.float64)\n",
      "#Loss 54 = tensor(12.9005, dtype=torch.float64)\n",
      "#Loss 55 = tensor(12.8862, dtype=torch.float64)\n",
      "#Loss 56 = tensor(12.8809, dtype=torch.float64)\n",
      "#Loss 57 = tensor(12.8781, dtype=torch.float64)\n",
      "#Loss 58 = tensor(12.8629, dtype=torch.float64)\n",
      "#Loss 59 = tensor(12.8467, dtype=torch.float64)\n",
      "#Loss 60 = tensor(12.8315, dtype=torch.float64)\n",
      "#Loss 61 = tensor(12.8138, dtype=torch.float64)\n",
      "#Loss 62 = tensor(12.8047, dtype=torch.float64)\n",
      "#Loss 63 = tensor(12.7899, dtype=torch.float64)\n",
      "#Loss 64 = tensor(12.6896, dtype=torch.float64)\n",
      "#Loss 65 = tensor(12.5622, dtype=torch.float64)\n",
      "#Loss 66 = tensor(12.4915, dtype=torch.float64)\n",
      "#Loss 67 = tensor(12.4641, dtype=torch.float64)\n",
      "#Loss 68 = tensor(12.4417, dtype=torch.float64)\n",
      "#Loss 69 = tensor(12.2367, dtype=torch.float64)\n",
      "#Loss 70 = tensor(12.0602, dtype=torch.float64)\n",
      "#Loss 71 = tensor(11.8819, dtype=torch.float64)\n",
      "#Loss 72 = tensor(11.8160, dtype=torch.float64)\n",
      "#Loss 73 = tensor(11.7856, dtype=torch.float64)\n",
      "#Loss 74 = tensor(11.7463, dtype=torch.float64)\n",
      "#Loss 75 = tensor(11.6861, dtype=torch.float64)\n",
      "#Loss 76 = tensor(11.6697, dtype=torch.float64)\n",
      "#Loss 77 = tensor(11.6435, dtype=torch.float64)\n",
      "#Loss 78 = tensor(11.6363, dtype=torch.float64)\n",
      "#Loss 79 = tensor(11.6312, dtype=torch.float64)\n",
      "#Loss 80 = tensor(11.6299, dtype=torch.float64)\n",
      "#Loss 81 = tensor(11.6294, dtype=torch.float64)\n",
      "#Loss 82 = tensor(11.6293, dtype=torch.float64)\n",
      "#Loss 83 = tensor(11.6292, dtype=torch.float64)\n",
      "#Loss 84 = tensor(11.6292, dtype=torch.float64)\n",
      "#Loss 85 = tensor(11.6292, dtype=torch.float64)\n",
      "#Loss 86 = tensor(11.6292, dtype=torch.float64)\n",
      "#Loss 87 = tensor(11.6292, dtype=torch.float64)\n",
      "#Loss 88 = tensor(11.6292, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(7.5042, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4095, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0570, dtype=torch.float64)   实验回归误差 tensor(0.0486, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(4677.3759, dtype=torch.float64)\n",
      "#Loss 1 = tensor(4315.3967, dtype=torch.float64)\n",
      "#Loss 2 = tensor(285.9823, dtype=torch.float64)\n",
      "#Loss 3 = tensor(227.5999, dtype=torch.float64)\n",
      "#Loss 4 = tensor(191.4102, dtype=torch.float64)\n",
      "#Loss 5 = tensor(164.3637, dtype=torch.float64)\n",
      "#Loss 6 = tensor(145.7161, dtype=torch.float64)\n",
      "#Loss 7 = tensor(131.2103, dtype=torch.float64)\n",
      "#Loss 8 = tensor(118.6223, dtype=torch.float64)\n",
      "#Loss 9 = tensor(108.4784, dtype=torch.float64)\n",
      "#Loss 10 = tensor(98.6967, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 11 = tensor(90.8764, dtype=torch.float64)\n",
      "#Loss 12 = tensor(83.6942, dtype=torch.float64)\n",
      "#Loss 13 = tensor(75.1360, dtype=torch.float64)\n",
      "#Loss 14 = tensor(66.4467, dtype=torch.float64)\n",
      "#Loss 15 = tensor(57.7199, dtype=torch.float64)\n",
      "#Loss 16 = tensor(47.5285, dtype=torch.float64)\n",
      "#Loss 17 = tensor(40.2411, dtype=torch.float64)\n",
      "#Loss 18 = tensor(35.2290, dtype=torch.float64)\n",
      "#Loss 19 = tensor(32.3965, dtype=torch.float64)\n",
      "#Loss 20 = tensor(30.0683, dtype=torch.float64)\n",
      "#Loss 21 = tensor(28.1232, dtype=torch.float64)\n",
      "#Loss 22 = tensor(26.5938, dtype=torch.float64)\n",
      "#Loss 23 = tensor(25.3942, dtype=torch.float64)\n",
      "#Loss 24 = tensor(23.7493, dtype=torch.float64)\n",
      "#Loss 25 = tensor(22.5503, dtype=torch.float64)\n",
      "#Loss 26 = tensor(21.8974, dtype=torch.float64)\n",
      "#Loss 27 = tensor(21.3508, dtype=torch.float64)\n",
      "#Loss 28 = tensor(20.6789, dtype=torch.float64)\n",
      "#Loss 29 = tensor(20.2412, dtype=torch.float64)\n",
      "#Loss 30 = tensor(19.8779, dtype=torch.float64)\n",
      "#Loss 31 = tensor(19.5229, dtype=torch.float64)\n",
      "#Loss 32 = tensor(19.0495, dtype=torch.float64)\n",
      "#Loss 33 = tensor(18.4734, dtype=torch.float64)\n",
      "#Loss 34 = tensor(18.0550, dtype=torch.float64)\n",
      "#Loss 35 = tensor(17.7500, dtype=torch.float64)\n",
      "#Loss 36 = tensor(17.5445, dtype=torch.float64)\n",
      "#Loss 37 = tensor(17.4761, dtype=torch.float64)\n",
      "#Loss 38 = tensor(17.4416, dtype=torch.float64)\n",
      "#Loss 39 = tensor(17.4038, dtype=torch.float64)\n",
      "#Loss 40 = tensor(17.3099, dtype=torch.float64)\n",
      "#Loss 41 = tensor(17.2386, dtype=torch.float64)\n",
      "#Loss 42 = tensor(17.1833, dtype=torch.float64)\n",
      "#Loss 43 = tensor(17.1040, dtype=torch.float64)\n",
      "#Loss 44 = tensor(17.0624, dtype=torch.float64)\n",
      "#Loss 45 = tensor(17.0375, dtype=torch.float64)\n",
      "#Loss 46 = tensor(17.0067, dtype=torch.float64)\n",
      "#Loss 47 = tensor(16.9939, dtype=torch.float64)\n",
      "#Loss 48 = tensor(16.9762, dtype=torch.float64)\n",
      "#Loss 49 = tensor(16.9596, dtype=torch.float64)\n",
      "#Loss 50 = tensor(16.9541, dtype=torch.float64)\n",
      "#Loss 51 = tensor(16.9518, dtype=torch.float64)\n",
      "#Loss 52 = tensor(16.9508, dtype=torch.float64)\n",
      "#Loss 53 = tensor(16.9503, dtype=torch.float64)\n",
      "#Loss 54 = tensor(16.9501, dtype=torch.float64)\n",
      "#Loss 55 = tensor(16.9498, dtype=torch.float64)\n",
      "#Loss 56 = tensor(16.9371, dtype=torch.float64)\n",
      "#Loss 57 = tensor(16.9345, dtype=torch.float64)\n",
      "#Loss 58 = tensor(16.9336, dtype=torch.float64)\n",
      "#Loss 59 = tensor(16.9325, dtype=torch.float64)\n",
      "#Loss 60 = tensor(16.8973, dtype=torch.float64)\n",
      "#Loss 61 = tensor(16.8494, dtype=torch.float64)\n",
      "#Loss 62 = tensor(16.8347, dtype=torch.float64)\n",
      "#Loss 63 = tensor(16.8302, dtype=torch.float64)\n",
      "#Loss 64 = tensor(16.8281, dtype=torch.float64)\n",
      "#Loss 65 = tensor(16.8260, dtype=torch.float64)\n",
      "#Loss 66 = tensor(16.8251, dtype=torch.float64)\n",
      "#Loss 67 = tensor(16.8246, dtype=torch.float64)\n",
      "#Loss 68 = tensor(16.8244, dtype=torch.float64)\n",
      "#Loss 69 = tensor(16.8243, dtype=torch.float64)\n",
      "#Loss 70 = tensor(16.8242, dtype=torch.float64)\n",
      "#Loss 71 = tensor(16.8058, dtype=torch.float64)\n",
      "#Loss 72 = tensor(16.6348, dtype=torch.float64)\n",
      "#Loss 73 = tensor(16.5441, dtype=torch.float64)\n",
      "#Loss 74 = tensor(16.5156, dtype=torch.float64)\n",
      "#Loss 75 = tensor(16.4941, dtype=torch.float64)\n",
      "#Loss 76 = tensor(16.4543, dtype=torch.float64)\n",
      "#Loss 77 = tensor(16.3976, dtype=torch.float64)\n",
      "#Loss 78 = tensor(16.3707, dtype=torch.float64)\n",
      "#Loss 79 = tensor(16.3412, dtype=torch.float64)\n",
      "#Loss 80 = tensor(16.3034, dtype=torch.float64)\n",
      "#Loss 81 = tensor(16.2699, dtype=torch.float64)\n",
      "#Loss 82 = tensor(16.2605, dtype=torch.float64)\n",
      "#Loss 83 = tensor(16.2563, dtype=torch.float64)\n",
      "#Loss 84 = tensor(16.2383, dtype=torch.float64)\n",
      "#Loss 85 = tensor(16.2206, dtype=torch.float64)\n",
      "#Loss 86 = tensor(16.2058, dtype=torch.float64)\n",
      "#Loss 87 = tensor(16.1641, dtype=torch.float64)\n",
      "#Loss 88 = tensor(16.1287, dtype=torch.float64)\n",
      "#Loss 89 = tensor(16.0420, dtype=torch.float64)\n",
      "#Loss 90 = tensor(15.8737, dtype=torch.float64)\n",
      "#Loss 91 = tensor(15.7761, dtype=torch.float64)\n",
      "#Loss 92 = tensor(15.7214, dtype=torch.float64)\n",
      "#Loss 93 = tensor(15.6615, dtype=torch.float64)\n",
      "#Loss 94 = tensor(15.6418, dtype=torch.float64)\n",
      "#Loss 95 = tensor(15.6262, dtype=torch.float64)\n",
      "#Loss 96 = tensor(15.5436, dtype=torch.float64)\n",
      "#Loss 97 = tensor(15.4364, dtype=torch.float64)\n",
      "#Loss 98 = tensor(15.3827, dtype=torch.float64)\n",
      "#Loss 99 = tensor(15.3319, dtype=torch.float64)\n",
      "#Loss 100 = tensor(15.2758, dtype=torch.float64)\n",
      "#Loss 101 = tensor(15.2487, dtype=torch.float64)\n",
      "#Loss 102 = tensor(15.2268, dtype=torch.float64)\n",
      "#Loss 103 = tensor(15.2181, dtype=torch.float64)\n",
      "#Loss 104 = tensor(15.2143, dtype=torch.float64)\n",
      "#Loss 105 = tensor(15.2126, dtype=torch.float64)\n",
      "#Loss 106 = tensor(15.2118, dtype=torch.float64)\n",
      "#Loss 107 = tensor(15.2114, dtype=torch.float64)\n",
      "#Loss 108 = tensor(15.2112, dtype=torch.float64)\n",
      "#Loss 109 = tensor(15.2111, dtype=torch.float64)\n",
      "#Loss 110 = tensor(15.1990, dtype=torch.float64)\n",
      "#Loss 111 = tensor(15.1922, dtype=torch.float64)\n",
      "#Loss 112 = tensor(15.1900, dtype=torch.float64)\n",
      "#Loss 113 = tensor(15.1889, dtype=torch.float64)\n",
      "#Loss 114 = tensor(15.1884, dtype=torch.float64)\n",
      "#Loss 115 = tensor(15.1864, dtype=torch.float64)\n",
      "#Loss 116 = tensor(15.1858, dtype=torch.float64)\n",
      "#Loss 117 = tensor(15.1856, dtype=torch.float64)\n",
      "#Loss 118 = tensor(15.1855, dtype=torch.float64)\n",
      "#Loss 119 = tensor(15.1854, dtype=torch.float64)\n",
      "#Loss 120 = tensor(15.1854, dtype=torch.float64)\n",
      "#Loss 121 = tensor(15.1854, dtype=torch.float64)\n",
      "#Loss 122 = tensor(15.1854, dtype=torch.float64)\n",
      "#Loss 123 = tensor(15.1854, dtype=torch.float64)\n",
      "#Loss 124 = tensor(15.1854, dtype=torch.float64)\n",
      " 30 150 平均相对误差2： tensor(7.4209, dtype=torch.float64, grad_fn=<NormBackward0>)   30 150 置换矩阵误差： tensor(1.4095, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0604, dtype=torch.float64)   实验回归误差 tensor(0.0570, dtype=torch.float64, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "gama_=1\n",
    "eta=0\n",
    "starts=1\n",
    "for i_____ in range(5):\n",
    "    for num_example in range(150,151,100): \n",
    "        for num_X2feature in [30]:\n",
    "            for i____ in range(10):\n",
    "                (y_,X2_,true_w2,true_P,error_reg1)=generatedata(noise=0.3)\n",
    "                y=y_\n",
    "                X2=X2_\n",
    "                results_Loss = []\n",
    "                results_w2=[]\n",
    "                results_error=[]\n",
    "                for i__ in range(starts):\n",
    "    #                     P_array=np.random.permutation(num_example)\n",
    "    #                     P=torch.zeros(num_example,num_example,dtype=torch.float64)\n",
    "    #                     for i in range(num_example):\n",
    "    #                         P[i][P_array[i]]=1\n",
    "    #                     X_=torch.cat([X1,X2],1)\n",
    "    #                     X=torch.mm(P,X_)\n",
    "    #                     w=torch.mm(torch.mm(torch.tensor(np.linalg.inv(torch.mm(X.transpose(1,0),X))),X.transpose(1,0)),y)\n",
    "    #                     w1,w2=w.split([num_X1feature,num_X2feature],dim=0)\n",
    "    #                     w1=torch.from_numpy(np.random.normal(0, 0,(num_X1feature,1)))\n",
    "    #                     w2=torch.from_numpy(np.random.normal(0, 0,(num_X2feature,1)))\n",
    "                    w2=generateinitialw(method='zeros')\n",
    "                    #w2=true_w2\n",
    "                    w2.requires_grad_(requires_grad=True)\n",
    "    #                 results_Loss = []\n",
    "                    lr=0.0025\n",
    "                    results_S=[]\n",
    "                    t=0\n",
    "                    before1=0\n",
    "                    while True:\n",
    "                        #start=time()\n",
    "                        Y1=y\n",
    "                        Y2=torch.mm(X2,w2)\n",
    "                        C=torch.zeros(num_example,num_example,dtype=torch.float64)\n",
    "                        for i in range(num_example):\n",
    "                            for j in range(num_example):\n",
    "                                C[i][j]=(Y1[i]-Y2[j])**2            \n",
    "\n",
    "                        #S=SinkhornIPOT(C)\n",
    "                        a=torch.ones(num_example,1,dtype=torch.float64)\n",
    "                        b=torch.ones(num_example,1,dtype=torch.float64)\n",
    "                        S=sinkhorn_epsilon_scaling(a, b, C, 0.00000001)\n",
    "                        #print(S.transpose(1,0).half())\n",
    "                        #results_S.append(S)\n",
    "                        #if t>0:\n",
    "                            #print('        S变化',(torch.norm(results_S[t]-results_S[t-1]))/(torch.norm(results_S[t-1])))\n",
    "                        #Loss=torch.sum(S*C)\n",
    "                        Loss=torch.norm(Y1-torch.mm(S,Y2))**2\n",
    "                        if Loss<1e-2:\n",
    "                            break\n",
    "                        Loss.backward()\n",
    "    #                         results_Loss.append(Loss)\n",
    "    #                         for i_ in range(num_X1features):\n",
    "    #                             results_w1[t][i_]=(w1[i_].data)\n",
    "    #                         for i_ in range(num_X2features):\n",
    "    #                             results_w2[t][i_]=(w2[i_].data)\n",
    "                        w2.data-=lr*(w2.grad+np.random.normal(0,np.sqrt(eta/(1+t)**gama_)))\n",
    "                        #print(w2.grad)\n",
    "    #                     if t==num_epochs-1:\n",
    "    #                         print('最终w1梯度：',w1.grad)\n",
    "    #                         print('最终w2梯度：',w2.grad)\n",
    "                        w2.grad.data.zero_() \n",
    "                        print('Loss',t,'=',Loss.data)\n",
    "    #                     if t%6==0:\n",
    "    #                         if torch.norm(Loss-before1)<1e-4:\n",
    "    #                             break\n",
    "    #                         before1=Loss\n",
    "                        if torch.norm(Loss-before1)/before1<1e-7:\n",
    "                            break\n",
    "                        before1=Loss\n",
    "                        if t>=200:\n",
    "                            print('超过迭代上限')\n",
    "                            break\n",
    "                        if math.isnan(Loss):\n",
    "                            break\n",
    "                        t+=1\n",
    "                        print('#',end='')\n",
    "                        #print(time()-start)\n",
    "\n",
    "\n",
    "\n",
    "                    print(' ',end='')\n",
    "                    error_each=(torch.norm(w2-true_w2))\n",
    "                    results_error.append(error_each)\n",
    "                    #results_Loss.append(Loss)\n",
    "                    #results_w1.append(w1.data)\n",
    "                    #results_w2.append(w2.data)\n",
    "\n",
    "\n",
    "                #w1=results_w1[results_Loss.index(min(results_Loss))]\n",
    "                #w2=results_w2[results_Loss.index(min(results_Loss))]\n",
    "\n",
    "    #                     for i_ in range(starts):\n",
    "    #                         results_w1[i_]=(w1[i_].data)\n",
    "    #                     for i_ in range(starts):\n",
    "    #                         results_w2[i_]=(w2[i_].data)\n",
    "\n",
    "\n",
    "                #error_w=((torch.norm(w1-true_w1))/(torch.norm(true_w1))+(torch.norm(w2-true_w2))/(torch.norm(true_w2)))/2\n",
    "                #print(num_X1feature,num_X2feature,num_example,'平均相对误差1：',error_w)\n",
    "                print(num_X2feature,num_example,'平均相对误差2：',np.min(results_error),end='   ')\n",
    "\n",
    "                #print('真实置换矩阵为：',true_P)\n",
    "                error_P=(torch.norm(S.transpose(1,0)-true_P))/(torch.norm(true_P))\n",
    "                print(num_X2feature,num_example,'置换矩阵误差：',error_P,end='   ')\n",
    "                error_reg2=(torch.norm(y_-torch.mm(torch.mm(S,X2_),w2))/torch.norm(y_))\n",
    "                print('真实回归误差',error_reg1,end='   ')\n",
    "                print('实验回归误差',error_reg2)\n",
    "                #print('双随机矩阵S为：',S.transpose(1,0).half())\n",
    "                #print(results)\n",
    "    #                 plt.figure(figsize=(6,6))\n",
    "    #                 plt.plot(results_w1_0,results_Loss, '-o',label='$w1[0]$')\n",
    "    #                 plt.plot(results_w1_1,results_Loss, '-o',label='$w1[1]$')\n",
    "    #                 plt.plot(results_w1_2,results_Loss, '-o',label='$w1[2]$')\n",
    "    #                 plt.plot(results_w2_0,results_Loss, '-o',label='$w2[0]$')\n",
    "    #                 plt.plot(results_w2_1,results_Loss, '-o',label='$w2[1]$')\n",
    "    #                 plt.plot(results_w2_2,results_Loss, '-o',label='$w2[2]$')\n",
    "    #                 plt.legend()\n",
    "    #                 plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
