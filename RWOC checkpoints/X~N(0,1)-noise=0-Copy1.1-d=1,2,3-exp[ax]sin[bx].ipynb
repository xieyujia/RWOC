{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline \n",
    "import torch \n",
    "#from IPython import display \n",
    "#from matplotlib import pyplot as plt\n",
    "import numpy as np \n",
    "import random\n",
    "import math\n",
    "#from time import time\n",
    "#from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatedata(noise,showpermutation=False,showtrue_w=False):\n",
    "    true_w2 = torch.from_numpy(np.random.normal(0, 1,(num_X2feature,1)))\n",
    "    if showtrue_w:\n",
    "        print('true_w2:',true_w2)\n",
    "    X2_before_ =torch.from_numpy(np.random.normal(0, 1, (num_example, 1)))\n",
    "    y_ = torch.exp(true_w2[0]*X2_before_)*torch.sin(true_w2[1]*X2_before_)\n",
    "    y_ += torch.from_numpy(np.random.normal(0, noise ,size=y_.size()))\n",
    "    P_array=np.random.permutation(num_example)\n",
    "    P=torch.zeros(num_example,num_example,dtype=torch.float64)\n",
    "    for i in range(num_example):\n",
    "        P[i][P_array[i]]=1\n",
    "    if showpermutation:\n",
    "        print('打乱X2的置换矩阵为',P)\n",
    "    X2_=torch.mm(P,X2_before_)\n",
    "    conditionnumber=np.linalg.cond(X2_.numpy())\n",
    "    #X2_=X2_before_\n",
    "    error_reg=(torch.norm(y_-torch.exp(true_w2[0]*X2_before_)*torch.sin(true_w2[1]*X2_before_))/torch.norm(y_))\n",
    "    return y_,X2_,true_w2,P,error_reg,conditionnumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateinitialw(method,showinitialw=False):\n",
    "    if method=='normal':\n",
    "        w2 = torch.from_numpy(np.random.normal(0, 1,(num_X2feature,1)))\n",
    "    if method=='zeros':\n",
    "        w2=torch.zeros(num_X2feature,1,dtype=torch.float64)\n",
    "    if showinitialw:\n",
    "        print('initial w2:',w2)\n",
    "    return w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinkhorn_stabilized(a, b, M, reg, numItermax=1000, tau=1e3, stopThr=1e-9,\n",
    "                        warmstart=None, verbose=False, print_period=20,\n",
    "                        log=False, **kwargs):\n",
    "\n",
    "#     a = np.asarray(a, dtype=np.float64)\n",
    "#     b = np.asarray(b, dtype=np.float64)\n",
    "#     M = np.asarray(M, dtype=np.float64)\n",
    "    a=a\n",
    "    b=b\n",
    "    M=M\n",
    "\n",
    "#     if len(a) == 0:\n",
    "#         a = np.ones((M.shape[0],), dtype=np.float64) / M.shape[0]\n",
    "#     if len(b) == 0:\n",
    "#         b = np.ones((M.shape[1],), dtype=np.float64) / M.shape[1]\n",
    "\n",
    "    # test if multiple target\n",
    "#     if len(b.shape) > 1:\n",
    "#         n_hists = b.shape[1]\n",
    "#         a = a[:, np.newaxis]\n",
    "#     else:\n",
    "#         n_hists = 0\n",
    "    n_hists = 0\n",
    "    # init data\n",
    "    dim_a = len(a)\n",
    "    dim_b = len(b)\n",
    "\n",
    "    cpt = 0\n",
    "    if log:\n",
    "        log = {'err': []}\n",
    "\n",
    "    # we assume that no distances are null except those of the diagonal of\n",
    "    # distances\n",
    "    if warmstart is None:\n",
    "        alpha, beta = torch.zeros(dim_a,1,dtype=torch.float64), torch.zeros(dim_b,1,dtype=torch.float64)\n",
    "    else:\n",
    "        alpha, beta = warmstart\n",
    "\n",
    "    if n_hists:\n",
    "        u = torch.ones((dim_a, n_hists)) / dim_a\n",
    "        v = torch.ones((dim_b, n_hists)) / dim_b\n",
    "    else:\n",
    "        u, v = torch.ones(dim_a,1,dtype=torch.float64) / dim_a, torch.ones(dim_b,1,dtype=torch.float64) / dim_b\n",
    "\n",
    "    def get_K(alpha, beta):\n",
    "        \"\"\"log space computation\"\"\"\n",
    "        return torch.exp(-(M - alpha.reshape((dim_a, 1))- beta.reshape((1, dim_b))) / reg)\n",
    "\n",
    "    def get_Gamma(alpha, beta, u, v):\n",
    "        \"\"\"log space gamma computation\"\"\"\n",
    "        return torch.exp(-(M - alpha.reshape((dim_a, 1)) - beta.reshape((1, dim_b)))\n",
    "                      / reg + torch.log(u.reshape((dim_a, 1))) + torch.log(v.reshape((1, dim_b))))\n",
    "\n",
    "    # print(np.min(K))\n",
    "\n",
    "    K = get_K(alpha, beta)\n",
    "    transp = K\n",
    "    loop = 1\n",
    "    cpt = 0\n",
    "    err = 1\n",
    "    while loop:\n",
    "\n",
    "        uprev = u\n",
    "        vprev = v\n",
    "        # sinkhornrn update\n",
    "        v = b / (torch.mm(K.transpose(1,0), u) + 1e-16)\n",
    "        u = a / (torch.mm(K, v) + 1e-16)\n",
    "        # remove numerical problems and store them in K\n",
    "        if torch.abs(u).max() > tau or torch.abs(v).max() > tau:\n",
    "            if n_hists:\n",
    "                alpha, beta = alpha + reg * \\\n",
    "                    torch.max(torch.log(u), 1), beta + reg * torch.max(np.log(v))\n",
    "            else:\n",
    "                alpha, beta = alpha + reg * torch.log(u), beta + reg * torch.log(v)\n",
    "                if n_hists:\n",
    "                    u, v = torch.ones((dim_a, n_hists)) / dim_a, torch.ones((dim_b, n_hists)) / dim_b\n",
    "                else:\n",
    "                    u, v = torch.ones(dim_a,1,dtype=torch.float64) / dim_a, torch.ones(dim_b,1,dtype=torch.float64) / dim_b\n",
    "            K = get_K(alpha, beta)\n",
    "            \n",
    "\n",
    "        if cpt % print_period == 0:\n",
    "            # we can speed up the process by checking for the error only all\n",
    "            # the 10th iterations\n",
    "            if n_hists:\n",
    "                err_u = abs(u - uprev).max()\n",
    "                err_u /= max(abs(u).max(), abs(uprev).max(), 1.)\n",
    "                err_v = abs(v - vprev).max()\n",
    "                err_v /= max(abs(v).max(), abs(vprev).max(), 1.)\n",
    "                err = 0.5 * (err_u + err_v)\n",
    "            else:\n",
    "                transp = get_Gamma(alpha, beta, u, v)\n",
    "                err = torch.norm((torch.sum(transp, axis=0) - b))\n",
    "            if log:\n",
    "                log['err'].append(err)\n",
    "\n",
    "            if verbose:\n",
    "                if cpt % (print_period * 20) == 0:\n",
    "                    print(\n",
    "                        '{:5s}|{:12s}'.format('It.', 'Err') + '\\n' + '-' * 19)\n",
    "                print('{:5d}|{:8e}|'.format(cpt, err))\n",
    "\n",
    "        if err <= stopThr:\n",
    "            loop = False\n",
    "\n",
    "        if cpt >= numItermax:\n",
    "            loop = False\n",
    "\n",
    "        if np.any(np.isnan(u.detach().numpy())) or np.any(np.isnan(v.detach().numpy())):\n",
    "            # we have reached the machine precision\n",
    "            # come back to previous solution and quit loop\n",
    "            print('Warning: numerical errors at iteration', cpt)\n",
    "            u = uprev\n",
    "            v = vprev\n",
    "            break\n",
    "\n",
    "        cpt = cpt + 1\n",
    "    #print(cpt)\n",
    "    if log:\n",
    "        if n_hists:\n",
    "            alpha = alpha[:, None]\n",
    "            beta = beta[:, None]\n",
    "        logu = alpha / reg + torch.log(u)\n",
    "        logv = beta / reg + torch.log(v)\n",
    "        log['logu'] = logu\n",
    "        log['logv'] = logv\n",
    "        log['alpha'] = alpha + reg * torch.log(u)\n",
    "        log['beta'] = beta + reg * torch.log(v)\n",
    "        log['warmstart'] = (log['alpha'], log['beta'])\n",
    "        if n_hists:\n",
    "            res = torch.zeros((n_hists))\n",
    "            for i in range(n_hists):\n",
    "                res[i] = torch.sum(get_Gamma(alpha, beta, u[:, i], v[:, i]) * M)\n",
    "            return res, log\n",
    "\n",
    "        else:\n",
    "            return get_Gamma(alpha, beta, u, v), log\n",
    "    else:\n",
    "        if n_hists:\n",
    "            res = torch.zeros((n_hists))\n",
    "            for i in range(n_hists):\n",
    "                res[i] = torch.sum(get_Gamma(alpha, beta, u[:, i], v[:, i]) * M)\n",
    "            return res\n",
    "        else:\n",
    "            return get_Gamma(alpha, beta, u, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinkhorn_epsilon_scaling(a, b, M, reg, numItermax=100, epsilon0=1e4,\n",
    "                             numInnerItermax=100, tau=1e3, stopThr=1e-9,\n",
    "                             warmstart=None, verbose=False, print_period=10,\n",
    "                             log=False, **kwargs):\n",
    "    #a = np.asarray(a, dtype=np.float64)\n",
    "    #b = np.asarray(b, dtype=np.float64)\n",
    "    #M = np.asarray(M, dtype=np.float64)\n",
    "    a=a\n",
    "    b=b\n",
    "    M=M\n",
    "#     if len(a) == 0:\n",
    "#         a = np.ones((M.shape[0],), dtype=np.float64) / M.shape[0]\n",
    "#     if len(b) == 0:\n",
    "#         b = np.ones((M.shape[1],), dtype=np.float64) / M.shape[1]\n",
    "\n",
    "    # init data\n",
    "    dim_a = len(a)\n",
    "    #dim_a=num_example\n",
    "    dim_b = len(b)\n",
    "    #dim_b=num_example\n",
    "    # nrelative umerical precision with 64 bits\n",
    "    numItermin = 35\n",
    "    numItermax = max(numItermin, numItermax)  # ensure that last velue is exact\n",
    "\n",
    "    cpt = 0\n",
    "    if log:\n",
    "        log = {'err': []}\n",
    "\n",
    "    # we assume that no distances are null except those of the diagonal of\n",
    "    # distances\n",
    "    if warmstart is None:\n",
    "        alpha, beta = torch.zeros(dim_a,1,dtype=torch.float64), torch.zeros(dim_b,1,dtype=torch.float64)\n",
    "    else:\n",
    "        alpha, beta = warmstart\n",
    "\n",
    "    def get_K(alpha, beta):\n",
    "        \"\"\"log space computation\"\"\"\n",
    "        return torch.exp(-(M - alpha.reshape((dim_a, 1))\n",
    "                        - beta.reshape((1, dim_b))) / reg)\n",
    "\n",
    "    # print(np.min(K))\n",
    "    def get_reg(n):  # exponential decreasing\n",
    "        return (epsilon0 - reg) * np.exp(-n) + reg\n",
    "\n",
    "    loop = 1\n",
    "    cpt = 0\n",
    "    err = 1\n",
    "    while loop:\n",
    "\n",
    "        regi = get_reg(cpt)\n",
    "\n",
    "        G, logi = sinkhorn_stabilized(a, b, M, regi,\n",
    "                                      numItermax=numInnerItermax, stopThr=1e-9,\n",
    "                                      warmstart=(alpha, beta), verbose=False,\n",
    "                                      print_period=20, tau=tau, log=True)\n",
    "\n",
    "        alpha = logi['alpha']\n",
    "        beta = logi['beta']\n",
    "\n",
    "        if cpt >= numItermax:\n",
    "            loop = False\n",
    "\n",
    "        if cpt % (print_period) == 0:  # spsion nearly converged\n",
    "            # we can speed up the process by checking for the error only all\n",
    "            # the 10th iterations\n",
    "            transp = G\n",
    "            err = torch.norm(\n",
    "                (torch.sum(transp, axis=0) - b))**2 + torch.norm((torch.sum(transp, axis=1) - a))**2\n",
    "            if log:\n",
    "                log['err'].append(err)\n",
    "\n",
    "            if verbose:\n",
    "                if cpt % (print_period * 10) == 0:\n",
    "                    print(\n",
    "                        '{:5s}|{:12s}'.format('It.', 'Err') + '\\n' + '-' * 19)\n",
    "                print('{:5d}|{:8e}|'.format(cpt, err))\n",
    "\n",
    "        if err <= stopThr and cpt > numItermin:\n",
    "            loop = False\n",
    "\n",
    "        cpt = cpt + 1\n",
    "    # print('err=',err,' cpt=',cpt)\n",
    "    if log:\n",
    "        log['alpha'] = alpha\n",
    "        log['beta'] = beta\n",
    "        log['warmstart'] = (log['alpha'], log['beta'])\n",
    "        return G, log\n",
    "    else:\n",
    "        return G\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0 =26.2376\n",
      "#Loss 1 =26.1318\n",
      "#Loss 2 =20.0777\n",
      "#Loss 3 =15.7599\n",
      "#Loss 4 =12.6989\n",
      "#Loss 5 =10.4896\n",
      "#Loss 6 =8.8455\n",
      "#Loss 7 =7.5795\n",
      "#Loss 8 =6.5729\n",
      "#Loss 9 =5.7509\n",
      "#Loss 10 =5.0657\n",
      "#Loss 11 =4.4862\n",
      "#Loss 12 =3.9910\n",
      "#Loss 13 =3.5651\n",
      "#Loss 14 =3.1973\n",
      "#Loss 15 =2.8762\n",
      "#Loss 16 =2.5938\n",
      "#Loss 17 =2.3412\n",
      "#Loss 18 =2.1218\n",
      "#Loss 19 =1.9308\n",
      "#Loss 20 =1.7649\n",
      "#Loss 21 =1.6207\n",
      "#Loss 22 =1.4950\n",
      "#Loss 23 =1.3813\n",
      "#Loss 24 =1.2798\n",
      "#Loss 25 =1.1892\n",
      "#Loss 26 =1.1094\n",
      "#Loss 27 =1.0391\n",
      "#Loss 28 =0.9764\n",
      "#Loss 29 =0.9214\n",
      "#Loss 30 =0.8737\n",
      "#Loss 31 =0.8319\n",
      "#Loss 32 =0.7947\n",
      "#Loss 33 =0.7616\n",
      "#Loss 34 =0.7298\n",
      "#Loss 35 =0.7019\n",
      "#Loss 36 =0.6774\n",
      "#Loss 37 =0.6557\n",
      "#Loss 38 =0.6364\n",
      "#Loss 39 =0.6193\n",
      "#Loss 40 =0.6039\n",
      "#Loss 41 =0.5891\n",
      "#Loss 42 =0.5737\n",
      "#Loss 43 =0.5582\n",
      "#Loss 44 =0.5443\n",
      "#Loss 45 =0.5317\n",
      "#Loss 46 =0.5202\n",
      "#Loss 47 =0.5095\n",
      "#Loss 48 =0.4994\n",
      "#Loss 49 =0.4901\n",
      "#Loss 50 =0.4817\n",
      "#Loss 51 =0.4732\n",
      "#Loss 52 =0.4643\n",
      "#Loss 53 =0.4560\n",
      "#Loss 54 =0.4484\n",
      "#Loss 55 =0.4413\n",
      "#Loss 56 =0.4348\n",
      "#Loss 57 =0.4287\n",
      "#Loss 58 =0.4231\n",
      "#Loss 59 =0.4178\n",
      "#Loss 60 =0.4129\n",
      "#Loss 61 =0.4084\n",
      "#Loss 62 =0.4040\n",
      "#Loss 63 =0.3997\n",
      "#Loss 64 =0.3956\n",
      "#Loss 65 =0.3918\n",
      "#Loss 66 =0.3882\n",
      "#Loss 67 =0.3844\n",
      "#Loss 68 =0.3809\n",
      "#Loss 69 =0.3776\n",
      "#Loss 70 =0.3745\n",
      "#Loss 71 =0.3716\n",
      "#Loss 72 =0.3689\n",
      "#Loss 73 =0.3663\n",
      "#Loss 74 =0.3637\n",
      "#Loss 75 =0.3613\n",
      "#Loss 76 =0.3582\n",
      "#Loss 77 =0.3541\n",
      "#Loss 78 =0.3502\n",
      "#Loss 79 =0.3465\n",
      "#Loss 80 =0.3431\n",
      "#Loss 81 =0.3398\n",
      "#Loss 82 =0.3367\n",
      "#Loss 83 =0.3338\n",
      "#Loss 84 =0.3310\n",
      "#Loss 85 =0.3284\n",
      "#Loss 86 =0.3257\n",
      "#Loss 87 =0.3228\n",
      "#Loss 88 =0.3201\n",
      "#Loss 89 =0.3175\n",
      "#Loss 90 =0.3150\n",
      "#Loss 91 =0.3127\n",
      "#Loss 92 =0.3105\n",
      "#Loss 93 =0.3084\n",
      "#Loss 94 =0.3065\n",
      "#Loss 95 =0.3046\n",
      "#Loss 96 =0.3026\n",
      "#Loss 97 =0.3008\n",
      "#Loss 98 =0.2989\n",
      "#Loss 99 =0.2971\n",
      "#Loss 100 =0.2952\n",
      "#Loss 101 =0.2931\n",
      "#Loss 102 =0.2911\n",
      "#Loss 103 =0.2892\n",
      "#Loss 104 =0.2874\n",
      "#Loss 105 =0.2857\n",
      "#Loss 106 =0.2840\n",
      "#Loss 107 =0.2825\n",
      "#Loss 108 =0.2810\n",
      "#Loss 109 =0.2795\n",
      "#Loss 110 =0.2781\n",
      "#Loss 111 =0.2766\n",
      "#Loss 112 =0.2753\n",
      "#Loss 113 =0.2740\n",
      "#Loss 114 =0.2728\n",
      "#Loss 115 =0.2716\n",
      "#Loss 116 =0.2705\n",
      "#Loss 117 =0.2694\n",
      "#Loss 118 =0.2684\n",
      "#Loss 119 =0.2674\n",
      "#Loss 120 =0.2664\n",
      "#Loss 121 =0.2655\n",
      "#Loss 122 =0.2646\n",
      "#Loss 123 =0.2637\n",
      "#Loss 124 =0.2629\n",
      "#Loss 125 =0.2622\n",
      "#Loss 126 =0.2615\n",
      "#Loss 127 =0.2608\n",
      "#Loss 128 =0.2601\n",
      "#Loss 129 =0.2595\n",
      "#Loss 130 =0.2589\n",
      "#Loss 131 =0.2584\n",
      "#Loss 132 =0.2578\n",
      "#Loss 133 =0.2573\n",
      "#Loss 134 =0.2568\n",
      "#Loss 135 =0.2564\n",
      "#Loss 136 =0.2559\n",
      "#Loss 137 =0.2555\n",
      "#Loss 138 =0.2551\n",
      "#Loss 139 =0.2547\n",
      "#Loss 140 =0.2543\n",
      "#Loss 141 =0.2539\n",
      "#Loss 142 =0.2536\n",
      "#Loss 143 =0.2533\n",
      "#Loss 144 =0.2529\n",
      "#Loss 145 =0.2526\n",
      "#Loss 146 =0.2524\n",
      "#Loss 147 =0.2521\n",
      "#Loss 148 =0.2518\n",
      "#Loss 149 =0.2515\n",
      "#Loss 150 =0.2512\n",
      "#Loss 151 =0.2509\n",
      "#Loss 152 =0.2506\n",
      "#Loss 153 =0.2503\n",
      "#Loss 154 =0.2501\n",
      "#Loss 155 =0.2498\n",
      "#Loss 156 =0.2496\n",
      "#Loss 157 =0.2493\n",
      "#Loss 158 =0.2491\n",
      "#Loss 159 =0.2489\n",
      "#Loss 160 =0.2487\n",
      "#Loss 161 =0.2485\n",
      "#Loss 162 =0.2484\n",
      "#Loss 163 =0.2482\n",
      "#Loss 164 =0.2480\n",
      "#Loss 165 =0.2476\n",
      "#Loss 166 =0.2472\n",
      "#Loss 167 =0.2468\n",
      "#Loss 168 =0.2464\n",
      "#Loss 169 =0.2460\n",
      "#Loss 170 =0.2457\n",
      "#Loss 171 =0.2454\n",
      "#Loss 172 =0.2451\n",
      "#Loss 173 =0.2448\n",
      "#Loss 174 =0.2445\n",
      "#Loss 175 =0.2442\n",
      "#Loss 176 =0.2440\n",
      "#Loss 177 =0.2437\n",
      "#Loss 178 =0.2435\n",
      "#Loss 179 =0.2433\n",
      "#Loss 180 =0.2431\n",
      "#Loss 181 =0.2429\n",
      "#Loss 182 =0.2427\n",
      "#Loss 183 =0.2425\n",
      "#Loss 184 =0.2424\n",
      "#Loss 185 =0.2422\n",
      "#Loss 186 =0.2420\n",
      "#Loss 187 =0.2419\n",
      "#Loss 188 =0.2418\n",
      "#Loss 189 =0.2416\n",
      "#Loss 190 =0.2415\n",
      "#Loss 191 =0.2414\n",
      "#Loss 192 =0.2412\n",
      "#Loss 193 =0.2410\n",
      "#Loss 194 =0.2409\n",
      "#Loss 195 =0.2407\n",
      "#Loss 196 =0.2406\n",
      "#Loss 197 =0.2405\n",
      "#Loss 198 =0.2403\n",
      "#Loss 199 =0.2402\n",
      "#Loss 200 =0.2401\n",
      "超过迭代上限\n",
      " 2 50 绝对误差 tensor(0.1040, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(0.1008, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.1387, dtype=torch.float64)   实验回归误差 tensor(0.0956, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.2961, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 50   条件数 1.0\n",
      "Loss 0 =8.9859\n",
      "#Loss 1 =8.9285\n",
      "#Loss 2 =7.8578\n",
      "#Loss 3 =6.9892\n",
      "#Loss 4 =6.2814\n",
      "#Loss 5 =5.7006\n",
      "#Loss 6 =5.2198\n",
      "#Loss 7 =4.8175\n",
      "#Loss 8 =4.4768\n",
      "#Loss 9 =4.1847\n",
      "#Loss 10 =3.9312\n",
      "#Loss 11 =3.7084\n",
      "#Loss 12 =3.5104\n",
      "#Loss 13 =3.3327\n",
      "#Loss 14 =3.1717\n",
      "#Loss 15 =3.0246\n",
      "#Loss 16 =2.8896\n",
      "#Loss 17 =2.7648\n",
      "#Loss 18 =2.6491\n",
      "#Loss 19 =2.5414\n",
      "#Loss 20 =2.4410\n",
      "#Loss 21 =2.3472\n",
      "#Loss 22 =2.2595\n",
      "#Loss 23 =2.1774\n",
      "#Loss 24 =2.1004\n",
      "#Loss 25 =2.0283\n",
      "#Loss 26 =1.9607\n",
      "#Loss 27 =1.8974\n",
      "#Loss 28 =1.8379\n",
      "#Loss 29 =1.7821\n",
      "#Loss 30 =1.7297\n",
      "#Loss 31 =1.6804\n",
      "#Loss 32 =1.6341\n",
      "#Loss 33 =1.5904\n",
      "#Loss 34 =1.5492\n",
      "#Loss 35 =1.5104\n",
      "#Loss 36 =1.4736\n",
      "#Loss 37 =1.4389\n",
      "#Loss 38 =1.4059\n",
      "#Loss 39 =1.3746\n",
      "#Loss 40 =1.3448\n",
      "#Loss 41 =1.3164\n",
      "#Loss 42 =1.2893\n",
      "#Loss 43 =1.2635\n",
      "#Loss 44 =1.2388\n",
      "#Loss 45 =1.2151\n",
      "#Loss 46 =1.1924\n",
      "#Loss 47 =1.1706\n",
      "#Loss 48 =1.1497\n",
      "#Loss 49 =1.1296\n",
      "#Loss 50 =1.1102\n",
      "#Loss 51 =1.0915\n",
      "#Loss 52 =1.0736\n",
      "#Loss 53 =1.0562\n",
      "#Loss 54 =1.0395\n",
      "#Loss 55 =1.0233\n",
      "#Loss 56 =1.0077\n",
      "#Loss 57 =0.9926\n",
      "#Loss 58 =0.9780\n",
      "#Loss 59 =0.9639\n",
      "#Loss 60 =0.9502\n",
      "#Loss 61 =0.9370\n",
      "#Loss 62 =0.9241\n",
      "#Loss 63 =0.9117\n",
      "#Loss 64 =0.8997\n",
      "#Loss 65 =0.8880\n",
      "#Loss 66 =0.8766\n",
      "#Loss 67 =0.8656\n",
      "#Loss 68 =0.8550\n",
      "#Loss 69 =0.8446\n",
      "#Loss 70 =0.8345\n",
      "#Loss 71 =0.8247\n",
      "#Loss 72 =0.8152\n",
      "#Loss 73 =0.8060\n",
      "#Loss 74 =0.7970\n",
      "#Loss 75 =0.7883\n",
      "#Loss 76 =0.7798\n",
      "#Loss 77 =0.7715\n",
      "#Loss 78 =0.7635\n",
      "#Loss 79 =0.7556\n",
      "#Loss 80 =0.7480\n",
      "#Loss 81 =0.7406\n",
      "#Loss 82 =0.7333\n",
      "#Loss 83 =0.7263\n",
      "#Loss 84 =0.7194\n",
      "#Loss 85 =0.7127\n",
      "#Loss 86 =0.7061\n",
      "#Loss 87 =0.6998\n",
      "#Loss 88 =0.6935\n",
      "#Loss 89 =0.6875\n",
      "#Loss 90 =0.6816\n",
      "#Loss 91 =0.6758\n",
      "#Loss 92 =0.6701\n",
      "#Loss 93 =0.6646\n",
      "#Loss 94 =0.6592\n",
      "#Loss 95 =0.6540\n",
      "#Loss 96 =0.6489\n",
      "#Loss 97 =0.6438\n",
      "#Loss 98 =0.6389\n",
      "#Loss 99 =0.6341\n",
      "#Loss 100 =0.6295\n",
      "#Loss 101 =0.6249\n",
      "#Loss 102 =0.6204\n",
      "#Loss 103 =0.6160\n",
      "#Loss 104 =0.6117\n",
      "#Loss 105 =0.6075\n",
      "#Loss 106 =0.6034\n",
      "#Loss 107 =0.5994\n",
      "#Loss 108 =0.5955\n",
      "#Loss 109 =0.5917\n",
      "#Loss 110 =0.5879\n",
      "#Loss 111 =0.5842\n",
      "#Loss 112 =0.5806\n",
      "#Loss 113 =0.5771\n",
      "#Loss 114 =0.5736\n",
      "#Loss 115 =0.5702\n",
      "#Loss 116 =0.5669\n",
      "#Loss 117 =0.5636\n",
      "#Loss 118 =0.5604\n",
      "#Loss 119 =0.5573\n",
      "#Loss 120 =0.5542\n",
      "#Loss 121 =0.5512\n",
      "#Loss 122 =0.5483\n",
      "#Loss 123 =0.5454\n",
      "#Loss 124 =0.5426\n",
      "#Loss 125 =0.5398\n",
      "#Loss 126 =0.5371\n",
      "#Loss 127 =0.5344\n",
      "#Loss 128 =0.5318\n",
      "#Loss 129 =0.5292\n",
      "#Loss 130 =0.5267\n",
      "#Loss 131 =0.5242\n",
      "#Loss 132 =0.5217\n",
      "#Loss 133 =0.5194\n",
      "#Loss 134 =0.5170\n",
      "#Loss 135 =0.5147\n",
      "#Loss 136 =0.5125\n",
      "#Loss 137 =0.5102\n",
      "#Loss 138 =0.5081\n",
      "#Loss 139 =0.5059\n",
      "#Loss 140 =0.5038\n",
      "#Loss 141 =0.5017\n",
      "#Loss 142 =0.4997\n",
      "#Loss 143 =0.4977\n",
      "#Loss 144 =0.4958\n",
      "#Loss 145 =0.4938\n",
      "#Loss 146 =0.4919\n",
      "#Loss 147 =0.4901\n",
      "#Loss 148 =0.4883\n",
      "#Loss 149 =0.4865\n",
      "#Loss 150 =0.4847\n",
      "#Loss 151 =0.4830\n",
      "#Loss 152 =0.4813\n",
      "#Loss 153 =0.4796\n",
      "#Loss 154 =0.4779\n",
      "#Loss 155 =0.4763\n",
      "#Loss 156 =0.4747\n",
      "#Loss 157 =0.4732\n",
      "#Loss 158 =0.4716\n",
      "#Loss 159 =0.4701\n",
      "#Loss 160 =0.4686\n",
      "#Loss 161 =0.4671\n",
      "#Loss 162 =0.4657\n",
      "#Loss 163 =0.4643\n",
      "#Loss 164 =0.4629\n",
      "#Loss 165 =0.4615\n",
      "#Loss 166 =0.4601\n",
      "#Loss 167 =0.4588\n",
      "#Loss 168 =0.4575\n",
      "#Loss 169 =0.4562\n",
      "#Loss 170 =0.4549\n",
      "#Loss 171 =0.4537\n",
      "#Loss 172 =0.4524\n",
      "#Loss 173 =0.4512\n",
      "#Loss 174 =0.4500\n",
      "#Loss 175 =0.4488\n",
      "#Loss 176 =0.4476\n",
      "#Loss 177 =0.4465\n",
      "#Loss 178 =0.4454\n",
      "#Loss 179 =0.4442\n",
      "#Loss 180 =0.4431\n",
      "#Loss 181 =0.4421\n",
      "#Loss 182 =0.4410\n",
      "#Loss 183 =0.4400\n",
      "#Loss 184 =0.4389\n",
      "#Loss 185 =0.4379\n",
      "#Loss 186 =0.4369\n",
      "#Loss 187 =0.4359\n",
      "#Loss 188 =0.4349\n",
      "#Loss 189 =0.4340\n",
      "#Loss 190 =0.4330\n",
      "#Loss 191 =0.4321\n",
      "#Loss 192 =0.4312\n",
      "#Loss 193 =0.4303\n",
      "#Loss 194 =0.4294\n",
      "#Loss 195 =0.4285\n",
      "#Loss 196 =0.4276\n",
      "#Loss 197 =0.4268\n",
      "#Loss 198 =0.4260\n",
      "#Loss 199 =0.4251\n",
      "#Loss 200 =0.4243\n",
      "超过迭代上限\n",
      " 2 50 绝对误差 tensor(1.5441, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(1.6536, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.1936, dtype=torch.float64)   实验回归误差 tensor(0.2171, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.4000, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 50   条件数 1.0\n",
      "Loss 0 =157.2573\n",
      "#Loss 1 =157.0051\n",
      "#Loss 2 =133.5166\n",
      "#Loss 3 =117.3246\n",
      "#Loss 4 =107.3763\n",
      "#Loss 5 =101.5190\n",
      "#Loss 6 =98.0994\n",
      "#Loss 7 =96.0968\n",
      "#Loss 8 =94.9148\n",
      "#Loss 9 =94.2074\n",
      "#Loss 10 =93.7740\n",
      "#Loss 11 =93.4921\n",
      "#Loss 12 =93.2857\n",
      "#Loss 13 =93.1104\n",
      "#Loss 14 =92.9552\n",
      "#Loss 15 =92.7933\n",
      "#Loss 16 =92.6022\n",
      "#Loss 17 =92.3745\n",
      "#Loss 18 =92.0914\n",
      "#Loss 19 =91.7300\n",
      "#Loss 20 =91.2499\n",
      "#Loss 21 =90.6353\n",
      "#Loss 22 =89.8427\n",
      "#Loss 23 =88.8121\n",
      "#Loss 24 =87.4795\n",
      "#Loss 25 =85.7944\n",
      "#Loss 26 =83.6060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 27 =80.9440\n",
      "#Loss 28 =77.7702\n",
      "#Loss 29 =74.3230\n",
      "#Loss 30 =70.9956\n",
      "#Loss 31 =68.2452\n",
      "#Loss 32 =66.3955\n",
      "#Loss 33 =65.3900\n",
      "#Loss 34 =64.8923\n",
      "#Loss 35 =64.6009\n",
      "#Loss 36 =64.3917\n",
      "#Loss 37 =64.2277\n",
      "#Loss 38 =64.0957\n",
      "#Loss 39 =63.9879\n",
      "#Loss 40 =63.8991\n",
      "#Loss 41 =63.8252\n",
      "#Loss 42 =63.7632\n",
      "#Loss 43 =63.7108\n",
      "#Loss 44 =63.6663\n",
      "#Loss 45 =63.6282\n",
      "#Loss 46 =63.5954\n",
      "#Loss 47 =63.5670\n",
      "#Loss 48 =63.5424\n",
      "#Loss 49 =63.5209\n",
      "#Loss 50 =63.5022\n",
      "#Loss 51 =63.4857\n",
      "#Loss 52 =63.4711\n",
      "#Loss 53 =63.4583\n",
      "#Loss 54 =63.4469\n",
      "#Loss 55 =63.4368\n",
      "#Loss 56 =63.4277\n",
      "#Loss 57 =63.4197\n",
      "#Loss 58 =63.4125\n",
      "#Loss 59 =63.4060\n",
      "#Loss 60 =63.4002\n",
      "#Loss 61 =63.3950\n",
      "#Loss 62 =63.3903\n",
      "#Loss 63 =63.3861\n",
      "#Loss 64 =63.3822\n",
      "#Loss 65 =63.3788\n",
      "#Loss 66 =63.3756\n",
      "#Loss 67 =63.3728\n",
      "#Loss 68 =63.3702\n",
      "#Loss 69 =63.3678\n",
      "#Loss 70 =63.3657\n",
      "#Loss 71 =63.3637\n",
      "#Loss 72 =63.3620\n",
      " 2 50 绝对误差 tensor(2.2307, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(1.1132, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0537, dtype=torch.float64)   实验回归误差 tensor(0.6348, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.3856, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 50   条件数 1.0\n",
      "Loss 0 =1.0456\n",
      "#Loss 1 =1.0408\n",
      "#Loss 2 =0.7961\n",
      "#Loss 3 =0.6185\n",
      "#Loss 4 =0.4895\n",
      "#Loss 5 =0.3959\n",
      "#Loss 6 =0.3277\n",
      "#Loss 7 =0.2780\n",
      "#Loss 8 =0.2416\n",
      "#Loss 9 =0.2150\n",
      "#Loss 10 =0.1954\n",
      "#Loss 11 =0.1810\n",
      "#Loss 12 =0.1703\n",
      "#Loss 13 =0.1623\n",
      "#Loss 14 =0.1563\n",
      "#Loss 15 =0.1517\n",
      "#Loss 16 =0.1483\n",
      "#Loss 17 =0.1456\n",
      "#Loss 18 =0.1435\n",
      "#Loss 19 =0.1418\n",
      "#Loss 20 =0.1404\n",
      "#Loss 21 =0.1393\n",
      "#Loss 22 =0.1383\n",
      "#Loss 23 =0.1375\n",
      "#Loss 24 =0.1367\n",
      "#Loss 25 =0.1360\n",
      "#Loss 26 =0.1354\n",
      "#Loss 27 =0.1348\n",
      "#Loss 28 =0.1343\n",
      "#Loss 29 =0.1338\n",
      "#Loss 30 =0.1333\n",
      "#Loss 31 =0.1328\n",
      "#Loss 32 =0.1323\n",
      "#Loss 33 =0.1318\n",
      "#Loss 34 =0.1314\n",
      "#Loss 35 =0.1309\n",
      "#Loss 36 =0.1305\n",
      "#Loss 37 =0.1301\n",
      "#Loss 38 =0.1296\n",
      "#Loss 39 =0.1292\n",
      "#Loss 40 =0.1288\n",
      "#Loss 41 =0.1284\n",
      "#Loss 42 =0.1280\n",
      "#Loss 43 =0.1276\n",
      "#Loss 44 =0.1272\n",
      "#Loss 45 =0.1268\n",
      "#Loss 46 =0.1264\n",
      "#Loss 47 =0.1261\n",
      "#Loss 48 =0.1257\n",
      "#Loss 49 =0.1253\n",
      "#Loss 50 =0.1250\n",
      "#Loss 51 =0.1246\n",
      "#Loss 52 =0.1242\n",
      "#Loss 53 =0.1239\n",
      "#Loss 54 =0.1236\n",
      "#Loss 55 =0.1232\n",
      "#Loss 56 =0.1229\n",
      "#Loss 57 =0.1225\n",
      "#Loss 58 =0.1222\n",
      "#Loss 59 =0.1219\n",
      "#Loss 60 =0.1216\n",
      "#Loss 61 =0.1212\n",
      "#Loss 62 =0.1209\n",
      "#Loss 63 =0.1206\n",
      "#Loss 64 =0.1203\n",
      "#Loss 65 =0.1200\n",
      "#Loss 66 =0.1197\n",
      "#Loss 67 =0.1194\n",
      "#Loss 68 =0.1191\n",
      "#Loss 69 =0.1188\n",
      "#Loss 70 =0.1186\n",
      "#Loss 71 =0.1183\n",
      "#Loss 72 =0.1180\n",
      "#Loss 73 =0.1177\n",
      "#Loss 74 =0.1175\n",
      "#Loss 75 =0.1172\n",
      "#Loss 76 =0.1169\n",
      "#Loss 77 =0.1167\n",
      "#Loss 78 =0.1164\n",
      "#Loss 79 =0.1162\n",
      "#Loss 80 =0.1159\n",
      "#Loss 81 =0.1157\n",
      "#Loss 82 =0.1154\n",
      "#Loss 83 =0.1152\n",
      "#Loss 84 =0.1149\n",
      "#Loss 85 =0.1147\n",
      "#Loss 86 =0.1145\n",
      "#Loss 87 =0.1142\n",
      "#Loss 88 =0.1140\n",
      "#Loss 89 =0.1138\n",
      "#Loss 90 =0.1136\n",
      "#Loss 91 =0.1133\n",
      "#Loss 92 =0.1131\n",
      "#Loss 93 =0.1129\n",
      "#Loss 94 =0.1127\n",
      "#Loss 95 =0.1125\n",
      "#Loss 96 =0.1123\n",
      "#Loss 97 =0.1121\n",
      "#Loss 98 =0.1119\n",
      "#Loss 99 =0.1117\n",
      "#Loss 100 =0.1115\n",
      "#Loss 101 =0.1113\n",
      "#Loss 102 =0.1111\n",
      "#Loss 103 =0.1109\n",
      "#Loss 104 =0.1107\n",
      "#Loss 105 =0.1105\n",
      "#Loss 106 =0.1104\n",
      "#Loss 107 =0.1102\n",
      "#Loss 108 =0.1100\n",
      "#Loss 109 =0.1098\n",
      "#Loss 110 =0.1097\n",
      "#Loss 111 =0.1095\n",
      "#Loss 112 =0.1093\n",
      "#Loss 113 =0.1091\n",
      "#Loss 114 =0.1090\n",
      "#Loss 115 =0.1088\n",
      "#Loss 116 =0.1087\n",
      "#Loss 117 =0.1085\n",
      "#Loss 118 =0.1083\n",
      "#Loss 119 =0.1082\n",
      "#Loss 120 =0.1080\n",
      "#Loss 121 =0.1079\n",
      "#Loss 122 =0.1077\n",
      "#Loss 123 =0.1076\n",
      "#Loss 124 =0.1074\n",
      "#Loss 125 =0.1073\n",
      "#Loss 126 =0.1071\n",
      "#Loss 127 =0.1070\n",
      "#Loss 128 =0.1069\n",
      "#Loss 129 =0.1067\n",
      "#Loss 130 =0.1066\n",
      "#Loss 131 =0.1065\n",
      "#Loss 132 =0.1063\n",
      "#Loss 133 =0.1062\n",
      "#Loss 134 =0.1061\n",
      "#Loss 135 =0.1059\n",
      "#Loss 136 =0.1058\n",
      "#Loss 137 =0.1057\n",
      "#Loss 138 =0.1056\n",
      "#Loss 139 =0.1054\n",
      "#Loss 140 =0.1053\n",
      "#Loss 141 =0.1052\n",
      "#Loss 142 =0.1051\n",
      "#Loss 143 =0.1050\n",
      "#Loss 144 =0.1048\n",
      "#Loss 145 =0.1047\n",
      "#Loss 146 =0.1046\n",
      "#Loss 147 =0.1045\n",
      "#Loss 148 =0.1044\n",
      "#Loss 149 =0.1043\n",
      "#Loss 150 =0.1042\n",
      "#Loss 151 =0.1041\n",
      "#Loss 152 =0.1040\n",
      "#Loss 153 =0.1039\n",
      "#Loss 154 =0.1038\n",
      "#Loss 155 =0.1037\n",
      "#Loss 156 =0.1036\n",
      "#Loss 157 =0.1035\n",
      "#Loss 158 =0.1034\n",
      "#Loss 159 =0.1033\n",
      "#Loss 160 =0.1032\n",
      "#Loss 161 =0.1031\n",
      "#Loss 162 =0.1030\n",
      "#Loss 163 =0.1029\n",
      "#Loss 164 =0.1028\n",
      "#Loss 165 =0.1027\n",
      "#Loss 166 =0.1026\n",
      "#Loss 167 =0.1025\n",
      "#Loss 168 =0.1024\n",
      "#Loss 169 =0.1024\n",
      "#Loss 170 =0.1023\n",
      "#Loss 171 =0.1022\n",
      "#Loss 172 =0.1021\n",
      "#Loss 173 =0.1020\n",
      "#Loss 174 =0.1019\n",
      "#Loss 175 =0.1019\n",
      "#Loss 176 =0.1018\n",
      "#Loss 177 =0.1017\n",
      "#Loss 178 =0.1016\n",
      "#Loss 179 =0.1015\n",
      "#Loss 180 =0.1015\n",
      "#Loss 181 =0.1014\n",
      "#Loss 182 =0.1013\n",
      "#Loss 183 =0.1012\n",
      "#Loss 184 =0.1012\n",
      "#Loss 185 =0.1011\n",
      "#Loss 186 =0.1010\n",
      "#Loss 187 =0.1010\n",
      "#Loss 188 =0.1009\n",
      "#Loss 189 =0.1008\n",
      "#Loss 190 =0.1008\n",
      "#Loss 191 =0.1007\n",
      "#Loss 192 =0.1006\n",
      "#Loss 193 =0.1006\n",
      "#Loss 194 =0.1005\n",
      "#Loss 195 =0.1004\n",
      "#Loss 196 =0.1004\n",
      "#Loss 197 =0.1003\n",
      "#Loss 198 =0.1002\n",
      "#Loss 199 =0.1002\n",
      "#Loss 200 =0.1001\n",
      "超过迭代上限\n",
      " 2 50 绝对误差 tensor(0.4222, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(0.8339, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.7435, dtype=torch.float64)   实验回归误差 tensor(0.3093, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.3856, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 50   条件数 1.0\n",
      "Loss 0 =21.5600\n",
      "#Loss 1 =21.3710\n",
      "#Loss 2 =18.5651\n",
      "#Loss 3 =16.1832\n",
      "#Loss 4 =14.1731\n",
      "#Loss 5 =12.4795\n",
      "#Loss 6 =11.0505\n",
      "#Loss 7 =9.8407\n",
      "#Loss 8 =8.8113\n",
      "#Loss 9 =7.9307\n",
      "#Loss 10 =7.1732\n",
      "#Loss 11 =6.5179\n",
      "#Loss 12 =5.9482\n",
      "#Loss 13 =5.4505\n",
      "#Loss 14 =5.0140\n",
      "#Loss 15 =4.6296\n",
      "#Loss 16 =4.2902\n",
      "#Loss 17 =3.9895\n",
      "#Loss 18 =3.7225\n",
      "#Loss 19 =3.4849\n",
      "#Loss 20 =3.2730\n",
      "#Loss 21 =3.0837\n",
      "#Loss 22 =2.9142\n",
      "#Loss 23 =2.7623\n",
      "#Loss 24 =2.6258\n",
      "#Loss 25 =2.5030\n",
      "#Loss 26 =2.3922\n",
      "#Loss 27 =2.2922\n",
      "#Loss 28 =2.2017\n",
      "#Loss 29 =2.1197\n",
      "#Loss 30 =2.0451\n",
      "#Loss 31 =1.9772\n",
      "#Loss 32 =1.9152\n",
      "#Loss 33 =1.8585\n",
      "#Loss 34 =1.8065\n",
      "#Loss 35 =1.7571\n",
      "#Loss 36 =1.7086\n",
      "#Loss 37 =1.6639\n",
      "#Loss 38 =1.6222\n",
      "#Loss 39 =1.5835\n",
      "#Loss 40 =1.5475\n",
      "#Loss 41 =1.5139\n",
      "#Loss 42 =1.4826\n",
      "#Loss 43 =1.4532\n",
      "#Loss 44 =1.4255\n",
      "#Loss 45 =1.3996\n",
      "#Loss 46 =1.3750\n",
      "#Loss 47 =1.3519\n",
      "#Loss 48 =1.3299\n",
      "#Loss 49 =1.3091\n",
      "#Loss 50 =1.2894\n",
      "#Loss 51 =1.2705\n",
      "#Loss 52 =1.2526\n",
      "#Loss 53 =1.2355\n",
      "#Loss 54 =1.2192\n",
      "#Loss 55 =1.2036\n",
      "#Loss 56 =1.1886\n",
      "#Loss 57 =1.1743\n",
      "#Loss 58 =1.1605\n",
      "#Loss 59 =1.1473\n",
      "#Loss 60 =1.1346\n",
      "#Loss 61 =1.1225\n",
      "#Loss 62 =1.1107\n",
      "#Loss 63 =1.0995\n",
      "#Loss 64 =1.0886\n",
      "#Loss 65 =1.0782\n",
      "#Loss 66 =1.0681\n",
      "#Loss 67 =1.0584\n",
      "#Loss 68 =1.0490\n",
      "#Loss 69 =1.0400\n",
      "#Loss 70 =1.0313\n",
      "#Loss 71 =1.0228\n",
      "#Loss 72 =1.0147\n",
      "#Loss 73 =1.0069\n",
      "#Loss 74 =0.9993\n",
      "#Loss 75 =0.9920\n",
      "#Loss 76 =0.9850\n",
      "#Loss 77 =0.9782\n",
      "#Loss 78 =0.9716\n",
      "#Loss 79 =0.9652\n",
      "#Loss 80 =0.9591\n",
      "#Loss 81 =0.9532\n",
      "#Loss 82 =0.9474\n",
      "#Loss 83 =0.9417\n",
      "#Loss 84 =0.9355\n",
      "#Loss 85 =0.9295\n",
      "#Loss 86 =0.9236\n",
      "#Loss 87 =0.9180\n",
      "#Loss 88 =0.9126\n",
      "#Loss 89 =0.9074\n",
      "#Loss 90 =0.9023\n",
      "#Loss 91 =0.8970\n",
      "#Loss 92 =0.8911\n",
      "#Loss 93 =0.8853\n",
      "#Loss 94 =0.8797\n",
      "#Loss 95 =0.8744\n",
      "#Loss 96 =0.8692\n",
      "#Loss 97 =0.8641\n",
      "#Loss 98 =0.8593\n",
      "#Loss 99 =0.8546\n",
      "#Loss 100 =0.8500\n",
      "#Loss 101 =0.8456\n",
      "#Loss 102 =0.8413\n",
      "#Loss 103 =0.8372\n",
      "#Loss 104 =0.8332\n",
      "#Loss 105 =0.8293\n",
      "#Loss 106 =0.8255\n",
      "#Loss 107 =0.8219\n",
      "#Loss 108 =0.8183\n",
      "#Loss 109 =0.8149\n",
      "#Loss 110 =0.8116\n",
      "#Loss 111 =0.8078\n",
      "#Loss 112 =0.8031\n",
      "#Loss 113 =0.7986\n",
      "#Loss 114 =0.7942\n",
      "#Loss 115 =0.7899\n",
      "#Loss 116 =0.7858\n",
      "#Loss 117 =0.7818\n",
      "#Loss 118 =0.7779\n",
      "#Loss 119 =0.7741\n",
      "#Loss 120 =0.7705\n",
      "#Loss 121 =0.7670\n",
      "#Loss 122 =0.7635\n",
      "#Loss 123 =0.7602\n",
      "#Loss 124 =0.7570\n",
      "#Loss 125 =0.7539\n",
      "#Loss 126 =0.7509\n",
      "#Loss 127 =0.7480\n",
      "#Loss 128 =0.7452\n",
      "#Loss 129 =0.7425\n",
      "#Loss 130 =0.7398\n",
      "#Loss 131 =0.7373\n",
      "#Loss 132 =0.7344\n",
      "#Loss 133 =0.7312\n",
      "#Loss 134 =0.7281\n",
      "#Loss 135 =0.7251\n",
      "#Loss 136 =0.7221\n",
      "#Loss 137 =0.7193\n",
      "#Loss 138 =0.7166\n",
      "#Loss 139 =0.7140\n",
      "#Loss 140 =0.7114\n",
      "#Loss 141 =0.7089\n",
      "#Loss 142 =0.7066\n",
      "#Loss 143 =0.7042\n",
      "#Loss 144 =0.7020\n",
      "#Loss 145 =0.6999\n",
      "#Loss 146 =0.6978\n",
      "#Loss 147 =0.6958\n",
      "#Loss 148 =0.6938\n",
      "#Loss 149 =0.6919\n",
      "#Loss 150 =0.6901\n",
      "#Loss 151 =0.6884\n",
      "#Loss 152 =0.6867\n",
      "#Loss 153 =0.6850\n",
      "#Loss 154 =0.6834\n",
      "#Loss 155 =0.6819\n",
      "#Loss 156 =0.6804\n",
      "#Loss 157 =0.6790\n",
      "#Loss 158 =0.6776\n",
      "#Loss 159 =0.6763\n",
      "#Loss 160 =0.6750\n",
      "#Loss 161 =0.6738\n",
      "#Loss 162 =0.6725\n",
      "#Loss 163 =0.6713\n",
      "#Loss 164 =0.6700\n",
      "#Loss 165 =0.6688\n",
      "#Loss 166 =0.6677\n",
      "#Loss 167 =0.6666\n",
      "#Loss 168 =0.6655\n",
      "#Loss 169 =0.6645\n",
      "#Loss 170 =0.6634\n",
      "#Loss 171 =0.6623\n",
      "#Loss 172 =0.6612\n",
      "#Loss 173 =0.6599\n",
      "#Loss 174 =0.6586\n",
      "#Loss 175 =0.6574\n",
      "#Loss 176 =0.6563\n",
      "#Loss 177 =0.6552\n",
      "#Loss 178 =0.6541\n",
      "#Loss 179 =0.6531\n",
      "#Loss 180 =0.6521\n",
      "#Loss 181 =0.6511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 182 =0.6502\n",
      "#Loss 183 =0.6493\n",
      "#Loss 184 =0.6484\n",
      "#Loss 185 =0.6476\n",
      "#Loss 186 =0.6468\n",
      "#Loss 187 =0.6460\n",
      "#Loss 188 =0.6453\n",
      "#Loss 189 =0.6446\n",
      "#Loss 190 =0.6439\n",
      "#Loss 191 =0.6432\n",
      "#Loss 192 =0.6426\n",
      "#Loss 193 =0.6420\n",
      "#Loss 194 =0.6414\n",
      "#Loss 195 =0.6408\n",
      "#Loss 196 =0.6403\n",
      "#Loss 197 =0.6398\n",
      "#Loss 198 =0.6393\n",
      "#Loss 199 =0.6388\n",
      "#Loss 200 =0.6383\n",
      "超过迭代上限\n",
      " 2 50 绝对误差 tensor(0.8083, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(0.4362, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.1546, dtype=torch.float64)   实验回归误差 tensor(0.1720, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.4142, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 50   条件数 1.0\n",
      "Loss 0 =768.6010\n",
      "#Loss 1 =765.8251\n",
      "#Loss 2 =712.8282\n",
      "#Loss 3 =662.7824\n",
      "#Loss 4 =592.4804\n",
      "#Loss 5 =460.1954\n",
      "#Loss 6 =148.3280\n",
      "#Loss 7 =1094.3681\n",
      "#Loss 8 =700.6016\n",
      "#Loss 9 =632.6594\n",
      "#Loss 10 =680.5202\n",
      "#Loss 11 =660.8483\n",
      "#Loss 12 =681.7491\n",
      "#Loss 13 =705.3146\n",
      "#Loss 14 =667.9935\n",
      "#Loss 15 =671.3782\n",
      "#Loss 16 =628.0210\n",
      "#Loss 17 =683.2897\n",
      "#Loss 18 =625.9647\n",
      "#Loss 19 =702.3776\n",
      "#Loss 20 =676.9814\n",
      "#Loss 21 =665.1277\n",
      "#Loss 22 =653.5217\n",
      "#Loss 23 =639.8863\n",
      "#Loss 24 =719.3130\n",
      "#Loss 25 =716.9521\n",
      "#Loss 26 =714.3257\n",
      "#Loss 27 =711.5541\n",
      "#Loss 28 =709.0151\n",
      "#Loss 29 =706.2826\n",
      "#Loss 30 =702.8719\n",
      "#Loss 31 =699.2184\n",
      "#Loss 32 =694.9331\n",
      "#Loss 33 =690.8808\n",
      "#Loss 34 =685.0897\n",
      "#Loss 35 =678.6076\n",
      "#Loss 36 =670.4335\n",
      "#Loss 37 =664.0283\n",
      "#Loss 38 =662.1664\n",
      "#Loss 39 =652.7897\n",
      "#Loss 40 =628.5774\n",
      "#Loss 41 =719.3370\n",
      "#Loss 42 =716.8802\n",
      "#Loss 43 =715.0356\n",
      "#Loss 44 =714.0166\n",
      "#Loss 45 =712.3178\n",
      "#Loss 46 =709.9359\n",
      "#Loss 47 =707.9703\n",
      "#Loss 48 =705.7176\n",
      "#Loss 49 =703.0549\n",
      "#Loss 50 =698.5280\n",
      "#Loss 51 =697.2521\n",
      "#Loss 52 =693.9673\n",
      "#Loss 53 =690.9379\n",
      "#Loss 54 =687.2131\n",
      "#Loss 55 =681.1097\n",
      "#Loss 56 =676.3310\n",
      "#Loss 57 =671.5196\n",
      "#Loss 58 =664.9015\n",
      "#Loss 59 =656.8959\n",
      "#Loss 60 =649.3581\n",
      "#Loss 61 =647.1770\n",
      "#Loss 62 =637.3548\n",
      "#Loss 63 =628.3932\n",
      "#Loss 64 =611.7731\n",
      "#Loss 65 =572.3350\n",
      "#Loss 66 =650.8844\n",
      "#Loss 67 =640.6380\n",
      "#Loss 68 =624.7166\n",
      "#Loss 69 =635.7718\n",
      "#Loss 70 =717.7595\n",
      "#Loss 71 =716.9606\n",
      "#Loss 72 =714.1372\n",
      "#Loss 73 =713.1534\n",
      "#Loss 74 =711.4623\n",
      "#Loss 75 =713.1361\n",
      "#Loss 76 =708.7059\n",
      "#Loss 77 =707.3154\n",
      "#Loss 78 =705.7113\n",
      "#Loss 79 =697.2572\n",
      "#Loss 80 =701.9766\n",
      "#Loss 81 =699.4181\n",
      "#Loss 82 =699.2133\n",
      "#Loss 83 =697.2613\n",
      "#Loss 84 =694.9971\n",
      "#Loss 85 =695.4716\n",
      "#Loss 86 =694.7361\n",
      "#Loss 87 =688.0439\n",
      "#Loss 88 =685.5131\n",
      "#Loss 89 =682.6950\n",
      "#Loss 90 =678.4352\n",
      "#Loss 91 =676.9445\n",
      "#Loss 92 =679.2979\n",
      "#Loss 93 =676.1126\n",
      "#Loss 94 =672.8905\n",
      "#Loss 95 =669.4819\n",
      "#Loss 96 =666.2517\n",
      "#Loss 97 =661.4712\n",
      "#Loss 98 =656.8397\n",
      "#Loss 99 =652.6197\n",
      "#Loss 100 =632.3326\n",
      "#Loss 101 =640.6423\n",
      "#Loss 102 =628.5516\n",
      "#Loss 103 =625.8486\n",
      "#Loss 104 =618.2465\n",
      "#Loss 105 =610.7654\n",
      "#Loss 106 =581.5880\n",
      "#Loss 107 =573.9024\n",
      "#Loss 108 =672.2455\n",
      "#Loss 109 =579.0205\n",
      "#Loss 110 =565.9833\n",
      "#Loss 111 =730.8454\n",
      "#Loss 112 =730.9990\n",
      "#Loss 113 =728.8285\n",
      "#Loss 114 =731.4074\n",
      "#Loss 115 =728.7229\n",
      "#Loss 116 =730.6041\n",
      "#Loss 117 =732.1232\n",
      "#Loss 118 =726.6540\n",
      "#Loss 119 =728.3173\n",
      "#Loss 120 =727.8725\n",
      "#Loss 121 =725.2011\n",
      "#Loss 122 =726.9023\n",
      "#Loss 123 =726.1448\n",
      "#Loss 124 =725.4466\n",
      "#Loss 125 =727.0854\n",
      "#Loss 126 =722.6249\n",
      "#Loss 127 =724.7482\n",
      "#Loss 128 =724.9948\n",
      "#Loss 129 =723.5075\n",
      "#Loss 130 =721.8399\n",
      "#Loss 131 =721.2596\n",
      "#Loss 132 =721.6776\n",
      "#Loss 133 =721.5898\n",
      "#Loss 134 =721.7247\n",
      "#Loss 135 =719.3511\n",
      "#Loss 136 =719.1272\n",
      "#Loss 137 =718.6460\n",
      "#Loss 138 =718.6921\n",
      "#Loss 139 =717.3323\n",
      "#Loss 140 =713.2676\n",
      "#Loss 141 =715.2701\n",
      "#Loss 142 =715.0123\n",
      "#Loss 143 =710.9368\n",
      "#Loss 144 =710.6978\n",
      "#Loss 145 =712.2082\n",
      "#Loss 146 =717.1578\n",
      "#Loss 147 =712.8183\n",
      "#Loss 148 =710.6527\n",
      "#Loss 149 =709.6280\n",
      "#Loss 150 =708.5638\n",
      "#Loss 151 =707.8530\n",
      "#Loss 152 =712.3619\n",
      "#Loss 153 =713.9258\n",
      "#Loss 154 =710.9067\n",
      "#Loss 155 =705.5124\n",
      "#Loss 156 =703.2393\n",
      "#Loss 157 =705.7727\n",
      "#Loss 158 =702.5660\n",
      "#Loss 159 =706.5322\n",
      "#Loss 160 =699.0977\n",
      "#Loss 161 =707.9856\n",
      "#Loss 162 =701.0480\n",
      "#Loss 163 =703.9048\n",
      "#Loss 164 =701.4997\n",
      "#Loss 165 =700.4548\n",
      "#Loss 166 =690.2531\n",
      "#Loss 167 =694.8399\n",
      "#Loss 168 =682.3478\n",
      "#Loss 169 =689.3818\n",
      "#Loss 170 =695.6312\n",
      "#Loss 171 =692.7594\n",
      "#Loss 172 =697.0379\n",
      "#Loss 173 =691.6401\n",
      "#Loss 174 =684.5549\n",
      "#Loss 175 =680.1648\n",
      "#Loss 176 =685.1313\n",
      "#Loss 177 =683.4910\n",
      "#Loss 178 =683.5127\n",
      "#Loss 179 =684.5343\n",
      "#Loss 180 =673.4902\n",
      "#Loss 181 =666.7154\n",
      "#Loss 182 =664.2424\n",
      "#Loss 183 =661.9311\n",
      "#Loss 184 =661.2404\n",
      "#Loss 185 =650.3765\n",
      "#Loss 186 =655.0509\n",
      "#Loss 187 =651.7246\n",
      "#Loss 188 =653.7269\n",
      "#Loss 189 =644.4558\n",
      "#Loss 190 =649.2426\n",
      "#Loss 191 =634.6122\n",
      "#Loss 192 =634.1561\n",
      "#Loss 193 =625.8281\n",
      "#Loss 194 =626.6905\n",
      "#Loss 195 =619.4470\n",
      "#Loss 196 =618.0882\n",
      "#Loss 197 =614.4104\n",
      "#Loss 198 =608.3381\n",
      "#Loss 199 =602.5966\n",
      "#Loss 200 =508.4819\n",
      "超过迭代上限\n",
      " 2 50 绝对误差 tensor(19.0302, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(11.6306, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0244, dtype=torch.float64)   实验回归误差 tensor(0.9999, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.0000, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 0   条件数 1.0\n",
      "Loss 0 =146.1182\n",
      "#Loss 1 =145.3307\n",
      "#Loss 2 =129.4152\n",
      "#Loss 3 =116.4326\n",
      "#Loss 4 =103.2897\n",
      "#Loss 5 =87.5358\n",
      "#Loss 6 =66.5213\n",
      "#Loss 7 =37.1345\n",
      "#Loss 8 =5.5604\n",
      "#Loss 9 =3.0046\n",
      "#Loss 10 =5.0655\n",
      "#Loss 11 =3.1338\n",
      "#Loss 12 =5.9779\n",
      "#Loss 13 =3.5055\n",
      "#Loss 14 =7.1562\n",
      "#Loss 15 =3.7201\n",
      "#Loss 16 =7.7722\n",
      "#Loss 17 =3.7593\n",
      "#Loss 18 =7.8808\n",
      "#Loss 19 =3.7613\n",
      "#Loss 20 =7.8852\n",
      "#Loss 21 =3.7608\n",
      "#Loss 22 =7.8838\n",
      "#Loss 23 =3.7607\n",
      "#Loss 24 =7.8832\n",
      "#Loss 25 =3.7606\n",
      "#Loss 26 =7.8831\n",
      "#Loss 27 =3.7606\n",
      "#Loss 28 =7.8830\n",
      "#Loss 29 =3.7606\n",
      "#Loss 30 =7.8830\n",
      "#Loss 31 =3.7606\n",
      "#Loss 32 =7.8830\n",
      "#Loss 33 =3.7606\n",
      "#Loss 34 =7.8830\n",
      "#Loss 35 =3.7606\n",
      "#Loss 36 =7.8830\n",
      "#Loss 37 =3.7606\n",
      "#Loss 38 =7.8830\n",
      "#Loss 39 =3.7606\n",
      "#Loss 40 =7.8830\n",
      "#Loss 41 =3.7606\n",
      "#Loss 42 =7.8830\n",
      "#Loss 43 =3.7606\n",
      "#Loss 44 =7.8830\n",
      "#Loss 45 =3.7606\n",
      "#Loss 46 =7.8830\n",
      "#Loss 47 =3.7606\n",
      "#Loss 48 =7.8830\n",
      "#Loss 49 =3.7606\n",
      "#Loss 50 =7.8830\n",
      "#Loss 51 =3.7606\n",
      "#Loss 52 =7.8830\n",
      "#Loss 53 =3.7606\n",
      "#Loss 54 =7.8830\n",
      "#Loss 55 =3.7606\n",
      "#Loss 56 =7.8830\n",
      "#Loss 57 =3.7606\n",
      "#Loss 58 =7.8830\n",
      "#Loss 59 =3.7606\n",
      "#Loss 60 =7.8830\n",
      "#Loss 61 =3.7606\n",
      "#Loss 62 =7.8830\n",
      "#Loss 63 =3.7606\n",
      "#Loss 64 =7.8830\n",
      "#Loss 65 =3.7606\n",
      "#Loss 66 =7.8830\n",
      "#Loss 67 =3.7606\n",
      "#Loss 68 =7.8830\n",
      "#Loss 69 =3.7606\n",
      "#Loss 70 =7.8830\n",
      "#Loss 71 =3.7606\n",
      "#Loss 72 =7.8830\n",
      "#Loss 73 =3.7606\n",
      "#Loss 74 =7.8830\n",
      "#Loss 75 =3.7606\n",
      "#Loss 76 =7.8830\n",
      "#Loss 77 =3.7606\n",
      "#Loss 78 =7.8830\n",
      "#Loss 79 =3.7606\n",
      "#Loss 80 =7.8830\n",
      "#Loss 81 =3.7606\n",
      "#Loss 82 =7.8830\n",
      "#Loss 83 =3.7606\n",
      "#Loss 84 =7.8830\n",
      "#Loss 85 =3.7606\n",
      "#Loss 86 =7.8830\n",
      "#Loss 87 =3.7606\n",
      "#Loss 88 =7.8830\n",
      "#Loss 89 =3.7606\n",
      "#Loss 90 =7.8830\n",
      "#Loss 91 =3.7606\n",
      "#Loss 92 =7.8830\n",
      "#Loss 93 =3.7606\n",
      "#Loss 94 =7.8830\n",
      "#Loss 95 =3.7606\n",
      "#Loss 96 =7.8830\n",
      "#Loss 97 =3.7606\n",
      "#Loss 98 =7.8830\n",
      "#Loss 99 =3.7606\n",
      "#Loss 100 =7.8830\n",
      "#Loss 101 =3.7606\n",
      "#Loss 102 =7.8830\n",
      "#Loss 103 =3.7606\n",
      "#Loss 104 =7.8830\n",
      "#Loss 105 =3.7606\n",
      "#Loss 106 =7.8830\n",
      "#Loss 107 =3.7606\n",
      "#Loss 108 =7.8830\n",
      "#Loss 109 =3.7606\n",
      "#Loss 110 =7.8830\n",
      "#Loss 111 =3.7606\n",
      "#Loss 112 =7.8830\n",
      "#Loss 113 =3.7606\n",
      "#Loss 114 =7.8830\n",
      "#Loss 115 =3.7606\n",
      "#Loss 116 =7.8830\n",
      "#Loss 117 =3.7606\n",
      "#Loss 118 =7.8830\n",
      "#Loss 119 =3.7606\n",
      "#Loss 120 =7.8830\n",
      "#Loss 121 =3.7606\n",
      "#Loss 122 =7.8830\n",
      "#Loss 123 =3.7606\n",
      "#Loss 124 =7.8830\n",
      "#Loss 125 =3.7606\n",
      "#Loss 126 =7.8830\n",
      "#Loss 127 =3.7606\n",
      "#Loss 128 =7.8830\n",
      "#Loss 129 =3.7606\n",
      "#Loss 130 =7.8830\n",
      "#Loss 131 =3.7606\n",
      "#Loss 132 =7.8830\n",
      "#Loss 133 =3.7606\n",
      "#Loss 134 =7.8830\n",
      "#Loss 135 =3.7606\n",
      "#Loss 136 =7.8830\n",
      "#Loss 137 =3.7606\n",
      "#Loss 138 =7.8830\n",
      "#Loss 139 =3.7606\n",
      "#Loss 140 =7.8830\n",
      "#Loss 141 =3.7606\n",
      "#Loss 142 =7.8830\n",
      "#Loss 143 =3.7606\n",
      "#Loss 144 =7.8830\n",
      "#Loss 145 =3.7606\n",
      "#Loss 146 =7.8830\n",
      "#Loss 147 =3.7606\n",
      "#Loss 148 =7.8830\n",
      "#Loss 149 =3.7606\n",
      "#Loss 150 =7.8830\n",
      "#Loss 151 =3.7606\n",
      "#Loss 152 =7.8830\n",
      "#Loss 153 =3.7606\n",
      "#Loss 154 =7.8830\n",
      "#Loss 155 =3.7606\n",
      "#Loss 156 =7.8830\n",
      "#Loss 157 =3.7606\n",
      "#Loss 158 =7.8830\n",
      "#Loss 159 =3.7606\n",
      "#Loss 160 =7.8830\n",
      "#Loss 161 =3.7606\n",
      "#Loss 162 =7.8830\n",
      "#Loss 163 =3.7606\n",
      "#Loss 164 =7.8830\n",
      "#Loss 165 =3.7606\n",
      "#Loss 166 =7.8830\n",
      "#Loss 167 =3.7606\n",
      "#Loss 168 =7.8830\n",
      "#Loss 169 =3.7606\n",
      "#Loss 170 =7.8830\n",
      "#Loss 171 =3.7606\n",
      "#Loss 172 =7.8830\n",
      "#Loss 173 =3.7606\n",
      "#Loss 174 =7.8830\n",
      "#Loss 175 =3.7606\n",
      "#Loss 176 =7.8830\n",
      "#Loss 177 =3.7606\n",
      "#Loss 178 =7.8830\n",
      "#Loss 179 =3.7606\n",
      "#Loss 180 =7.8830\n",
      "#Loss 181 =3.7606\n",
      "#Loss 182 =7.8830\n",
      "#Loss 183 =3.7606\n",
      "#Loss 184 =7.8830\n",
      "#Loss 185 =3.7606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 186 =7.8830\n",
      "#Loss 187 =3.7606\n",
      "#Loss 188 =7.8830\n",
      "#Loss 189 =3.7606\n",
      "#Loss 190 =7.8830\n",
      "#Loss 191 =3.7606\n",
      "#Loss 192 =7.8830\n",
      "#Loss 193 =3.7606\n",
      "#Loss 194 =7.8830\n",
      "#Loss 195 =3.7606\n",
      "#Loss 196 =7.8830\n",
      "#Loss 197 =3.7606\n",
      "#Loss 198 =7.8830\n",
      "#Loss 199 =3.7606\n",
      "#Loss 200 =7.8830\n",
      "超过迭代上限\n",
      " 2 50 绝对误差 tensor(0.0719, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(0.0825, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0598, dtype=torch.float64)   实验回归误差 tensor(0.1605, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.1832, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 50   条件数 1.0\n",
      "Loss 0 =16.6970\n",
      "#Loss 1 =16.6292\n",
      "#Loss 2 =13.8026\n",
      "#Loss 3 =11.5375\n",
      "#Loss 4 =9.7189\n",
      "#Loss 5 =8.2480\n",
      "#Loss 6 =7.0451\n",
      "#Loss 7 =6.0490\n",
      "#Loss 8 =5.2139\n",
      "#Loss 9 =4.5061\n",
      "#Loss 10 =3.9007\n",
      "#Loss 11 =3.3797\n",
      "#Loss 12 =2.9297\n",
      "#Loss 13 =2.5405\n",
      "#Loss 14 =2.2043\n",
      "#Loss 15 =1.9148\n",
      "#Loss 16 =1.6667\n",
      "#Loss 17 =1.4553\n",
      "#Loss 18 =1.2765\n",
      "#Loss 19 =1.1264\n",
      "#Loss 20 =1.0014\n",
      "#Loss 21 =0.8981\n",
      "#Loss 22 =0.8136\n",
      "#Loss 23 =0.7449\n",
      "#Loss 24 =0.6895\n",
      "#Loss 25 =0.6452\n",
      "#Loss 26 =0.6100\n",
      "#Loss 27 =0.5823\n",
      "#Loss 28 =0.5604\n",
      "#Loss 29 =0.5434\n",
      "#Loss 30 =0.5302\n",
      "#Loss 31 =0.5199\n",
      "#Loss 32 =0.5120\n",
      "#Loss 33 =0.5059\n",
      "#Loss 34 =0.5012\n",
      "#Loss 35 =0.4976\n",
      "#Loss 36 =0.4948\n",
      "#Loss 37 =0.4927\n",
      "#Loss 38 =0.4910\n",
      "#Loss 39 =0.4898\n",
      "#Loss 40 =0.4888\n",
      "#Loss 41 =0.4880\n",
      "#Loss 42 =0.4874\n",
      "#Loss 43 =0.4869\n",
      "#Loss 44 =0.4866\n",
      "#Loss 45 =0.4862\n",
      "#Loss 46 =0.4860\n",
      "#Loss 47 =0.4858\n",
      "#Loss 48 =0.4856\n",
      "#Loss 49 =0.4855\n",
      "#Loss 50 =0.4854\n",
      "#Loss 51 =0.4853\n",
      "#Loss 52 =0.4852\n",
      "#Loss 53 =0.4851\n",
      "#Loss 54 =0.4851\n",
      "#Loss 55 =0.4850\n",
      "#Loss 56 =0.4849\n",
      "#Loss 57 =0.4849\n",
      "#Loss 58 =0.4849\n",
      "#Loss 59 =0.4848\n",
      "#Loss 60 =0.4848\n",
      "#Loss 61 =0.4848\n",
      "#Loss 62 =0.4847\n",
      "#Loss 63 =0.4847\n",
      "#Loss 64 =0.4847\n",
      "#Loss 65 =0.4847\n",
      "#Loss 66 =0.4846\n",
      "#Loss 67 =0.4846\n",
      "#Loss 68 =0.4846\n",
      "#Loss 69 =0.4846\n",
      "#Loss 70 =0.4846\n",
      " 2 50 绝对误差 tensor(1.2153, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(1.8747, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.1886, dtype=torch.float64)   实验回归误差 tensor(0.1704, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.4000, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 50   条件数 1.0\n",
      "Loss 0 =0.4727\n",
      "#Loss 1 =0.4727\n",
      " 2 50 绝对误差 tensor(0.1306, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(0.9860, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.9816, dtype=torch.float64)   实验回归误差 tensor(0.9152, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.0311, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 1   条件数 1.0\n",
      "Loss 0 =557.6519\n",
      "#Loss 1 =554.7020\n",
      "#Loss 2 =503.4958\n",
      "#Loss 3 =457.7065\n",
      "#Loss 4 =398.0333\n",
      "#Loss 5 =294.4416\n",
      "#Loss 6 =69.7159\n",
      "#Loss 7 =724.0224\n",
      "#Loss 8 =558.2788\n",
      "#Loss 9 =558.0191\n",
      "#Loss 10 =558.3456\n",
      "#Loss 11 =557.9740\n",
      "#Loss 12 =557.4281\n",
      "#Loss 13 =557.3592\n",
      "#Loss 14 =557.5130\n",
      "#Loss 15 =557.2342\n",
      "#Loss 16 =557.2049\n",
      "#Loss 17 =557.3004\n",
      "#Loss 18 =557.1492\n",
      "#Loss 19 =557.2176\n",
      "#Loss 20 =557.1185\n",
      "#Loss 21 =557.0877\n",
      "#Loss 22 =557.1103\n",
      "#Loss 23 =557.1054\n",
      " 2 50 绝对误差 tensor(5.9548, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(4.1952, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0273, dtype=torch.float64)   实验回归误差 tensor(1.0000, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.0000, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 0   条件数 1.0\n",
      "Loss 0 =21.1550\n",
      "#Loss 1 =21.1456\n",
      "#Loss 2 =18.3962\n",
      "#Loss 3 =16.0370\n",
      "#Loss 4 =14.0230\n",
      "#Loss 5 =12.3077\n",
      "#Loss 6 =10.8469\n",
      "#Loss 7 =9.6007\n",
      "#Loss 8 =8.5345\n",
      "#Loss 9 =7.6189\n",
      "#Loss 10 =6.8294\n",
      "#Loss 11 =6.1455\n",
      "#Loss 12 =5.5506\n",
      "#Loss 13 =5.0309\n",
      "#Loss 14 =4.5749\n",
      "#Loss 15 =4.1732\n",
      "#Loss 16 =3.8182\n",
      "#Loss 17 =3.5033\n",
      "#Loss 18 =3.2232\n",
      "#Loss 19 =2.9733\n",
      "#Loss 20 =2.7498\n",
      "#Loss 21 =2.5494\n",
      "#Loss 22 =2.3694\n",
      "#Loss 23 =2.2073\n",
      "#Loss 24 =2.0612\n",
      "#Loss 25 =1.9292\n",
      "#Loss 26 =1.8098\n",
      "#Loss 27 =1.7015\n",
      "#Loss 28 =1.6033\n",
      "#Loss 29 =1.5141\n",
      "#Loss 30 =1.4329\n",
      "#Loss 31 =1.3589\n",
      "#Loss 32 =1.2913\n",
      "#Loss 33 =1.2296\n",
      "#Loss 34 =1.1731\n",
      "#Loss 35 =1.1213\n",
      "#Loss 36 =1.0738\n",
      "#Loss 37 =1.0301\n",
      "#Loss 38 =0.9899\n",
      "#Loss 39 =0.9528\n",
      "#Loss 40 =0.9186\n",
      "#Loss 41 =0.8869\n",
      "#Loss 42 =0.8576\n",
      "#Loss 43 =0.8304\n",
      "#Loss 44 =0.8051\n",
      "#Loss 45 =0.7816\n",
      "#Loss 46 =0.7597\n",
      "#Loss 47 =0.7393\n",
      "#Loss 48 =0.7202\n",
      "#Loss 49 =0.7023\n",
      "#Loss 50 =0.6856\n",
      "#Loss 51 =0.6699\n",
      "#Loss 52 =0.6551\n",
      "#Loss 53 =0.6413\n",
      "#Loss 54 =0.6282\n",
      "#Loss 55 =0.6159\n",
      "#Loss 56 =0.6042\n",
      "#Loss 57 =0.5932\n",
      "#Loss 58 =0.5828\n",
      "#Loss 59 =0.5730\n",
      "#Loss 60 =0.5637\n",
      "#Loss 61 =0.5548\n",
      "#Loss 62 =0.5464\n",
      "#Loss 63 =0.5385\n",
      "#Loss 64 =0.5309\n",
      "#Loss 65 =0.5237\n",
      "#Loss 66 =0.5168\n",
      "#Loss 67 =0.5103\n",
      "#Loss 68 =0.5041\n",
      "#Loss 69 =0.4981\n",
      "#Loss 70 =0.4925\n",
      "#Loss 71 =0.4870\n",
      "#Loss 72 =0.4819\n",
      "#Loss 73 =0.4770\n",
      "#Loss 74 =0.4722\n",
      "#Loss 75 =0.4677\n",
      "#Loss 76 =0.4634\n",
      "#Loss 77 =0.4593\n",
      "#Loss 78 =0.4554\n",
      "#Loss 79 =0.4516\n",
      "#Loss 80 =0.4480\n",
      "#Loss 81 =0.4445\n",
      "#Loss 82 =0.4412\n",
      "#Loss 83 =0.4380\n",
      "#Loss 84 =0.4350\n",
      "#Loss 85 =0.4317\n",
      "#Loss 86 =0.4286\n",
      "#Loss 87 =0.4257\n",
      "#Loss 88 =0.4228\n",
      "#Loss 89 =0.4201\n",
      "#Loss 90 =0.4174\n",
      "#Loss 91 =0.4149\n",
      "#Loss 92 =0.4125\n",
      "#Loss 93 =0.4102\n",
      "#Loss 94 =0.4079\n",
      "#Loss 95 =0.4058\n",
      "#Loss 96 =0.4037\n",
      "#Loss 97 =0.4017\n",
      "#Loss 98 =0.3998\n",
      "#Loss 99 =0.3980\n",
      "#Loss 100 =0.3961\n",
      "#Loss 101 =0.3944\n",
      "#Loss 102 =0.3927\n",
      "#Loss 103 =0.3911\n",
      "#Loss 104 =0.3895\n",
      "#Loss 105 =0.3880\n",
      "#Loss 106 =0.3865\n",
      "#Loss 107 =0.3851\n",
      "#Loss 108 =0.3838\n",
      "#Loss 109 =0.3825\n",
      "#Loss 110 =0.3812\n",
      "#Loss 111 =0.3800\n",
      "#Loss 112 =0.3789\n",
      "#Loss 113 =0.3778\n",
      "#Loss 114 =0.3767\n",
      "#Loss 115 =0.3757\n",
      "#Loss 116 =0.3747\n",
      "#Loss 117 =0.3737\n",
      "#Loss 118 =0.3728\n",
      "#Loss 119 =0.3719\n",
      "#Loss 120 =0.3710\n",
      "#Loss 121 =0.3702\n",
      "#Loss 122 =0.3694\n",
      "#Loss 123 =0.3687\n",
      "#Loss 124 =0.3679\n",
      "#Loss 125 =0.3672\n",
      "#Loss 126 =0.3665\n",
      "#Loss 127 =0.3659\n",
      "#Loss 128 =0.3652\n",
      "#Loss 129 =0.3646\n",
      "#Loss 130 =0.3640\n",
      "#Loss 131 =0.3634\n",
      "#Loss 132 =0.3629\n",
      "#Loss 133 =0.3624\n",
      "#Loss 134 =0.3618\n",
      "#Loss 135 =0.3613\n",
      "#Loss 136 =0.3609\n",
      "#Loss 137 =0.3604\n",
      "#Loss 138 =0.3600\n",
      "#Loss 139 =0.3595\n",
      "#Loss 140 =0.3591\n",
      "#Loss 141 =0.3587\n",
      "#Loss 142 =0.3583\n",
      "#Loss 143 =0.3580\n",
      "#Loss 144 =0.3576\n",
      "#Loss 145 =0.3573\n",
      "#Loss 146 =0.3569\n",
      "#Loss 147 =0.3566\n",
      "#Loss 148 =0.3563\n",
      "#Loss 149 =0.3560\n",
      "#Loss 150 =0.3557\n",
      "#Loss 151 =0.3554\n",
      "#Loss 152 =0.3552\n",
      "#Loss 153 =0.3549\n",
      "#Loss 154 =0.3547\n",
      "#Loss 155 =0.3544\n",
      "#Loss 156 =0.3542\n",
      "#Loss 157 =0.3540\n",
      "#Loss 158 =0.3537\n",
      "#Loss 159 =0.3535\n",
      "#Loss 160 =0.3533\n",
      "#Loss 161 =0.3531\n",
      "#Loss 162 =0.3529\n",
      "#Loss 163 =0.3528\n",
      "#Loss 164 =0.3526\n",
      "#Loss 165 =0.3524\n",
      "#Loss 166 =0.3522\n",
      "#Loss 167 =0.3520\n",
      "#Loss 168 =0.3519\n",
      "#Loss 169 =0.3517\n",
      "#Loss 170 =0.3515\n",
      "#Loss 171 =0.3514\n",
      "#Loss 172 =0.3512\n",
      "#Loss 173 =0.3511\n",
      "#Loss 174 =0.3510\n",
      "#Loss 175 =0.3508\n",
      "#Loss 176 =0.3507\n",
      "#Loss 177 =0.3506\n",
      "#Loss 178 =0.3505\n",
      "#Loss 179 =0.3503\n",
      "#Loss 180 =0.3502\n",
      "#Loss 181 =0.3501\n",
      "#Loss 182 =0.3500\n",
      "#Loss 183 =0.3499\n",
      "#Loss 184 =0.3498\n",
      "#Loss 185 =0.3497\n",
      "#Loss 186 =0.3496\n",
      "#Loss 187 =0.3495\n",
      "#Loss 188 =0.3494\n",
      "#Loss 189 =0.3493\n",
      "#Loss 190 =0.3492\n",
      "#Loss 191 =0.3492\n",
      "#Loss 192 =0.3491\n",
      "#Loss 193 =0.3490\n",
      "#Loss 194 =0.3489\n",
      "#Loss 195 =0.3489\n",
      "#Loss 196 =0.3488\n",
      "#Loss 197 =0.3487\n",
      "#Loss 198 =0.3487\n",
      "#Loss 199 =0.3486\n",
      "#Loss 200 =0.3485\n",
      "超过迭代上限\n",
      " 2 50 绝对误差 tensor(1.9742, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(1.9585, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.1540, dtype=torch.float64)   实验回归误差 tensor(0.1283, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.4142, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 50   条件数 1.0\n",
      "Loss 0 =31.3074\n",
      "#Loss 1 =31.1252\n",
      "#Loss 2 =28.1875\n",
      "#Loss 3 =25.7568\n",
      "#Loss 4 =23.7197\n",
      "#Loss 5 =21.9797\n",
      "#Loss 6 =20.4616\n",
      "#Loss 7 =19.1104\n",
      "#Loss 8 =17.8878\n",
      "#Loss 9 =16.7686\n",
      "#Loss 10 =15.7370\n",
      "#Loss 11 =14.7836\n",
      "#Loss 12 =13.9034\n",
      "#Loss 13 =13.0940\n",
      "#Loss 14 =12.3544\n",
      "#Loss 15 =11.6842\n",
      "#Loss 16 =11.0826\n",
      "#Loss 17 =10.5484\n",
      "#Loss 18 =10.0792\n",
      "#Loss 19 =9.6714\n",
      "#Loss 20 =9.3202\n",
      "#Loss 21 =9.0199\n",
      "#Loss 22 =8.7637\n",
      "#Loss 23 =8.5435\n",
      "#Loss 24 =8.3543\n",
      "#Loss 25 =8.1908\n",
      "#Loss 26 =8.0477\n",
      "#Loss 27 =7.9204\n",
      "#Loss 28 =7.8053\n",
      "#Loss 29 =7.6997\n",
      "#Loss 30 =7.6017\n",
      "#Loss 31 =7.5097\n",
      "#Loss 32 =7.4229\n",
      "#Loss 33 =7.3404\n",
      "#Loss 34 =7.2618\n",
      "#Loss 35 =7.1866\n",
      "#Loss 36 =7.1147\n",
      "#Loss 37 =7.0456\n",
      "#Loss 38 =6.9794\n",
      "#Loss 39 =6.9157\n",
      "#Loss 40 =6.8545\n",
      "#Loss 41 =6.7955\n",
      "#Loss 42 =6.7387\n",
      "#Loss 43 =6.6840\n",
      "#Loss 44 =6.6313\n",
      "#Loss 45 =6.5804\n",
      "#Loss 46 =6.5313\n",
      "#Loss 47 =6.4838\n",
      "#Loss 48 =6.4379\n",
      "#Loss 49 =6.3935\n",
      "#Loss 50 =6.3506\n",
      "#Loss 51 =6.3090\n",
      "#Loss 52 =6.2688\n",
      "#Loss 53 =6.2297\n",
      "#Loss 54 =6.1919\n",
      "#Loss 55 =6.1552\n",
      "#Loss 56 =6.1195\n",
      "#Loss 57 =6.0849\n",
      "#Loss 58 =6.0513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 59 =6.0186\n",
      "#Loss 60 =5.9868\n",
      "#Loss 61 =5.9559\n",
      "#Loss 62 =5.9259\n",
      "#Loss 63 =5.8966\n",
      "#Loss 64 =5.8680\n",
      "#Loss 65 =5.8402\n",
      "#Loss 66 =5.8132\n",
      "#Loss 67 =5.7868\n",
      "#Loss 68 =5.7610\n",
      "#Loss 69 =5.7359\n",
      "#Loss 70 =5.7114\n",
      "#Loss 71 =5.6875\n",
      "#Loss 72 =5.6641\n",
      "#Loss 73 =5.6413\n",
      "#Loss 74 =5.6190\n",
      "#Loss 75 =5.5971\n",
      "#Loss 76 =5.5758\n",
      "#Loss 77 =5.5550\n",
      "#Loss 78 =5.5346\n",
      "#Loss 79 =5.5146\n",
      "#Loss 80 =5.4951\n",
      "#Loss 81 =5.4760\n",
      "#Loss 82 =5.4573\n",
      "#Loss 83 =5.4390\n",
      "#Loss 84 =5.4211\n",
      "#Loss 85 =5.4035\n",
      "#Loss 86 =5.3863\n",
      "#Loss 87 =5.3694\n",
      "#Loss 88 =5.3528\n",
      "#Loss 89 =5.3366\n",
      "#Loss 90 =5.3206\n",
      "#Loss 91 =5.3050\n",
      "#Loss 92 =5.2897\n",
      "#Loss 93 =5.2747\n",
      "#Loss 94 =5.2599\n",
      "#Loss 95 =5.2454\n",
      "#Loss 96 =5.2312\n",
      "#Loss 97 =5.2173\n",
      "#Loss 98 =5.2036\n",
      "#Loss 99 =5.1901\n",
      "#Loss 100 =5.1769\n",
      "#Loss 101 =5.1639\n",
      "#Loss 102 =5.1512\n",
      "#Loss 103 =5.1386\n",
      "#Loss 104 =5.1263\n",
      "#Loss 105 =5.1142\n",
      "#Loss 106 =5.1023\n",
      "#Loss 107 =5.0906\n",
      "#Loss 108 =5.0791\n",
      "#Loss 109 =5.0677\n",
      "#Loss 110 =5.0566\n",
      "#Loss 111 =5.0456\n",
      "#Loss 112 =5.0348\n",
      "#Loss 113 =5.0242\n",
      "#Loss 114 =5.0138\n",
      "#Loss 115 =5.0035\n",
      "#Loss 116 =4.9934\n",
      "#Loss 117 =4.9834\n",
      "#Loss 118 =4.9736\n",
      "#Loss 119 =4.9639\n",
      "#Loss 120 =4.9544\n",
      "#Loss 121 =4.9450\n",
      "#Loss 122 =4.9357\n",
      "#Loss 123 =4.9266\n",
      "#Loss 124 =4.9177\n",
      "#Loss 125 =4.9088\n",
      "#Loss 126 =4.9001\n",
      "#Loss 127 =4.8916\n",
      "#Loss 128 =4.8831\n",
      "#Loss 129 =4.8748\n",
      "#Loss 130 =4.8666\n",
      "#Loss 131 =4.8585\n",
      "#Loss 132 =4.8505\n",
      "#Loss 133 =4.8426\n",
      "#Loss 134 =4.8348\n",
      "#Loss 135 =4.8272\n",
      "#Loss 136 =4.8196\n",
      "#Loss 137 =4.8122\n",
      "#Loss 138 =4.8048\n",
      "#Loss 139 =4.7976\n",
      "#Loss 140 =4.7904\n",
      "#Loss 141 =4.7834\n",
      "#Loss 142 =4.7764\n",
      "#Loss 143 =4.7696\n",
      "#Loss 144 =4.7628\n",
      "#Loss 145 =4.7561\n",
      "#Loss 146 =4.7495\n",
      "#Loss 147 =4.7430\n",
      "#Loss 148 =4.7365\n",
      "#Loss 149 =4.7302\n",
      "#Loss 150 =4.7239\n",
      "#Loss 151 =4.7177\n",
      "#Loss 152 =4.7116\n",
      "#Loss 153 =4.7056\n",
      "#Loss 154 =4.6996\n",
      "#Loss 155 =4.6937\n",
      "#Loss 156 =4.6879\n",
      "#Loss 157 =4.6822\n",
      "#Loss 158 =4.6764\n",
      "#Loss 159 =4.6708\n",
      "#Loss 160 =4.6652\n",
      "#Loss 161 =4.6597\n",
      "#Loss 162 =4.6543\n",
      "#Loss 163 =4.6489\n",
      "#Loss 164 =4.6436\n",
      "#Loss 165 =4.6384\n",
      "#Loss 166 =4.6332\n",
      "#Loss 167 =4.6281\n",
      "#Loss 168 =4.6230\n",
      "#Loss 169 =4.6180\n",
      "#Loss 170 =4.6131\n",
      "#Loss 171 =4.6082\n",
      "#Loss 172 =4.6034\n",
      "#Loss 173 =4.5986\n",
      "#Loss 174 =4.5939\n",
      "#Loss 175 =4.5893\n",
      "#Loss 176 =4.5847\n",
      "#Loss 177 =4.5801\n",
      "#Loss 178 =4.5756\n",
      "#Loss 179 =4.5712\n",
      "#Loss 180 =4.5668\n",
      "#Loss 181 =4.5624\n",
      "#Loss 182 =4.5581\n",
      "#Loss 183 =4.5539\n",
      "#Loss 184 =4.5497\n",
      "#Loss 185 =4.5455\n",
      "#Loss 186 =4.5414\n",
      "#Loss 187 =4.5373\n",
      "#Loss 188 =4.5333\n",
      "#Loss 189 =4.5293\n",
      "#Loss 190 =4.5254\n",
      "#Loss 191 =4.5215\n",
      "#Loss 192 =4.5177\n",
      "#Loss 193 =4.5138\n",
      "#Loss 194 =4.5101\n",
      "#Loss 195 =4.5064\n",
      "#Loss 196 =4.5027\n",
      "#Loss 197 =4.4990\n",
      "#Loss 198 =4.4954\n",
      "#Loss 199 =4.4918\n",
      "#Loss 200 =4.4883\n",
      "超过迭代上限\n",
      " 2 50 绝对误差 tensor(1.7661, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(2.1226, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.1489, dtype=torch.float64)   实验回归误差 tensor(0.3785, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.4142, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 50   条件数 1.0\n",
      "Loss 0 =502.9707\n",
      "#Loss 1 =499.4847\n",
      "#Loss 2 =466.5626\n",
      "#Loss 3 =437.3829\n",
      "#Loss 4 =402.7899\n",
      "#Loss 5 =351.7335\n",
      "#Loss 6 =262.5232\n",
      "#Loss 7 =123.1613\n",
      "#Loss 8 =109.2731\n",
      "#Loss 9 =413.2198\n",
      "#Loss 10 =177.5870\n",
      "#Loss 11 =104.2173\n",
      "#Loss 12 =260.5382\n",
      "#Loss 13 =247.0431\n",
      "#Loss 14 =391.8226\n",
      "#Loss 15 =343.7713\n",
      "#Loss 16 =253.7904\n",
      "#Loss 17 =116.5701\n",
      "#Loss 18 =93.3173\n",
      "#Loss 19 =325.3886\n",
      "#Loss 20 =233.3034\n",
      "#Loss 21 =209.1455\n",
      "#Loss 22 =110.0504\n",
      "#Loss 23 =181.2282\n",
      "#Loss 24 =426.1745\n",
      "#Loss 25 =898.6862\n",
      "#Loss 26 =613.1536\n",
      "#Loss 27 =465.5934\n",
      "#Loss 28 =451.1195\n",
      "#Loss 29 =436.9411\n",
      "#Loss 30 =419.9726\n",
      "#Loss 31 =386.0218\n",
      "#Loss 32 =320.9704\n",
      "#Loss 33 =161.3370\n",
      "#Loss 34 =203.4068\n",
      "#Loss 35 =907.6186\n",
      "#Loss 36 =273.4698\n",
      "#Loss 37 =47.6744\n",
      "#Loss 38 =838.6203\n",
      "#Loss 39 =512.3449\n",
      "#Loss 40 =508.9844\n",
      "#Loss 41 =504.6102\n",
      "#Loss 42 =510.6648\n",
      "#Loss 43 =508.6802\n",
      "#Loss 44 =504.1383\n",
      "#Loss 45 =503.7035\n",
      "#Loss 46 =506.1175\n",
      "#Loss 47 =504.0516\n",
      "#Loss 48 =509.5124\n",
      "#Loss 49 =505.2963\n",
      "#Loss 50 =505.0253\n",
      "#Loss 51 =505.0866\n",
      "#Loss 52 =508.0374\n",
      "#Loss 53 =504.4423\n",
      "#Loss 54 =507.1724\n",
      "#Loss 55 =506.5789\n",
      "#Loss 56 =504.1524\n",
      "#Loss 57 =506.2145\n",
      "#Loss 58 =505.6190\n",
      "#Loss 59 =505.8615\n",
      "#Loss 60 =504.6173\n",
      "#Loss 61 =508.7506\n",
      "#Loss 62 =509.6434\n",
      "#Loss 63 =505.1545\n",
      "#Loss 64 =508.2772\n",
      "#Loss 65 =506.5126\n",
      "#Loss 66 =503.7068\n",
      "#Loss 67 =505.4077\n",
      "#Loss 68 =505.3882\n",
      "#Loss 69 =505.2120\n",
      "#Loss 70 =504.7470\n",
      "#Loss 71 =508.3349\n",
      "#Loss 72 =507.6286\n",
      "#Loss 73 =503.9756\n",
      "#Loss 74 =504.0443\n",
      "#Loss 75 =503.9351\n",
      "#Loss 76 =506.4018\n",
      "#Loss 77 =509.7943\n",
      "#Loss 78 =510.5707\n",
      "#Loss 79 =509.3405\n",
      "#Loss 80 =506.4150\n",
      "#Loss 81 =507.4571\n",
      "#Loss 82 =505.0009\n",
      "#Loss 83 =505.1243\n",
      "#Loss 84 =508.1829\n",
      "#Loss 85 =507.4657\n",
      "#Loss 86 =506.7451\n",
      "#Loss 87 =503.6245\n",
      "#Loss 88 =503.6397\n",
      "#Loss 89 =503.9004\n",
      "#Loss 95 =504.7098\n",
      "#Loss 96 =503.0333\n",
      "#Loss 97 =502.6783\n",
      "#Loss 98 =502.9405\n",
      "#Loss 99 =504.1861\n",
      "#Loss 100 =503.0073\n",
      "#Loss 101 =508.1813\n",
      "#Loss 102 =502.8292\n",
      "#Loss 103 =505.8538\n",
      "#Loss 104 =82921867.1382\n",
      "#Loss 105 =nan\n",
      " 2 50 绝对误差 tensor(nan, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(nan, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0339, dtype=torch.float64)   实验回归误差 tensor(nan, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.0000, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 0   条件数 1.0\n",
      "Loss 0 =21.7799\n",
      "#Loss 1 =21.5914\n",
      "#Loss 2 =17.8420\n",
      "#Loss 3 =14.8410\n",
      "#Loss 4 =12.4582\n",
      "#Loss 5 =10.5653\n",
      "#Loss 6 =9.0529\n",
      "#Loss 7 =7.8336\n",
      "#Loss 8 =6.8408\n",
      "#Loss 9 =6.0242\n",
      "#Loss 10 =5.3458\n",
      "#Loss 11 =4.7773\n",
      "#Loss 12 =4.2971\n",
      "#Loss 13 =3.8886\n",
      "#Loss 14 =3.5390\n",
      "#Loss 15 =3.2381\n",
      "#Loss 16 =2.9779\n",
      "#Loss 17 =2.7517\n",
      "#Loss 18 =2.5544\n",
      "#Loss 19 =2.3814\n",
      "#Loss 20 =2.2293\n",
      "#Loss 21 =2.0949\n",
      "#Loss 22 =1.9758\n",
      "#Loss 23 =1.8697\n",
      "#Loss 24 =1.7750\n",
      "#Loss 25 =1.6900\n",
      "#Loss 26 =1.6136\n",
      "#Loss 27 =1.5445\n",
      "#Loss 28 =1.4819\n",
      "#Loss 29 =1.4246\n",
      "#Loss 30 =1.3718\n",
      "#Loss 31 =1.3234\n",
      "#Loss 32 =1.2789\n",
      "#Loss 33 =1.2379\n",
      "#Loss 34 =1.2001\n",
      "#Loss 35 =1.1650\n",
      "#Loss 36 =1.1325\n",
      "#Loss 37 =1.1022\n",
      "#Loss 38 =1.0732\n",
      "#Loss 39 =1.0453\n",
      "#Loss 40 =1.0192\n",
      "#Loss 41 =0.9947\n",
      "#Loss 42 =0.9717\n",
      "#Loss 43 =0.9501\n",
      "#Loss 44 =0.9297\n",
      "#Loss 45 =0.9106\n",
      "#Loss 46 =0.8922\n",
      "#Loss 47 =0.8740\n",
      "#Loss 48 =0.8568\n",
      "#Loss 49 =0.8394\n",
      "#Loss 50 =0.8198\n",
      "#Loss 51 =0.8012\n",
      "#Loss 52 =0.7832\n",
      "#Loss 53 =0.7651\n",
      "#Loss 54 =0.7480\n",
      "#Loss 55 =0.7317\n",
      "#Loss 56 =0.7161\n",
      "#Loss 57 =0.7014\n",
      "#Loss 58 =0.6873\n",
      "#Loss 59 =0.6739\n",
      "#Loss 60 =0.6610\n",
      "#Loss 61 =0.6488\n",
      "#Loss 62 =0.6371\n",
      "#Loss 63 =0.6260\n",
      "#Loss 64 =0.6153\n",
      "#Loss 65 =0.6051\n",
      "#Loss 66 =0.5954\n",
      "#Loss 67 =0.5861\n",
      "#Loss 68 =0.5772\n",
      "#Loss 69 =0.5686\n",
      "#Loss 70 =0.5605\n",
      "#Loss 71 =0.5527\n",
      "#Loss 72 =0.5452\n",
      "#Loss 73 =0.5381\n",
      "#Loss 74 =0.5313\n",
      "#Loss 75 =0.5247\n",
      "#Loss 76 =0.5185\n",
      "#Loss 77 =0.5125\n",
      "#Loss 78 =0.5062\n",
      "#Loss 79 =0.5002\n",
      "#Loss 80 =0.4944\n",
      "#Loss 81 =0.4887\n",
      "#Loss 82 =0.4833\n",
      "#Loss 83 =0.4781\n",
      "#Loss 84 =0.4730\n",
      "#Loss 85 =0.4681\n",
      "#Loss 86 =0.4634\n",
      "#Loss 87 =0.4590\n",
      "#Loss 88 =0.4539\n",
      "#Loss 89 =0.4466\n",
      "#Loss 90 =0.4395\n",
      "#Loss 91 =0.4328\n",
      "#Loss 92 =0.4263\n",
      "#Loss 93 =0.4202\n",
      "#Loss 94 =0.4143\n",
      "#Loss 95 =0.4087\n",
      "#Loss 96 =0.4033\n",
      "#Loss 97 =0.3980\n",
      "#Loss 98 =0.3928\n",
      "#Loss 99 =0.3878\n",
      "#Loss 100 =0.3830\n",
      "#Loss 101 =0.3783\n",
      "#Loss 102 =0.3739\n",
      "#Loss 103 =0.3697\n",
      "#Loss 104 =0.3657\n",
      "#Loss 105 =0.3618\n",
      "#Loss 106 =0.3580\n",
      "#Loss 107 =0.3544\n",
      "#Loss 108 =0.3509\n",
      "#Loss 109 =0.3475\n",
      "#Loss 110 =0.3440\n",
      "#Loss 111 =0.3407\n",
      "#Loss 112 =0.3375\n",
      "#Loss 113 =0.3345\n",
      "#Loss 114 =0.3316\n",
      "#Loss 115 =0.3286\n",
      "#Loss 116 =0.3258\n",
      "#Loss 117 =0.3230\n",
      "#Loss 118 =0.3204\n",
      "#Loss 119 =0.3179\n",
      "#Loss 120 =0.3153\n",
      "#Loss 121 =0.3128\n",
      "#Loss 122 =0.3104\n",
      "#Loss 123 =0.3082\n",
      "#Loss 124 =0.3060\n",
      "#Loss 125 =0.3039\n",
      "#Loss 126 =0.3019\n",
      "#Loss 127 =0.3000\n",
      "#Loss 128 =0.2982\n",
      "#Loss 129 =0.2965\n",
      "#Loss 130 =0.2949\n",
      "#Loss 131 =0.2932\n",
      "#Loss 132 =0.2912\n",
      "#Loss 133 =0.2885\n",
      "#Loss 134 =0.2858\n",
      "#Loss 135 =0.2833\n",
      "#Loss 136 =0.2809\n",
      "#Loss 137 =0.2785\n",
      "#Loss 138 =0.2763\n",
      "#Loss 139 =0.2742\n",
      "#Loss 140 =0.2719\n",
      "#Loss 141 =0.2697\n",
      "#Loss 142 =0.2677\n",
      "#Loss 143 =0.2657\n",
      "#Loss 144 =0.2638\n",
      "#Loss 145 =0.2620\n",
      "#Loss 146 =0.2603\n",
      "#Loss 147 =0.2586\n",
      "#Loss 148 =0.2570\n",
      "#Loss 149 =0.2556\n",
      "#Loss 150 =0.2541\n",
      "#Loss 151 =0.2528\n",
      "#Loss 152 =0.2515\n",
      "#Loss 153 =0.2502\n",
      "#Loss 154 =0.2490\n",
      "#Loss 155 =0.2478\n",
      "#Loss 156 =0.2468\n",
      "#Loss 157 =0.2457\n",
      "#Loss 158 =0.2447\n",
      "#Loss 159 =0.2438\n",
      "#Loss 160 =0.2429\n",
      "#Loss 161 =0.2420\n",
      "#Loss 162 =0.2412\n",
      "#Loss 163 =0.2405\n",
      "#Loss 164 =0.2397\n",
      "#Loss 165 =0.2390\n",
      "#Loss 166 =0.2384\n",
      "#Loss 167 =0.2377\n",
      "#Loss 168 =0.2371\n",
      "#Loss 169 =0.2365\n",
      "#Loss 170 =0.2359\n",
      "#Loss 171 =0.2354\n",
      "#Loss 172 =0.2349\n",
      "#Loss 173 =0.2344\n",
      "#Loss 174 =0.2339\n",
      "#Loss 175 =0.2335\n",
      "#Loss 176 =0.2331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 177 =0.2327\n",
      "#Loss 178 =0.2323\n",
      "#Loss 179 =0.2320\n",
      "#Loss 180 =0.2316\n",
      "#Loss 181 =0.2313\n",
      "#Loss 182 =0.2310\n",
      "#Loss 183 =0.2307\n",
      "#Loss 184 =0.2304\n",
      "#Loss 185 =0.2302\n",
      "#Loss 186 =0.2299\n",
      "#Loss 187 =0.2297\n",
      "#Loss 188 =0.2295\n",
      "#Loss 189 =0.2293\n",
      "#Loss 190 =0.2291\n",
      "#Loss 191 =0.2289\n",
      "#Loss 192 =0.2287\n",
      "#Loss 193 =0.2284\n",
      "#Loss 194 =0.2282\n",
      "#Loss 195 =0.2279\n",
      "#Loss 196 =0.2277\n",
      "#Loss 197 =0.2274\n",
      "#Loss 198 =0.2272\n",
      "#Loss 199 =0.2270\n",
      "#Loss 200 =0.2268\n",
      "超过迭代上限\n",
      " 2 50 绝对误差 tensor(0.4000, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(0.2847, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.1468, dtype=torch.float64)   实验回归误差 tensor(0.1020, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.3416, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 50   条件数 1.0\n",
      "Loss 0 =34.2318\n",
      "#Loss 1 =33.8911\n",
      "#Loss 2 =29.0144\n",
      "#Loss 3 =24.9364\n",
      "#Loss 4 =21.5139\n",
      "#Loss 5 =18.6194\n",
      "#Loss 6 =16.1461\n",
      "#Loss 7 =14.0098\n",
      "#Loss 8 =12.1457\n",
      "#Loss 9 =10.5060\n",
      "#Loss 10 =9.0558\n",
      "#Loss 11 =7.7702\n",
      "#Loss 12 =6.6312\n",
      "#Loss 13 =5.6255\n",
      "#Loss 14 =4.7429\n",
      "#Loss 15 =3.9744\n",
      "#Loss 16 =3.3119\n",
      "#Loss 17 =2.7472\n",
      "#Loss 18 =2.2716\n",
      "#Loss 19 =1.8760\n",
      "#Loss 20 =1.5512\n",
      "#Loss 21 =1.2877\n",
      "#Loss 22 =1.0764\n",
      "#Loss 23 =0.9088\n",
      "#Loss 24 =0.7770\n",
      "#Loss 25 =0.6741\n",
      "#Loss 26 =0.5942\n",
      "#Loss 27 =0.5322\n",
      "#Loss 28 =0.4841\n",
      "#Loss 29 =0.4468\n",
      "#Loss 30 =0.4175\n",
      "#Loss 31 =0.3943\n",
      "#Loss 32 =0.3757\n",
      "#Loss 33 =0.3606\n",
      "#Loss 34 =0.3480\n",
      "#Loss 35 =0.3374\n",
      "#Loss 36 =0.3283\n",
      "#Loss 37 =0.3204\n",
      "#Loss 38 =0.3133\n",
      "#Loss 39 =0.3069\n",
      "#Loss 40 =0.3010\n",
      "#Loss 41 =0.2956\n",
      "#Loss 42 =0.2906\n",
      "#Loss 43 =0.2859\n",
      "#Loss 44 =0.2815\n",
      "#Loss 45 =0.2774\n",
      "#Loss 46 =0.2735\n",
      "#Loss 47 =0.2698\n",
      "#Loss 48 =0.2664\n",
      "#Loss 49 =0.2631\n",
      "#Loss 50 =0.2599\n",
      "#Loss 51 =0.2569\n",
      "#Loss 52 =0.2541\n",
      "#Loss 53 =0.2514\n",
      "#Loss 54 =0.2489\n",
      "#Loss 55 =0.2464\n",
      "#Loss 56 =0.2441\n",
      "#Loss 57 =0.2419\n",
      "#Loss 58 =0.2398\n",
      "#Loss 59 =0.2378\n",
      "#Loss 60 =0.2359\n",
      "#Loss 61 =0.2341\n",
      "#Loss 62 =0.2324\n",
      "#Loss 63 =0.2308\n",
      "#Loss 64 =0.2292\n",
      "#Loss 65 =0.2277\n",
      "#Loss 66 =0.2263\n",
      "#Loss 67 =0.2250\n",
      "#Loss 68 =0.2237\n",
      "#Loss 69 =0.2224\n",
      "#Loss 70 =0.2213\n",
      "#Loss 71 =0.2201\n",
      "#Loss 72 =0.2191\n",
      "#Loss 73 =0.2180\n",
      "#Loss 74 =0.2171\n",
      "#Loss 75 =0.2162\n",
      "#Loss 76 =0.2153\n",
      "#Loss 77 =0.2144\n",
      "#Loss 78 =0.2136\n",
      "#Loss 79 =0.2129\n",
      "#Loss 80 =0.2122\n",
      "#Loss 81 =0.2115\n",
      "#Loss 82 =0.2108\n",
      "#Loss 83 =0.2102\n",
      "#Loss 84 =0.2096\n",
      "#Loss 85 =0.2091\n",
      "#Loss 86 =0.2085\n",
      "#Loss 87 =0.2080\n",
      "#Loss 88 =0.2075\n",
      "#Loss 89 =0.2071\n",
      "#Loss 90 =0.2066\n",
      "#Loss 91 =0.2062\n",
      "#Loss 92 =0.2058\n",
      "#Loss 93 =0.2055\n",
      "#Loss 94 =0.2051\n",
      "#Loss 95 =0.2048\n",
      "#Loss 96 =0.2044\n",
      "#Loss 97 =0.2041\n",
      "#Loss 98 =0.2038\n",
      "#Loss 99 =0.2035\n",
      "#Loss 100 =0.2033\n",
      "#Loss 101 =0.2030\n",
      "#Loss 102 =0.2028\n",
      "#Loss 103 =0.2026\n",
      "#Loss 104 =0.2023\n",
      "#Loss 105 =0.2021\n",
      "#Loss 106 =0.2019\n",
      "#Loss 107 =0.2017\n",
      "#Loss 108 =0.2016\n",
      "#Loss 109 =0.2014\n",
      "#Loss 110 =0.2012\n",
      "#Loss 111 =0.2011\n",
      "#Loss 112 =0.2009\n",
      "#Loss 113 =0.2008\n",
      "#Loss 114 =0.2007\n",
      "#Loss 115 =0.2005\n",
      "#Loss 116 =0.2004\n",
      "#Loss 117 =0.2003\n",
      "#Loss 118 =0.2002\n",
      "#Loss 119 =0.2001\n",
      "#Loss 120 =0.2000\n",
      "#Loss 121 =0.1999\n",
      "#Loss 122 =0.1998\n",
      "#Loss 123 =0.1997\n",
      "#Loss 124 =0.1996\n",
      "#Loss 125 =0.1996\n",
      "#Loss 126 =0.1995\n",
      "#Loss 127 =0.1994\n",
      "#Loss 128 =0.1993\n",
      "#Loss 129 =0.1993\n",
      "#Loss 130 =0.1992\n",
      "#Loss 131 =0.1992\n",
      "#Loss 132 =0.1991\n",
      "#Loss 133 =0.1991\n",
      "#Loss 134 =0.1990\n",
      "#Loss 135 =0.1990\n",
      "#Loss 136 =0.1989\n",
      "#Loss 137 =0.1989\n",
      "#Loss 138 =0.1988\n",
      "#Loss 139 =0.1988\n",
      "#Loss 140 =0.1988\n",
      "#Loss 141 =0.1987\n",
      "#Loss 142 =0.1987\n",
      "#Loss 143 =0.1987\n",
      "#Loss 144 =0.1986\n",
      "#Loss 145 =0.1986\n",
      "#Loss 146 =0.1986\n",
      "#Loss 147 =0.1986\n",
      "#Loss 148 =0.1985\n",
      "#Loss 149 =0.1985\n",
      "#Loss 150 =0.1985\n",
      "#Loss 151 =0.1985\n",
      "#Loss 152 =0.1984\n",
      "#Loss 153 =0.1984\n",
      "#Loss 154 =0.1984\n",
      "#Loss 155 =0.1984\n",
      "#Loss 156 =0.1984\n",
      "#Loss 157 =0.1984\n",
      "#Loss 158 =0.1983\n",
      "#Loss 159 =0.1983\n",
      "#Loss 160 =0.1983\n",
      "#Loss 161 =0.1983\n",
      "#Loss 162 =0.1983\n",
      "#Loss 163 =0.1983\n",
      "#Loss 164 =0.1983\n",
      "#Loss 165 =0.1983\n",
      "#Loss 166 =0.1982\n",
      "#Loss 167 =0.1982\n",
      "#Loss 168 =0.1982\n",
      "#Loss 169 =0.1982\n",
      "#Loss 170 =0.1982\n",
      "#Loss 171 =0.1982\n",
      "#Loss 172 =0.1982\n",
      "#Loss 173 =0.1982\n",
      "#Loss 174 =0.1982\n",
      "#Loss 175 =0.1982\n",
      "#Loss 176 =0.1982\n",
      "#Loss 177 =0.1982\n",
      " 2 50 绝对误差 tensor(0.0303, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(0.0337, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.1101, dtype=torch.float64)   实验回归误差 tensor(0.0761, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.2166, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 50   条件数 1.0\n",
      "Loss 0 =23.6046\n",
      "#Loss 1 =23.6000\n",
      "#Loss 2 =20.1597\n",
      "#Loss 3 =17.3052\n",
      "#Loss 4 =14.9552\n",
      "#Loss 5 =13.0243\n",
      "#Loss 6 =11.4342\n",
      "#Loss 7 =10.1182\n",
      "#Loss 8 =9.0215\n",
      "#Loss 9 =8.1007\n",
      "#Loss 10 =7.3213\n",
      "#Loss 11 =6.6563\n",
      "#Loss 12 =6.0844\n",
      "#Loss 13 =5.5888\n",
      "#Loss 14 =5.1564\n",
      "#Loss 15 =4.7765\n",
      "#Loss 16 =4.4407\n",
      "#Loss 17 =4.1422\n",
      "#Loss 18 =3.8754\n",
      "#Loss 19 =3.6358\n",
      "#Loss 20 =3.4196\n",
      "#Loss 21 =3.2239\n",
      "#Loss 22 =3.0459\n",
      "#Loss 23 =2.8836\n",
      "#Loss 24 =2.7351\n",
      "#Loss 25 =2.5988\n",
      "#Loss 26 =2.4735\n",
      "#Loss 27 =2.3579\n",
      "#Loss 28 =2.2512\n",
      "#Loss 29 =2.1524\n",
      "#Loss 30 =2.0608\n",
      "#Loss 31 =1.9758\n",
      "#Loss 32 =1.8967\n",
      "#Loss 33 =1.8231\n",
      "#Loss 34 =1.7545\n",
      "#Loss 35 =1.6905\n",
      "#Loss 36 =1.6308\n",
      "#Loss 37 =1.5748\n",
      "#Loss 38 =1.5224\n",
      "#Loss 39 =1.4733\n",
      "#Loss 40 =1.4273\n",
      "#Loss 41 =1.3843\n",
      "#Loss 42 =1.3439\n",
      "#Loss 43 =1.3054\n",
      "#Loss 44 =1.2646\n",
      "#Loss 45 =1.2262\n",
      "#Loss 46 =1.1901\n",
      "#Loss 47 =1.1561\n",
      "#Loss 48 =1.1241\n",
      "#Loss 49 =1.0937\n",
      "#Loss 50 =1.0651\n",
      "#Loss 51 =1.0381\n",
      "#Loss 52 =1.0128\n",
      "#Loss 53 =0.9888\n",
      "#Loss 54 =0.9658\n",
      "#Loss 55 =0.9442\n",
      "#Loss 56 =0.9231\n",
      "#Loss 57 =0.9013\n",
      "#Loss 58 =0.8805\n",
      "#Loss 59 =0.8607\n",
      "#Loss 60 =0.8420\n",
      "#Loss 61 =0.8244\n",
      "#Loss 62 =0.8068\n",
      "#Loss 63 =0.7900\n",
      "#Loss 64 =0.7740\n",
      "#Loss 65 =0.7589\n",
      "#Loss 66 =0.7447\n",
      "#Loss 67 =0.7313\n",
      "#Loss 68 =0.7187\n",
      "#Loss 69 =0.7068\n",
      "#Loss 70 =0.6954\n",
      "#Loss 71 =0.6836\n",
      "#Loss 72 =0.6723\n",
      "#Loss 73 =0.6616\n",
      "#Loss 74 =0.6515\n",
      "#Loss 75 =0.6420\n",
      "#Loss 76 =0.6331\n",
      "#Loss 77 =0.6247\n",
      "#Loss 78 =0.6167\n",
      "#Loss 79 =0.6089\n",
      "#Loss 80 =0.6016\n",
      "#Loss 81 =0.5943\n",
      "#Loss 82 =0.5866\n",
      "#Loss 83 =0.5793\n",
      "#Loss 84 =0.5722\n",
      "#Loss 85 =0.5655\n",
      "#Loss 86 =0.5588\n",
      "#Loss 87 =0.5525\n",
      "#Loss 88 =0.5466\n",
      "#Loss 89 =0.5410\n",
      "#Loss 90 =0.5358\n",
      "#Loss 91 =0.5309\n",
      "#Loss 92 =0.5262\n",
      "#Loss 93 =0.5219\n",
      "#Loss 94 =0.5178\n",
      "#Loss 95 =0.5140\n",
      "#Loss 96 =0.5104\n",
      "#Loss 97 =0.5069\n",
      "#Loss 98 =0.5036\n",
      "#Loss 99 =0.5005\n",
      "#Loss 100 =0.4975\n",
      "#Loss 101 =0.4948\n",
      "#Loss 102 =0.4922\n",
      "#Loss 103 =0.4895\n",
      "#Loss 104 =0.4870\n",
      "#Loss 105 =0.4846\n",
      "#Loss 106 =0.4823\n",
      "#Loss 107 =0.4802\n",
      "#Loss 108 =0.4782\n",
      "#Loss 109 =0.4763\n",
      "#Loss 110 =0.4746\n",
      "#Loss 111 =0.4729\n",
      "#Loss 112 =0.4714\n",
      "#Loss 113 =0.4699\n",
      "#Loss 114 =0.4685\n",
      "#Loss 115 =0.4673\n",
      "#Loss 116 =0.4661\n",
      "#Loss 117 =0.4649\n",
      "#Loss 118 =0.4627\n",
      "#Loss 119 =0.4606\n",
      "#Loss 120 =0.4586\n",
      "#Loss 121 =0.4568\n",
      "#Loss 122 =0.4550\n",
      "#Loss 123 =0.4534\n",
      "#Loss 124 =0.4519\n",
      "#Loss 125 =0.4505\n",
      "#Loss 126 =0.4492\n",
      "#Loss 127 =0.4479\n",
      "#Loss 128 =0.4467\n",
      "#Loss 129 =0.4456\n",
      "#Loss 130 =0.4446\n",
      "#Loss 131 =0.4436\n",
      "#Loss 132 =0.4427\n",
      "#Loss 133 =0.4419\n",
      "#Loss 134 =0.4410\n",
      "#Loss 135 =0.4402\n",
      "#Loss 136 =0.4394\n",
      "#Loss 137 =0.4386\n",
      "#Loss 138 =0.4377\n",
      "#Loss 139 =0.4367\n",
      "#Loss 140 =0.4355\n",
      "#Loss 141 =0.4344\n",
      "#Loss 142 =0.4334\n",
      "#Loss 143 =0.4321\n",
      "#Loss 144 =0.4309\n",
      "#Loss 145 =0.4298\n",
      "#Loss 146 =0.4288\n",
      "#Loss 147 =0.4277\n",
      "#Loss 148 =0.4266\n",
      "#Loss 149 =0.4257\n",
      "#Loss 150 =0.4247\n",
      "#Loss 151 =0.4239\n",
      "#Loss 152 =0.4231\n",
      "#Loss 153 =0.4223\n",
      "#Loss 154 =0.4217\n",
      "#Loss 155 =0.4210\n",
      "#Loss 156 =0.4204\n",
      "#Loss 157 =0.4195\n",
      "#Loss 158 =0.4180\n",
      "#Loss 159 =0.4161\n",
      "#Loss 160 =0.4143\n",
      "#Loss 161 =0.4126\n",
      "#Loss 162 =0.4110\n",
      "#Loss 163 =0.4096\n",
      "#Loss 164 =0.4082\n",
      "#Loss 165 =0.4069\n",
      "#Loss 166 =0.4056\n",
      "#Loss 167 =0.4045\n",
      "#Loss 168 =0.4034\n",
      "#Loss 169 =0.4024\n",
      "#Loss 170 =0.4012\n",
      "#Loss 171 =0.3995\n",
      "#Loss 172 =0.3978\n",
      "#Loss 173 =0.3963\n",
      "#Loss 174 =0.3948\n",
      "#Loss 175 =0.3934\n",
      "#Loss 176 =0.3922\n",
      "#Loss 177 =0.3910\n",
      "#Loss 178 =0.3898\n",
      "#Loss 179 =0.3879\n",
      "#Loss 180 =0.3858\n",
      "#Loss 181 =0.3838\n",
      "#Loss 182 =0.3820\n",
      "#Loss 183 =0.3802\n",
      "#Loss 184 =0.3786\n",
      "#Loss 185 =0.3771\n",
      "#Loss 186 =0.3756\n",
      "#Loss 187 =0.3742\n",
      "#Loss 188 =0.3729\n",
      "#Loss 189 =0.3716\n",
      "#Loss 190 =0.3704\n",
      "#Loss 191 =0.3688\n",
      "#Loss 192 =0.3673\n",
      "#Loss 193 =0.3658\n",
      "#Loss 194 =0.3645\n",
      "#Loss 195 =0.3632\n",
      "#Loss 196 =0.3619\n",
      "#Loss 197 =0.3608\n",
      "#Loss 198 =0.3598\n",
      "#Loss 199 =0.3587\n",
      "#Loss 200 =0.3578\n",
      "超过迭代上限\n",
      " 2 50 绝对误差 tensor(0.5906, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(0.3473, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.1300, dtype=torch.float64)   实验回归误差 tensor(0.1230, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.3711, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 50   条件数 1.0\n",
      "Loss 0 =184019.4362\n",
      "#Loss 1 =183627.0963\n",
      "#Loss 2 =176739.8675\n",
      "#Loss 3 =181863.3944\n",
      "#Loss 4 =182757.2878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 5 =181566.9549\n",
      "#Loss 6 =182879.0262\n",
      "#Loss 7 =182813.3486\n",
      "#Loss 8 =181684.2166\n",
      "#Loss 9 =182536.0851\n",
      "#Loss 10 =182738.9328\n",
      "#Loss 11 =182469.4445\n",
      "#Loss 12 =183077.2341\n",
      "#Loss 13 =182939.4601\n",
      "#Loss 14 =183927.2970\n",
      "#Loss 15 =183928.0111\n",
      " 2 50 绝对误差 tensor(21.1139, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(7.5546, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0015, dtype=torch.float64)   实验回归误差 tensor(1.0000, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.0000, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 0   条件数 1.0\n",
      "Loss 0 =66.2801\n",
      "#Loss 1 =66.0516\n",
      "#Loss 2 =56.2710\n",
      "#Loss 3 =48.4398\n",
      "#Loss 4 =42.1663\n",
      "#Loss 5 =37.0392\n",
      "#Loss 6 =32.7245\n",
      "#Loss 7 =28.9866\n",
      "#Loss 8 =25.6738\n",
      "#Loss 9 =22.6969\n",
      "#Loss 10 =20.0098\n",
      "#Loss 11 =17.5944\n",
      "#Loss 12 =15.3606\n",
      "#Loss 13 =13.4177\n",
      "#Loss 14 =11.7641\n",
      "#Loss 15 =10.3949\n",
      "#Loss 16 =9.3150\n",
      "#Loss 17 =8.4920\n",
      "#Loss 18 =7.8635\n",
      "#Loss 19 =7.3930\n",
      "#Loss 20 =7.0543\n",
      "#Loss 21 =6.8079\n",
      "#Loss 22 =6.6218\n",
      "#Loss 23 =6.4741\n",
      "#Loss 24 =6.3513\n",
      "#Loss 25 =6.2444\n",
      "#Loss 26 =6.1473\n",
      "#Loss 27 =6.0576\n",
      "#Loss 28 =5.9730\n",
      "#Loss 29 =5.8928\n",
      "#Loss 30 =5.8168\n",
      "#Loss 31 =5.7445\n",
      "#Loss 32 =5.6759\n",
      "#Loss 33 =5.6087\n",
      "#Loss 34 =5.5449\n",
      "#Loss 35 =5.4843\n",
      "#Loss 36 =5.4269\n",
      "#Loss 37 =5.3724\n",
      "#Loss 38 =5.3191\n",
      "#Loss 39 =5.2684\n",
      "#Loss 40 =5.2182\n",
      "#Loss 41 =5.1671\n",
      "#Loss 42 =5.1186\n",
      "#Loss 43 =5.0727\n",
      "#Loss 44 =5.0289\n",
      "#Loss 45 =4.9874\n",
      "#Loss 46 =4.9476\n",
      "#Loss 47 =4.9094\n",
      "#Loss 48 =4.8730\n",
      "#Loss 49 =4.8387\n",
      "#Loss 50 =4.8064\n",
      "#Loss 51 =4.7758\n",
      "#Loss 52 =4.7467\n",
      "#Loss 53 =4.7193\n",
      "#Loss 54 =4.6932\n",
      "#Loss 55 =4.6682\n",
      "#Loss 56 =4.6439\n",
      "#Loss 57 =4.6209\n",
      "#Loss 58 =4.5994\n",
      "#Loss 59 =4.5786\n",
      "#Loss 60 =4.5557\n",
      "#Loss 61 =4.5321\n",
      "#Loss 62 =4.5100\n",
      "#Loss 63 =4.4880\n",
      "#Loss 64 =4.4656\n",
      "#Loss 65 =4.4432\n",
      "#Loss 66 =4.4222\n",
      "#Loss 67 =4.4018\n",
      "#Loss 68 =4.3804\n",
      "#Loss 69 =4.3595\n",
      "#Loss 70 =4.3397\n",
      "#Loss 71 =4.3203\n",
      "#Loss 72 =4.3015\n",
      "#Loss 73 =4.2823\n",
      "#Loss 74 =4.2638\n",
      "#Loss 75 =4.2465\n",
      "#Loss 76 =4.2300\n",
      "#Loss 77 =4.2138\n",
      "#Loss 78 =4.1985\n",
      "#Loss 79 =4.1843\n",
      "#Loss 80 =4.1711\n",
      "#Loss 81 =4.1586\n",
      "#Loss 82 =4.1470\n",
      "#Loss 83 =4.1363\n",
      "#Loss 84 =4.1263\n",
      "#Loss 85 =4.1165\n",
      "#Loss 86 =4.1060\n",
      "#Loss 87 =4.0964\n",
      "#Loss 88 =4.0874\n",
      "#Loss 89 =4.0790\n",
      "#Loss 90 =4.0713\n",
      "#Loss 91 =4.0641\n",
      "#Loss 92 =4.0574\n",
      "#Loss 93 =4.0512\n",
      "#Loss 94 =4.0454\n",
      "#Loss 95 =4.0399\n",
      "#Loss 96 =4.0349\n",
      "#Loss 97 =4.0302\n",
      "#Loss 98 =4.0258\n",
      "#Loss 99 =4.0214\n",
      "#Loss 100 =4.0171\n",
      "#Loss 101 =4.0132\n",
      "#Loss 102 =4.0095\n",
      "#Loss 103 =4.0060\n",
      "#Loss 104 =4.0026\n",
      "#Loss 105 =3.9994\n",
      "#Loss 106 =3.9964\n",
      "#Loss 107 =3.9937\n",
      "#Loss 108 =3.9911\n",
      "#Loss 109 =3.9887\n",
      "#Loss 110 =3.9864\n",
      "#Loss 111 =3.9842\n",
      "#Loss 112 =3.9821\n",
      "#Loss 113 =3.9803\n",
      "#Loss 114 =3.9785\n",
      "#Loss 115 =3.9769\n",
      "#Loss 116 =3.9754\n",
      "#Loss 117 =3.9741\n",
      "#Loss 118 =3.9729\n",
      "#Loss 119 =3.9717\n",
      "#Loss 120 =3.9707\n",
      "#Loss 121 =3.9697\n",
      "#Loss 122 =3.9688\n",
      "#Loss 123 =3.9680\n",
      "#Loss 124 =3.9672\n",
      "#Loss 125 =3.9666\n",
      "#Loss 126 =3.9659\n",
      "#Loss 127 =3.9653\n",
      "#Loss 128 =3.9648\n",
      "#Loss 129 =3.9643\n",
      "#Loss 130 =3.9639\n",
      "#Loss 131 =3.9634\n",
      "#Loss 132 =3.9630\n",
      "#Loss 133 =3.9627\n",
      "#Loss 134 =3.9623\n",
      "#Loss 135 =3.9620\n",
      "#Loss 136 =3.9618\n",
      "#Loss 137 =3.9615\n",
      "#Loss 138 =3.9613\n",
      "#Loss 139 =3.9611\n",
      "#Loss 140 =3.9609\n",
      "#Loss 141 =3.9607\n",
      "#Loss 142 =3.9605\n",
      "#Loss 143 =3.9604\n",
      "#Loss 144 =3.9603\n",
      "#Loss 145 =3.9601\n",
      "#Loss 146 =3.9600\n",
      " 2 50 绝对误差 tensor(3.2818, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(1.7628, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0893, dtype=torch.float64)   实验回归误差 tensor(0.2444, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.4142, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 50   条件数 1.0\n",
      "Loss 0 =4122.6330\n",
      "#Loss 1 =4122.4256\n",
      "#Loss 2 =3853.9104\n",
      "#Loss 3 =3764.8572\n",
      "#Loss 4 =3155.1479\n",
      "#Loss 5 =8062712.9504\n",
      "#Loss 6 =nan\n",
      " 2 50 绝对误差 tensor(nan, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(nan, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0111, dtype=torch.float64)   实验回归误差 tensor(nan, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.0000, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 0   条件数 1.0\n",
      "Loss 0 =148.1716\n",
      "#Loss 1 =146.9745\n",
      "#Loss 2 =133.4853\n",
      "#Loss 3 =121.8102\n",
      "#Loss 4 =111.0119\n",
      "#Loss 5 =100.3036\n",
      "#Loss 6 =89.0342\n",
      "#Loss 7 =76.6677\n",
      "#Loss 8 =62.8046\n",
      "#Loss 9 =47.3566\n",
      "#Loss 10 =31.0574\n",
      "#Loss 11 =16.3012\n",
      "#Loss 12 =6.8566\n",
      "#Loss 13 =3.7241\n",
      "#Loss 14 =3.1966\n",
      "#Loss 15 =2.9662\n",
      "#Loss 16 =2.7790\n",
      "#Loss 17 =2.6235\n",
      "#Loss 18 =2.4935\n",
      "#Loss 19 =2.3844\n",
      "#Loss 20 =2.2924\n",
      "#Loss 21 =2.2144\n",
      "#Loss 22 =2.1481\n",
      "#Loss 23 =2.0915\n",
      "#Loss 24 =2.0431\n",
      "#Loss 25 =2.0015\n",
      "#Loss 26 =1.9658\n",
      "#Loss 27 =1.9350\n",
      "#Loss 28 =1.9084\n",
      "#Loss 29 =1.8854\n",
      "#Loss 30 =1.8655\n",
      "#Loss 31 =1.8481\n",
      "#Loss 32 =1.8331\n",
      "#Loss 33 =1.8199\n",
      "#Loss 34 =1.8085\n",
      "#Loss 35 =1.7985\n",
      "#Loss 36 =1.7898\n",
      "#Loss 37 =1.7822\n",
      "#Loss 38 =1.7755\n",
      "#Loss 39 =1.7697\n",
      "#Loss 40 =1.7645\n",
      "#Loss 41 =1.7600\n",
      "#Loss 42 =1.7561\n",
      "#Loss 43 =1.7526\n",
      "#Loss 44 =1.7496\n",
      "#Loss 45 =1.7469\n",
      "#Loss 46 =1.7445\n",
      "#Loss 47 =1.7424\n",
      "#Loss 48 =1.7406\n",
      "#Loss 49 =1.7390\n",
      "#Loss 50 =1.7376\n",
      "#Loss 51 =1.7363\n",
      "#Loss 52 =1.7352\n",
      "#Loss 53 =1.7342\n",
      "#Loss 54 =1.7334\n",
      "#Loss 55 =1.7326\n",
      "#Loss 56 =1.7319\n",
      "#Loss 57 =1.7313\n",
      "#Loss 58 =1.7308\n",
      "#Loss 59 =1.7303\n",
      "#Loss 60 =1.7299\n",
      "#Loss 61 =1.7296\n",
      "#Loss 62 =1.7293\n",
      "#Loss 63 =1.7290\n",
      "#Loss 64 =1.7287\n",
      "#Loss 65 =1.7285\n",
      "#Loss 66 =1.7283\n",
      "#Loss 67 =1.7281\n",
      "#Loss 68 =1.7280\n",
      "#Loss 69 =1.7278\n",
      "#Loss 70 =1.7277\n",
      "#Loss 71 =1.7276\n",
      "#Loss 72 =1.7275\n",
      "#Loss 73 =1.7274\n",
      "#Loss 74 =1.7274\n",
      "#Loss 75 =1.7273\n",
      "#Loss 76 =1.7272\n",
      "#Loss 77 =1.7272\n",
      " 2 50 绝对误差 tensor(2.7086, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(1.7208, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0581, dtype=torch.float64)   实验回归误差 tensor(0.1080, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.4142, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 50   条件数 1.0\n",
      "Loss 0 =16.1510\n",
      "#Loss 1 =16.1507\n",
      " 2 50 绝对误差 tensor(0.7723, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(0.9476, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.1967, dtype=torch.float64)   实验回归误差 tensor(0.9409, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.0468, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 2   条件数 1.0\n",
      "Loss 0 =101.6064\n",
      "#Loss 1 =101.3143\n",
      "#Loss 2 =88.7360\n",
      "#Loss 3 =78.7160\n",
      "#Loss 4 =69.6862\n",
      "#Loss 5 =60.5256\n",
      "#Loss 6 =50.5553\n",
      "#Loss 7 =39.4455\n",
      "#Loss 8 =27.3758\n",
      "#Loss 9 =15.7019\n",
      "#Loss 10 =7.5339\n",
      "#Loss 11 =4.8107\n",
      "#Loss 12 =4.5333\n",
      "#Loss 13 =4.4468\n",
      "#Loss 14 =4.3794\n",
      "#Loss 15 =4.3265\n",
      "#Loss 16 =4.2847\n",
      "#Loss 17 =4.2515\n",
      "#Loss 18 =4.2250\n",
      "#Loss 19 =4.2038\n",
      "#Loss 20 =4.1868\n",
      "#Loss 21 =4.1730\n",
      "#Loss 22 =4.1619\n",
      "#Loss 23 =4.1529\n",
      "#Loss 24 =4.1455\n",
      "#Loss 25 =4.1396\n",
      "#Loss 26 =4.1347\n",
      "#Loss 27 =4.1308\n",
      "#Loss 28 =4.1275\n",
      "#Loss 29 =4.1249\n",
      "#Loss 30 =4.1227\n",
      "#Loss 31 =4.1209\n",
      "#Loss 32 =4.1195\n",
      "#Loss 33 =4.1183\n",
      "#Loss 34 =4.1173\n",
      "#Loss 35 =4.1165\n",
      "#Loss 36 =4.1158\n",
      "#Loss 37 =4.1152\n",
      "#Loss 38 =4.1148\n",
      "#Loss 39 =4.1144\n",
      "#Loss 40 =4.1141\n",
      "#Loss 41 =4.1139\n",
      "#Loss 42 =4.1136\n",
      "#Loss 43 =4.1135\n",
      "#Loss 44 =4.1133\n",
      "#Loss 45 =4.1132\n",
      " 2 50 绝对误差 tensor(1.8125, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(1.8926, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0816, dtype=torch.float64)   实验回归误差 tensor(0.2012, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.4000, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 50   条件数 1.0\n",
      "Loss 0 =0.8660\n",
      "#Loss 1 =0.8649\n",
      "#Loss 2 =0.7517\n",
      "#Loss 3 =0.6570\n",
      "#Loss 4 =0.5778\n",
      "#Loss 5 =0.5115\n",
      "#Loss 6 =0.4561\n",
      "#Loss 7 =0.4097\n",
      "#Loss 8 =0.3708\n",
      "#Loss 9 =0.3383\n",
      "#Loss 10 =0.3110\n",
      "#Loss 11 =0.2881\n",
      "#Loss 12 =0.2689\n",
      "#Loss 13 =0.2528\n",
      "#Loss 14 =0.2393\n",
      "#Loss 15 =0.2278\n",
      "#Loss 16 =0.2182\n",
      "#Loss 17 =0.2101\n",
      "#Loss 18 =0.2033\n",
      "#Loss 19 =0.1975\n",
      "#Loss 20 =0.1926\n",
      "#Loss 21 =0.1885\n",
      "#Loss 22 =0.1850\n",
      "#Loss 23 =0.1820\n",
      "#Loss 24 =0.1794\n",
      "#Loss 25 =0.1772\n",
      "#Loss 26 =0.1753\n",
      "#Loss 27 =0.1737\n",
      "#Loss 28 =0.1723\n",
      "#Loss 29 =0.1711\n",
      "#Loss 30 =0.1700\n",
      "#Loss 31 =0.1691\n",
      "#Loss 32 =0.1683\n",
      "#Loss 33 =0.1675\n",
      "#Loss 34 =0.1669\n",
      "#Loss 35 =0.1663\n",
      "#Loss 36 =0.1657\n",
      "#Loss 37 =0.1653\n",
      "#Loss 38 =0.1648\n",
      "#Loss 39 =0.1644\n",
      "#Loss 40 =0.1640\n",
      "#Loss 41 =0.1637\n",
      "#Loss 42 =0.1633\n",
      "#Loss 43 =0.1630\n",
      "#Loss 44 =0.1627\n",
      "#Loss 45 =0.1624\n",
      "#Loss 46 =0.1621\n",
      "#Loss 47 =0.1618\n",
      "#Loss 48 =0.1616\n",
      "#Loss 49 =0.1613\n",
      "#Loss 50 =0.1610\n",
      "#Loss 51 =0.1608\n",
      "#Loss 52 =0.1606\n",
      "#Loss 53 =0.1603\n",
      "#Loss 54 =0.1601\n",
      "#Loss 55 =0.1598\n",
      "#Loss 56 =0.1596\n",
      "#Loss 57 =0.1594\n",
      "#Loss 58 =0.1592\n",
      "#Loss 59 =0.1589\n",
      "#Loss 60 =0.1587\n",
      "#Loss 61 =0.1585\n",
      "#Loss 62 =0.1583\n",
      "#Loss 63 =0.1581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 64 =0.1579\n",
      "#Loss 65 =0.1577\n",
      "#Loss 66 =0.1574\n",
      "#Loss 67 =0.1572\n",
      "#Loss 68 =0.1570\n",
      "#Loss 69 =0.1568\n",
      "#Loss 70 =0.1566\n",
      "#Loss 71 =0.1564\n",
      "#Loss 72 =0.1562\n",
      "#Loss 73 =0.1560\n",
      "#Loss 74 =0.1558\n",
      "#Loss 75 =0.1556\n",
      "#Loss 76 =0.1554\n",
      "#Loss 77 =0.1552\n",
      "#Loss 78 =0.1550\n",
      "#Loss 79 =0.1549\n",
      "#Loss 80 =0.1547\n",
      "#Loss 81 =0.1545\n",
      "#Loss 82 =0.1543\n",
      "#Loss 83 =0.1541\n",
      "#Loss 84 =0.1539\n",
      "#Loss 85 =0.1537\n",
      "#Loss 86 =0.1535\n",
      "#Loss 87 =0.1534\n",
      "#Loss 88 =0.1532\n",
      "#Loss 89 =0.1530\n",
      "#Loss 90 =0.1528\n",
      "#Loss 91 =0.1526\n",
      "#Loss 92 =0.1525\n",
      "#Loss 93 =0.1523\n",
      "#Loss 94 =0.1521\n",
      "#Loss 95 =0.1519\n",
      "#Loss 96 =0.1518\n",
      "#Loss 97 =0.1516\n",
      "#Loss 98 =0.1514\n",
      "#Loss 99 =0.1512\n",
      "#Loss 100 =0.1511\n",
      "#Loss 101 =0.1509\n",
      "#Loss 102 =0.1507\n",
      "#Loss 103 =0.1506\n",
      "#Loss 104 =0.1504\n",
      "#Loss 105 =0.1502\n",
      "#Loss 106 =0.1501\n",
      "#Loss 107 =0.1499\n",
      "#Loss 108 =0.1498\n",
      "#Loss 109 =0.1496\n",
      "#Loss 110 =0.1494\n",
      "#Loss 111 =0.1493\n",
      "#Loss 112 =0.1491\n",
      "#Loss 113 =0.1490\n",
      "#Loss 114 =0.1488\n",
      "#Loss 115 =0.1487\n",
      "#Loss 116 =0.1485\n",
      "#Loss 117 =0.1483\n",
      "#Loss 118 =0.1482\n",
      "#Loss 119 =0.1480\n",
      "#Loss 120 =0.1479\n",
      "#Loss 121 =0.1477\n",
      "#Loss 122 =0.1476\n",
      "#Loss 123 =0.1474\n",
      "#Loss 124 =0.1473\n",
      "#Loss 125 =0.1472\n",
      "#Loss 126 =0.1470\n",
      "#Loss 127 =0.1469\n",
      "#Loss 128 =0.1467\n",
      "#Loss 129 =0.1466\n",
      "#Loss 130 =0.1464\n",
      "#Loss 131 =0.1463\n",
      "#Loss 132 =0.1462\n",
      "#Loss 133 =0.1460\n",
      "#Loss 134 =0.1459\n",
      "#Loss 135 =0.1457\n",
      "#Loss 136 =0.1456\n",
      "#Loss 137 =0.1455\n",
      "#Loss 138 =0.1453\n",
      "#Loss 139 =0.1452\n",
      "#Loss 140 =0.1451\n",
      "#Loss 141 =0.1449\n",
      "#Loss 142 =0.1448\n",
      "#Loss 143 =0.1447\n",
      "#Loss 144 =0.1445\n",
      "#Loss 145 =0.1444\n",
      "#Loss 146 =0.1443\n",
      "#Loss 147 =0.1442\n",
      "#Loss 148 =0.1440\n",
      "#Loss 149 =0.1439\n",
      "#Loss 150 =0.1438\n",
      "#Loss 151 =0.1436\n",
      "#Loss 152 =0.1435\n",
      "#Loss 153 =0.1434\n",
      "#Loss 154 =0.1433\n",
      "#Loss 155 =0.1432\n",
      "#Loss 156 =0.1430\n",
      "#Loss 157 =0.1429\n",
      "#Loss 158 =0.1428\n",
      "#Loss 159 =0.1427\n",
      "#Loss 160 =0.1426\n",
      "#Loss 161 =0.1424\n",
      "#Loss 162 =0.1423\n",
      "#Loss 163 =0.1422\n",
      "#Loss 164 =0.1421\n",
      "#Loss 165 =0.1420\n",
      "#Loss 166 =0.1419\n",
      "#Loss 167 =0.1417\n",
      "#Loss 168 =0.1416\n",
      "#Loss 169 =0.1415\n",
      "#Loss 170 =0.1414\n",
      "#Loss 171 =0.1413\n",
      "#Loss 172 =0.1412\n",
      "#Loss 173 =0.1411\n",
      "#Loss 174 =0.1410\n",
      "#Loss 175 =0.1408\n",
      "#Loss 176 =0.1407\n",
      "#Loss 177 =0.1406\n",
      "#Loss 178 =0.1405\n",
      "#Loss 179 =0.1404\n",
      "#Loss 180 =0.1403\n",
      "#Loss 181 =0.1402\n",
      "#Loss 182 =0.1401\n",
      "#Loss 183 =0.1400\n",
      "#Loss 184 =0.1399\n",
      "#Loss 185 =0.1398\n",
      "#Loss 186 =0.1397\n",
      "#Loss 187 =0.1396\n",
      "#Loss 188 =0.1395\n",
      "#Loss 189 =0.1394\n",
      "#Loss 190 =0.1393\n",
      "#Loss 191 =0.1392\n",
      "#Loss 192 =0.1391\n",
      "#Loss 193 =0.1390\n",
      "#Loss 194 =0.1389\n",
      "#Loss 195 =0.1388\n",
      "#Loss 196 =0.1387\n",
      "#Loss 197 =0.1386\n",
      "#Loss 198 =0.1385\n",
      "#Loss 199 =0.1384\n",
      "#Loss 200 =0.1383\n",
      "超过迭代上限\n",
      " 2 50 绝对误差 tensor(0.7079, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(1.1722, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.6471, dtype=torch.float64)   实验回归误差 tensor(0.3995, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.3959, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 48   条件数 1.0\n",
      "Loss 0 =31.1686\n",
      "#Loss 1 =31.1188\n",
      "#Loss 2 =23.7188\n",
      "#Loss 3 =18.4276\n",
      "#Loss 4 =14.7082\n",
      "#Loss 5 =12.0729\n",
      "#Loss 6 =10.1650\n",
      "#Loss 7 =8.7455\n",
      "#Loss 8 =7.6591\n",
      "#Loss 9 =6.8058\n",
      "#Loss 10 =6.1204\n",
      "#Loss 11 =5.5598\n",
      "#Loss 12 =5.0948\n",
      "#Loss 13 =4.7051\n",
      "#Loss 14 =4.3758\n",
      "#Loss 15 =4.0962\n",
      "#Loss 16 =3.8578\n",
      "#Loss 17 =3.6539\n",
      "#Loss 18 =3.4786\n",
      "#Loss 19 =3.3268\n",
      "#Loss 20 =3.1944\n",
      "#Loss 21 =3.0793\n",
      "#Loss 22 =2.9783\n",
      "#Loss 23 =2.8903\n",
      "#Loss 24 =2.8131\n",
      "#Loss 25 =2.7459\n",
      "#Loss 26 =2.6874\n",
      "#Loss 27 =2.6354\n",
      "#Loss 28 =2.5900\n",
      "#Loss 29 =2.5497\n",
      "#Loss 30 =2.5147\n",
      "#Loss 31 =2.4838\n",
      "#Loss 32 =2.4547\n",
      "#Loss 33 =2.4287\n",
      "#Loss 34 =2.4053\n",
      "#Loss 35 =2.3848\n",
      "#Loss 36 =2.3668\n",
      "#Loss 37 =2.3509\n",
      "#Loss 38 =2.3368\n",
      "#Loss 39 =2.3244\n",
      "#Loss 40 =2.3134\n",
      "#Loss 41 =2.3037\n",
      "#Loss 42 =2.2950\n",
      "#Loss 43 =2.2869\n",
      "#Loss 44 =2.2792\n",
      "#Loss 45 =2.2723\n",
      "#Loss 46 =2.2662\n",
      "#Loss 47 =2.2607\n",
      "#Loss 48 =2.2558\n",
      "#Loss 49 =2.2515\n",
      "#Loss 50 =2.2475\n",
      "#Loss 51 =2.2440\n",
      "#Loss 52 =2.2408\n",
      "#Loss 53 =2.2380\n",
      "#Loss 54 =2.2354\n",
      "#Loss 55 =2.2331\n",
      "#Loss 56 =2.2310\n",
      "#Loss 57 =2.2291\n",
      "#Loss 58 =2.2274\n",
      "#Loss 59 =2.2259\n",
      "#Loss 60 =2.2245\n",
      "#Loss 61 =2.2232\n",
      "#Loss 62 =2.2220\n",
      "#Loss 63 =2.2207\n",
      "#Loss 64 =2.2196\n",
      "#Loss 65 =2.2186\n",
      "#Loss 66 =2.2177\n",
      "#Loss 67 =2.2169\n",
      "#Loss 68 =2.2161\n",
      "#Loss 69 =2.2136\n",
      "#Loss 70 =2.2115\n",
      "#Loss 71 =2.2095\n",
      "#Loss 72 =2.2078\n",
      "#Loss 73 =2.2063\n",
      "#Loss 74 =2.2049\n",
      "#Loss 75 =2.2037\n",
      "#Loss 76 =2.2027\n",
      "#Loss 77 =2.2017\n",
      "#Loss 78 =2.2009\n",
      "#Loss 79 =2.2001\n",
      "#Loss 80 =2.1994\n",
      "#Loss 81 =2.1986\n",
      "#Loss 82 =2.1976\n",
      "#Loss 83 =2.1967\n",
      "#Loss 84 =2.1959\n",
      "#Loss 85 =2.1952\n",
      "#Loss 86 =2.1945\n",
      "#Loss 87 =2.1939\n",
      "#Loss 88 =2.1934\n",
      "#Loss 89 =2.1930\n",
      "#Loss 90 =2.1925\n",
      "#Loss 91 =2.1922\n",
      "#Loss 92 =2.1918\n",
      "#Loss 93 =2.1915\n",
      "#Loss 94 =2.1912\n",
      "#Loss 95 =2.1910\n",
      "#Loss 96 =2.1908\n",
      "#Loss 97 =2.1906\n",
      "#Loss 98 =2.1904\n",
      "#Loss 99 =2.1902\n",
      "#Loss 100 =2.1901\n",
      "#Loss 101 =2.1899\n",
      "#Loss 102 =2.1898\n",
      "#Loss 103 =2.1897\n",
      "#Loss 104 =2.1896\n",
      "#Loss 105 =2.1895\n",
      "#Loss 106 =2.1894\n",
      "#Loss 107 =2.1893\n",
      "#Loss 108 =2.1892\n",
      "#Loss 109 =2.1892\n",
      "#Loss 110 =2.1891\n",
      " 2 50 绝对误差 tensor(1.4285, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(0.6380, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.1313, dtype=torch.float64)   实验回归误差 tensor(0.2650, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.3266, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 50   条件数 1.0\n",
      "Loss 0 =1384.4743\n",
      "#Loss 1 =1381.8269\n",
      "#Loss 2 =1274.9105\n",
      "#Loss 3 =1153.6512\n",
      "#Loss 4 =846.4212\n",
      "#Loss 5 =202.1722\n",
      "#Loss 6 =1642.5525\n",
      "#Loss 7 =1305.0799\n",
      "#Loss 8 =1264.7141\n",
      "#Loss 9 =1198.1891\n",
      "#Loss 10 =1027.0407\n",
      "#Loss 11 =349.1499\n",
      "#Loss 12 =67904.1466\n",
      "#Loss 13 =1384.4743\n",
      "#Loss 14 =1384.4743\n",
      " 2 50 绝对误差 tensor(317.3622, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(200.5055, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0174, dtype=torch.float64)   实验回归误差 tensor(0.9999, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.0000, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 0   条件数 1.0\n",
      "Loss 0 =14.7642\n",
      "#Loss 1 =14.7609\n",
      "#Loss 2 =12.6759\n",
      "#Loss 3 =10.9073\n",
      "#Loss 4 =9.4152\n",
      "#Loss 5 =8.1594\n",
      "#Loss 6 =7.1026\n",
      "#Loss 7 =6.2120\n",
      "#Loss 8 =5.4594\n",
      "#Loss 9 =4.8212\n",
      "#Loss 10 =4.2778\n",
      "#Loss 11 =3.8132\n",
      "#Loss 12 =3.4142\n",
      "#Loss 13 =3.0699\n",
      "#Loss 14 =2.7715\n",
      "#Loss 15 =2.5117\n",
      "#Loss 16 =2.2847\n",
      "#Loss 17 =2.0853\n",
      "#Loss 18 =1.9097\n",
      "#Loss 19 =1.7543\n",
      "#Loss 20 =1.6163\n",
      "#Loss 21 =1.4934\n",
      "#Loss 22 =1.3836\n",
      "#Loss 23 =1.2851\n",
      "#Loss 24 =1.1965\n",
      "#Loss 25 =1.1166\n",
      "#Loss 26 =1.0444\n",
      "#Loss 27 =0.9789\n",
      "#Loss 28 =0.9195\n",
      "#Loss 29 =0.8653\n",
      "#Loss 30 =0.8159\n",
      "#Loss 31 =0.7707\n",
      "#Loss 32 =0.7292\n",
      "#Loss 33 =0.6912\n",
      "#Loss 34 =0.6563\n",
      "#Loss 35 =0.6241\n",
      "#Loss 36 =0.5944\n",
      "#Loss 37 =0.5669\n",
      "#Loss 38 =0.5416\n",
      "#Loss 39 =0.5181\n",
      "#Loss 40 =0.4963\n",
      "#Loss 41 =0.4760\n",
      "#Loss 42 =0.4572\n",
      "#Loss 43 =0.4397\n",
      "#Loss 44 =0.4234\n",
      "#Loss 45 =0.4082\n",
      "#Loss 46 =0.3940\n",
      "#Loss 47 =0.3808\n",
      "#Loss 48 =0.3684\n",
      "#Loss 49 =0.3568\n",
      "#Loss 50 =0.3460\n",
      "#Loss 51 =0.3358\n",
      "#Loss 52 =0.3263\n",
      "#Loss 53 =0.3174\n",
      "#Loss 54 =0.3090\n",
      "#Loss 55 =0.3011\n",
      "#Loss 56 =0.2937\n",
      "#Loss 57 =0.2867\n",
      "#Loss 58 =0.2802\n",
      "#Loss 59 =0.2740\n",
      "#Loss 60 =0.2682\n",
      "#Loss 61 =0.2627\n",
      "#Loss 62 =0.2575\n",
      "#Loss 63 =0.2527\n",
      "#Loss 64 =0.2481\n",
      "#Loss 65 =0.2437\n",
      "#Loss 66 =0.2396\n",
      "#Loss 67 =0.2358\n",
      "#Loss 68 =0.2321\n",
      "#Loss 69 =0.2286\n",
      "#Loss 70 =0.2254\n",
      "#Loss 71 =0.2223\n",
      "#Loss 72 =0.2193\n",
      "#Loss 73 =0.2165\n",
      "#Loss 74 =0.2139\n",
      "#Loss 75 =0.2114\n",
      "#Loss 76 =0.2091\n",
      "#Loss 77 =0.2068\n",
      "#Loss 78 =0.2047\n",
      "#Loss 79 =0.2027\n",
      "#Loss 80 =0.2008\n",
      "#Loss 81 =0.1990\n",
      "#Loss 82 =0.1972\n",
      "#Loss 83 =0.1956\n",
      "#Loss 84 =0.1941\n",
      "#Loss 85 =0.1926\n",
      "#Loss 86 =0.1912\n",
      "#Loss 87 =0.1898\n",
      "#Loss 88 =0.1886\n",
      "#Loss 89 =0.1874\n",
      "#Loss 90 =0.1862\n",
      "#Loss 91 =0.1851\n",
      "#Loss 92 =0.1841\n",
      "#Loss 93 =0.1831\n",
      "#Loss 94 =0.1822\n",
      "#Loss 95 =0.1813\n",
      "#Loss 96 =0.1804\n",
      "#Loss 97 =0.1796\n",
      "#Loss 98 =0.1789\n",
      "#Loss 99 =0.1781\n",
      "#Loss 100 =0.1774\n",
      "#Loss 101 =0.1768\n",
      "#Loss 102 =0.1761\n",
      "#Loss 103 =0.1755\n",
      "#Loss 104 =0.1750\n",
      "#Loss 105 =0.1744\n",
      "#Loss 106 =0.1739\n",
      "#Loss 107 =0.1734\n",
      "#Loss 108 =0.1729\n",
      "#Loss 109 =0.1725\n",
      "#Loss 110 =0.1720\n",
      "#Loss 111 =0.1716\n",
      "#Loss 112 =0.1712\n",
      "#Loss 113 =0.1708\n",
      "#Loss 114 =0.1705\n",
      "#Loss 115 =0.1701\n",
      "#Loss 116 =0.1698\n",
      "#Loss 117 =0.1695\n",
      "#Loss 118 =0.1692\n",
      "#Loss 119 =0.1689\n",
      "#Loss 120 =0.1687\n",
      "#Loss 121 =0.1684\n",
      "#Loss 122 =0.1682\n",
      "#Loss 123 =0.1679\n",
      "#Loss 124 =0.1677\n",
      "#Loss 125 =0.1675\n",
      "#Loss 126 =0.1673\n",
      "#Loss 127 =0.1671\n",
      "#Loss 128 =0.1669\n",
      "#Loss 129 =0.1667\n",
      "#Loss 130 =0.1665\n",
      "#Loss 131 =0.1664\n",
      "#Loss 132 =0.1662\n",
      "#Loss 133 =0.1661\n",
      "#Loss 134 =0.1659\n",
      "#Loss 135 =0.1658\n",
      "#Loss 136 =0.1657\n",
      "#Loss 137 =0.1655\n",
      "#Loss 138 =0.1654\n",
      "#Loss 139 =0.1653\n",
      "#Loss 140 =0.1652\n",
      "#Loss 141 =0.1651\n",
      "#Loss 142 =0.1650\n",
      "#Loss 143 =0.1649\n",
      "#Loss 144 =0.1648\n",
      "#Loss 145 =0.1647\n",
      "#Loss 146 =0.1646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 147 =0.1646\n",
      "#Loss 148 =0.1645\n",
      "#Loss 149 =0.1644\n",
      "#Loss 150 =0.1643\n",
      "#Loss 151 =0.1643\n",
      "#Loss 152 =0.1642\n",
      "#Loss 153 =0.1640\n",
      "#Loss 154 =0.1638\n",
      "#Loss 155 =0.1637\n",
      "#Loss 156 =0.1635\n",
      "#Loss 157 =0.1634\n",
      "#Loss 158 =0.1632\n",
      "#Loss 159 =0.1631\n",
      "#Loss 160 =0.1630\n",
      "#Loss 161 =0.1628\n",
      "#Loss 162 =0.1627\n",
      "#Loss 163 =0.1626\n",
      "#Loss 164 =0.1625\n",
      "#Loss 165 =0.1624\n",
      "#Loss 166 =0.1623\n",
      "#Loss 167 =0.1622\n",
      "#Loss 168 =0.1621\n",
      "#Loss 169 =0.1620\n",
      "#Loss 170 =0.1619\n",
      "#Loss 171 =0.1619\n",
      "#Loss 172 =0.1618\n",
      "#Loss 173 =0.1617\n",
      "#Loss 174 =0.1617\n",
      "#Loss 175 =0.1616\n",
      "#Loss 176 =0.1615\n",
      "#Loss 177 =0.1615\n",
      "#Loss 178 =0.1614\n",
      "#Loss 179 =0.1614\n",
      "#Loss 180 =0.1612\n",
      "#Loss 181 =0.1610\n",
      "#Loss 182 =0.1608\n",
      "#Loss 183 =0.1606\n",
      "#Loss 184 =0.1603\n",
      "#Loss 185 =0.1601\n",
      "#Loss 186 =0.1600\n",
      "#Loss 187 =0.1598\n",
      "#Loss 188 =0.1596\n",
      "#Loss 189 =0.1595\n",
      "#Loss 190 =0.1593\n",
      "#Loss 191 =0.1592\n",
      "#Loss 192 =0.1590\n",
      "#Loss 193 =0.1589\n",
      "#Loss 194 =0.1588\n",
      "#Loss 195 =0.1586\n",
      "#Loss 196 =0.1585\n",
      "#Loss 197 =0.1584\n",
      "#Loss 198 =0.1583\n",
      "#Loss 199 =0.1582\n",
      "#Loss 200 =0.1581\n",
      "超过迭代上限\n",
      " 2 50 绝对误差 tensor(0.0147, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(0.0189, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.1719, dtype=torch.float64)   实验回归误差 tensor(0.1034, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.3115, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 50   条件数 1.0\n",
      "Loss 0 =270.8673\n",
      "#Loss 1 =270.4258\n",
      "#Loss 2 =237.5160\n",
      "#Loss 3 =209.4922\n",
      "#Loss 4 =172.9212\n",
      "#Loss 5 =112.7021\n",
      "#Loss 6 =22.3326\n",
      "#Loss 7 =46.6607\n",
      "#Loss 8 =156.2675\n",
      "#Loss 9 =87.9435\n",
      "#Loss 10 =12.2078\n",
      "#Loss 11 =12.4459\n",
      "#Loss 12 =14.7708\n",
      "#Loss 13 =30.0407\n",
      "#Loss 14 =59.0348\n",
      "#Loss 15 =184.9550\n",
      "#Loss 16 =140.9626\n",
      "#Loss 17 =61.5813\n",
      "#Loss 18 =29.2475\n",
      "#Loss 19 =98.4136\n",
      "#Loss 20 =13.6185\n",
      "#Loss 21 =19.4132\n",
      "#Loss 22 =54.6429\n",
      "#Loss 23 =39.3432\n",
      "#Loss 24 =134.7527\n",
      "#Loss 25 =51.2881\n",
      "#Loss 26 =41.1629\n",
      "#Loss 27 =139.9890\n",
      "#Loss 28 =59.9907\n",
      "#Loss 29 =31.0173\n",
      "#Loss 30 =105.4040\n",
      "#Loss 31 =17.2632\n",
      "#Loss 32 =33.6347\n",
      "#Loss 33 =116.4388\n",
      "#Loss 34 =26.2621\n",
      "#Loss 35 =52.1848\n",
      "#Loss 36 =169.4657\n",
      "#Loss 37 =112.8722\n",
      "#Loss 38 =23.6187\n",
      "#Loss 39 =48.5189\n",
      "#Loss 40 =160.6760\n",
      "#Loss 41 =96.4062\n",
      "#Loss 42 =13.0834\n",
      "#Loss 43 =16.7636\n",
      "#Loss 44 =40.2760\n",
      "#Loss 45 =54.6631\n",
      "#Loss 46 =174.9887\n",
      "#Loss 47 =123.2206\n",
      "#Loss 48 =35.3180\n",
      "#Loss 49 =54.5711\n",
      "#Loss 50 =174.3060\n",
      "#Loss 51 =122.3105\n",
      "#Loss 52 =34.2694\n",
      "#Loss 53 =54.7819\n",
      "#Loss 54 =174.7662\n",
      "#Loss 55 =123.1663\n",
      "#Loss 56 =35.3646\n",
      "#Loss 57 =54.5184\n",
      "#Loss 58 =174.1728\n",
      "#Loss 59 =122.0755\n",
      "#Loss 60 =33.9773\n",
      "#Loss 61 =54.8283\n",
      "#Loss 62 =174.8721\n",
      "#Loss 63 =123.3596\n",
      "#Loss 64 =35.6131\n",
      "#Loss 65 =54.4412\n",
      "#Loss 66 =174.0002\n",
      "#Loss 67 =121.7568\n",
      "#Loss 68 =33.5785\n",
      "#Loss 69 =54.8774\n",
      "#Loss 70 =174.9871\n",
      "#Loss 71 =123.5675\n",
      "#Loss 72 =35.8806\n",
      "#Loss 73 =54.3512\n",
      "#Loss 74 =173.7995\n",
      "#Loss 75 =121.3853\n",
      "#Loss 76 =33.1174\n",
      "#Loss 77 =54.9106\n",
      "#Loss 78 =175.0698\n",
      "#Loss 79 =123.7135\n",
      "#Loss 80 =36.0697\n",
      "#Loss 81 =54.2837\n",
      "#Loss 82 =173.6494\n",
      "#Loss 83 =121.1072\n",
      "#Loss 84 =32.7746\n",
      "#Loss 85 =54.9184\n",
      "#Loss 86 =175.0954\n",
      "#Loss 87 =123.7549\n",
      "#Loss 88 =36.1216\n",
      "#Loss 89 =54.2651\n",
      "#Loss 90 =173.6079\n",
      "#Loss 91 =121.0302\n",
      "#Loss 92 =32.6802\n",
      "#Loss 93 =54.9188\n",
      "#Loss 94 =175.0986\n",
      "#Loss 95 =123.7591\n",
      "#Loss 96 =36.1264\n",
      "#Loss 97 =54.2634\n",
      "#Loss 98 =173.6044\n",
      "#Loss 99 =121.0236\n",
      "#Loss 100 =32.6721\n",
      "#Loss 101 =54.9186\n",
      "#Loss 102 =175.0985\n",
      "#Loss 103 =123.7589\n",
      "#Loss 104 =36.1261\n",
      "#Loss 105 =54.2636\n",
      "#Loss 106 =173.6047\n",
      "#Loss 107 =121.0241\n",
      "#Loss 108 =32.6727\n",
      "#Loss 109 =54.9187\n",
      "#Loss 110 =175.0985\n",
      "#Loss 111 =123.7589\n",
      "#Loss 112 =36.1261\n",
      "#Loss 113 =54.2635\n",
      "#Loss 114 =173.6047\n",
      "#Loss 115 =121.0241\n",
      "#Loss 116 =32.6726\n",
      "#Loss 117 =54.9187\n",
      "#Loss 118 =175.0985\n",
      "#Loss 119 =123.7589\n",
      "#Loss 120 =36.1261\n",
      "#Loss 121 =54.2635\n",
      "#Loss 122 =173.6047\n",
      "#Loss 123 =121.0241\n",
      "#Loss 124 =32.6726\n",
      "#Loss 125 =54.9187\n",
      "#Loss 126 =175.0985\n",
      "#Loss 127 =123.7589\n",
      "#Loss 128 =36.1261\n",
      "#Loss 129 =54.2635\n",
      "#Loss 130 =173.6047\n",
      "#Loss 131 =121.0241\n",
      "#Loss 132 =32.6726\n",
      "#Loss 133 =54.9187\n",
      "#Loss 134 =175.0985\n",
      "#Loss 135 =123.7589\n",
      "#Loss 136 =36.1261\n",
      "#Loss 137 =54.2635\n",
      "#Loss 138 =173.6047\n",
      "#Loss 139 =121.0241\n",
      "#Loss 140 =32.6726\n",
      "#Loss 141 =54.9187\n",
      "#Loss 142 =175.0985\n",
      "#Loss 143 =123.7589\n",
      "#Loss 144 =36.1261\n",
      "#Loss 145 =54.2635\n",
      "#Loss 146 =173.6047\n",
      "#Loss 147 =121.0241\n",
      "#Loss 148 =32.6726\n",
      "#Loss 149 =54.9187\n",
      "#Loss 150 =175.0985\n",
      "#Loss 151 =123.7589\n",
      "#Loss 152 =36.1261\n",
      "#Loss 153 =54.2635\n",
      "#Loss 154 =173.6047\n",
      "#Loss 155 =121.0241\n",
      "#Loss 156 =32.6726\n",
      "#Loss 157 =54.9187\n",
      "#Loss 158 =175.0985\n",
      "#Loss 159 =123.7589\n",
      "#Loss 160 =36.1261\n",
      "#Loss 161 =54.2635\n",
      "#Loss 162 =173.6047\n",
      "#Loss 163 =121.0241\n",
      "#Loss 164 =32.6726\n",
      "#Loss 165 =54.9187\n",
      "#Loss 166 =175.0985\n",
      "#Loss 167 =123.7589\n",
      "#Loss 168 =36.1261\n",
      "#Loss 169 =54.2635\n",
      "#Loss 170 =173.6047\n",
      "#Loss 171 =121.0241\n",
      "#Loss 172 =32.6726\n",
      "#Loss 173 =54.9187\n",
      "#Loss 174 =175.0985\n",
      "#Loss 175 =123.7589\n",
      "#Loss 176 =36.1261\n",
      "#Loss 177 =54.2635\n",
      "#Loss 178 =173.6047\n",
      "#Loss 179 =121.0241\n",
      "#Loss 180 =32.6726\n",
      "#Loss 181 =54.9187\n",
      "#Loss 182 =175.0985\n",
      "#Loss 183 =123.7589\n",
      "#Loss 184 =36.1261\n",
      "#Loss 185 =54.2635\n",
      "#Loss 186 =173.6047\n",
      "#Loss 187 =121.0241\n",
      "#Loss 188 =32.6726\n",
      "#Loss 189 =54.9187\n",
      "#Loss 190 =175.0985\n",
      "#Loss 191 =123.7589\n",
      "#Loss 192 =36.1261\n",
      "#Loss 193 =54.2635\n",
      "#Loss 194 =173.6047\n",
      "#Loss 195 =121.0241\n",
      "#Loss 196 =32.6726\n",
      "#Loss 197 =54.9187\n",
      "#Loss 198 =175.0985\n",
      "#Loss 199 =123.7589\n",
      "#Loss 200 =36.1261\n",
      "超过迭代上限\n",
      " 2 50 绝对误差 tensor(2.2292, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(1.9833, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0465, dtype=torch.float64)   实验回归误差 tensor(0.4477, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.4000, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 50   条件数 1.0\n",
      "Loss 0 =11.1183\n",
      "#Loss 1 =11.0851\n",
      "#Loss 2 =9.2021\n",
      "#Loss 3 =7.6840\n",
      "#Loss 4 =6.4601\n",
      "#Loss 5 =5.4702\n",
      "#Loss 6 =4.6652\n",
      "#Loss 7 =4.0059\n",
      "#Loss 8 =3.4618\n",
      "#Loss 9 =3.0091\n",
      "#Loss 10 =2.6295\n",
      "#Loss 11 =2.3090\n",
      "#Loss 12 =2.0365\n",
      "#Loss 13 =1.8035\n",
      "#Loss 14 =1.6035\n",
      "#Loss 15 =1.4311\n",
      "#Loss 16 =1.2821\n",
      "#Loss 17 =1.1531\n",
      "#Loss 18 =1.0414\n",
      "#Loss 19 =0.9446\n",
      "#Loss 20 =0.8608\n",
      "#Loss 21 =0.7882\n",
      "#Loss 22 =0.7255\n",
      "#Loss 23 =0.6714\n",
      "#Loss 24 =0.6248\n",
      "#Loss 25 =0.5847\n",
      "#Loss 26 =0.5503\n",
      "#Loss 27 =0.5208\n",
      "#Loss 28 =0.4957\n",
      "#Loss 29 =0.4742\n",
      "#Loss 30 =0.4559\n",
      "#Loss 31 =0.4404\n",
      "#Loss 32 =0.4272\n",
      "#Loss 33 =0.4159\n",
      "#Loss 34 =0.4064\n",
      "#Loss 35 =0.3984\n",
      "#Loss 36 =0.3915\n",
      "#Loss 37 =0.3858\n",
      "#Loss 38 =0.3808\n",
      "#Loss 39 =0.3767\n",
      "#Loss 40 =0.3731\n",
      "#Loss 41 =0.3701\n",
      "#Loss 42 =0.3675\n",
      "#Loss 43 =0.3653\n",
      "#Loss 44 =0.3634\n",
      "#Loss 45 =0.3617\n",
      "#Loss 46 =0.3603\n",
      "#Loss 47 =0.3590\n",
      "#Loss 48 =0.3580\n",
      "#Loss 49 =0.3570\n",
      "#Loss 50 =0.3562\n",
      "#Loss 51 =0.3554\n",
      "#Loss 52 =0.3548\n",
      "#Loss 53 =0.3542\n",
      "#Loss 54 =0.3536\n",
      "#Loss 55 =0.3531\n",
      "#Loss 56 =0.3527\n",
      "#Loss 57 =0.3523\n",
      "#Loss 58 =0.3519\n",
      "#Loss 59 =0.3516\n",
      "#Loss 60 =0.3513\n",
      "#Loss 61 =0.3510\n",
      "#Loss 62 =0.3508\n",
      "#Loss 63 =0.3505\n",
      "#Loss 64 =0.3503\n",
      "#Loss 65 =0.3501\n",
      "#Loss 66 =0.3499\n",
      "#Loss 67 =0.3497\n",
      "#Loss 68 =0.3496\n",
      "#Loss 69 =0.3494\n",
      "#Loss 70 =0.3493\n",
      "#Loss 71 =0.3491\n",
      "#Loss 72 =0.3490\n",
      "#Loss 73 =0.3489\n",
      "#Loss 74 =0.3488\n",
      "#Loss 75 =0.3487\n",
      "#Loss 76 =0.3486\n",
      "#Loss 77 =0.3485\n",
      "#Loss 78 =0.3484\n",
      "#Loss 79 =0.3483\n",
      "#Loss 80 =0.3482\n",
      "#Loss 81 =0.3482\n",
      "#Loss 82 =0.3481\n",
      "#Loss 83 =0.3480\n",
      "#Loss 84 =0.3480\n",
      "#Loss 85 =0.3479\n",
      "#Loss 86 =0.3479\n",
      "#Loss 87 =0.3478\n",
      "#Loss 88 =0.3478\n",
      "#Loss 89 =0.3477\n",
      "#Loss 90 =0.3477\n",
      "#Loss 91 =0.3476\n",
      "#Loss 92 =0.3476\n",
      "#Loss 93 =0.3476\n",
      "#Loss 94 =0.3475\n",
      "#Loss 95 =0.3475\n",
      "#Loss 96 =0.3475\n",
      "#Loss 97 =0.3474\n",
      "#Loss 98 =0.3474\n",
      "#Loss 99 =0.3474\n",
      "#Loss 100 =0.3474\n",
      "#Loss 101 =0.3474\n",
      "#Loss 102 =0.3473\n",
      "#Loss 103 =0.3473\n",
      "#Loss 104 =0.3473\n",
      "#Loss 105 =0.3473\n",
      "#Loss 106 =0.3473\n",
      "#Loss 107 =0.3473\n",
      "#Loss 108 =0.3472\n",
      "#Loss 109 =0.3472\n",
      "#Loss 110 =0.3472\n",
      "#Loss 111 =0.3472\n",
      "#Loss 112 =0.3472\n",
      "#Loss 113 =0.3472\n",
      " 2 50 绝对误差 tensor(1.0228, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(1.8598, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.2034, dtype=torch.float64)   实验回归误差 tensor(0.1767, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.3856, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 50   条件数 1.0\n",
      "Loss 0 =24.5926\n",
      "#Loss 1 =24.5904\n",
      "#Loss 2 =21.8179\n",
      "#Loss 3 =19.6454\n",
      "#Loss 4 =17.9021\n",
      "#Loss 5 =16.4474\n",
      "#Loss 6 =15.1771\n",
      "#Loss 7 =14.0189\n",
      "#Loss 8 =12.9267\n",
      "#Loss 9 =11.8730\n",
      "#Loss 10 =10.8448\n",
      "#Loss 11 =9.8386\n",
      "#Loss 12 =8.8580\n",
      "#Loss 13 =7.9111\n",
      "#Loss 14 =7.0084\n",
      "#Loss 15 =6.1615\n",
      "#Loss 16 =5.3812\n",
      "#Loss 17 =4.6767\n",
      "#Loss 18 =4.0533\n",
      "#Loss 19 =3.5141\n",
      "#Loss 20 =3.0579\n",
      "#Loss 21 =2.6798\n",
      "#Loss 22 =2.3719\n",
      "#Loss 23 =2.1239\n",
      "#Loss 24 =1.9257\n",
      "#Loss 25 =1.7678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 26 =1.6407\n",
      "#Loss 27 =1.5366\n",
      "#Loss 28 =1.4500\n",
      "#Loss 29 =1.3762\n",
      "#Loss 30 =1.3116\n",
      "#Loss 31 =1.2538\n",
      "#Loss 32 =1.2014\n",
      "#Loss 33 =1.1531\n",
      "#Loss 34 =1.1083\n",
      "#Loss 35 =1.0662\n",
      "#Loss 36 =1.0267\n",
      "#Loss 37 =0.9894\n",
      "#Loss 38 =0.9542\n",
      "#Loss 39 =0.9210\n",
      "#Loss 40 =0.8896\n",
      "#Loss 41 =0.8598\n",
      "#Loss 42 =0.8316\n",
      "#Loss 43 =0.8048\n",
      "#Loss 44 =0.7794\n",
      "#Loss 45 =0.7552\n",
      "#Loss 46 =0.7323\n",
      "#Loss 47 =0.7105\n",
      "#Loss 48 =0.6898\n",
      "#Loss 49 =0.6701\n",
      "#Loss 50 =0.6513\n",
      "#Loss 51 =0.6334\n",
      "#Loss 52 =0.6163\n",
      "#Loss 53 =0.6000\n",
      "#Loss 54 =0.5845\n",
      "#Loss 55 =0.5696\n",
      "#Loss 56 =0.5553\n",
      "#Loss 57 =0.5417\n",
      "#Loss 58 =0.5287\n",
      "#Loss 59 =0.5162\n",
      "#Loss 60 =0.5043\n",
      "#Loss 61 =0.4929\n",
      "#Loss 62 =0.4820\n",
      "#Loss 63 =0.4716\n",
      "#Loss 64 =0.4615\n",
      "#Loss 65 =0.4519\n",
      "#Loss 66 =0.4427\n",
      "#Loss 67 =0.4339\n",
      "#Loss 68 =0.4254\n",
      "#Loss 69 =0.4173\n",
      "#Loss 70 =0.4095\n",
      "#Loss 71 =0.4020\n",
      "#Loss 72 =0.3947\n",
      "#Loss 73 =0.3878\n",
      "#Loss 74 =0.3811\n",
      "#Loss 75 =0.3747\n",
      "#Loss 76 =0.3685\n",
      "#Loss 77 =0.3626\n",
      "#Loss 78 =0.3569\n",
      "#Loss 79 =0.3514\n",
      "#Loss 80 =0.3460\n",
      "#Loss 81 =0.3409\n",
      "#Loss 82 =0.3360\n",
      "#Loss 83 =0.3313\n",
      "#Loss 84 =0.3267\n",
      "#Loss 85 =0.3222\n",
      "#Loss 86 =0.3180\n",
      "#Loss 87 =0.3138\n",
      "#Loss 88 =0.3098\n",
      "#Loss 89 =0.3060\n",
      "#Loss 90 =0.3022\n",
      "#Loss 91 =0.2986\n",
      "#Loss 92 =0.2952\n",
      "#Loss 93 =0.2918\n",
      "#Loss 94 =0.2886\n",
      "#Loss 95 =0.2854\n",
      "#Loss 96 =0.2824\n",
      "#Loss 97 =0.2795\n",
      "#Loss 98 =0.2767\n",
      "#Loss 99 =0.2739\n",
      "#Loss 100 =0.2713\n",
      "#Loss 101 =0.2687\n",
      "#Loss 102 =0.2663\n",
      "#Loss 103 =0.2638\n",
      "#Loss 104 =0.2615\n",
      "#Loss 105 =0.2592\n",
      "#Loss 106 =0.2570\n",
      "#Loss 107 =0.2549\n",
      "#Loss 108 =0.2528\n",
      "#Loss 109 =0.2508\n",
      "#Loss 110 =0.2488\n",
      "#Loss 111 =0.2470\n",
      "#Loss 112 =0.2451\n",
      "#Loss 113 =0.2434\n",
      "#Loss 114 =0.2417\n",
      "#Loss 115 =0.2400\n",
      "#Loss 116 =0.2383\n",
      "#Loss 117 =0.2367\n",
      "#Loss 118 =0.2352\n",
      "#Loss 119 =0.2337\n",
      "#Loss 120 =0.2322\n",
      "#Loss 121 =0.2308\n",
      "#Loss 122 =0.2295\n",
      "#Loss 123 =0.2282\n",
      "#Loss 124 =0.2269\n",
      "#Loss 125 =0.2256\n",
      "#Loss 126 =0.2244\n",
      "#Loss 127 =0.2233\n",
      "#Loss 128 =0.2221\n",
      "#Loss 129 =0.2210\n",
      "#Loss 130 =0.2200\n",
      "#Loss 131 =0.2189\n",
      "#Loss 132 =0.2179\n",
      "#Loss 133 =0.2169\n",
      "#Loss 134 =0.2160\n",
      "#Loss 135 =0.2151\n",
      "#Loss 136 =0.2142\n",
      "#Loss 137 =0.2133\n",
      "#Loss 138 =0.2124\n",
      "#Loss 139 =0.2116\n",
      "#Loss 140 =0.2108\n",
      "#Loss 141 =0.2100\n",
      "#Loss 142 =0.2093\n",
      "#Loss 143 =0.2085\n",
      "#Loss 144 =0.2078\n",
      "#Loss 145 =0.2071\n",
      "#Loss 146 =0.2064\n",
      "#Loss 147 =0.2057\n",
      "#Loss 148 =0.2050\n",
      "#Loss 149 =0.2044\n",
      "#Loss 150 =0.2038\n",
      "#Loss 151 =0.2032\n",
      "#Loss 152 =0.2026\n",
      "#Loss 153 =0.2020\n",
      "#Loss 154 =0.2015\n",
      "#Loss 155 =0.2009\n",
      "#Loss 156 =0.2004\n",
      "#Loss 157 =0.1999\n",
      "#Loss 158 =0.1994\n",
      "#Loss 159 =0.1989\n",
      "#Loss 160 =0.1985\n",
      "#Loss 161 =0.1980\n",
      "#Loss 162 =0.1976\n",
      "#Loss 163 =0.1971\n",
      "#Loss 164 =0.1967\n",
      "#Loss 165 =0.1963\n",
      "#Loss 166 =0.1959\n",
      "#Loss 167 =0.1955\n",
      "#Loss 168 =0.1951\n",
      "#Loss 169 =0.1948\n",
      "#Loss 170 =0.1944\n",
      "#Loss 171 =0.1941\n",
      "#Loss 172 =0.1937\n",
      "#Loss 173 =0.1934\n",
      "#Loss 174 =0.1931\n",
      "#Loss 175 =0.1928\n",
      "#Loss 176 =0.1925\n",
      "#Loss 177 =0.1922\n",
      "#Loss 178 =0.1919\n",
      "#Loss 179 =0.1916\n",
      "#Loss 180 =0.1913\n",
      "#Loss 181 =0.1911\n",
      "#Loss 182 =0.1908\n",
      "#Loss 183 =0.1906\n",
      "#Loss 184 =0.1903\n",
      "#Loss 185 =0.1901\n",
      "#Loss 186 =0.1899\n",
      "#Loss 187 =0.1896\n",
      "#Loss 188 =0.1894\n",
      "#Loss 189 =0.1892\n",
      "#Loss 190 =0.1890\n",
      "#Loss 191 =0.1888\n",
      "#Loss 192 =0.1886\n",
      "#Loss 193 =0.1884\n",
      "#Loss 194 =0.1882\n",
      "#Loss 195 =0.1880\n",
      "#Loss 196 =0.1878\n",
      "#Loss 197 =0.1877\n",
      "#Loss 198 =0.1875\n",
      "#Loss 199 =0.1873\n",
      "#Loss 200 =0.1871\n",
      "超过迭代上限\n",
      " 2 50 绝对误差 tensor(0.0655, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(0.0783, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.1428, dtype=torch.float64)   实验回归误差 tensor(0.0879, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.2771, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 48   条件数 1.0\n",
      "Loss 0 =0.7463\n",
      "#Loss 1 =0.7446\n",
      "#Loss 2 =0.6018\n",
      "#Loss 3 =0.4891\n",
      "#Loss 4 =0.4001\n",
      "#Loss 5 =0.3298\n",
      "#Loss 6 =0.2742\n",
      "#Loss 7 =0.2304\n",
      "#Loss 8 =0.1957\n",
      "#Loss 9 =0.1682\n",
      "#Loss 10 =0.1464\n",
      "#Loss 11 =0.1291\n",
      "#Loss 12 =0.1153\n",
      "#Loss 13 =0.1044\n",
      "#Loss 14 =0.0956\n",
      "#Loss 15 =0.0886\n",
      "#Loss 16 =0.0829\n",
      "#Loss 17 =0.0783\n",
      "#Loss 18 =0.0746\n",
      "#Loss 19 =0.0716\n",
      "#Loss 20 =0.0691\n",
      "#Loss 21 =0.0671\n",
      "#Loss 22 =0.0653\n",
      "#Loss 23 =0.0639\n",
      "#Loss 24 =0.0626\n",
      "#Loss 25 =0.0616\n",
      "#Loss 26 =0.0607\n",
      "#Loss 27 =0.0598\n",
      "#Loss 28 =0.0591\n",
      "#Loss 29 =0.0585\n",
      "#Loss 30 =0.0579\n",
      "#Loss 31 =0.0573\n",
      "#Loss 32 =0.0568\n",
      "#Loss 33 =0.0563\n",
      "#Loss 34 =0.0558\n",
      "#Loss 35 =0.0554\n",
      "#Loss 36 =0.0549\n",
      "#Loss 37 =0.0545\n",
      "#Loss 38 =0.0541\n",
      "#Loss 39 =0.0537\n",
      "#Loss 40 =0.0534\n",
      "#Loss 41 =0.0530\n",
      "#Loss 42 =0.0526\n",
      "#Loss 43 =0.0522\n",
      "#Loss 44 =0.0519\n",
      "#Loss 45 =0.0515\n",
      "#Loss 46 =0.0512\n",
      "#Loss 47 =0.0508\n",
      "#Loss 48 =0.0505\n",
      "#Loss 49 =0.0502\n",
      "#Loss 50 =0.0498\n",
      "#Loss 51 =0.0495\n",
      "#Loss 52 =0.0492\n",
      "#Loss 53 =0.0489\n",
      "#Loss 54 =0.0485\n",
      "#Loss 55 =0.0482\n",
      "#Loss 56 =0.0479\n",
      "#Loss 57 =0.0476\n",
      "#Loss 58 =0.0473\n",
      "#Loss 59 =0.0470\n",
      "#Loss 60 =0.0467\n",
      "#Loss 61 =0.0464\n",
      "#Loss 62 =0.0461\n",
      "#Loss 63 =0.0458\n",
      "#Loss 64 =0.0455\n",
      "#Loss 65 =0.0452\n",
      "#Loss 66 =0.0449\n",
      "#Loss 67 =0.0446\n",
      "#Loss 68 =0.0444\n",
      "#Loss 69 =0.0441\n",
      "#Loss 70 =0.0438\n",
      "#Loss 71 =0.0435\n",
      "#Loss 72 =0.0433\n",
      "#Loss 73 =0.0430\n",
      "#Loss 74 =0.0427\n",
      "#Loss 75 =0.0425\n",
      "#Loss 76 =0.0422\n",
      "#Loss 77 =0.0420\n",
      "#Loss 78 =0.0417\n",
      "#Loss 79 =0.0414\n",
      "#Loss 80 =0.0412\n",
      "#Loss 81 =0.0409\n",
      "#Loss 82 =0.0407\n",
      "#Loss 83 =0.0405\n",
      "#Loss 84 =0.0402\n",
      "#Loss 85 =0.0400\n",
      "#Loss 86 =0.0397\n",
      "#Loss 87 =0.0395\n",
      "#Loss 88 =0.0393\n",
      "#Loss 89 =0.0390\n",
      "#Loss 90 =0.0388\n",
      "#Loss 91 =0.0386\n",
      "#Loss 92 =0.0384\n",
      "#Loss 93 =0.0381\n",
      "#Loss 94 =0.0379\n",
      "#Loss 95 =0.0377\n",
      "#Loss 96 =0.0375\n",
      "#Loss 97 =0.0373\n",
      "#Loss 98 =0.0371\n",
      "#Loss 99 =0.0369\n",
      "#Loss 100 =0.0366\n",
      "#Loss 101 =0.0364\n",
      "#Loss 102 =0.0362\n",
      "#Loss 103 =0.0360\n",
      "#Loss 104 =0.0358\n",
      "#Loss 105 =0.0356\n",
      "#Loss 106 =0.0354\n",
      "#Loss 107 =0.0353\n",
      "#Loss 108 =0.0351\n",
      "#Loss 109 =0.0349\n",
      "#Loss 110 =0.0347\n",
      "#Loss 111 =0.0345\n",
      "#Loss 112 =0.0343\n",
      "#Loss 113 =0.0341\n",
      "#Loss 114 =0.0339\n",
      "#Loss 115 =0.0338\n",
      "#Loss 116 =0.0336\n",
      "#Loss 117 =0.0334\n",
      "#Loss 118 =0.0332\n",
      "#Loss 119 =0.0331\n",
      "#Loss 120 =0.0329\n",
      "#Loss 121 =0.0327\n",
      "#Loss 122 =0.0326\n",
      "#Loss 123 =0.0324\n",
      "#Loss 124 =0.0322\n",
      "#Loss 125 =0.0321\n",
      "#Loss 126 =0.0319\n",
      "#Loss 127 =0.0317\n",
      "#Loss 128 =0.0316\n",
      "#Loss 129 =0.0314\n",
      "#Loss 130 =0.0313\n",
      "#Loss 131 =0.0311\n",
      "#Loss 132 =0.0310\n",
      "#Loss 133 =0.0308\n",
      "#Loss 134 =0.0307\n",
      "#Loss 135 =0.0305\n",
      "#Loss 136 =0.0304\n",
      "#Loss 137 =0.0302\n",
      "#Loss 138 =0.0301\n",
      "#Loss 139 =0.0300\n",
      "#Loss 140 =0.0298\n",
      "#Loss 141 =0.0297\n",
      "#Loss 142 =0.0295\n",
      "#Loss 143 =0.0294\n",
      "#Loss 144 =0.0293\n",
      "#Loss 145 =0.0291\n",
      "#Loss 146 =0.0290\n",
      "#Loss 147 =0.0289\n",
      "#Loss 148 =0.0287\n",
      "#Loss 149 =0.0286\n",
      "#Loss 150 =0.0285\n",
      "#Loss 151 =0.0284\n",
      "#Loss 152 =0.0282\n",
      "#Loss 153 =0.0281\n",
      "#Loss 154 =0.0280\n",
      "#Loss 155 =0.0279\n",
      "#Loss 156 =0.0278\n",
      "#Loss 157 =0.0276\n",
      "#Loss 158 =0.0275\n",
      "#Loss 159 =0.0274\n",
      "#Loss 160 =0.0273\n",
      "#Loss 161 =0.0272\n",
      "#Loss 162 =0.0271\n",
      "#Loss 163 =0.0270\n",
      "#Loss 164 =0.0268\n",
      "#Loss 165 =0.0267\n",
      "#Loss 166 =0.0266\n",
      "#Loss 167 =0.0265\n",
      "#Loss 168 =0.0264\n",
      "#Loss 169 =0.0263\n",
      "#Loss 170 =0.0262\n",
      "#Loss 171 =0.0261\n",
      "#Loss 172 =0.0260\n",
      "#Loss 173 =0.0259\n",
      "#Loss 174 =0.0258\n",
      "#Loss 175 =0.0257\n",
      "#Loss 176 =0.0256\n",
      "#Loss 177 =0.0255\n",
      "#Loss 178 =0.0254\n",
      "#Loss 179 =0.0253\n",
      "#Loss 180 =0.0252\n",
      "#Loss 181 =0.0251\n",
      "#Loss 182 =0.0250\n",
      "#Loss 183 =0.0249\n",
      "#Loss 184 =0.0249\n",
      "#Loss 185 =0.0248\n",
      "#Loss 186 =0.0247\n",
      "#Loss 187 =0.0246\n",
      "#Loss 188 =0.0245\n",
      "#Loss 189 =0.0244\n",
      "#Loss 190 =0.0243\n",
      "#Loss 191 =0.0243\n",
      "#Loss 192 =0.0242\n",
      "#Loss 193 =0.0241\n",
      "#Loss 194 =0.0240\n",
      "#Loss 195 =0.0239\n",
      "#Loss 196 =0.0238\n",
      "#Loss 197 =0.0238\n",
      "#Loss 198 =0.0237\n",
      "#Loss 199 =0.0236\n",
      "#Loss 200 =0.0235\n",
      "超过迭代上限\n",
      " 2 50 绝对误差 tensor(0.0734, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(0.4530, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.6724, dtype=torch.float64)   实验回归误差 tensor(0.1773, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.4000, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 50   条件数 1.0\n",
      "Loss 0 =314.2276\n",
      "#Loss 1 =312.4121\n",
      "#Loss 2 =282.1493\n",
      "#Loss 3 =256.1971\n",
      "#Loss 4 =231.1964\n",
      "#Loss 5 =204.3792\n",
      "#Loss 6 =173.6738\n",
      "#Loss 7 =137.6391\n",
      "#Loss 8 =96.2358\n",
      "#Loss 9 =54.2946\n",
      "#Loss 10 =25.7169\n",
      "#Loss 11 =16.9136\n",
      "#Loss 12 =12.8824\n",
      "#Loss 13 =9.6272\n",
      "#Loss 14 =7.1616\n",
      "#Loss 15 =5.4271\n",
      "#Loss 16 =4.3045\n",
      "#Loss 17 =3.6007\n",
      "#Loss 18 =3.0664\n",
      "#Loss 19 =2.7540\n",
      "#Loss 20 =2.6009\n",
      "#Loss 21 =2.4350\n",
      "#Loss 22 =1.8232\n",
      "#Loss 23 =1.5179\n",
      "#Loss 24 =1.4164\n",
      "#Loss 25 =1.3772\n",
      "#Loss 26 =1.3907\n",
      "#Loss 27 =1.3893\n",
      "#Loss 28 =1.4102\n",
      "#Loss 29 =1.2769\n",
      "#Loss 30 =1.2894\n",
      "#Loss 31 =1.2088\n",
      "#Loss 32 =1.2067\n",
      "#Loss 33 =1.2065\n",
      "#Loss 34 =1.2081\n",
      "#Loss 35 =1.2076\n",
      "#Loss 36 =1.2102\n",
      "#Loss 37 =1.2097\n",
      "#Loss 38 =1.2129\n",
      "#Loss 39 =1.2125\n",
      "#Loss 40 =1.2164\n",
      "#Loss 41 =1.2166\n",
      "#Loss 42 =1.2214\n",
      "#Loss 43 =1.2222\n",
      "#Loss 44 =1.2284\n",
      "#Loss 45 =1.2302\n",
      "#Loss 46 =1.2384\n",
      "#Loss 47 =1.2418\n",
      "#Loss 48 =1.2530\n",
      "#Loss 49 =1.2587\n",
      "#Loss 50 =1.2747\n",
      "#Loss 51 =1.2838\n",
      "#Loss 52 =1.3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 53 =1.2110\n",
      "#Loss 54 =1.2107\n",
      "#Loss 55 =1.2110\n",
      "#Loss 56 =1.2138\n",
      "#Loss 57 =1.2140\n",
      "#Loss 58 =1.2181\n",
      "#Loss 59 =1.2186\n",
      "#Loss 60 =1.2239\n",
      "#Loss 61 =1.2252\n",
      "#Loss 62 =1.2320\n",
      "#Loss 63 =1.2345\n",
      "#Loss 64 =1.2438\n",
      "#Loss 65 =1.2480\n",
      "#Loss 66 =1.2610\n",
      "#Loss 67 =1.2679\n",
      "#Loss 68 =1.2858\n",
      "#Loss 69 =1.2029\n",
      "#Loss 70 =1.2007\n",
      "#Loss 71 =1.1997\n",
      "#Loss 72 =1.2002\n",
      "#Loss 73 =1.1987\n",
      "#Loss 74 =1.1997\n",
      "#Loss 75 =1.1979\n",
      "#Loss 76 =1.1990\n",
      "#Loss 77 =1.1970\n",
      "#Loss 78 =1.1980\n",
      "#Loss 79 =1.1959\n",
      "#Loss 80 =1.1968\n",
      "#Loss 81 =1.1946\n",
      "#Loss 82 =1.1954\n",
      "#Loss 83 =1.1932\n",
      "#Loss 84 =1.1939\n",
      "#Loss 85 =1.1916\n",
      "#Loss 86 =1.1922\n",
      "#Loss 87 =1.1900\n",
      "#Loss 88 =1.1903\n",
      "#Loss 89 =1.1908\n",
      "#Loss 90 =1.1915\n",
      "#Loss 91 =1.1924\n",
      "#Loss 92 =1.1934\n",
      "#Loss 93 =1.1908\n",
      "#Loss 94 =1.1915\n",
      "#Loss 95 =1.1923\n",
      "#Loss 96 =1.1933\n",
      "#Loss 97 =1.1908\n",
      "#Loss 98 =1.1914\n",
      "#Loss 99 =1.1922\n",
      "#Loss 100 =1.1931\n",
      "#Loss 101 =1.1906\n",
      "#Loss 102 =1.1912\n",
      "#Loss 103 =1.1920\n",
      "#Loss 104 =1.1929\n",
      "#Loss 105 =1.1904\n",
      "#Loss 106 =1.1909\n",
      "#Loss 107 =1.1916\n",
      "#Loss 108 =1.1925\n",
      "#Loss 109 =1.1901\n",
      "#Loss 110 =1.1905\n",
      "#Loss 111 =1.1910\n",
      "#Loss 112 =1.1918\n",
      "#Loss 113 =1.1927\n",
      "#Loss 114 =1.1937\n",
      "#Loss 115 =1.1911\n",
      "#Loss 116 =1.1919\n",
      "#Loss 117 =1.1928\n",
      "#Loss 118 =1.1938\n",
      "#Loss 119 =1.1912\n",
      "#Loss 120 =1.1920\n",
      "#Loss 121 =1.1898\n",
      "#Loss 122 =1.1900\n",
      "#Loss 123 =1.1904\n",
      "#Loss 124 =1.1910\n",
      "#Loss 125 =1.1917\n",
      "#Loss 126 =1.1927\n",
      "#Loss 127 =1.1902\n",
      "#Loss 128 =1.1907\n",
      "#Loss 129 =1.1913\n",
      "#Loss 130 =1.1921\n",
      "#Loss 131 =1.1931\n",
      "#Loss 132 =1.1941\n",
      "#Loss 133 =1.1915\n",
      "#Loss 134 =1.1923\n",
      "#Loss 135 =1.1900\n",
      "#Loss 136 =1.1904\n",
      "#Loss 137 =1.1909\n",
      "#Loss 138 =1.1916\n",
      "#Loss 139 =1.1925\n",
      "#Loss 140 =1.1935\n",
      "#Loss 141 =1.1909\n",
      "#Loss 142 =1.1916\n",
      "#Loss 143 =1.1925\n",
      "#Loss 144 =1.1934\n",
      "#Loss 145 =1.1909\n",
      "#Loss 146 =1.1916\n",
      "#Loss 147 =1.1924\n",
      "#Loss 148 =1.1934\n",
      "#Loss 149 =1.1909\n",
      "#Loss 150 =1.1915\n",
      "#Loss 151 =1.1923\n",
      "#Loss 152 =1.1933\n",
      "#Loss 153 =1.1908\n",
      "#Loss 154 =1.1914\n",
      "#Loss 155 =1.1922\n",
      "#Loss 156 =1.1932\n",
      "#Loss 157 =1.1907\n",
      "#Loss 158 =1.1912\n",
      "#Loss 159 =1.1920\n",
      "#Loss 160 =1.1930\n",
      "#Loss 161 =1.1905\n",
      "#Loss 162 =1.1910\n",
      "#Loss 163 =1.1917\n",
      "#Loss 164 =1.1926\n",
      "#Loss 165 =1.1902\n",
      "#Loss 166 =1.1906\n",
      "#Loss 167 =1.1912\n",
      "#Loss 168 =1.1920\n",
      "#Loss 169 =1.1930\n",
      "#Loss 170 =1.1940\n",
      "#Loss 171 =1.1914\n",
      "#Loss 172 =1.1922\n",
      "#Loss 173 =1.1899\n",
      "#Loss 174 =1.1902\n",
      "#Loss 175 =1.1907\n",
      "#Loss 176 =1.1913\n",
      "#Loss 177 =1.1921\n",
      "#Loss 178 =1.1931\n",
      "#Loss 179 =1.1906\n",
      "#Loss 180 =1.1912\n",
      "#Loss 181 =1.1919\n",
      "#Loss 182 =1.1928\n",
      "#Loss 183 =1.1904\n",
      "#Loss 184 =1.1908\n",
      "#Loss 185 =1.1915\n",
      "#Loss 186 =1.1924\n",
      "#Loss 187 =1.1935\n",
      "#Loss 188 =1.1946\n",
      "#Loss 189 =1.1920\n",
      "#Loss 190 =1.1927\n",
      "#Loss 191 =1.1904\n",
      "#Loss 192 =1.1909\n",
      "#Loss 193 =1.1916\n",
      "#Loss 194 =1.1925\n",
      "#Loss 195 =1.1900\n",
      "#Loss 196 =1.1904\n",
      "#Loss 197 =1.1910\n",
      "#Loss 198 =1.1917\n",
      "#Loss 199 =1.1926\n",
      "#Loss 200 =1.1936\n",
      "超过迭代上限\n",
      " 2 50 绝对误差 tensor(0.1675, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(0.0778, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0400, dtype=torch.float64)   实验回归误差 tensor(0.0617, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.3115, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 50   条件数 1.0\n",
      "Loss 0 =283.3311\n",
      "#Loss 1 =281.9772\n",
      "#Loss 2 =265.5067\n",
      "#Loss 3 =251.0608\n",
      "#Loss 4 =236.6122\n",
      "#Loss 5 =220.3817\n",
      "#Loss 6 =200.5992\n",
      "#Loss 7 =175.2615\n",
      "#Loss 8 =142.3920\n",
      "#Loss 9 =103.0224\n",
      "#Loss 10 =70.5528\n",
      "#Loss 11 =61.2082\n",
      "#Loss 12 =57.0599\n",
      "#Loss 13 =53.6654\n",
      "#Loss 14 =50.9106\n",
      "#Loss 15 =48.5372\n",
      "#Loss 16 =46.6237\n",
      "#Loss 17 =45.2029\n",
      "#Loss 18 =46.1506\n",
      "#Loss 19 =60.1717\n",
      "#Loss 20 =163.1288\n",
      "#Loss 21 =118.4933\n",
      "#Loss 22 =123.5584\n",
      "#Loss 23 =77.5645\n",
      "#Loss 24 =60.0115\n",
      "#Loss 25 =56.1152\n",
      "#Loss 26 =52.9113\n",
      "#Loss 27 =50.2461\n",
      "#Loss 28 =47.9499\n",
      "#Loss 29 =45.9945\n",
      "#Loss 30 =44.3159\n",
      "#Loss 31 =43.3932\n",
      "#Loss 32 =46.3479\n",
      "#Loss 33 =85.8858\n",
      "#Loss 34 =276.8767\n",
      "#Loss 35 =275.3232\n",
      "#Loss 36 =265.7559\n",
      "#Loss 37 =256.8550\n",
      "#Loss 38 =247.6484\n",
      "#Loss 39 =237.2179\n",
      "#Loss 40 =224.6180\n",
      "#Loss 41 =208.7226\n",
      "#Loss 42 =188.0314\n",
      "#Loss 43 =160.6194\n",
      "#Loss 44 =125.2177\n",
      "#Loss 45 =86.8255\n",
      "#Loss 46 =64.6949\n",
      "#Loss 47 =59.5317\n",
      "#Loss 48 =55.7314\n",
      "#Loss 49 =52.5809\n",
      "#Loss 50 =49.9897\n",
      "#Loss 51 =47.7491\n",
      "#Loss 52 =45.9560\n",
      "#Loss 53 =44.7592\n",
      "#Loss 54 =46.9283\n",
      "#Loss 55 =70.2127\n",
      "#Loss 56 =216.6526\n",
      "#Loss 57 =69.3475\n",
      "#Loss 58 =62.9876\n",
      "#Loss 59 =56.9732\n",
      "#Loss 60 =53.7617\n",
      "#Loss 61 =50.9769\n",
      "#Loss 62 =49.1031\n",
      "#Loss 63 =48.0000\n",
      "#Loss 64 =51.2273\n",
      "#Loss 65 =68.5126\n",
      "#Loss 66 =159.5553\n",
      "#Loss 67 =74.7927\n",
      "#Loss 68 =75.3062\n",
      "#Loss 69 =56.3256\n",
      "#Loss 70 =53.6633\n",
      "#Loss 71 =51.1634\n",
      "#Loss 72 =50.9429\n",
      "#Loss 73 =53.0854\n",
      "#Loss 74 =72.7882\n",
      "#Loss 75 =104.2159\n",
      "#Loss 76 =191.6992\n",
      "#Loss 77 =80.7631\n",
      "#Loss 78 =57.2180\n",
      "#Loss 79 =53.8795\n",
      "#Loss 80 =51.0406\n",
      "#Loss 81 =48.8042\n",
      "#Loss 82 =46.9829\n",
      "#Loss 83 =46.6082\n",
      "#Loss 84 =51.1977\n",
      "#Loss 85 =90.6026\n",
      "#Loss 86 =174.4415\n",
      "#Loss 87 =238.7648\n",
      "#Loss 88 =191.7062\n",
      "#Loss 89 =146.6642\n",
      "#Loss 90 =99.8736\n",
      "#Loss 91 =66.1803\n",
      "#Loss 92 =59.0425\n",
      "#Loss 93 =55.3445\n",
      "#Loss 94 =52.2373\n",
      "#Loss 95 =49.7980\n",
      "#Loss 96 =47.7376\n",
      "#Loss 97 =46.6965\n",
      "#Loss 98 =48.2461\n",
      "#Loss 99 =67.5968\n",
      "#Loss 100 =145.2917\n",
      "#Loss 101 =267.8920\n",
      "#Loss 102 =179.9402\n",
      "#Loss 103 =120.9307\n",
      "#Loss 104 =74.1634\n",
      "#Loss 105 =59.2612\n",
      "#Loss 106 =55.5146\n",
      "#Loss 107 =52.3926\n",
      "#Loss 108 =49.8577\n",
      "#Loss 109 =47.6730\n",
      "#Loss 110 =46.0852\n",
      "#Loss 111 =45.6142\n",
      "#Loss 112 =52.4604\n",
      "#Loss 113 =100.1638\n",
      "#Loss 114 =273.5389\n",
      "#Loss 115 =99.8429\n",
      "#Loss 116 =61.2423\n",
      "#Loss 117 =56.3221\n",
      "#Loss 118 =53.2190\n",
      "#Loss 119 =50.5377\n",
      "#Loss 120 =48.7096\n",
      "#Loss 121 =47.7060\n",
      "#Loss 122 =51.3474\n",
      "#Loss 123 =71.2392\n",
      "#Loss 124 =172.6293\n",
      "#Loss 125 =67.7205\n",
      "#Loss 126 =64.5887\n",
      "#Loss 127 =55.7401\n",
      "#Loss 128 =53.7697\n",
      "#Loss 129 =51.7499\n",
      "#Loss 130 =54.0502\n",
      "#Loss 131 =60.3940\n",
      "#Loss 132 =99.3752\n",
      "#Loss 133 =93.2404\n",
      "#Loss 134 =133.1107\n",
      "#Loss 135 =60.0218\n",
      "#Loss 136 =55.0018\n",
      "#Loss 137 =52.4876\n",
      "#Loss 138 =50.2909\n",
      "#Loss 139 =50.3014\n",
      "#Loss 140 =53.5891\n",
      "#Loss 141 =79.2703\n",
      "#Loss 142 =115.3012\n",
      "#Loss 143 =198.5358\n",
      "#Loss 144 =98.7084\n",
      "#Loss 145 =59.8384\n",
      "#Loss 146 =55.5458\n",
      "#Loss 147 =52.5752\n",
      "#Loss 148 =50.0134\n",
      "#Loss 149 =48.2801\n",
      "#Loss 150 =47.4955\n",
      "#Loss 151 =52.2207\n",
      "#Loss 152 =77.4613\n",
      "#Loss 153 =194.9112\n",
      "#Loss 154 =60.1250\n",
      "#Loss 155 =56.1945\n",
      "#Loss 156 =52.9216\n",
      "#Loss 157 =50.3630\n",
      "#Loss 158 =48.1783\n",
      "#Loss 159 =46.8551\n",
      "#Loss 160 =47.3264\n",
      "#Loss 161 =59.6986\n",
      "#Loss 162 =119.8900\n",
      "#Loss 163 =267.2394\n",
      "#Loss 164 =136.6177\n",
      "#Loss 165 =78.0427\n",
      "#Loss 166 =58.5019\n",
      "#Loss 167 =54.9022\n",
      "#Loss 168 =51.8913\n",
      "#Loss 169 =49.4168\n",
      "#Loss 170 =47.2787\n",
      "#Loss 171 =45.6790\n",
      "#Loss 172 =45.1094\n",
      "#Loss 173 =51.4371\n",
      "#Loss 174 =100.1631\n",
      "#Loss 175 =283.2438\n",
      "#Loss 176 =103.4138\n",
      "#Loss 177 =62.5902\n",
      "#Loss 178 =56.8317\n",
      "#Loss 179 =53.6477\n",
      "#Loss 180 =50.8873\n",
      "#Loss 181 =49.0373\n",
      "#Loss 182 =47.9843\n",
      "#Loss 183 =51.4444\n",
      "#Loss 184 =69.6752\n",
      "#Loss 185 =163.8776\n",
      "#Loss 186 =71.4607\n",
      "#Loss 187 =70.2538\n",
      "#Loss 188 =56.2179\n",
      "#Loss 189 =53.9733\n",
      "#Loss 190 =51.6711\n",
      "#Loss 191 =52.8974\n",
      "#Loss 192 =57.3437\n",
      "#Loss 193 =88.0067\n",
      "#Loss 194 =100.1064\n",
      "#Loss 195 =157.8827\n",
      "#Loss 196 =68.5253\n",
      "#Loss 197 =56.6381\n",
      "#Loss 198 =53.7487\n",
      "#Loss 199 =51.1070\n",
      "#Loss 200 =50.2003\n",
      "超过迭代上限\n",
      " 2 50 绝对误差 tensor(3.2499, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(1.6954, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0414, dtype=torch.float64)   实验回归误差 tensor(0.4243, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.4000, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 50   条件数 1.0\n",
      "Loss 0 =17.6605\n",
      "#Loss 1 =17.4417\n",
      "#Loss 2 =15.1141\n",
      "#Loss 3 =13.1192\n",
      "#Loss 4 =11.4167\n",
      "#Loss 5 =9.9668\n",
      "#Loss 6 =8.7326\n",
      "#Loss 7 =7.6814\n",
      "#Loss 8 =6.7847\n",
      "#Loss 9 =6.0180\n",
      "#Loss 10 =5.3609\n",
      "#Loss 11 =4.7961\n",
      "#Loss 12 =4.3092\n",
      "#Loss 13 =3.8882\n",
      "#Loss 14 =3.5230\n",
      "#Loss 15 =3.2053\n",
      "#Loss 16 =2.9280\n",
      "#Loss 17 =2.6853\n",
      "#Loss 18 =2.4722\n",
      "#Loss 19 =2.2845\n",
      "#Loss 20 =2.1187\n",
      "#Loss 21 =1.9717\n",
      "#Loss 22 =1.8411\n",
      "#Loss 23 =1.7247\n",
      "#Loss 24 =1.6205\n",
      "#Loss 25 =1.5271\n",
      "#Loss 26 =1.4430\n",
      "#Loss 27 =1.3671\n",
      "#Loss 28 =1.2984\n",
      "#Loss 29 =1.2359\n",
      "#Loss 30 =1.1790\n",
      "#Loss 31 =1.1270\n",
      "#Loss 32 =1.0794\n",
      "#Loss 33 =1.0356\n",
      "#Loss 34 =0.9952\n",
      "#Loss 35 =0.9579\n",
      "#Loss 36 =0.9234\n",
      "#Loss 37 =0.8913\n",
      "#Loss 38 =0.8615\n",
      "#Loss 39 =0.8336\n",
      "#Loss 40 =0.8076\n",
      "#Loss 41 =0.7832\n",
      "#Loss 42 =0.7603\n",
      "#Loss 43 =0.7388\n",
      "#Loss 44 =0.7186\n",
      "#Loss 45 =0.6995\n",
      "#Loss 46 =0.6815\n",
      "#Loss 47 =0.6645\n",
      "#Loss 48 =0.6484\n",
      "#Loss 49 =0.6331\n",
      "#Loss 50 =0.6187\n",
      "#Loss 51 =0.6050\n",
      "#Loss 52 =0.5919\n",
      "#Loss 53 =0.5796\n",
      "#Loss 54 =0.5678\n",
      "#Loss 55 =0.5566\n",
      "#Loss 56 =0.5459\n",
      "#Loss 57 =0.5358\n",
      "#Loss 58 =0.5261\n",
      "#Loss 59 =0.5169\n",
      "#Loss 60 =0.5081\n",
      "#Loss 61 =0.4997\n",
      "#Loss 62 =0.4917\n",
      "#Loss 63 =0.4840\n",
      "#Loss 64 =0.4767\n",
      "#Loss 65 =0.4697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 66 =0.4631\n",
      "#Loss 67 =0.4567\n",
      "#Loss 68 =0.4506\n",
      "#Loss 69 =0.4448\n",
      "#Loss 70 =0.4392\n",
      "#Loss 71 =0.4339\n",
      "#Loss 72 =0.4288\n",
      "#Loss 73 =0.4239\n",
      "#Loss 74 =0.4193\n",
      "#Loss 75 =0.4148\n",
      "#Loss 76 =0.4105\n",
      "#Loss 77 =0.4065\n",
      "#Loss 78 =0.4025\n",
      "#Loss 79 =0.3988\n",
      "#Loss 80 =0.3952\n",
      "#Loss 81 =0.3918\n",
      "#Loss 82 =0.3885\n",
      "#Loss 83 =0.3853\n",
      "#Loss 84 =0.3823\n",
      "#Loss 85 =0.3794\n",
      "#Loss 86 =0.3767\n",
      "#Loss 87 =0.3740\n",
      "#Loss 88 =0.3714\n",
      "#Loss 89 =0.3690\n",
      "#Loss 90 =0.3667\n",
      "#Loss 91 =0.3644\n",
      "#Loss 92 =0.3623\n",
      "#Loss 93 =0.3602\n",
      "#Loss 94 =0.3582\n",
      "#Loss 95 =0.3563\n",
      "#Loss 96 =0.3545\n",
      "#Loss 97 =0.3527\n",
      "#Loss 98 =0.3511\n",
      "#Loss 99 =0.3495\n",
      "#Loss 100 =0.3479\n",
      "#Loss 101 =0.3464\n",
      "#Loss 102 =0.3450\n",
      "#Loss 103 =0.3436\n",
      "#Loss 104 =0.3423\n",
      "#Loss 105 =0.3410\n",
      "#Loss 106 =0.3398\n",
      "#Loss 107 =0.3387\n",
      "#Loss 108 =0.3376\n",
      "#Loss 109 =0.3365\n",
      "#Loss 110 =0.3354\n",
      "#Loss 111 =0.3345\n",
      "#Loss 112 =0.3335\n",
      "#Loss 113 =0.3326\n",
      "#Loss 114 =0.3317\n",
      "#Loss 115 =0.3308\n",
      "#Loss 116 =0.3300\n",
      "#Loss 117 =0.3292\n",
      "#Loss 118 =0.3285\n",
      "#Loss 119 =0.3278\n",
      "#Loss 120 =0.3271\n",
      "#Loss 121 =0.3264\n",
      "#Loss 122 =0.3258\n",
      "#Loss 123 =0.3251\n",
      "#Loss 124 =0.3245\n",
      "#Loss 125 =0.3240\n",
      "#Loss 126 =0.3234\n",
      "#Loss 127 =0.3229\n",
      "#Loss 128 =0.3224\n",
      "#Loss 129 =0.3219\n",
      "#Loss 130 =0.3214\n",
      "#Loss 131 =0.3209\n",
      "#Loss 132 =0.3205\n",
      "#Loss 133 =0.3201\n",
      "#Loss 134 =0.3197\n",
      "#Loss 135 =0.3193\n",
      "#Loss 136 =0.3189\n",
      "#Loss 137 =0.3185\n",
      "#Loss 138 =0.3182\n",
      "#Loss 139 =0.3178\n",
      "#Loss 140 =0.3175\n",
      "#Loss 141 =0.3172\n",
      "#Loss 142 =0.3169\n",
      "#Loss 143 =0.3166\n",
      "#Loss 144 =0.3163\n",
      "#Loss 145 =0.3160\n",
      "#Loss 146 =0.3158\n",
      "#Loss 147 =0.3155\n",
      "#Loss 148 =0.3153\n",
      "#Loss 149 =0.3151\n",
      "#Loss 150 =0.3148\n",
      "#Loss 151 =0.3146\n",
      "#Loss 152 =0.3144\n",
      "#Loss 153 =0.3142\n",
      "#Loss 154 =0.3140\n",
      "#Loss 155 =0.3138\n",
      "#Loss 156 =0.3136\n",
      "#Loss 157 =0.3135\n",
      "#Loss 158 =0.3133\n",
      "#Loss 159 =0.3131\n",
      "#Loss 160 =0.3130\n",
      "#Loss 161 =0.3128\n",
      "#Loss 162 =0.3127\n",
      "#Loss 163 =0.3125\n",
      "#Loss 164 =0.3124\n",
      "#Loss 165 =0.3123\n",
      "#Loss 166 =0.3121\n",
      "#Loss 167 =0.3120\n",
      "#Loss 168 =0.3119\n",
      "#Loss 169 =0.3118\n",
      "#Loss 170 =0.3117\n",
      "#Loss 171 =0.3116\n",
      "#Loss 172 =0.3115\n",
      "#Loss 173 =0.3114\n",
      "#Loss 174 =0.3113\n",
      "#Loss 175 =0.3112\n",
      "#Loss 176 =0.3111\n",
      "#Loss 177 =0.3110\n",
      "#Loss 178 =0.3109\n",
      "#Loss 179 =0.3109\n",
      "#Loss 180 =0.3108\n",
      "#Loss 181 =0.3107\n",
      "#Loss 182 =0.3106\n",
      "#Loss 183 =0.3106\n",
      "#Loss 184 =0.3105\n",
      "#Loss 185 =0.3104\n",
      "#Loss 186 =0.3104\n",
      "#Loss 187 =0.3103\n",
      "#Loss 188 =0.3102\n",
      "#Loss 189 =0.3102\n",
      "#Loss 190 =0.3101\n",
      "#Loss 191 =0.3101\n",
      "#Loss 192 =0.3100\n",
      "#Loss 193 =0.3100\n",
      "#Loss 194 =0.3099\n",
      "#Loss 195 =0.3099\n",
      "#Loss 196 =0.3098\n",
      "#Loss 197 =0.3098\n",
      "#Loss 198 =0.3098\n",
      "#Loss 199 =0.3097\n",
      "#Loss 200 =0.3097\n",
      "超过迭代上限\n",
      " 2 50 绝对误差 tensor(0.0614, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(0.0660, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.1790, dtype=torch.float64)   实验回归误差 tensor(0.1324, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.3266, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 50   条件数 1.0\n",
      "Loss 0 =598.4646\n",
      "#Loss 1 =597.8280\n",
      "#Loss 2 =527.2197\n",
      "#Loss 3 =441.5457\n",
      "#Loss 4 =162.0381\n",
      "#Loss 5 =13128.3587\n",
      "#Loss 6 =586.8313\n",
      "#Loss 7 =586.8306\n",
      " 2 50 绝对误差 tensor(95.7187, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(75.5631, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0306, dtype=torch.float64)   实验回归误差 tensor(1.0001, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.0000, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 0   条件数 1.0\n",
      "Loss 0 =45.6246\n",
      "#Loss 1 =44.7317\n",
      "#Loss 2 =37.1357\n",
      "#Loss 3 =31.0560\n",
      "#Loss 4 =26.1472\n",
      "#Loss 5 =22.1184\n",
      "#Loss 6 =18.7519\n",
      "#Loss 7 =15.8968\n",
      "#Loss 8 =13.4531\n",
      "#Loss 9 =11.3557\n",
      "#Loss 10 =9.5615\n",
      "#Loss 11 =8.0395\n",
      "#Loss 12 =6.7638\n",
      "#Loss 13 =5.7103\n",
      "#Loss 14 =4.8541\n",
      "#Loss 15 =4.1695\n",
      "#Loss 16 =3.6304\n",
      "#Loss 17 =3.2113\n",
      "#Loss 18 =2.8881\n",
      "#Loss 19 =2.6405\n",
      "#Loss 20 =2.4504\n",
      "#Loss 21 =2.3029\n",
      "#Loss 22 =2.1872\n",
      "#Loss 23 =2.0947\n",
      "#Loss 24 =2.0187\n",
      "#Loss 25 =1.9543\n",
      "#Loss 26 =1.8982\n",
      "#Loss 27 =1.8484\n",
      "#Loss 28 =1.8032\n",
      "#Loss 29 =1.7616\n",
      "#Loss 30 =1.7226\n",
      "#Loss 31 =1.6859\n",
      "#Loss 32 =1.6510\n",
      "#Loss 33 =1.6176\n",
      "#Loss 34 =1.5853\n",
      "#Loss 35 =1.5536\n",
      "#Loss 36 =1.5231\n",
      "#Loss 37 =1.4936\n",
      "#Loss 38 =1.4651\n",
      "#Loss 39 =1.4376\n",
      "#Loss 40 =1.4111\n",
      "#Loss 41 =1.3855\n",
      "#Loss 42 =1.3607\n",
      "#Loss 43 =1.3368\n",
      "#Loss 44 =1.3137\n",
      "#Loss 45 =1.2914\n",
      "#Loss 46 =1.2698\n",
      "#Loss 47 =1.2489\n",
      "#Loss 48 =1.2287\n",
      "#Loss 49 =1.2091\n",
      "#Loss 50 =1.1899\n",
      "#Loss 51 =1.1713\n",
      "#Loss 52 =1.1533\n",
      "#Loss 53 =1.1353\n",
      "#Loss 54 =1.1179\n",
      "#Loss 55 =1.1010\n",
      "#Loss 56 =1.0847\n",
      "#Loss 57 =1.0688\n",
      "#Loss 58 =1.0533\n",
      "#Loss 59 =1.0382\n",
      "#Loss 60 =1.0236\n",
      "#Loss 61 =1.0095\n",
      "#Loss 62 =0.9958\n",
      "#Loss 63 =0.9826\n",
      "#Loss 64 =0.9696\n",
      "#Loss 65 =0.9570\n",
      "#Loss 66 =0.9448\n",
      "#Loss 67 =0.9331\n",
      "#Loss 68 =0.9215\n",
      "#Loss 69 =0.9103\n",
      "#Loss 70 =0.8993\n",
      "#Loss 71 =0.8887\n",
      "#Loss 72 =0.8783\n",
      "#Loss 73 =0.8684\n",
      "#Loss 74 =0.8587\n",
      "#Loss 75 =0.8494\n",
      "#Loss 76 =0.8404\n",
      "#Loss 77 =0.8315\n",
      "#Loss 78 =0.8225\n",
      "#Loss 79 =0.8138\n",
      "#Loss 80 =0.8053\n",
      "#Loss 81 =0.7971\n",
      "#Loss 82 =0.7891\n",
      "#Loss 83 =0.7814\n",
      "#Loss 84 =0.7740\n",
      "#Loss 85 =0.7668\n",
      "#Loss 86 =0.7598\n",
      "#Loss 87 =0.7528\n",
      "#Loss 88 =0.7461\n",
      "#Loss 89 =0.7396\n",
      "#Loss 90 =0.7333\n",
      "#Loss 91 =0.7272\n",
      "#Loss 92 =0.7208\n",
      "#Loss 93 =0.7144\n",
      "#Loss 94 =0.7082\n",
      "#Loss 95 =0.7021\n",
      "#Loss 96 =0.6963\n",
      "#Loss 97 =0.6906\n",
      "#Loss 98 =0.6851\n",
      "#Loss 99 =0.6798\n",
      "#Loss 100 =0.6746\n",
      "#Loss 101 =0.6695\n",
      "#Loss 102 =0.6646\n",
      "#Loss 103 =0.6599\n",
      "#Loss 104 =0.6553\n",
      "#Loss 105 =0.6509\n",
      "#Loss 106 =0.6463\n",
      "#Loss 107 =0.6414\n",
      "#Loss 108 =0.6367\n",
      "#Loss 109 =0.6322\n",
      "#Loss 110 =0.6278\n",
      "#Loss 111 =0.6236\n",
      "#Loss 112 =0.6196\n",
      "#Loss 113 =0.6156\n",
      "#Loss 114 =0.6118\n",
      "#Loss 115 =0.6081\n",
      "#Loss 116 =0.6046\n",
      "#Loss 117 =0.6012\n",
      "#Loss 118 =0.5979\n",
      "#Loss 119 =0.5947\n",
      "#Loss 120 =0.5917\n",
      "#Loss 121 =0.5887\n",
      "#Loss 122 =0.5859\n",
      "#Loss 123 =0.5831\n",
      "#Loss 124 =0.5804\n",
      "#Loss 125 =0.5777\n",
      "#Loss 126 =0.5751\n",
      "#Loss 127 =0.5725\n",
      "#Loss 128 =0.5698\n",
      "#Loss 129 =0.5672\n",
      "#Loss 130 =0.5647\n",
      "#Loss 131 =0.5622\n",
      "#Loss 132 =0.5584\n",
      "#Loss 133 =0.5547\n",
      "#Loss 134 =0.5511\n",
      "#Loss 135 =0.5475\n",
      "#Loss 136 =0.5439\n",
      "#Loss 137 =0.5404\n",
      "#Loss 138 =0.5368\n",
      "#Loss 139 =0.5324\n",
      "#Loss 140 =0.5282\n",
      "#Loss 141 =0.5241\n",
      "#Loss 142 =0.5201\n",
      "#Loss 143 =0.5161\n",
      "#Loss 144 =0.5121\n",
      "#Loss 145 =0.5080\n",
      "#Loss 146 =0.5041\n",
      "#Loss 147 =0.5004\n",
      "#Loss 148 =0.4968\n",
      "#Loss 149 =0.4933\n",
      "#Loss 150 =0.4899\n",
      "#Loss 151 =0.4863\n",
      "#Loss 152 =0.4829\n",
      "#Loss 153 =0.4796\n",
      "#Loss 154 =0.4765\n",
      "#Loss 155 =0.4734\n",
      "#Loss 156 =0.4705\n",
      "#Loss 157 =0.4677\n",
      "#Loss 158 =0.4650\n",
      "#Loss 159 =0.4624\n",
      "#Loss 160 =0.4599\n",
      "#Loss 161 =0.4575\n",
      "#Loss 162 =0.4552\n",
      "#Loss 163 =0.4530\n",
      "#Loss 164 =0.4509\n",
      "#Loss 165 =0.4488\n",
      "#Loss 166 =0.4469\n",
      "#Loss 167 =0.4449\n",
      "#Loss 168 =0.4431\n",
      "#Loss 169 =0.4413\n",
      "#Loss 170 =0.4395\n",
      "#Loss 171 =0.4379\n",
      "#Loss 172 =0.4363\n",
      "#Loss 173 =0.4348\n",
      "#Loss 174 =0.4334\n",
      "#Loss 175 =0.4317\n",
      "#Loss 176 =0.4298\n",
      "#Loss 177 =0.4278\n",
      "#Loss 178 =0.4260\n",
      "#Loss 179 =0.4241\n",
      "#Loss 180 =0.4219\n",
      "#Loss 181 =0.4199\n",
      "#Loss 182 =0.4179\n",
      "#Loss 183 =0.4158\n",
      "#Loss 184 =0.4134\n",
      "#Loss 185 =0.4111\n",
      "#Loss 186 =0.4089\n",
      "#Loss 187 =0.4069\n",
      "#Loss 188 =0.4049\n",
      "#Loss 189 =0.4030\n",
      "#Loss 190 =0.4012\n",
      "#Loss 191 =0.3992\n",
      "#Loss 192 =0.3965\n",
      "#Loss 193 =0.3940\n",
      "#Loss 194 =0.3915\n",
      "#Loss 195 =0.3890\n",
      "#Loss 196 =0.3867\n",
      "#Loss 197 =0.3844\n",
      "#Loss 198 =0.3821\n",
      "#Loss 199 =0.3796\n",
      "#Loss 200 =0.3767\n",
      "超过迭代上限\n",
      " 2 50 绝对误差 tensor(0.2630, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(0.1688, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.1063, dtype=torch.float64)   实验回归误差 tensor(0.0905, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.3565, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 50   条件数 1.0\n",
      "Loss 0 =28.2352\n",
      "#Loss 1 =27.9772\n",
      "#Loss 2 =21.8947\n",
      "#Loss 3 =17.3074\n",
      "#Loss 4 =13.8971\n",
      "#Loss 5 =11.3562\n",
      "#Loss 6 =9.4420\n",
      "#Loss 7 =7.9786\n",
      "#Loss 8 =6.8426\n",
      "#Loss 9 =5.9478\n",
      "#Loss 10 =5.2335\n",
      "#Loss 11 =4.6567\n",
      "#Loss 12 =4.1860\n",
      "#Loss 13 =3.7984\n",
      "#Loss 14 =3.4765\n",
      "#Loss 15 =3.2072\n",
      "#Loss 16 =2.9804\n",
      "#Loss 17 =2.7882\n",
      "#Loss 18 =2.6243\n",
      "#Loss 19 =2.4838\n",
      "#Loss 20 =2.3627\n",
      "#Loss 21 =2.2577\n",
      "#Loss 22 =2.1663\n",
      "#Loss 23 =2.0865\n",
      "#Loss 24 =2.0166\n",
      "#Loss 25 =1.9551\n",
      "#Loss 26 =1.9008\n",
      "#Loss 27 =1.8527\n",
      "#Loss 28 =1.8088\n",
      "#Loss 29 =1.7675\n",
      "#Loss 30 =1.7305\n",
      "#Loss 31 =1.6975\n",
      "#Loss 32 =1.6678\n",
      "#Loss 33 =1.6412\n",
      "#Loss 34 =1.6172\n",
      "#Loss 35 =1.5955\n",
      "#Loss 36 =1.5759\n",
      "#Loss 37 =1.5571\n",
      "#Loss 38 =1.5361\n",
      "#Loss 39 =1.5169\n",
      "#Loss 40 =1.4994\n",
      "#Loss 41 =1.4834\n",
      "#Loss 42 =1.4686\n",
      "#Loss 43 =1.4522\n",
      "#Loss 44 =1.4303\n",
      "#Loss 45 =1.4102\n",
      "#Loss 46 =1.3918\n",
      "#Loss 47 =1.3749\n",
      "#Loss 48 =1.3595\n",
      "#Loss 49 =1.3453\n",
      "#Loss 50 =1.3313\n",
      "#Loss 51 =1.3184\n",
      "#Loss 52 =1.3066\n",
      "#Loss 53 =1.2956\n",
      "#Loss 54 =1.2852\n",
      "#Loss 55 =1.2758\n",
      "#Loss 56 =1.2671\n",
      "#Loss 57 =1.2591\n",
      "#Loss 58 =1.2518\n",
      "#Loss 59 =1.2450\n",
      "#Loss 60 =1.2389\n",
      "#Loss 61 =1.2332\n",
      "#Loss 62 =1.2281\n",
      "#Loss 63 =1.2233\n",
      "#Loss 64 =1.2190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 65 =1.2150\n",
      "#Loss 66 =1.2113\n",
      "#Loss 67 =1.2079\n",
      "#Loss 68 =1.2043\n",
      "#Loss 69 =1.2011\n",
      "#Loss 70 =1.1979\n",
      "#Loss 71 =1.1941\n",
      "#Loss 72 =1.1905\n",
      "#Loss 73 =1.1872\n",
      "#Loss 74 =1.1842\n",
      "#Loss 75 =1.1813\n",
      "#Loss 76 =1.1781\n",
      "#Loss 77 =1.1752\n",
      "#Loss 78 =1.1726\n",
      "#Loss 79 =1.1701\n",
      "#Loss 80 =1.1679\n",
      "#Loss 81 =1.1659\n",
      "#Loss 82 =1.1640\n",
      "#Loss 83 =1.1623\n",
      "#Loss 84 =1.1607\n",
      "#Loss 85 =1.1592\n",
      "#Loss 86 =1.1576\n",
      "#Loss 87 =1.1556\n",
      "#Loss 88 =1.1536\n",
      "#Loss 89 =1.1517\n",
      "#Loss 90 =1.1499\n",
      "#Loss 91 =1.1480\n",
      "#Loss 92 =1.1463\n",
      "#Loss 93 =1.1447\n",
      "#Loss 94 =1.1432\n",
      "#Loss 95 =1.1418\n",
      "#Loss 96 =1.1406\n",
      "#Loss 97 =1.1394\n",
      "#Loss 98 =1.1384\n",
      "#Loss 99 =1.1374\n",
      "#Loss 100 =1.1362\n",
      "#Loss 101 =1.1352\n",
      "#Loss 102 =1.1343\n",
      "#Loss 103 =1.1334\n",
      "#Loss 104 =1.1327\n",
      "#Loss 105 =1.1319\n",
      "#Loss 106 =1.1313\n",
      "#Loss 107 =1.1307\n",
      "#Loss 108 =1.1301\n",
      "#Loss 109 =1.1296\n",
      "#Loss 110 =1.1291\n",
      "#Loss 111 =1.1285\n",
      "#Loss 112 =1.1280\n",
      "#Loss 113 =1.1275\n",
      "#Loss 114 =1.1270\n",
      "#Loss 115 =1.1266\n",
      "#Loss 116 =1.1262\n",
      "#Loss 117 =1.1259\n",
      "#Loss 118 =1.1256\n",
      "#Loss 119 =1.1253\n",
      "#Loss 120 =1.1250\n",
      "#Loss 121 =1.1248\n",
      "#Loss 122 =1.1246\n",
      "#Loss 123 =1.1243\n",
      "#Loss 124 =1.1242\n",
      "#Loss 125 =1.1240\n",
      "#Loss 126 =1.1238\n",
      "#Loss 127 =1.1237\n",
      "#Loss 128 =1.1234\n",
      "#Loss 129 =1.1229\n",
      "#Loss 130 =1.1223\n",
      "#Loss 131 =1.1219\n",
      "#Loss 132 =1.1214\n",
      "#Loss 133 =1.1210\n",
      "#Loss 134 =1.1206\n",
      "#Loss 135 =1.1203\n",
      "#Loss 136 =1.1200\n",
      "#Loss 137 =1.1197\n",
      "#Loss 138 =1.1195\n",
      "#Loss 139 =1.1192\n",
      "#Loss 140 =1.1190\n",
      "#Loss 141 =1.1188\n",
      "#Loss 142 =1.1186\n",
      "#Loss 143 =1.1184\n",
      "#Loss 144 =1.1183\n",
      "#Loss 145 =1.1181\n",
      "#Loss 146 =1.1180\n",
      "#Loss 147 =1.1179\n",
      "#Loss 148 =1.1178\n",
      "#Loss 149 =1.1177\n",
      "#Loss 150 =1.1176\n",
      "#Loss 151 =1.1175\n",
      "#Loss 152 =1.1174\n",
      "#Loss 153 =1.1174\n",
      "#Loss 154 =1.1173\n",
      "#Loss 155 =1.1173\n",
      "#Loss 156 =1.1172\n",
      "#Loss 157 =1.1171\n",
      "#Loss 158 =1.1171\n",
      "#Loss 159 =1.1171\n",
      "#Loss 160 =1.1170\n",
      "#Loss 161 =1.1170\n",
      "#Loss 162 =1.1170\n",
      "#Loss 163 =1.1169\n",
      " 2 50 绝对误差 tensor(0.8770, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(0.4963, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.1196, dtype=torch.float64)   实验回归误差 tensor(0.1989, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.3856, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 50   条件数 1.0\n",
      "Loss 0 =164.0960\n",
      "#Loss 1 =162.4499\n",
      "#Loss 2 =128.2247\n",
      "#Loss 3 =102.4623\n",
      "#Loss 4 =74.0154\n",
      "#Loss 5 =38.5879\n",
      "#Loss 6 =7.8357\n",
      "#Loss 7 =5.4553\n",
      "#Loss 8 =5.3321\n",
      "#Loss 9 =4.5647\n",
      "#Loss 10 =9.1853\n",
      "#Loss 11 =10.1740\n",
      "#Loss 12 =30.0321\n",
      "#Loss 13 =2.1594\n",
      "#Loss 14 =2.6216\n",
      "#Loss 15 =4.5557\n",
      "#Loss 16 =15.9422\n",
      "#Loss 17 =17.0652\n",
      "#Loss 18 =47.2482\n",
      "#Loss 19 =10.6537\n",
      "#Loss 20 =9.8619\n",
      "#Loss 21 =27.9384\n",
      "#Loss 22 =5.0764\n",
      "#Loss 23 =9.0610\n",
      "#Loss 24 =8.8081\n",
      "#Loss 25 =24.8559\n",
      "#Loss 26 =6.5579\n",
      "#Loss 27 =14.1230\n",
      "#Loss 28 =9.0797\n",
      "#Loss 29 =23.6176\n",
      "#Loss 30 =6.0368\n",
      "#Loss 31 =12.5034\n",
      "#Loss 32 =9.3552\n",
      "#Loss 33 =25.1513\n",
      "#Loss 34 =5.7094\n",
      "#Loss 35 =11.3056\n",
      "#Loss 36 =9.2921\n",
      "#Loss 37 =25.4196\n",
      "#Loss 38 =5.8091\n",
      "#Loss 39 =11.6166\n",
      "#Loss 40 =9.2892\n",
      "#Loss 41 =25.2652\n",
      "#Loss 42 =5.8078\n",
      "#Loss 43 =11.6237\n",
      "#Loss 44 =9.2968\n",
      "#Loss 45 =25.2913\n",
      "#Loss 46 =5.7975\n",
      "#Loss 47 =11.5880\n",
      "#Loss 48 =9.2950\n",
      "#Loss 49 =25.3003\n",
      "#Loss 50 =5.8005\n",
      "#Loss 51 =11.5972\n",
      "#Loss 52 =9.2947\n",
      "#Loss 53 =25.2951\n",
      "#Loss 54 =5.8007\n",
      "#Loss 55 =11.5983\n",
      "#Loss 56 =9.2950\n",
      "#Loss 57 =25.2957\n",
      "#Loss 58 =5.8004\n",
      "#Loss 59 =11.5970\n",
      "#Loss 60 =9.2950\n",
      "#Loss 61 =25.2961\n",
      "#Loss 62 =5.8004\n",
      "#Loss 63 =11.5972\n",
      "#Loss 64 =9.2950\n",
      "#Loss 65 =25.2959\n",
      "#Loss 66 =5.8005\n",
      "#Loss 67 =11.5973\n",
      "#Loss 68 =9.2950\n",
      "#Loss 69 =25.2959\n",
      "#Loss 70 =5.8004\n",
      "#Loss 71 =11.5973\n",
      "#Loss 72 =9.2950\n",
      "#Loss 73 =25.2959\n",
      "#Loss 74 =5.8004\n",
      "#Loss 75 =11.5973\n",
      "#Loss 76 =9.2950\n",
      "#Loss 77 =25.2959\n",
      "#Loss 78 =5.8004\n",
      "#Loss 79 =11.5973\n",
      "#Loss 80 =9.2950\n",
      "#Loss 81 =25.2959\n",
      "#Loss 82 =5.8004\n",
      "#Loss 83 =11.5973\n",
      "#Loss 84 =9.2950\n",
      "#Loss 85 =25.2959\n",
      "#Loss 86 =5.8004\n",
      "#Loss 87 =11.5973\n",
      "#Loss 88 =9.2950\n",
      "#Loss 89 =25.2959\n",
      "#Loss 90 =5.8004\n",
      "#Loss 91 =11.5973\n",
      "#Loss 92 =9.2950\n",
      "#Loss 93 =25.2959\n",
      "#Loss 94 =5.8004\n",
      "#Loss 95 =11.5973\n",
      "#Loss 96 =9.2950\n",
      "#Loss 97 =25.2959\n",
      "#Loss 98 =5.8004\n",
      "#Loss 99 =11.5973\n",
      "#Loss 100 =9.2950\n",
      "#Loss 101 =25.2959\n",
      "#Loss 102 =5.8004\n",
      "#Loss 103 =11.5973\n",
      "#Loss 104 =9.2950\n",
      "#Loss 105 =25.2959\n",
      "#Loss 106 =5.8004\n",
      "#Loss 107 =11.5973\n",
      "#Loss 108 =9.2950\n",
      "#Loss 109 =25.2959\n",
      "#Loss 110 =5.8004\n",
      "#Loss 111 =11.5973\n",
      "#Loss 112 =9.2950\n",
      "#Loss 113 =25.2959\n",
      "#Loss 114 =5.8004\n",
      "#Loss 115 =11.5973\n",
      "#Loss 116 =9.2950\n",
      "#Loss 117 =25.2959\n",
      "#Loss 118 =5.8004\n",
      "#Loss 119 =11.5973\n",
      "#Loss 120 =9.2950\n",
      "#Loss 121 =25.2959\n",
      "#Loss 122 =5.8004\n",
      "#Loss 123 =11.5973\n",
      "#Loss 124 =9.2950\n",
      "#Loss 125 =25.2959\n",
      "#Loss 126 =5.8004\n",
      "#Loss 127 =11.5973\n",
      "#Loss 128 =9.2950\n",
      "#Loss 129 =25.2959\n",
      "#Loss 130 =5.8004\n",
      "#Loss 131 =11.5973\n",
      "#Loss 132 =9.2950\n",
      "#Loss 133 =25.2959\n",
      "#Loss 134 =5.8004\n",
      "#Loss 135 =11.5973\n",
      "#Loss 136 =9.2950\n",
      "#Loss 137 =25.2959\n",
      "#Loss 138 =5.8004\n",
      "#Loss 139 =11.5973\n",
      "#Loss 140 =9.2950\n",
      "#Loss 141 =25.2959\n",
      "#Loss 142 =5.8004\n",
      "#Loss 143 =11.5973\n",
      "#Loss 144 =9.2950\n",
      "#Loss 145 =25.2959\n",
      "#Loss 146 =5.8004\n",
      "#Loss 147 =11.5973\n",
      "#Loss 148 =9.2950\n",
      "#Loss 149 =25.2959\n",
      "#Loss 150 =5.8004\n",
      "#Loss 151 =11.5973\n",
      "#Loss 152 =9.2950\n",
      "#Loss 153 =25.2959\n",
      "#Loss 154 =5.8004\n",
      "#Loss 155 =11.5973\n",
      "#Loss 156 =9.2950\n",
      "#Loss 157 =25.2959\n",
      "#Loss 158 =5.8004\n",
      "#Loss 159 =11.5973\n",
      "#Loss 160 =9.2950\n",
      "#Loss 161 =25.2959\n",
      "#Loss 162 =5.8004\n",
      "#Loss 163 =11.5973\n",
      "#Loss 164 =9.2950\n",
      "#Loss 165 =25.2959\n",
      "#Loss 166 =5.8004\n",
      "#Loss 167 =11.5973\n",
      "#Loss 168 =9.2950\n",
      "#Loss 169 =25.2959\n",
      "#Loss 170 =5.8004\n",
      "#Loss 171 =11.5973\n",
      "#Loss 172 =9.2950\n",
      "#Loss 173 =25.2959\n",
      "#Loss 174 =5.8004\n",
      "#Loss 175 =11.5973\n",
      "#Loss 176 =9.2950\n",
      "#Loss 177 =25.2959\n",
      "#Loss 178 =5.8004\n",
      "#Loss 179 =11.5973\n",
      "#Loss 180 =9.2950\n",
      "#Loss 181 =25.2959\n",
      "#Loss 182 =5.8004\n",
      "#Loss 183 =11.5973\n",
      "#Loss 184 =9.2950\n",
      "#Loss 185 =25.2959\n",
      "#Loss 186 =5.8004\n",
      "#Loss 187 =11.5973\n",
      "#Loss 188 =9.2950\n",
      "#Loss 189 =25.2959\n",
      "#Loss 190 =5.8004\n",
      "#Loss 191 =11.5973\n",
      "#Loss 192 =9.2950\n",
      "#Loss 193 =25.2959\n",
      "#Loss 194 =5.8004\n",
      "#Loss 195 =11.5973\n",
      "#Loss 196 =9.2950\n",
      "#Loss 197 =25.2959\n",
      "#Loss 198 =5.8004\n",
      "#Loss 199 =11.5973\n",
      "#Loss 200 =9.2950\n",
      "超过迭代上限\n",
      " 2 50 绝对误差 tensor(0.2042, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(0.1955, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0550, dtype=torch.float64)   实验回归误差 tensor(0.3939, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.1832, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 50   条件数 1.0\n",
      "Loss 0 =31.7378\n",
      "#Loss 1 =31.6431\n",
      "#Loss 2 =29.4053\n",
      "#Loss 3 =27.5822\n",
      "#Loss 4 =26.0129\n",
      "#Loss 5 =24.5715\n",
      "#Loss 6 =23.1597\n",
      "#Loss 7 =21.6994\n",
      "#Loss 8 =20.1276\n",
      "#Loss 9 =18.3943\n",
      "#Loss 10 =16.4660\n",
      "#Loss 11 =14.3373\n",
      "#Loss 12 =12.0552\n",
      "#Loss 13 =9.7516\n",
      "#Loss 14 =7.6567\n",
      "#Loss 15 =6.0265\n",
      "#Loss 16 =4.9624\n",
      "#Loss 17 =4.3143\n",
      "#Loss 18 =3.8634\n",
      "#Loss 19 =3.4994\n",
      "#Loss 20 =3.1911\n",
      "#Loss 21 =2.9266\n",
      "#Loss 22 =2.6977\n",
      "#Loss 23 =2.4981\n",
      "#Loss 24 =2.3226\n",
      "#Loss 25 =2.1675\n",
      "#Loss 26 =2.0295\n",
      "#Loss 27 =1.9060\n",
      "#Loss 28 =1.7951\n",
      "#Loss 29 =1.6950\n",
      "#Loss 30 =1.6042\n",
      "#Loss 31 =1.5217\n",
      "#Loss 32 =1.4463\n",
      "#Loss 33 =1.3772\n",
      "#Loss 34 =1.3138\n",
      "#Loss 35 =1.2553\n",
      "#Loss 36 =1.2013\n",
      "#Loss 37 =1.1512\n",
      "#Loss 38 =1.1047\n",
      "#Loss 39 =1.0615\n",
      "#Loss 40 =1.0213\n",
      "#Loss 41 =0.9837\n",
      "#Loss 42 =0.9485\n",
      "#Loss 43 =0.9155\n",
      "#Loss 44 =0.8846\n",
      "#Loss 45 =0.8560\n",
      "#Loss 46 =0.8310\n",
      "#Loss 47 =0.8212\n",
      "#Loss 48 =0.9068\n",
      "#Loss 49 =1.7156\n",
      "#Loss 50 =7.8774\n",
      "#Loss 51 =31.5422\n",
      "#Loss 52 =31.5336\n",
      "#Loss 53 =31.5276\n",
      "#Loss 54 =31.5235\n",
      "#Loss 55 =31.5207\n",
      "#Loss 56 =31.5188\n",
      "#Loss 57 =31.5174\n",
      "#Loss 58 =31.5163\n",
      "#Loss 59 =31.5154\n",
      " 2 50 绝对误差 tensor(0.6276, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(0.5136, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.1093, dtype=torch.float64)   实验回归误差 tensor(0.9965, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.3999, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 50   条件数 1.0\n",
      "Loss 0 =34.8235\n",
      "#Loss 1 =34.8234\n",
      " 2 50 绝对误差 tensor(0.8079, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(1.0408, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.1040, dtype=torch.float64)   实验回归误差 tensor(0.9559, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.1419, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 4   条件数 1.0\n",
      "Loss 0 =15.4629\n",
      "#Loss 1 =15.3330\n",
      "#Loss 2 =12.5457\n",
      "#Loss 3 =10.3090\n",
      "#Loss 4 =8.5239\n",
      "#Loss 5 =7.0989\n",
      "#Loss 6 =5.9568\n",
      "#Loss 7 =5.0359\n",
      "#Loss 8 =4.2885\n",
      "#Loss 9 =3.6775\n",
      "#Loss 10 =3.1748\n",
      "#Loss 11 =2.7588\n",
      "#Loss 12 =2.4124\n",
      "#Loss 13 =2.1226\n",
      "#Loss 14 =1.8789\n",
      "#Loss 15 =1.6731\n",
      "#Loss 16 =1.4986\n",
      "#Loss 17 =1.3498\n",
      "#Loss 18 =1.2225\n",
      "#Loss 19 =1.1131\n",
      "#Loss 20 =1.0187\n",
      "#Loss 21 =0.9367\n",
      "#Loss 22 =0.8652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 23 =0.8027\n",
      "#Loss 24 =0.7476\n",
      "#Loss 25 =0.6988\n",
      "#Loss 26 =0.6555\n",
      "#Loss 27 =0.6167\n",
      "#Loss 28 =0.5820\n",
      "#Loss 29 =0.5506\n",
      "#Loss 30 =0.5222\n",
      "#Loss 31 =0.4964\n",
      "#Loss 32 =0.4729\n",
      "#Loss 33 =0.4513\n",
      "#Loss 34 =0.4314\n",
      "#Loss 35 =0.4131\n",
      "#Loss 36 =0.3962\n",
      "#Loss 37 =0.3806\n",
      "#Loss 38 =0.3661\n",
      "#Loss 39 =0.3525\n",
      "#Loss 40 =0.3399\n",
      "#Loss 41 =0.3282\n",
      "#Loss 42 =0.3172\n",
      "#Loss 43 =0.3069\n",
      "#Loss 44 =0.2973\n",
      "#Loss 45 =0.2882\n",
      "#Loss 46 =0.2798\n",
      "#Loss 47 =0.2718\n",
      "#Loss 48 =0.2643\n",
      "#Loss 49 =0.2573\n",
      "#Loss 50 =0.2507\n",
      "#Loss 51 =0.2444\n",
      "#Loss 52 =0.2386\n",
      "#Loss 53 =0.2330\n",
      "#Loss 54 =0.2278\n",
      "#Loss 55 =0.2229\n",
      "#Loss 56 =0.2183\n",
      "#Loss 57 =0.2140\n",
      "#Loss 58 =0.2098\n",
      "#Loss 59 =0.2060\n",
      "#Loss 60 =0.2023\n",
      "#Loss 61 =0.1989\n",
      "#Loss 62 =0.1956\n",
      "#Loss 63 =0.1925\n",
      "#Loss 64 =0.1896\n",
      "#Loss 65 =0.1869\n",
      "#Loss 66 =0.1843\n",
      "#Loss 67 =0.1818\n",
      "#Loss 68 =0.1795\n",
      "#Loss 69 =0.1773\n",
      "#Loss 70 =0.1753\n",
      "#Loss 71 =0.1733\n",
      "#Loss 72 =0.1715\n",
      "#Loss 73 =0.1697\n",
      "#Loss 74 =0.1681\n",
      "#Loss 75 =0.1665\n",
      "#Loss 76 =0.1651\n",
      "#Loss 77 =0.1637\n",
      "#Loss 78 =0.1623\n",
      "#Loss 79 =0.1611\n",
      "#Loss 80 =0.1599\n",
      "#Loss 81 =0.1588\n",
      "#Loss 82 =0.1577\n",
      "#Loss 83 =0.1567\n",
      "#Loss 84 =0.1558\n",
      "#Loss 85 =0.1549\n",
      "#Loss 86 =0.1541\n",
      "#Loss 87 =0.1533\n",
      "#Loss 88 =0.1525\n",
      "#Loss 89 =0.1518\n",
      "#Loss 90 =0.1511\n",
      "#Loss 91 =0.1505\n",
      "#Loss 92 =0.1499\n",
      "#Loss 93 =0.1493\n",
      "#Loss 94 =0.1487\n",
      "#Loss 95 =0.1482\n",
      "#Loss 96 =0.1477\n",
      "#Loss 97 =0.1473\n",
      "#Loss 98 =0.1468\n",
      "#Loss 99 =0.1464\n",
      "#Loss 100 =0.1460\n",
      "#Loss 101 =0.1456\n",
      "#Loss 102 =0.1453\n",
      "#Loss 103 =0.1449\n",
      "#Loss 104 =0.1446\n",
      "#Loss 105 =0.1443\n",
      "#Loss 106 =0.1440\n",
      "#Loss 107 =0.1438\n",
      "#Loss 108 =0.1435\n",
      "#Loss 109 =0.1433\n",
      "#Loss 110 =0.1430\n",
      "#Loss 111 =0.1428\n",
      "#Loss 112 =0.1426\n",
      "#Loss 113 =0.1424\n",
      "#Loss 114 =0.1422\n",
      "#Loss 115 =0.1421\n",
      "#Loss 116 =0.1419\n",
      "#Loss 117 =0.1417\n",
      "#Loss 118 =0.1416\n",
      "#Loss 119 =0.1414\n",
      "#Loss 120 =0.1413\n",
      "#Loss 121 =0.1412\n",
      "#Loss 122 =0.1411\n",
      "#Loss 123 =0.1409\n",
      "#Loss 124 =0.1408\n",
      "#Loss 125 =0.1407\n",
      "#Loss 126 =0.1406\n",
      "#Loss 127 =0.1405\n",
      "#Loss 128 =0.1404\n",
      "#Loss 129 =0.1404\n",
      "#Loss 130 =0.1403\n",
      "#Loss 131 =0.1402\n",
      "#Loss 132 =0.1401\n",
      "#Loss 133 =0.1401\n",
      "#Loss 134 =0.1400\n",
      "#Loss 135 =0.1399\n",
      "#Loss 136 =0.1399\n",
      "#Loss 137 =0.1398\n",
      "#Loss 138 =0.1398\n",
      "#Loss 139 =0.1397\n",
      "#Loss 140 =0.1397\n",
      "#Loss 141 =0.1396\n",
      "#Loss 142 =0.1396\n",
      "#Loss 143 =0.1396\n",
      "#Loss 144 =0.1395\n",
      "#Loss 145 =0.1395\n",
      "#Loss 146 =0.1394\n",
      "#Loss 147 =0.1394\n",
      "#Loss 148 =0.1394\n",
      "#Loss 149 =0.1394\n",
      "#Loss 150 =0.1393\n",
      "#Loss 151 =0.1393\n",
      "#Loss 152 =0.1393\n",
      "#Loss 153 =0.1393\n",
      "#Loss 154 =0.1392\n",
      "#Loss 155 =0.1392\n",
      "#Loss 156 =0.1392\n",
      "#Loss 157 =0.1392\n",
      "#Loss 158 =0.1391\n",
      "#Loss 159 =0.1391\n",
      "#Loss 160 =0.1391\n",
      "#Loss 161 =0.1391\n",
      "#Loss 162 =0.1391\n",
      "#Loss 163 =0.1391\n",
      "#Loss 164 =0.1391\n",
      "#Loss 165 =0.1390\n",
      "#Loss 166 =0.1390\n",
      "#Loss 167 =0.1390\n",
      "#Loss 168 =0.1390\n",
      "#Loss 169 =0.1390\n",
      "#Loss 170 =0.1390\n",
      "#Loss 171 =0.1390\n",
      "#Loss 172 =0.1390\n",
      "#Loss 173 =0.1390\n",
      "#Loss 174 =0.1390\n",
      "#Loss 175 =0.1389\n",
      "#Loss 176 =0.1389\n",
      "#Loss 177 =0.1389\n",
      "#Loss 178 =0.1389\n",
      "#Loss 179 =0.1389\n",
      "#Loss 180 =0.1389\n",
      "#Loss 181 =0.1389\n",
      "#Loss 182 =0.1389\n",
      "#Loss 183 =0.1389\n",
      "#Loss 184 =0.1389\n",
      "#Loss 185 =0.1389\n",
      "#Loss 186 =0.1389\n",
      "#Loss 187 =0.1389\n",
      " 2 50 绝对误差 tensor(0.0192, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(0.0268, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.1882, dtype=torch.float64)   实验回归误差 tensor(0.0948, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.2649, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 50   条件数 1.0\n",
      "Loss 0 =35.0686\n",
      "#Loss 1 =33.8676\n",
      "#Loss 2 =28.8340\n",
      "#Loss 3 =24.7088\n",
      "#Loss 4 =21.2477\n",
      "#Loss 5 =18.2748\n",
      "#Loss 6 =15.6699\n",
      "#Loss 7 =13.3567\n",
      "#Loss 8 =11.2905\n",
      "#Loss 9 =9.4481\n",
      "#Loss 10 =7.8194\n",
      "#Loss 11 =6.4003\n",
      "#Loss 12 =5.1878\n",
      "#Loss 13 =4.1760\n",
      "#Loss 14 =3.3538\n",
      "#Loss 15 =2.7041\n",
      "#Loss 16 =2.2049\n",
      "#Loss 17 =1.8311\n",
      "#Loss 18 =1.5572\n",
      "#Loss 19 =1.3591\n",
      "#Loss 20 =1.2165\n",
      "#Loss 21 =1.1127\n",
      "#Loss 22 =1.0356\n",
      "#Loss 23 =0.9760\n",
      "#Loss 24 =0.9282\n",
      "#Loss 25 =0.8880\n",
      "#Loss 26 =0.8529\n",
      "#Loss 27 =0.8215\n",
      "#Loss 28 =0.7926\n",
      "#Loss 29 =0.7658\n",
      "#Loss 30 =0.7406\n",
      "#Loss 31 =0.7169\n",
      "#Loss 32 =0.6944\n",
      "#Loss 33 =0.6731\n",
      "#Loss 34 =0.6529\n",
      "#Loss 35 =0.6337\n",
      "#Loss 36 =0.6153\n",
      "#Loss 37 =0.5978\n",
      "#Loss 38 =0.5812\n",
      "#Loss 39 =0.5653\n",
      "#Loss 40 =0.5502\n",
      "#Loss 41 =0.5358\n",
      "#Loss 42 =0.5221\n",
      "#Loss 43 =0.5091\n",
      "#Loss 44 =0.4966\n",
      "#Loss 45 =0.4847\n",
      "#Loss 46 =0.4734\n",
      "#Loss 47 =0.4626\n",
      "#Loss 48 =0.4523\n",
      "#Loss 49 =0.4425\n",
      "#Loss 50 =0.4331\n",
      "#Loss 51 =0.4241\n",
      "#Loss 52 =0.4155\n",
      "#Loss 53 =0.4073\n",
      "#Loss 54 =0.3995\n",
      "#Loss 55 =0.3920\n",
      "#Loss 56 =0.3849\n",
      "#Loss 57 =0.3781\n",
      "#Loss 58 =0.3715\n",
      "#Loss 59 =0.3653\n",
      "#Loss 60 =0.3593\n",
      "#Loss 61 =0.3536\n",
      "#Loss 62 =0.3481\n",
      "#Loss 63 =0.3429\n",
      "#Loss 64 =0.3379\n",
      "#Loss 65 =0.3331\n",
      "#Loss 66 =0.3285\n",
      "#Loss 67 =0.3241\n",
      "#Loss 68 =0.3199\n",
      "#Loss 69 =0.3159\n",
      "#Loss 70 =0.3120\n",
      "#Loss 71 =0.3083\n",
      "#Loss 72 =0.3047\n",
      "#Loss 73 =0.3013\n",
      "#Loss 74 =0.2980\n",
      "#Loss 75 =0.2949\n",
      "#Loss 76 =0.2918\n",
      "#Loss 77 =0.2889\n",
      "#Loss 78 =0.2862\n",
      "#Loss 79 =0.2835\n",
      "#Loss 80 =0.2810\n",
      "#Loss 81 =0.2785\n",
      "#Loss 82 =0.2762\n",
      "#Loss 83 =0.2739\n",
      "#Loss 84 =0.2717\n",
      "#Loss 85 =0.2697\n",
      "#Loss 86 =0.2677\n",
      "#Loss 87 =0.2658\n",
      "#Loss 88 =0.2639\n",
      "#Loss 89 =0.2622\n",
      "#Loss 90 =0.2605\n",
      "#Loss 91 =0.2588\n",
      "#Loss 92 =0.2573\n",
      "#Loss 93 =0.2558\n",
      "#Loss 94 =0.2543\n",
      "#Loss 95 =0.2529\n",
      "#Loss 96 =0.2516\n",
      "#Loss 97 =0.2503\n",
      "#Loss 98 =0.2491\n",
      "#Loss 99 =0.2479\n",
      "#Loss 100 =0.2468\n",
      "#Loss 101 =0.2457\n",
      "#Loss 102 =0.2446\n",
      "#Loss 103 =0.2436\n",
      "#Loss 104 =0.2426\n",
      "#Loss 105 =0.2417\n",
      "#Loss 106 =0.2408\n",
      "#Loss 107 =0.2399\n",
      "#Loss 108 =0.2391\n",
      "#Loss 109 =0.2383\n",
      "#Loss 110 =0.2375\n",
      "#Loss 111 =0.2368\n",
      "#Loss 112 =0.2361\n",
      "#Loss 113 =0.2354\n",
      "#Loss 114 =0.2347\n",
      "#Loss 115 =0.2341\n",
      "#Loss 116 =0.2335\n",
      "#Loss 117 =0.2329\n",
      "#Loss 118 =0.2323\n",
      "#Loss 119 =0.2318\n",
      "#Loss 120 =0.2312\n",
      "#Loss 121 =0.2307\n",
      "#Loss 122 =0.2303\n",
      "#Loss 123 =0.2298\n",
      "#Loss 124 =0.2293\n",
      "#Loss 125 =0.2289\n",
      "#Loss 126 =0.2285\n",
      "#Loss 127 =0.2281\n",
      "#Loss 128 =0.2277\n",
      "#Loss 129 =0.2273\n",
      "#Loss 130 =0.2270\n",
      "#Loss 131 =0.2266\n",
      "#Loss 132 =0.2263\n",
      "#Loss 133 =0.2260\n",
      "#Loss 134 =0.2257\n",
      "#Loss 135 =0.2254\n",
      "#Loss 136 =0.2251\n",
      "#Loss 137 =0.2248\n",
      "#Loss 138 =0.2245\n",
      "#Loss 139 =0.2243\n",
      "#Loss 140 =0.2240\n",
      "#Loss 141 =0.2238\n",
      "#Loss 142 =0.2236\n",
      "#Loss 143 =0.2233\n",
      "#Loss 144 =0.2231\n",
      "#Loss 145 =0.2229\n",
      "#Loss 146 =0.2227\n",
      "#Loss 147 =0.2225\n",
      "#Loss 148 =0.2224\n",
      "#Loss 149 =0.2222\n",
      "#Loss 150 =0.2220\n",
      "#Loss 151 =0.2218\n",
      "#Loss 152 =0.2217\n",
      "#Loss 153 =0.2215\n",
      "#Loss 154 =0.2214\n",
      "#Loss 155 =0.2213\n",
      "#Loss 156 =0.2211\n",
      "#Loss 157 =0.2210\n",
      "#Loss 158 =0.2209\n",
      "#Loss 159 =0.2207\n",
      "#Loss 160 =0.2206\n",
      "#Loss 161 =0.2205\n",
      "#Loss 162 =0.2204\n",
      "#Loss 163 =0.2203\n",
      "#Loss 164 =0.2202\n",
      "#Loss 165 =0.2201\n",
      "#Loss 166 =0.2200\n",
      "#Loss 167 =0.2199\n",
      "#Loss 168 =0.2198\n",
      "#Loss 169 =0.2197\n",
      "#Loss 170 =0.2197\n",
      "#Loss 171 =0.2196\n",
      "#Loss 172 =0.2195\n",
      "#Loss 173 =0.2194\n",
      "#Loss 174 =0.2194\n",
      "#Loss 175 =0.2193\n",
      "#Loss 176 =0.2192\n",
      "#Loss 177 =0.2192\n",
      "#Loss 178 =0.2191\n",
      "#Loss 179 =0.2190\n",
      "#Loss 180 =0.2190\n",
      "#Loss 181 =0.2189\n",
      "#Loss 182 =0.2189\n",
      "#Loss 183 =0.2188\n",
      "#Loss 184 =0.2188\n",
      "#Loss 185 =0.2187\n",
      "#Loss 186 =0.2187\n",
      "#Loss 187 =0.2186\n",
      "#Loss 188 =0.2186\n",
      "#Loss 189 =0.2186\n",
      "#Loss 190 =0.2185\n",
      "#Loss 191 =0.2185\n",
      "#Loss 192 =0.2184\n",
      "#Loss 193 =0.2184\n",
      "#Loss 194 =0.2184\n",
      "#Loss 195 =0.2183\n",
      "#Loss 196 =0.2183\n",
      "#Loss 197 =0.2183\n",
      "#Loss 198 =0.2182\n",
      "#Loss 199 =0.2182\n",
      "#Loss 200 =0.2182\n",
      "超过迭代上限\n",
      " 2 50 绝对误差 tensor(0.0282, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(0.0391, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.1230, dtype=torch.float64)   实验回归误差 tensor(0.0789, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.2166, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 50   条件数 1.0\n",
      "Loss 0 =20.9813\n",
      "#Loss 1 =20.9786\n",
      "#Loss 2 =18.4746\n",
      "#Loss 3 =16.3958\n",
      "#Loss 4 =14.6605\n",
      "#Loss 5 =13.1969\n",
      "#Loss 6 =11.9459\n",
      "#Loss 7 =10.8608\n",
      "#Loss 8 =9.9057\n",
      "#Loss 9 =9.0538\n",
      "#Loss 10 =8.2859\n",
      "#Loss 11 =7.5882\n",
      "#Loss 12 =6.9515\n",
      "#Loss 13 =6.3693\n",
      "#Loss 14 =5.8376\n",
      "#Loss 15 =5.3537\n",
      "#Loss 16 =4.9158\n",
      "#Loss 17 =4.5223\n",
      "#Loss 18 =4.1717\n",
      "#Loss 19 =3.8624\n",
      "#Loss 20 =3.5924\n",
      "#Loss 21 =3.3591\n",
      "#Loss 22 =3.1598\n",
      "#Loss 23 =2.9914\n",
      "#Loss 24 =2.8505\n",
      "#Loss 25 =2.7338\n",
      "#Loss 26 =2.6380\n",
      "#Loss 27 =2.5599\n",
      "#Loss 28 =2.4965\n",
      "#Loss 29 =2.4452\n",
      "#Loss 30 =2.4038\n",
      "#Loss 31 =2.3703\n",
      "#Loss 32 =2.3430\n",
      "#Loss 33 =2.3207\n",
      "#Loss 34 =2.3022\n",
      "#Loss 35 =2.2867\n",
      "#Loss 36 =2.2735\n",
      "#Loss 37 =2.2621\n",
      "#Loss 38 =2.2520\n",
      "#Loss 39 =2.2431\n",
      "#Loss 40 =2.2350\n",
      "#Loss 41 =2.2277\n",
      "#Loss 42 =2.2209\n",
      "#Loss 43 =2.2145\n",
      "#Loss 44 =2.2085\n",
      "#Loss 45 =2.2029\n",
      "#Loss 46 =2.1976\n",
      "#Loss 47 =2.1925\n",
      "#Loss 48 =2.1877\n",
      "#Loss 49 =2.1831\n",
      "#Loss 50 =2.1787\n",
      "#Loss 51 =2.1745\n",
      "#Loss 52 =2.1705\n",
      "#Loss 53 =2.1666\n",
      "#Loss 54 =2.1629\n",
      "#Loss 55 =2.1594\n",
      "#Loss 56 =2.1560\n",
      "#Loss 57 =2.1527\n",
      "#Loss 58 =2.1495\n",
      "#Loss 59 =2.1465\n",
      "#Loss 60 =2.1436\n",
      "#Loss 61 =2.1408\n",
      "#Loss 62 =2.1381\n",
      "#Loss 63 =2.1356\n",
      "#Loss 64 =2.1331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 65 =2.1307\n",
      "#Loss 66 =2.1284\n",
      "#Loss 67 =2.1262\n",
      "#Loss 68 =2.1241\n",
      "#Loss 69 =2.1220\n",
      "#Loss 70 =2.1201\n",
      "#Loss 71 =2.1182\n",
      "#Loss 72 =2.1164\n",
      "#Loss 73 =2.1146\n",
      "#Loss 74 =2.1129\n",
      "#Loss 75 =2.1113\n",
      "#Loss 76 =2.1097\n",
      "#Loss 77 =2.1082\n",
      "#Loss 78 =2.1068\n",
      "#Loss 79 =2.1054\n",
      "#Loss 80 =2.1040\n",
      "#Loss 81 =2.1027\n",
      "#Loss 82 =2.1015\n",
      "#Loss 83 =2.1002\n",
      "#Loss 84 =2.0991\n",
      "#Loss 85 =2.0980\n",
      "#Loss 86 =2.0969\n",
      "#Loss 87 =2.0958\n",
      "#Loss 88 =2.0948\n",
      "#Loss 89 =2.0938\n",
      "#Loss 90 =2.0929\n",
      "#Loss 91 =2.0920\n",
      "#Loss 92 =2.0911\n",
      "#Loss 93 =2.0903\n",
      "#Loss 94 =2.0895\n",
      "#Loss 95 =2.0887\n",
      "#Loss 96 =2.0879\n",
      "#Loss 97 =2.0872\n",
      "#Loss 98 =2.0865\n",
      "#Loss 99 =2.0858\n",
      "#Loss 100 =2.0851\n",
      "#Loss 101 =2.0845\n",
      "#Loss 102 =2.0839\n",
      "#Loss 103 =2.0833\n",
      "#Loss 104 =2.0827\n",
      "#Loss 105 =2.0821\n",
      "#Loss 106 =2.0816\n",
      "#Loss 107 =2.0811\n",
      "#Loss 108 =2.0806\n",
      "#Loss 109 =2.0801\n",
      "#Loss 110 =2.0796\n",
      "#Loss 111 =2.0792\n",
      "#Loss 112 =2.0787\n",
      "#Loss 113 =2.0783\n",
      "#Loss 114 =2.0779\n",
      "#Loss 115 =2.0775\n",
      "#Loss 116 =2.0771\n",
      "#Loss 117 =2.0767\n",
      "#Loss 118 =2.0764\n",
      "#Loss 119 =2.0760\n",
      "#Loss 120 =2.0757\n",
      "#Loss 121 =2.0754\n",
      "#Loss 122 =2.0750\n",
      "#Loss 123 =2.0747\n",
      "#Loss 124 =2.0744\n",
      "#Loss 125 =2.0742\n",
      "#Loss 126 =2.0739\n",
      "#Loss 127 =2.0736\n",
      "#Loss 128 =2.0734\n",
      "#Loss 129 =2.0731\n",
      "#Loss 130 =2.0729\n",
      "#Loss 131 =2.0726\n",
      "#Loss 132 =2.0724\n",
      "#Loss 133 =2.0722\n",
      "#Loss 134 =2.0720\n",
      "#Loss 135 =2.0718\n",
      "#Loss 136 =2.0716\n",
      "#Loss 137 =2.0714\n",
      "#Loss 138 =2.0712\n",
      "#Loss 139 =2.0710\n",
      "#Loss 140 =2.0708\n",
      "#Loss 141 =2.0707\n",
      "#Loss 142 =2.0705\n",
      "#Loss 143 =2.0703\n",
      "#Loss 144 =2.0702\n",
      "#Loss 145 =2.0700\n",
      "#Loss 146 =2.0699\n",
      "#Loss 147 =2.0697\n",
      "#Loss 148 =2.0696\n",
      "#Loss 149 =2.0695\n",
      "#Loss 150 =2.0693\n",
      "#Loss 151 =2.0692\n",
      "#Loss 152 =2.0691\n",
      "#Loss 153 =2.0690\n",
      "#Loss 154 =2.0689\n",
      "#Loss 155 =2.0688\n",
      "#Loss 156 =2.0687\n",
      "#Loss 157 =2.0686\n",
      "#Loss 158 =2.0685\n",
      "#Loss 159 =2.0684\n",
      "#Loss 160 =2.0683\n",
      "#Loss 161 =2.0682\n",
      "#Loss 162 =2.0681\n",
      "#Loss 163 =2.0680\n",
      "#Loss 164 =2.0679\n",
      "#Loss 165 =2.0678\n",
      "#Loss 166 =2.0678\n",
      "#Loss 167 =2.0677\n",
      "#Loss 168 =2.0676\n",
      "#Loss 169 =2.0675\n",
      "#Loss 170 =2.0675\n",
      "#Loss 171 =2.0674\n",
      "#Loss 172 =2.0673\n",
      "#Loss 173 =2.0673\n",
      "#Loss 174 =2.0672\n",
      " 2 50 绝对误差 tensor(1.4037, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(1.8104, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.1496, dtype=torch.float64)   实验回归误差 tensor(0.3139, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.4142, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 50   条件数 1.0\n",
      "Loss 0 =3211.8021\n",
      "#Loss 1 =3211.1038\n",
      "#Loss 2 =3013.6301\n",
      "#Loss 3 =2921.7642\n",
      "#Loss 4 =2716.5880\n",
      "#Loss 5 =1424.2390\n",
      "#Loss 6 =10115511.3314\n",
      "#Loss 7 =nan\n",
      " 2 50 绝对误差 tensor(nan, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(nan, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0118, dtype=torch.float64)   实验回归误差 tensor(nan, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.0000, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 0   条件数 1.0\n",
      "Loss 0 =1.0177\n",
      "#Loss 1 =1.0150\n",
      "#Loss 2 =0.8034\n",
      "#Loss 3 =0.6380\n",
      "#Loss 4 =0.5088\n",
      "#Loss 5 =0.4078\n",
      "#Loss 6 =0.3289\n",
      "#Loss 7 =0.2671\n",
      "#Loss 8 =0.2188\n",
      "#Loss 9 =0.1808\n",
      "#Loss 10 =0.1511\n",
      "#Loss 11 =0.1277\n",
      "#Loss 12 =0.1093\n",
      "#Loss 13 =0.0948\n",
      "#Loss 14 =0.0834\n",
      "#Loss 15 =0.0744\n",
      "#Loss 16 =0.0672\n",
      "#Loss 17 =0.0616\n",
      "#Loss 18 =0.0572\n",
      "#Loss 19 =0.0537\n",
      "#Loss 20 =0.0509\n",
      "#Loss 21 =0.0487\n",
      "#Loss 22 =0.0469\n",
      "#Loss 23 =0.0455\n",
      "#Loss 24 =0.0444\n",
      "#Loss 25 =0.0435\n",
      "#Loss 26 =0.0428\n",
      "#Loss 27 =0.0422\n",
      "#Loss 28 =0.0417\n",
      "#Loss 29 =0.0414\n",
      "#Loss 30 =0.0411\n",
      "#Loss 31 =0.0408\n",
      "#Loss 32 =0.0406\n",
      "#Loss 33 =0.0405\n",
      "#Loss 34 =0.0403\n",
      "#Loss 35 =0.0402\n",
      "#Loss 36 =0.0401\n",
      "#Loss 37 =0.0400\n",
      "#Loss 38 =0.0400\n",
      "#Loss 39 =0.0399\n",
      "#Loss 40 =0.0398\n",
      "#Loss 41 =0.0398\n",
      "#Loss 42 =0.0397\n",
      "#Loss 43 =0.0397\n",
      "#Loss 44 =0.0397\n",
      "#Loss 45 =0.0396\n",
      "#Loss 46 =0.0396\n",
      "#Loss 47 =0.0396\n",
      "#Loss 48 =0.0395\n",
      "#Loss 49 =0.0395\n",
      "#Loss 50 =0.0395\n",
      "#Loss 51 =0.0394\n",
      "#Loss 52 =0.0394\n",
      "#Loss 53 =0.0394\n",
      "#Loss 54 =0.0394\n",
      "#Loss 55 =0.0393\n",
      "#Loss 56 =0.0393\n",
      "#Loss 57 =0.0393\n",
      "#Loss 58 =0.0393\n",
      "#Loss 59 =0.0393\n",
      "#Loss 60 =0.0392\n",
      "#Loss 61 =0.0392\n",
      "#Loss 62 =0.0392\n",
      "#Loss 63 =0.0392\n",
      "#Loss 64 =0.0391\n",
      "#Loss 65 =0.0391\n",
      "#Loss 66 =0.0391\n",
      "#Loss 67 =0.0391\n",
      "#Loss 68 =0.0391\n",
      "#Loss 69 =0.0390\n",
      "#Loss 70 =0.0390\n",
      "#Loss 71 =0.0390\n",
      "#Loss 72 =0.0390\n",
      "#Loss 73 =0.0390\n",
      "#Loss 74 =0.0390\n",
      "#Loss 75 =0.0389\n",
      "#Loss 76 =0.0389\n",
      "#Loss 77 =0.0389\n",
      "#Loss 78 =0.0389\n",
      "#Loss 79 =0.0389\n",
      "#Loss 80 =0.0389\n",
      "#Loss 81 =0.0388\n",
      "#Loss 82 =0.0388\n",
      "#Loss 83 =0.0388\n",
      "#Loss 84 =0.0388\n",
      "#Loss 85 =0.0388\n",
      "#Loss 86 =0.0388\n",
      "#Loss 87 =0.0387\n",
      "#Loss 88 =0.0387\n",
      "#Loss 89 =0.0387\n",
      "#Loss 90 =0.0387\n",
      "#Loss 91 =0.0387\n",
      "#Loss 92 =0.0387\n",
      "#Loss 93 =0.0387\n",
      "#Loss 94 =0.0386\n",
      "#Loss 95 =0.0386\n",
      "#Loss 96 =0.0386\n",
      "#Loss 97 =0.0386\n",
      "#Loss 98 =0.0386\n",
      "#Loss 99 =0.0386\n",
      "#Loss 100 =0.0386\n",
      "#Loss 101 =0.0386\n",
      "#Loss 102 =0.0385\n",
      "#Loss 103 =0.0385\n",
      "#Loss 104 =0.0385\n",
      "#Loss 105 =0.0385\n",
      "#Loss 106 =0.0385\n",
      "#Loss 107 =0.0385\n",
      "#Loss 108 =0.0385\n",
      "#Loss 109 =0.0385\n",
      "#Loss 110 =0.0385\n",
      "#Loss 111 =0.0384\n",
      "#Loss 112 =0.0384\n",
      "#Loss 113 =0.0384\n",
      "#Loss 114 =0.0384\n",
      "#Loss 115 =0.0384\n",
      "#Loss 116 =0.0384\n",
      "#Loss 117 =0.0384\n",
      "#Loss 118 =0.0384\n",
      "#Loss 119 =0.0384\n",
      "#Loss 120 =0.0384\n",
      "#Loss 121 =0.0384\n",
      "#Loss 122 =0.0383\n",
      "#Loss 123 =0.0383\n",
      "#Loss 124 =0.0383\n",
      "#Loss 125 =0.0383\n",
      "#Loss 126 =0.0383\n",
      "#Loss 127 =0.0383\n",
      "#Loss 128 =0.0383\n",
      "#Loss 129 =0.0383\n",
      "#Loss 130 =0.0383\n",
      "#Loss 131 =0.0383\n",
      "#Loss 132 =0.0383\n",
      "#Loss 133 =0.0383\n",
      "#Loss 134 =0.0383\n",
      "#Loss 135 =0.0382\n",
      "#Loss 136 =0.0382\n",
      "#Loss 137 =0.0382\n",
      "#Loss 138 =0.0382\n",
      "#Loss 139 =0.0382\n",
      "#Loss 140 =0.0382\n",
      "#Loss 141 =0.0382\n",
      "#Loss 142 =0.0382\n",
      "#Loss 143 =0.0382\n",
      "#Loss 144 =0.0382\n",
      "#Loss 145 =0.0382\n",
      "#Loss 146 =0.0382\n",
      "#Loss 147 =0.0382\n",
      "#Loss 148 =0.0382\n",
      "#Loss 149 =0.0382\n",
      "#Loss 150 =0.0381\n",
      "#Loss 151 =0.0381\n",
      "#Loss 152 =0.0381\n",
      "#Loss 153 =0.0381\n",
      "#Loss 154 =0.0381\n",
      "#Loss 155 =0.0381\n",
      "#Loss 156 =0.0381\n",
      "#Loss 157 =0.0381\n",
      "#Loss 158 =0.0381\n",
      "#Loss 159 =0.0381\n",
      "#Loss 160 =0.0381\n",
      "#Loss 161 =0.0381\n",
      "#Loss 162 =0.0381\n",
      "#Loss 163 =0.0381\n",
      "#Loss 164 =0.0381\n",
      "#Loss 165 =0.0381\n",
      "#Loss 166 =0.0381\n",
      "#Loss 167 =0.0381\n",
      "#Loss 168 =0.0381\n",
      "#Loss 169 =0.0381\n",
      "#Loss 170 =0.0381\n",
      "#Loss 171 =0.0380\n",
      "#Loss 172 =0.0380\n",
      "#Loss 173 =0.0380\n",
      "#Loss 174 =0.0380\n",
      "#Loss 175 =0.0380\n",
      "#Loss 176 =0.0380\n",
      "#Loss 177 =0.0380\n",
      "#Loss 178 =0.0380\n",
      "#Loss 179 =0.0380\n",
      "#Loss 180 =0.0380\n",
      "#Loss 181 =0.0380\n",
      "#Loss 182 =0.0380\n",
      "#Loss 183 =0.0380\n",
      "#Loss 184 =0.0380\n",
      "#Loss 185 =0.0380\n",
      "#Loss 186 =0.0380\n",
      "#Loss 187 =0.0380\n",
      "#Loss 188 =0.0380\n",
      "#Loss 189 =0.0380\n",
      "#Loss 190 =0.0380\n",
      "#Loss 191 =0.0380\n",
      "#Loss 192 =0.0380\n",
      "#Loss 193 =0.0380\n",
      "#Loss 194 =0.0380\n",
      "#Loss 195 =0.0380\n",
      "#Loss 196 =0.0380\n",
      "#Loss 197 =0.0380\n",
      "#Loss 198 =0.0380\n",
      "#Loss 199 =0.0380\n",
      "#Loss 200 =0.0379\n",
      "超过迭代上限\n",
      " 2 50 绝对误差 tensor(0.2024, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(0.8572, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.6298, dtype=torch.float64)   实验回归误差 tensor(0.1931, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.3856, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 50   条件数 1.0\n",
      "Loss 0 =115.8419\n",
      "#Loss 1 =114.8955\n",
      "#Loss 2 =104.1760\n",
      "#Loss 3 =95.1551\n",
      "#Loss 4 =87.0775\n",
      "#Loss 5 =79.3571\n",
      "#Loss 6 =71.5769\n",
      "#Loss 7 =63.4716\n",
      "#Loss 8 =54.9161\n",
      "#Loss 9 =45.9427\n",
      "#Loss 10 =36.7995\n",
      "#Loss 11 =28.0320\n",
      "#Loss 12 =20.4778\n",
      "#Loss 13 =14.9853\n",
      "#Loss 14 =11.7473\n",
      "#Loss 15 =10.0745\n",
      "#Loss 16 =9.0870\n",
      "#Loss 17 =8.3316\n",
      "#Loss 18 =7.6847\n",
      "#Loss 19 =7.1179\n",
      "#Loss 20 =6.6180\n",
      "#Loss 21 =6.1748\n",
      "#Loss 22 =5.7801\n",
      "#Loss 23 =5.4273\n",
      "#Loss 24 =5.1107\n",
      "#Loss 25 =4.8256\n",
      "#Loss 26 =4.5682\n",
      "#Loss 27 =4.3350\n",
      "#Loss 28 =4.1233\n",
      "#Loss 29 =3.9307\n",
      "#Loss 30 =3.7549\n",
      "#Loss 31 =3.5942\n",
      "#Loss 32 =3.4471\n",
      "#Loss 33 =3.3121\n",
      "#Loss 34 =3.1880\n",
      "#Loss 35 =3.0737\n",
      "#Loss 36 =2.9683\n",
      "#Loss 37 =2.8710\n",
      "#Loss 38 =2.7811\n",
      "#Loss 39 =2.6979\n",
      "#Loss 40 =2.6208\n",
      "#Loss 41 =2.5493\n",
      "#Loss 42 =2.4829\n",
      "#Loss 43 =2.4212\n",
      "#Loss 44 =2.3638\n",
      "#Loss 45 =2.3103\n",
      "#Loss 46 =2.2605\n",
      "#Loss 47 =2.2141\n",
      "#Loss 48 =2.1707\n",
      "#Loss 49 =2.1302\n",
      "#Loss 50 =2.0924\n",
      "#Loss 51 =2.0570\n",
      "#Loss 52 =2.0239\n",
      "#Loss 53 =1.9929\n",
      "#Loss 54 =1.9638\n",
      "#Loss 55 =1.9366\n",
      "#Loss 56 =1.9111\n",
      "#Loss 57 =1.8871\n",
      "#Loss 58 =1.8646\n",
      "#Loss 59 =1.8435\n",
      "#Loss 60 =1.8236\n",
      "#Loss 61 =1.8050\n",
      "#Loss 62 =1.7874\n",
      "#Loss 63 =1.7709\n",
      "#Loss 64 =1.7555\n",
      "#Loss 65 =1.7414\n",
      "#Loss 66 =1.7292\n",
      "#Loss 67 =1.7216\n",
      "#Loss 68 =1.7270\n",
      "#Loss 69 =1.7774\n",
      "#Loss 70 =1.9823\n",
      "#Loss 71 =2.7848\n",
      "#Loss 72 =5.5562\n",
      "#Loss 73 =16.1008\n",
      "#Loss 74 =33.5355\n",
      "#Loss 75 =62.2873\n",
      "#Loss 76 =4.3461\n",
      "#Loss 77 =3.7560\n",
      "#Loss 78 =3.5429\n",
      "#Loss 79 =3.3946\n",
      "#Loss 80 =3.2630\n",
      "#Loss 81 =3.1427\n",
      "#Loss 82 =3.0319\n",
      "#Loss 83 =2.9297\n",
      "#Loss 84 =2.8353\n",
      "#Loss 85 =2.7481\n",
      "#Loss 86 =2.6673\n",
      "#Loss 87 =2.5924\n",
      "#Loss 88 =2.5230\n",
      "#Loss 89 =2.4585\n",
      "#Loss 90 =2.3985\n",
      "#Loss 91 =2.3426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 92 =2.2906\n",
      "#Loss 93 =2.2421\n",
      "#Loss 94 =2.1969\n",
      "#Loss 95 =2.1547\n",
      "#Loss 96 =2.1153\n",
      "#Loss 97 =2.0784\n",
      "#Loss 98 =2.0439\n",
      "#Loss 99 =2.0116\n",
      "#Loss 100 =1.9814\n",
      "#Loss 101 =1.9531\n",
      "#Loss 102 =1.9265\n",
      "#Loss 103 =1.9016\n",
      "#Loss 104 =1.8782\n",
      "#Loss 105 =1.8563\n",
      "#Loss 106 =1.8357\n",
      "#Loss 107 =1.8164\n",
      "#Loss 108 =1.7984\n",
      "#Loss 109 =1.7819\n",
      "#Loss 110 =1.7677\n",
      "#Loss 111 =1.7582\n",
      "#Loss 112 =1.7611\n",
      "#Loss 113 =1.8031\n",
      "#Loss 114 =1.9676\n",
      "#Loss 115 =2.5729\n",
      "#Loss 116 =4.5211\n",
      "#Loss 117 =11.6004\n",
      "#Loss 118 =25.1691\n",
      "#Loss 119 =54.0433\n",
      "#Loss 120 =8.8821\n",
      "#Loss 121 =5.3543\n",
      "#Loss 122 =3.5405\n",
      "#Loss 123 =3.2723\n",
      "#Loss 124 =3.1202\n",
      "#Loss 125 =3.0048\n",
      "#Loss 126 =2.9028\n",
      "#Loss 127 =2.8099\n",
      "#Loss 128 =2.7243\n",
      "#Loss 129 =2.6452\n",
      "#Loss 130 =2.5719\n",
      "#Loss 131 =2.5039\n",
      "#Loss 132 =2.4407\n",
      "#Loss 133 =2.3820\n",
      "#Loss 134 =2.3273\n",
      "#Loss 135 =2.2763\n",
      "#Loss 136 =2.2288\n",
      "#Loss 137 =2.1845\n",
      "#Loss 138 =2.1431\n",
      "#Loss 139 =2.1044\n",
      "#Loss 140 =2.0683\n",
      "#Loss 141 =2.0345\n",
      "#Loss 142 =2.0029\n",
      "#Loss 143 =1.9734\n",
      "#Loss 144 =1.9459\n",
      "#Loss 145 =1.9204\n",
      "#Loss 146 =1.8972\n",
      "#Loss 147 =1.8771\n",
      "#Loss 148 =1.8621\n",
      "#Loss 149 =1.8584\n",
      "#Loss 150 =1.8804\n",
      "#Loss 151 =1.9750\n",
      "#Loss 152 =2.2523\n",
      "#Loss 153 =3.1220\n",
      "#Loss 154 =5.3227\n",
      "#Loss 155 =12.2461\n",
      "#Loss 156 =20.9131\n",
      "#Loss 157 =39.3567\n",
      "#Loss 158 =9.8206\n",
      "#Loss 159 =6.6082\n",
      "#Loss 160 =3.6196\n",
      "#Loss 161 =3.2032\n",
      "#Loss 162 =2.9849\n",
      "#Loss 163 =2.8613\n",
      "#Loss 164 =2.7619\n",
      "#Loss 165 =2.6767\n",
      "#Loss 166 =2.5995\n",
      "#Loss 167 =2.5289\n",
      "#Loss 168 =2.4635\n",
      "#Loss 169 =2.4031\n",
      "#Loss 170 =2.3469\n",
      "#Loss 171 =2.2946\n",
      "#Loss 172 =2.2459\n",
      "#Loss 173 =2.2007\n",
      "#Loss 174 =2.1585\n",
      "#Loss 175 =2.1193\n",
      "#Loss 176 =2.0828\n",
      "#Loss 177 =2.0494\n",
      "#Loss 178 =2.0188\n",
      "#Loss 179 =1.9922\n",
      "#Loss 180 =1.9706\n",
      "#Loss 181 =1.9584\n",
      "#Loss 182 =1.9626\n",
      "#Loss 183 =2.0070\n",
      "#Loss 184 =2.1312\n",
      "#Loss 185 =2.4861\n",
      "#Loss 186 =3.2824\n",
      "#Loss 187 =5.5627\n",
      "#Loss 188 =9.4831\n",
      "#Loss 189 =20.0761\n",
      "#Loss 190 =19.0047\n",
      "#Loss 191 =23.8645\n",
      "#Loss 192 =5.8948\n",
      "#Loss 193 =4.3578\n",
      "#Loss 194 =3.2769\n",
      "#Loss 195 =3.0018\n",
      "#Loss 196 =2.8285\n",
      "#Loss 197 =2.7197\n",
      "#Loss 198 =2.6297\n",
      "#Loss 199 =2.5534\n",
      "#Loss 200 =2.4842\n",
      "超过迭代上限\n",
      " 2 50 绝对误差 tensor(2.4386, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(1.8745, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0817, dtype=torch.float64)   实验回归误差 tensor(0.1446, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.4128, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 48   条件数 1.0\n",
      "Loss 0 =11.3111\n",
      "#Loss 1 =11.1613\n",
      "#Loss 2 =8.6860\n",
      "#Loss 3 =6.8078\n",
      "#Loss 4 =5.3840\n",
      "#Loss 5 =4.2993\n",
      "#Loss 6 =3.4661\n",
      "#Loss 7 =2.8195\n",
      "#Loss 8 =2.3125\n",
      "#Loss 9 =1.9108\n",
      "#Loss 10 =1.5894\n",
      "#Loss 11 =1.3303\n",
      "#Loss 12 =1.1199\n",
      "#Loss 13 =0.9481\n",
      "#Loss 14 =0.8071\n",
      "#Loss 15 =0.6911\n",
      "#Loss 16 =0.5954\n",
      "#Loss 17 =0.5162\n",
      "#Loss 18 =0.4508\n",
      "#Loss 19 =0.3966\n",
      "#Loss 20 =0.3518\n",
      "#Loss 21 =0.3147\n",
      "#Loss 22 =0.2840\n",
      "#Loss 23 =0.2585\n",
      "#Loss 24 =0.2375\n",
      "#Loss 25 =0.2201\n",
      "#Loss 26 =0.2057\n",
      "#Loss 27 =0.1938\n",
      "#Loss 28 =0.1839\n",
      "#Loss 29 =0.1758\n",
      "#Loss 30 =0.1690\n",
      "#Loss 31 =0.1633\n",
      "#Loss 32 =0.1586\n",
      "#Loss 33 =0.1547\n",
      "#Loss 34 =0.1514\n",
      "#Loss 35 =0.1486\n",
      "#Loss 36 =0.1463\n",
      "#Loss 37 =0.1443\n",
      "#Loss 38 =0.1426\n",
      "#Loss 39 =0.1411\n",
      "#Loss 40 =0.1399\n",
      "#Loss 41 =0.1388\n",
      "#Loss 42 =0.1379\n",
      "#Loss 43 =0.1370\n",
      "#Loss 44 =0.1363\n",
      "#Loss 45 =0.1356\n",
      "#Loss 46 =0.1351\n",
      "#Loss 47 =0.1345\n",
      "#Loss 48 =0.1341\n",
      "#Loss 49 =0.1336\n",
      "#Loss 50 =0.1333\n",
      "#Loss 51 =0.1329\n",
      "#Loss 52 =0.1326\n",
      "#Loss 53 =0.1323\n",
      "#Loss 54 =0.1320\n",
      "#Loss 55 =0.1318\n",
      "#Loss 56 =0.1315\n",
      "#Loss 57 =0.1313\n",
      "#Loss 58 =0.1311\n",
      "#Loss 59 =0.1309\n",
      "#Loss 60 =0.1308\n",
      "#Loss 61 =0.1306\n",
      "#Loss 62 =0.1305\n",
      "#Loss 63 =0.1303\n",
      "#Loss 64 =0.1302\n",
      "#Loss 65 =0.1301\n",
      "#Loss 66 =0.1300\n",
      "#Loss 67 =0.1299\n",
      "#Loss 68 =0.1298\n",
      "#Loss 69 =0.1297\n",
      "#Loss 70 =0.1296\n",
      "#Loss 71 =0.1295\n",
      "#Loss 72 =0.1294\n",
      "#Loss 73 =0.1293\n",
      "#Loss 74 =0.1293\n",
      "#Loss 75 =0.1292\n",
      "#Loss 76 =0.1292\n",
      "#Loss 77 =0.1291\n",
      "#Loss 78 =0.1291\n",
      "#Loss 79 =0.1290\n",
      "#Loss 80 =0.1290\n",
      "#Loss 81 =0.1289\n",
      "#Loss 82 =0.1289\n",
      "#Loss 83 =0.1288\n",
      "#Loss 84 =0.1288\n",
      "#Loss 85 =0.1288\n",
      "#Loss 86 =0.1287\n",
      "#Loss 87 =0.1287\n",
      "#Loss 88 =0.1287\n",
      "#Loss 89 =0.1287\n",
      "#Loss 90 =0.1286\n",
      "#Loss 91 =0.1286\n",
      "#Loss 92 =0.1286\n",
      "#Loss 93 =0.1286\n",
      "#Loss 94 =0.1286\n",
      "#Loss 95 =0.1285\n",
      "#Loss 96 =0.1285\n",
      "#Loss 97 =0.1285\n",
      "#Loss 98 =0.1285\n",
      "#Loss 99 =0.1285\n",
      "#Loss 100 =0.1285\n",
      "#Loss 101 =0.1285\n",
      "#Loss 102 =0.1285\n",
      "#Loss 103 =0.1284\n",
      "#Loss 104 =0.1284\n",
      "#Loss 105 =0.1284\n",
      "#Loss 106 =0.1284\n",
      "#Loss 107 =0.1284\n",
      "#Loss 108 =0.1284\n",
      "#Loss 109 =0.1284\n",
      "#Loss 110 =0.1284\n",
      "#Loss 111 =0.1284\n",
      "#Loss 112 =0.1284\n",
      "#Loss 113 =0.1284\n",
      "#Loss 114 =0.1284\n",
      "#Loss 115 =0.1284\n",
      "#Loss 116 =0.1284\n",
      "#Loss 117 =0.1283\n",
      "#Loss 118 =0.1283\n",
      "#Loss 119 =0.1283\n",
      " 2 50 绝对误差 tensor(0.0158, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(0.0350, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.2019, dtype=torch.float64)   实验回归误差 tensor(0.1065, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.3115, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 50   条件数 1.0\n",
      "Loss 0 =11.1714\n",
      "#Loss 1 =10.9776\n",
      "#Loss 2 =9.2103\n",
      "#Loss 3 =7.7414\n",
      "#Loss 4 =6.5232\n",
      "#Loss 5 =5.5130\n",
      "#Loss 6 =4.6739\n",
      "#Loss 7 =3.9752\n",
      "#Loss 8 =3.3918\n",
      "#Loss 9 =2.9031\n",
      "#Loss 10 =2.4926\n",
      "#Loss 11 =2.1468\n",
      "#Loss 12 =1.8547\n",
      "#Loss 13 =1.6076\n",
      "#Loss 14 =1.3982\n",
      "#Loss 15 =1.2204\n",
      "#Loss 16 =1.0692\n",
      "#Loss 17 =0.9407\n",
      "#Loss 18 =0.8311\n",
      "#Loss 19 =0.7378\n",
      "#Loss 20 =0.6581\n",
      "#Loss 21 =0.5901\n",
      "#Loss 22 =0.5320\n",
      "#Loss 23 =0.4822\n",
      "#Loss 24 =0.4396\n",
      "#Loss 25 =0.4031\n",
      "#Loss 26 =0.3717\n",
      "#Loss 27 =0.3446\n",
      "#Loss 28 =0.3213\n",
      "#Loss 29 =0.3011\n",
      "#Loss 30 =0.2837\n",
      "#Loss 31 =0.2685\n",
      "#Loss 32 =0.2552\n",
      "#Loss 33 =0.2436\n",
      "#Loss 34 =0.2335\n",
      "#Loss 35 =0.2245\n",
      "#Loss 36 =0.2165\n",
      "#Loss 37 =0.2095\n",
      "#Loss 38 =0.2032\n",
      "#Loss 39 =0.1975\n",
      "#Loss 40 =0.1925\n",
      "#Loss 41 =0.1879\n",
      "#Loss 42 =0.1837\n",
      "#Loss 43 =0.1799\n",
      "#Loss 44 =0.1764\n",
      "#Loss 45 =0.1732\n",
      "#Loss 46 =0.1702\n",
      "#Loss 47 =0.1675\n",
      "#Loss 48 =0.1650\n",
      "#Loss 49 =0.1626\n",
      "#Loss 50 =0.1604\n",
      "#Loss 51 =0.1583\n",
      "#Loss 52 =0.1564\n",
      "#Loss 53 =0.1545\n",
      "#Loss 54 =0.1528\n",
      "#Loss 55 =0.1512\n",
      "#Loss 56 =0.1496\n",
      "#Loss 57 =0.1482\n",
      "#Loss 58 =0.1468\n",
      "#Loss 59 =0.1455\n",
      "#Loss 60 =0.1442\n",
      "#Loss 61 =0.1430\n",
      "#Loss 62 =0.1419\n",
      "#Loss 63 =0.1408\n",
      "#Loss 64 =0.1398\n",
      "#Loss 65 =0.1388\n",
      "#Loss 66 =0.1379\n",
      "#Loss 67 =0.1370\n",
      "#Loss 68 =0.1361\n",
      "#Loss 69 =0.1353\n",
      "#Loss 70 =0.1345\n",
      "#Loss 71 =0.1338\n",
      "#Loss 72 =0.1331\n",
      "#Loss 73 =0.1324\n",
      "#Loss 74 =0.1318\n",
      "#Loss 75 =0.1311\n",
      "#Loss 76 =0.1306\n",
      "#Loss 77 =0.1300\n",
      "#Loss 78 =0.1294\n",
      "#Loss 79 =0.1289\n",
      "#Loss 80 =0.1284\n",
      "#Loss 81 =0.1280\n",
      "#Loss 82 =0.1275\n",
      "#Loss 83 =0.1271\n",
      "#Loss 84 =0.1267\n",
      "#Loss 85 =0.1263\n",
      "#Loss 86 =0.1259\n",
      "#Loss 87 =0.1255\n",
      "#Loss 88 =0.1252\n",
      "#Loss 89 =0.1248\n",
      "#Loss 90 =0.1245\n",
      "#Loss 91 =0.1242\n",
      "#Loss 92 =0.1239\n",
      "#Loss 93 =0.1236\n",
      "#Loss 94 =0.1234\n",
      "#Loss 95 =0.1231\n",
      "#Loss 96 =0.1229\n",
      "#Loss 97 =0.1227\n",
      "#Loss 98 =0.1224\n",
      "#Loss 99 =0.1222\n",
      "#Loss 100 =0.1220\n",
      "#Loss 101 =0.1218\n",
      "#Loss 102 =0.1216\n",
      "#Loss 103 =0.1215\n",
      "#Loss 104 =0.1213\n",
      "#Loss 105 =0.1211\n",
      "#Loss 106 =0.1210\n",
      "#Loss 107 =0.1208\n",
      "#Loss 108 =0.1207\n",
      "#Loss 109 =0.1206\n",
      "#Loss 110 =0.1204\n",
      "#Loss 111 =0.1203\n",
      "#Loss 112 =0.1202\n",
      "#Loss 113 =0.1201\n",
      "#Loss 114 =0.1200\n",
      "#Loss 115 =0.1199\n",
      "#Loss 116 =0.1198\n",
      "#Loss 117 =0.1197\n",
      "#Loss 118 =0.1196\n",
      "#Loss 119 =0.1195\n",
      "#Loss 120 =0.1194\n",
      "#Loss 121 =0.1193\n",
      "#Loss 122 =0.1193\n",
      "#Loss 123 =0.1192\n",
      "#Loss 124 =0.1191\n",
      "#Loss 125 =0.1191\n",
      "#Loss 126 =0.1190\n",
      "#Loss 127 =0.1189\n",
      "#Loss 128 =0.1189\n",
      "#Loss 129 =0.1188\n",
      "#Loss 130 =0.1188\n",
      "#Loss 131 =0.1187\n",
      "#Loss 132 =0.1187\n",
      "#Loss 133 =0.1186\n",
      "#Loss 134 =0.1186\n",
      "#Loss 135 =0.1186\n",
      "#Loss 136 =0.1185\n",
      "#Loss 137 =0.1185\n",
      "#Loss 138 =0.1184\n",
      "#Loss 139 =0.1184\n",
      "#Loss 140 =0.1184\n",
      "#Loss 141 =0.1184\n",
      "#Loss 142 =0.1183\n",
      "#Loss 143 =0.1183\n",
      "#Loss 144 =0.1183\n",
      "#Loss 145 =0.1182\n",
      "#Loss 146 =0.1182\n",
      "#Loss 147 =0.1182\n",
      "#Loss 148 =0.1182\n",
      "#Loss 149 =0.1181\n",
      "#Loss 150 =0.1181\n",
      "#Loss 151 =0.1181\n",
      "#Loss 152 =0.1181\n",
      "#Loss 153 =0.1181\n",
      "#Loss 154 =0.1181\n",
      "#Loss 155 =0.1180\n",
      "#Loss 156 =0.1180\n",
      "#Loss 157 =0.1180\n",
      "#Loss 158 =0.1180\n",
      "#Loss 159 =0.1180\n",
      "#Loss 160 =0.1180\n",
      "#Loss 161 =0.1180\n",
      "#Loss 162 =0.1179\n",
      "#Loss 163 =0.1179\n",
      "#Loss 164 =0.1179\n",
      "#Loss 165 =0.1179\n",
      "#Loss 166 =0.1179\n",
      "#Loss 167 =0.1179\n",
      "#Loss 168 =0.1179\n",
      "#Loss 169 =0.1179\n",
      "#Loss 170 =0.1179\n",
      "#Loss 171 =0.1179\n",
      "#Loss 172 =0.1179\n",
      "#Loss 173 =0.1178\n",
      "#Loss 174 =0.1178\n",
      "#Loss 175 =0.1178\n",
      "#Loss 176 =0.1178\n",
      "#Loss 177 =0.1178\n",
      "#Loss 178 =0.1178\n",
      "#Loss 179 =0.1178\n",
      "#Loss 180 =0.1178\n",
      "#Loss 181 =0.1178\n",
      "#Loss 182 =0.1178\n",
      "#Loss 183 =0.1178\n",
      "#Loss 184 =0.1178\n",
      "#Loss 185 =0.1178\n",
      "#Loss 186 =0.1178\n",
      "#Loss 187 =0.1178\n",
      "#Loss 188 =0.1178\n",
      "#Loss 189 =0.1178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2 50 绝对误差 tensor(0.0211, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(0.0379, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.1967, dtype=torch.float64)   实验回归误差 tensor(0.1027, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.2490, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 50   条件数 1.0\n",
      "Loss 0 =5516.4861\n",
      "#Loss 1 =5515.3859\n",
      "#Loss 2 =5262.8973\n",
      "#Loss 3 =4835.8591\n",
      "#Loss 4 =110.3886\n",
      "#Loss 5 =4187.1993\n",
      "#Loss 6 =78503.3613\n",
      "#Loss 7 =nan\n",
      " 2 50 绝对误差 tensor(nan, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(nan, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0098, dtype=torch.float64)   实验回归误差 tensor(nan, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.0000, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 0   条件数 1.0\n",
      "Loss 0 =317.6623\n",
      "#Loss 1 =316.3779\n",
      "#Loss 2 =289.5972\n",
      "#Loss 3 =266.4510\n",
      "#Loss 4 =239.5698\n",
      "#Loss 5 =201.9294\n",
      "#Loss 6 =143.3468\n",
      "#Loss 7 =56.0893\n",
      "#Loss 8 =35.1009\n",
      "#Loss 9 =69.2222\n",
      "#Loss 10 =28.2010\n",
      "#Loss 11 =44.1535\n",
      "#Loss 12 =40.1259\n",
      "#Loss 13 =86.7974\n",
      "#Loss 14 =22.4417\n",
      "#Loss 15 =23.1273\n",
      "#Loss 16 =24.9122\n",
      "#Loss 17 =32.5863\n",
      "#Loss 18 =38.7188\n",
      "#Loss 19 =83.0477\n",
      "#Loss 20 =23.2976\n",
      "#Loss 21 =26.2752\n",
      "#Loss 22 =31.2653\n",
      "#Loss 23 =56.3652\n",
      "#Loss 24 =35.8215\n",
      "#Loss 25 =72.2788\n",
      "#Loss 26 =26.9550\n",
      "#Loss 27 =39.6435\n",
      "#Loss 28 =40.6285\n",
      "#Loss 29 =88.6674\n",
      "#Loss 30 =22.2424\n",
      "#Loss 31 =22.4820\n",
      "#Loss 32 =23.2896\n",
      "#Loss 33 =26.6380\n",
      "#Loss 34 =32.1480\n",
      "#Loss 35 =60.0773\n",
      "#Loss 36 =34.1737\n",
      "#Loss 37 =66.5580\n",
      "#Loss 38 =29.8733\n",
      "#Loss 39 =50.5443\n",
      "#Loss 40 =38.1239\n",
      "#Loss 41 =80.0287\n",
      "#Loss 42 =23.9176\n",
      "#Loss 43 =28.3564\n",
      "#Loss 44 =34.1555\n",
      "#Loss 45 =66.6282\n",
      "#Loss 46 =29.9164\n",
      "#Loss 47 =50.7421\n",
      "#Loss 48 =38.0671\n",
      "#Loss 49 =79.8516\n",
      "#Loss 50 =23.9746\n",
      "#Loss 51 =28.5668\n",
      "#Loss 52 =34.4188\n",
      "#Loss 53 =67.5657\n",
      "#Loss 54 =29.4159\n",
      "#Loss 55 =48.8826\n",
      "#Loss 56 =38.8377\n",
      "#Loss 57 =82.5054\n",
      "#Loss 58 =23.2548\n",
      "#Loss 59 =25.9777\n",
      "#Loss 60 =30.6801\n",
      "#Loss 61 =54.0654\n",
      "#Loss 62 =36.9067\n",
      "#Loss 63 =76.0467\n",
      "#Loss 64 =25.3485\n",
      "#Loss 65 =33.6565\n",
      "#Loss 66 =38.8926\n",
      "#Loss 67 =83.0140\n",
      "#Loss 68 =23.1853\n",
      "#Loss 69 =25.7823\n",
      "#Loss 70 =30.3776\n",
      "#Loss 71 =53.0057\n",
      "#Loss 72 =37.4973\n",
      "#Loss 73 =78.1401\n",
      "#Loss 74 =24.5915\n",
      "#Loss 75 =30.8697\n",
      "#Loss 76 =36.8805\n",
      "#Loss 77 =76.2081\n",
      "#Loss 78 =25.3705\n",
      "#Loss 79 =33.7884\n",
      "#Loss 80 =39.0050\n",
      "#Loss 81 =83.4388\n",
      "#Loss 82 =23.0933\n",
      "#Loss 83 =25.4619\n",
      "#Loss 84 =29.8162\n",
      "#Loss 85 =50.9402\n",
      "#Loss 86 =38.4936\n",
      "#Loss 87 =81.6095\n",
      "#Loss 88 =23.5327\n",
      "#Loss 89 =27.0199\n",
      "#Loss 90 =32.3628\n",
      "#Loss 91 =60.2534\n",
      "#Loss 92 =33.5355\n",
      "#Loss 93 =64.0418\n",
      "#Loss 94 =31.1064\n",
      "#Loss 95 =55.0281\n",
      "#Loss 96 =35.9195\n",
      "#Loss 97 =72.3083\n",
      "#Loss 98 =26.8186\n",
      "#Loss 99 =39.0595\n",
      "#Loss 100 =40.5295\n",
      "#Loss 101 =88.2953\n",
      "#Loss 102 =22.2757\n",
      "#Loss 103 =22.5877\n",
      "#Loss 104 =23.5665\n",
      "#Loss 105 =27.6399\n",
      "#Loss 106 =33.6423\n",
      "#Loss 107 =65.4727\n",
      "#Loss 108 =31.0324\n",
      "#Loss 109 =55.0652\n",
      "#Loss 110 =36.1301\n",
      "#Loss 111 =73.1852\n",
      "#Loss 112 =26.4798\n",
      "#Loss 113 =37.8299\n",
      "#Loss 114 =40.3872\n",
      "#Loss 115 =87.8819\n",
      "#Loss 116 =22.3206\n",
      "#Loss 117 =22.7469\n",
      "#Loss 118 =23.9843\n",
      "#Loss 119 =29.1761\n",
      "#Loss 120 =35.6122\n",
      "#Loss 121 =72.4560\n",
      "#Loss 122 =27.3195\n",
      "#Loss 123 =41.2080\n",
      "#Loss 124 =40.7948\n",
      "#Loss 125 =89.3326\n",
      "#Loss 126 =22.1909\n",
      "#Loss 127 =22.3251\n",
      "#Loss 128 =22.8726\n",
      "#Loss 129 =25.1482\n",
      "#Loss 130 =29.5703\n",
      "#Loss 131 =50.5827\n",
      "#Loss 132 =39.2959\n",
      "#Loss 133 =84.6555\n",
      "#Loss 134 =22.8671\n",
      "#Loss 135 =24.6957\n",
      "#Loss 136 =28.3911\n",
      "#Loss 137 =45.6777\n",
      "#Loss 138 =40.5107\n",
      "#Loss 139 =88.5856\n",
      "#Loss 140 =22.2599\n",
      "#Loss 141 =22.5812\n",
      "#Loss 142 =23.5767\n",
      "#Loss 143 =27.7096\n",
      "#Loss 144 =33.7714\n",
      "#Loss 145 =65.9813\n",
      "#Loss 146 =30.7789\n",
      "#Loss 147 =54.1392\n",
      "#Loss 148 =36.6137\n",
      "#Loss 149 =74.8894\n",
      "#Loss 150 =25.7640\n",
      "#Loss 151 =35.1695\n",
      "#Loss 152 =39.6095\n",
      "#Loss 153 =85.3609\n",
      "#Loss 154 =22.6881\n",
      "#Loss 155 =24.0192\n",
      "#Loss 156 =26.9682\n",
      "#Loss 157 =40.3073\n",
      "#Loss 158 =41.2435\n",
      "#Loss 159 =91.1847\n",
      "#Loss 160 =22.0936\n",
      "#Loss 161 =22.0473\n",
      "#Loss 162 =22.1089\n",
      "#Loss 163 =22.5070\n",
      "#Loss 164 =23.6496\n",
      "#Loss 165 =28.3187\n",
      "#Loss 166 =34.9968\n",
      "#Loss 167 =70.8901\n",
      "#Loss 168 =28.4911\n",
      "#Loss 169 =45.7295\n",
      "#Loss 170 =40.1584\n",
      "#Loss 171 =87.1929\n",
      "#Loss 172 =22.4067\n",
      "#Loss 173 =23.0493\n",
      "#Loss 174 =24.7461\n",
      "#Loss 175 =32.0013\n",
      "#Loss 176 =38.3240\n",
      "#Loss 177 =81.7682\n",
      "#Loss 178 =23.6582\n",
      "#Loss 179 =27.5865\n",
      "#Loss 180 =33.2504\n",
      "#Loss 181 =63.5801\n",
      "#Loss 182 =31.7365\n",
      "#Loss 183 =57.5201\n",
      "#Loss 184 =34.7214\n",
      "#Loss 185 =68.1344\n",
      "#Loss 186 =28.8547\n",
      "#Loss 187 =46.6568\n",
      "#Loss 188 =39.5184\n",
      "#Loss 189 =84.7604\n",
      "#Loss 190 =22.7664\n",
      "#Loss 191 =24.2473\n",
      "#Loss 192 =27.4247\n",
      "#Loss 193 =41.9749\n",
      "#Loss 194 =41.1220\n",
      "#Loss 195 =90.6811\n",
      "#Loss 196 =22.1136\n",
      "#Loss 197 =22.1016\n",
      "#Loss 198 =22.2606\n",
      "#Loss 199 =23.0183\n",
      "#Loss 200 =24.9632\n",
      "超过迭代上限\n",
      " 2 50 绝对误差 tensor(2.5522, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(1.6887, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0402, dtype=torch.float64)   实验回归误差 tensor(0.3235, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.4000, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 50   条件数 1.0\n",
      "Loss 0 =188.8358\n",
      "#Loss 1 =188.3154\n",
      "#Loss 2 =170.3371\n",
      "#Loss 3 =155.1310\n",
      "#Loss 4 =141.5354\n",
      "#Loss 5 =128.5332\n",
      "#Loss 6 =115.4085\n",
      "#Loss 7 =101.7528\n",
      "#Loss 8 =87.4237\n",
      "#Loss 9 =72.5101\n",
      "#Loss 10 =57.4033\n",
      "#Loss 11 =42.8943\n",
      "#Loss 12 =30.2200\n",
      "#Loss 13 =20.6268\n",
      "#Loss 14 =14.6494\n",
      "#Loss 15 =11.5399\n",
      "#Loss 16 =9.9331\n",
      "#Loss 17 =8.8623\n",
      "#Loss 18 =7.9575\n",
      "#Loss 19 =7.1280\n",
      "#Loss 20 =6.3597\n",
      "#Loss 21 =5.6515\n",
      "#Loss 22 =5.0028\n",
      "#Loss 23 =4.4125\n",
      "#Loss 24 =3.8818\n",
      "#Loss 25 =3.4086\n",
      "#Loss 26 =2.9910\n",
      "#Loss 27 =2.6258\n",
      "#Loss 28 =2.3089\n",
      "#Loss 29 =2.0332\n",
      "#Loss 30 =1.7870\n",
      "#Loss 31 =1.5414\n",
      "#Loss 32 =1.3194\n",
      "#Loss 33 =1.1349\n",
      "#Loss 34 =0.9825\n",
      "#Loss 35 =0.8574\n",
      "#Loss 36 =0.7555\n",
      "#Loss 37 =0.6734\n",
      "#Loss 38 =0.6075\n",
      "#Loss 39 =0.5552\n",
      "#Loss 40 =0.5137\n",
      "#Loss 41 =0.4810\n",
      "#Loss 42 =0.4554\n",
      "#Loss 43 =0.4353\n",
      "#Loss 44 =0.4194\n",
      "#Loss 45 =0.4036\n",
      "#Loss 46 =0.3917\n",
      "#Loss 47 =0.3824\n",
      "#Loss 48 =0.3730\n",
      "#Loss 49 =0.3600\n",
      "#Loss 50 =0.3512\n",
      "#Loss 51 =0.3444\n",
      "#Loss 52 =0.3391\n",
      "#Loss 53 =0.3350\n",
      "#Loss 54 =0.3319\n",
      "#Loss 55 =0.3295\n",
      "#Loss 56 =0.3278\n",
      "#Loss 57 =0.3264\n",
      "#Loss 58 =0.3254\n",
      "#Loss 59 =0.3246\n",
      "#Loss 60 =0.3240\n",
      "#Loss 61 =0.3236\n",
      "#Loss 62 =0.3233\n",
      "#Loss 63 =0.3230\n",
      "#Loss 64 =0.3228\n",
      "#Loss 65 =0.3226\n",
      "#Loss 66 =0.3225\n",
      "#Loss 67 =0.3224\n",
      "#Loss 68 =0.3223\n",
      "#Loss 69 =0.3222\n",
      "#Loss 70 =0.3222\n",
      "#Loss 71 =0.3222\n",
      "#Loss 72 =0.3221\n",
      "#Loss 73 =0.3221\n",
      "#Loss 74 =0.3221\n",
      "#Loss 75 =0.3221\n",
      " 2 50 绝对误差 tensor(0.0191, dtype=torch.float64, grad_fn=<NormBackward0>)   相对误差 tensor(0.0097, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0540, dtype=torch.float64)   实验回归误差 tensor(0.0413, dtype=torch.float64, grad_fn=<DivBackward0>)   置换矩阵误差 tensor(1.1489, dtype=torch.float64, grad_fn=<DivBackward0>)   离置换矩阵距离 50   条件数 1.0\n"
     ]
    }
   ],
   "source": [
    "gama_=1\n",
    "eta=0\n",
    "starts=1\n",
    "for i_____ in range(5):\n",
    "    for num_example in range(50,51,100): \n",
    "        for num_X2feature in [2]:\n",
    "            for i____ in range(10):\n",
    "                (y_,X2_,true_w2,true_P,error_reg1,conditionnumber)=generatedata(noise=0.1)\n",
    "                y=y_\n",
    "                X2=X2_\n",
    "                results_Loss = []\n",
    "                results_w2=[]\n",
    "                results_error=[]\n",
    "                for i__ in range(starts):\n",
    "    #                     P_array=np.random.permutation(num_example)\n",
    "    #                     P=torch.zeros(num_example,num_example,dtype=torch.float64)\n",
    "    #                     for i in range(num_example):\n",
    "    #                         P[i][P_array[i]]=1\n",
    "    #                     X_=torch.cat([X1,X2],1)\n",
    "    #                     X=torch.mm(P,X_)\n",
    "    #                     w=torch.mm(torch.mm(torch.tensor(np.linalg.inv(torch.mm(X.transpose(1,0),X))),X.transpose(1,0)),y)\n",
    "    #                     w1,w2=w.split([num_X1feature,num_X2feature],dim=0)\n",
    "    #                     w1=torch.from_numpy(np.random.normal(0, 0,(num_X1feature,1)))\n",
    "    #                     w2=torch.from_numpy(np.random.normal(0, 0,(num_X2feature,1)))\n",
    "                    w2=generateinitialw(method='zeros')\n",
    "                    #w2=true_w2\n",
    "                    w2.requires_grad_(requires_grad=True)\n",
    "    #                 results_Loss = []\n",
    "                    lr=0.001\n",
    "                    results_S=[]\n",
    "                    t=0\n",
    "                    before1=0\n",
    "                    while True:                     \n",
    "                        Y1=y\n",
    "                        Y2=torch.exp(w2[0]*X2)*torch.sin(w2[1]*X2)\n",
    "                        C=torch.zeros(num_example,num_example,dtype=torch.float64)\n",
    "                        for i in range(num_example):\n",
    "                            for j in range(num_example):\n",
    "                                C[i][j]=(Y1[i]-Y2[j])**2            \n",
    "\n",
    "                        #S=SinkhornIPOT(C)\n",
    "                        a=torch.ones(num_example,1,dtype=torch.float64)\n",
    "                        b=torch.ones(num_example,1,dtype=torch.float64)\n",
    "                        S=sinkhorn_epsilon_scaling(a, b, C, 0.00000001)\n",
    "                        #print(S.transpose(1,0).half())\n",
    "                        #results_S.append(S)\n",
    "                        #if t>0:\n",
    "                            #print('        S变化',(torch.norm(results_S[t]-results_S[t-1]))/(torch.norm(results_S[t-1])))\n",
    "                        #Loss=torch.sum(S*C)\n",
    "                        Loss=torch.norm(Y1-torch.mm(S,Y2))**2\n",
    "                        if Loss<1e-2:\n",
    "                            break\n",
    "                        Loss.backward()\n",
    "    #                         results_Loss.append(Loss)\n",
    "    #                         for i_ in range(num_X1features):\n",
    "    #                             results_w1[t][i_]=(w1[i_].data)\n",
    "    #                         for i_ in range(num_X2features):\n",
    "    #                             results_w2[t][i_]=(w2[i_].data)\n",
    "                        w2.data-=lr*(w2.grad+np.random.normal(0,np.sqrt(eta/(1+t)**gama_)))\n",
    "                        #print(w2.grad)\n",
    "    #                     if t==num_epochs-1:\n",
    "    #                         print('最终w1梯度：',w1.grad)\n",
    "    #                         print('最终w2梯度：',w2.grad)\n",
    "                        w2.grad.data.zero_() \n",
    "                        print('Loss',t,'={:.4f}'.format(Loss.data))\n",
    "                        #print('Loss',t,'=',Loss)\n",
    "    #                     if t%6==0:\n",
    "    #                         if torch.norm(Loss-before1)<1e-4:\n",
    "    #                             break\n",
    "    #                         before1=Loss\n",
    "                        if torch.norm(Loss-before1)/before1<3e-5:\n",
    "                            break\n",
    "                        before1=Loss\n",
    "                        if t>=200:\n",
    "                            print('超过迭代上限')\n",
    "                            break\n",
    "                        if math.isnan(Loss):\n",
    "                            break\n",
    "                        t+=1\n",
    "                        print('#',end='')\n",
    "\n",
    "\n",
    "\n",
    "                    print(' ',end='')\n",
    "                    error_each=(torch.norm(w2-true_w2))\n",
    "                    #results_error.append(error_each)\n",
    "                    error_each2=(torch.norm(w2-true_w2))/torch.norm(true_w2)\n",
    "                    \n",
    "                    #results_Loss.append(Loss)\n",
    "                    #results_w1.append(w1.data)\n",
    "                    #results_w2.append(w2.data)\n",
    "\n",
    "\n",
    "                #w1=results_w1[results_Loss.index(min(results_Loss))]\n",
    "                #w2=results_w2[results_Loss.index(min(results_Loss))]\n",
    "\n",
    "    #                     for i_ in range(starts):\n",
    "    #                         results_w1[i_]=(w1[i_].data)\n",
    "    #                     for i_ in range(starts):\n",
    "    #                         results_w2[i_]=(w2[i_].data)\n",
    "\n",
    "\n",
    "                #error_w=((torch.norm(w1-true_w1))/(torch.norm(true_w1))+(torch.norm(w2-true_w2))/(torch.norm(true_w2)))/2\n",
    "                #print(num_X1feature,num_X2feature,num_example,'平均相对误差1：',error_w)\n",
    "                #print(num_X2feature,num_example,'平均相对误差2：',np.min(results_error),end='   ')\n",
    "                print(num_X2feature,num_example,'绝对误差',error_each,end='   ')\n",
    "                print('相对误差',error_each2,end='   ')\n",
    "                #print('真实置换矩阵为：',true_P)    \n",
    "                \n",
    "                error_reg2=(torch.norm(y_-torch.exp(w2[0]*torch.mm(S,X2_))*torch.sin(w2[1]*torch.mm(S,X2_)))/torch.norm(y_))\n",
    "                print('真实回归误差',error_reg1,end='   ')\n",
    "                print('实验回归误差',error_reg2,end='   ')\n",
    "                error_P=(torch.norm(S.transpose(1,0)-true_P))/(torch.norm(true_P))\n",
    "                print('置换矩阵误差',error_P,end='   ')\n",
    "                matrix_count=0\n",
    "                for i_2 in range(num_example):\n",
    "                    for j_2 in range(num_example):\n",
    "                        if (abs(S[i_2][j_2]-1)<0.02):\n",
    "                            matrix_count+=1\n",
    "                print('离置换矩阵距离',matrix_count,end='   ')\n",
    "                print('条件数',conditionnumber)\n",
    "                #print('双随机矩阵S为：',S.transpose(1,0).half())\n",
    "                #print(results)\n",
    "    #                 plt.figure(figsize=(6,6))\n",
    "    #                 plt.plot(results_w1_0,results_Loss, '-o',label='$w1[0]$')\n",
    "    #                 plt.plot(results_w1_1,results_Loss, '-o',label='$w1[1]$')\n",
    "    #                 plt.plot(results_w1_2,results_Loss, '-o',label='$w1[2]$')\n",
    "    #                 plt.plot(results_w2_0,results_Loss, '-o',label='$w2[0]$')\n",
    "    #                 plt.plot(results_w2_1,results_Loss, '-o',label='$w2[1]$')\n",
    "    #                 plt.plot(results_w2_2,results_Loss, '-o',label='$w2[2]$')\n",
    "    #                 plt.legend()\n",
    "    #                 plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
