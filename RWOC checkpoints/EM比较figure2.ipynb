{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline \n",
    "import torch \n",
    "#from IPython import display \n",
    "#from matplotlib import pyplot as plt\n",
    "import numpy as np \n",
    "import random\n",
    "import math\n",
    "from time import time\n",
    "#from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatedata(noise,showpermutation=False,showtrue_w=False):\n",
    "    true_w2 = torch.from_numpy(np.random.normal(0, 1,(num_X2feature,1)))\n",
    "    if showtrue_w:\n",
    "        print('true_w2:',true_w2)\n",
    "    X2_before_ =torch.from_numpy(np.random.normal(0, 1, (num_example, num_X2feature)))\n",
    "    y_ = torch.mm(X2_before_,true_w2)\n",
    "    y_ += torch.from_numpy(np.random.normal(0, noise ,size=y_.size()))\n",
    "    P_array=np.random.permutation(num_example)\n",
    "    P=torch.zeros(num_example,num_example,dtype=torch.float64)\n",
    "    for i in range(num_example):\n",
    "        P[i][P_array[i]]=1\n",
    "    if showpermutation:\n",
    "        print('打乱X2的置换矩阵为',P)\n",
    "    X2_=torch.mm(P,X2_before_)\n",
    "    #X2_=X2_before_\n",
    "    error_reg=(torch.norm(y_-torch.mm(X2_before_,true_w2))/torch.norm(y_))\n",
    "    return y_,X2_,true_w2,P,error_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateinitialw(method,showinitialw=False):\n",
    "    if method=='normal':\n",
    "        w2 = torch.from_numpy(np.random.normal(0, 1,(num_X2feature,1)))\n",
    "    if method=='zeros':\n",
    "        w2=torch.zeros(num_X2feature,1,dtype=torch.float64)\n",
    "    if showinitialw:\n",
    "        print('initial w2:',w2)\n",
    "    return w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinkhorn_stabilized(a, b, M, reg, numItermax=1000, tau=1e3, stopThr=1e-9,\n",
    "                        warmstart=None, verbose=False, print_period=20,\n",
    "                        log=False, **kwargs):\n",
    "\n",
    "#     a = np.asarray(a, dtype=np.float64)\n",
    "#     b = np.asarray(b, dtype=np.float64)\n",
    "#     M = np.asarray(M, dtype=np.float64)\n",
    "    a=a\n",
    "    b=b\n",
    "    M=M\n",
    "\n",
    "#     if len(a) == 0:\n",
    "#         a = np.ones((M.shape[0],), dtype=np.float64) / M.shape[0]\n",
    "#     if len(b) == 0:\n",
    "#         b = np.ones((M.shape[1],), dtype=np.float64) / M.shape[1]\n",
    "\n",
    "    # test if multiple target\n",
    "#     if len(b.shape) > 1:\n",
    "#         n_hists = b.shape[1]\n",
    "#         a = a[:, np.newaxis]\n",
    "#     else:\n",
    "#         n_hists = 0\n",
    "    n_hists = 0\n",
    "    # init data\n",
    "    dim_a = len(a)\n",
    "    dim_b = len(b)\n",
    "\n",
    "    cpt = 0\n",
    "    if log:\n",
    "        log = {'err': []}\n",
    "\n",
    "    # we assume that no distances are null except those of the diagonal of\n",
    "    # distances\n",
    "    if warmstart is None:\n",
    "        alpha, beta = torch.zeros(dim_a,1,dtype=torch.float64), torch.zeros(dim_b,1,dtype=torch.float64)\n",
    "    else:\n",
    "        alpha, beta = warmstart\n",
    "\n",
    "    if n_hists:\n",
    "        u = torch.ones((dim_a, n_hists)) / dim_a\n",
    "        v = torch.ones((dim_b, n_hists)) / dim_b\n",
    "    else:\n",
    "        u, v = torch.ones(dim_a,1,dtype=torch.float64) / dim_a, torch.ones(dim_b,1,dtype=torch.float64) / dim_b\n",
    "\n",
    "    def get_K(alpha, beta):\n",
    "        \"\"\"log space computation\"\"\"\n",
    "        return torch.exp(-(M - alpha.reshape((dim_a, 1))- beta.reshape((1, dim_b))) / reg)\n",
    "\n",
    "    def get_Gamma(alpha, beta, u, v):\n",
    "        \"\"\"log space gamma computation\"\"\"\n",
    "        return torch.exp(-(M - alpha.reshape((dim_a, 1)) - beta.reshape((1, dim_b)))\n",
    "                      / reg + torch.log(u.reshape((dim_a, 1))) + torch.log(v.reshape((1, dim_b))))\n",
    "\n",
    "    # print(np.min(K))\n",
    "\n",
    "    K = get_K(alpha, beta)\n",
    "    transp = K\n",
    "    loop = 1\n",
    "    cpt = 0\n",
    "    err = 1\n",
    "    while loop:\n",
    "\n",
    "        uprev = u\n",
    "        vprev = v\n",
    "        # sinkhornrn update\n",
    "        v = b / (torch.mm(K.transpose(1,0), u) + 1e-16)\n",
    "        u = a / (torch.mm(K, v) + 1e-16)\n",
    "        # remove numerical problems and store them in K\n",
    "        if torch.abs(u).max() > tau or torch.abs(v).max() > tau:\n",
    "            if n_hists:\n",
    "                alpha, beta = alpha + reg * \\\n",
    "                    torch.max(torch.log(u), 1), beta + reg * torch.max(np.log(v))\n",
    "            else:\n",
    "                alpha, beta = alpha + reg * torch.log(u), beta + reg * torch.log(v)\n",
    "                if n_hists:\n",
    "                    u, v = torch.ones((dim_a, n_hists)) / dim_a, torch.ones((dim_b, n_hists)) / dim_b\n",
    "                else:\n",
    "                    u, v = torch.ones(dim_a,1,dtype=torch.float64) / dim_a, torch.ones(dim_b,1,dtype=torch.float64) / dim_b\n",
    "            K = get_K(alpha, beta)\n",
    "            \n",
    "\n",
    "        if cpt % print_period == 0:\n",
    "            # we can speed up the process by checking for the error only all\n",
    "            # the 10th iterations\n",
    "            if n_hists:\n",
    "                err_u = abs(u - uprev).max()\n",
    "                err_u /= max(abs(u).max(), abs(uprev).max(), 1.)\n",
    "                err_v = abs(v - vprev).max()\n",
    "                err_v /= max(abs(v).max(), abs(vprev).max(), 1.)\n",
    "                err = 0.5 * (err_u + err_v)\n",
    "            else:\n",
    "                transp = get_Gamma(alpha, beta, u, v)\n",
    "                err = torch.norm((torch.sum(transp, axis=0) - b))\n",
    "            if log:\n",
    "                log['err'].append(err)\n",
    "\n",
    "            if verbose:\n",
    "                if cpt % (print_period * 20) == 0:\n",
    "                    print(\n",
    "                        '{:5s}|{:12s}'.format('It.', 'Err') + '\\n' + '-' * 19)\n",
    "                print('{:5d}|{:8e}|'.format(cpt, err))\n",
    "\n",
    "        if err <= stopThr:\n",
    "            loop = False\n",
    "\n",
    "        if cpt >= numItermax:\n",
    "            loop = False\n",
    "\n",
    "        if np.any(np.isnan(u.detach().numpy())) or np.any(np.isnan(v.detach().numpy())):\n",
    "            # we have reached the machine precision\n",
    "            # come back to previous solution and quit loop\n",
    "            print('Warning: numerical errors at iteration', cpt)\n",
    "            u = uprev\n",
    "            v = vprev\n",
    "            break\n",
    "\n",
    "        cpt = cpt + 1\n",
    "    #print(cpt)\n",
    "    if log:\n",
    "        if n_hists:\n",
    "            alpha = alpha[:, None]\n",
    "            beta = beta[:, None]\n",
    "        logu = alpha / reg + torch.log(u)\n",
    "        logv = beta / reg + torch.log(v)\n",
    "        log['logu'] = logu\n",
    "        log['logv'] = logv\n",
    "        log['alpha'] = alpha + reg * torch.log(u)\n",
    "        log['beta'] = beta + reg * torch.log(v)\n",
    "        log['warmstart'] = (log['alpha'], log['beta'])\n",
    "        if n_hists:\n",
    "            res = torch.zeros((n_hists))\n",
    "            for i in range(n_hists):\n",
    "                res[i] = torch.sum(get_Gamma(alpha, beta, u[:, i], v[:, i]) * M)\n",
    "            return res, log\n",
    "\n",
    "        else:\n",
    "            return get_Gamma(alpha, beta, u, v), log\n",
    "    else:\n",
    "        if n_hists:\n",
    "            res = torch.zeros((n_hists))\n",
    "            for i in range(n_hists):\n",
    "                res[i] = torch.sum(get_Gamma(alpha, beta, u[:, i], v[:, i]) * M)\n",
    "            return res\n",
    "        else:\n",
    "            return get_Gamma(alpha, beta, u, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinkhorn_epsilon_scaling(a, b, M, reg, numItermax=100, epsilon0=1e4,\n",
    "                             numInnerItermax=100, tau=1e3, stopThr=1e-9,\n",
    "                             warmstart=None, verbose=False, print_period=10,\n",
    "                             log=False, **kwargs):\n",
    "    #a = np.asarray(a, dtype=np.float64)\n",
    "    #b = np.asarray(b, dtype=np.float64)\n",
    "    #M = np.asarray(M, dtype=np.float64)\n",
    "    a=a\n",
    "    b=b\n",
    "    M=M\n",
    "#     if len(a) == 0:\n",
    "#         a = np.ones((M.shape[0],), dtype=np.float64) / M.shape[0]\n",
    "#     if len(b) == 0:\n",
    "#         b = np.ones((M.shape[1],), dtype=np.float64) / M.shape[1]\n",
    "\n",
    "    # init data\n",
    "    dim_a = len(a)\n",
    "    #dim_a=num_example\n",
    "    dim_b = len(b)\n",
    "    #dim_b=num_example\n",
    "    # nrelative umerical precision with 64 bits\n",
    "    numItermin = 35\n",
    "    numItermax = max(numItermin, numItermax)  # ensure that last velue is exact\n",
    "\n",
    "    cpt = 0\n",
    "    if log:\n",
    "        log = {'err': []}\n",
    "\n",
    "    # we assume that no distances are null except those of the diagonal of\n",
    "    # distances\n",
    "    if warmstart is None:\n",
    "        alpha, beta = torch.zeros(dim_a,1,dtype=torch.float64), torch.zeros(dim_b,1,dtype=torch.float64)\n",
    "    else:\n",
    "        alpha, beta = warmstart\n",
    "\n",
    "    def get_K(alpha, beta):\n",
    "        \"\"\"log space computation\"\"\"\n",
    "        return torch.exp(-(M - alpha.reshape((dim_a, 1))\n",
    "                        - beta.reshape((1, dim_b))) / reg)\n",
    "\n",
    "    # print(np.min(K))\n",
    "    def get_reg(n):  # exponential decreasing\n",
    "        return (epsilon0 - reg) * np.exp(-n) + reg\n",
    "\n",
    "    loop = 1\n",
    "    cpt = 0\n",
    "    err = 1\n",
    "    while loop:\n",
    "\n",
    "        regi = get_reg(cpt)\n",
    "\n",
    "        G, logi = sinkhorn_stabilized(a, b, M, regi,\n",
    "                                      numItermax=numInnerItermax, stopThr=1e-9,\n",
    "                                      warmstart=(alpha, beta), verbose=False,\n",
    "                                      print_period=20, tau=tau, log=True)\n",
    "\n",
    "        alpha = logi['alpha']\n",
    "        beta = logi['beta']\n",
    "\n",
    "        if cpt >= numItermax:\n",
    "            loop = False\n",
    "\n",
    "        if cpt % (print_period) == 0:  # spsion nearly converged\n",
    "            # we can speed up the process by checking for the error only all\n",
    "            # the 10th iterations\n",
    "            transp = G\n",
    "            err = torch.norm(\n",
    "                (torch.sum(transp, axis=0) - b))**2 + torch.norm((torch.sum(transp, axis=1) - a))**2\n",
    "            if log:\n",
    "                log['err'].append(err)\n",
    "\n",
    "            if verbose:\n",
    "                if cpt % (print_period * 10) == 0:\n",
    "                    print(\n",
    "                        '{:5s}|{:12s}'.format('It.', 'Err') + '\\n' + '-' * 19)\n",
    "                print('{:5d}|{:8e}|'.format(cpt, err))\n",
    "\n",
    "        if err <= stopThr and cpt > numItermin:\n",
    "            loop = False\n",
    "\n",
    "        cpt = cpt + 1\n",
    "    # print('err=',err,' cpt=',cpt)\n",
    "    if log:\n",
    "        log['alpha'] = alpha\n",
    "        log['beta'] = beta\n",
    "        log['warmstart'] = (log['alpha'], log['beta'])\n",
    "        return G, log\n",
    "    else:\n",
    "        return G\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0 = tensor(6436.7081, dtype=torch.float64)\n",
      "#Loss 1 = tensor(6395.9361, dtype=torch.float64)\n",
      "#Loss 2 = tensor(598.4297, dtype=torch.float64)\n",
      "#Loss 3 = tensor(523.8526, dtype=torch.float64)\n",
      "#Loss 4 = tensor(482.5247, dtype=torch.float64)\n",
      "#Loss 5 = tensor(443.3002, dtype=torch.float64)\n",
      "#Loss 6 = tensor(407.7794, dtype=torch.float64)\n",
      "#Loss 7 = tensor(376.8144, dtype=torch.float64)\n",
      "#Loss 8 = tensor(347.6016, dtype=torch.float64)\n",
      "#Loss 9 = tensor(320.5688, dtype=torch.float64)\n",
      "#Loss 10 = tensor(294.2892, dtype=torch.float64)\n",
      "#Loss 11 = tensor(272.2351, dtype=torch.float64)\n",
      "#Loss 12 = tensor(250.7513, dtype=torch.float64)\n",
      "#Loss 13 = tensor(231.5020, dtype=torch.float64)\n",
      "#Loss 14 = tensor(213.5727, dtype=torch.float64)\n",
      "#Loss 15 = tensor(195.8759, dtype=torch.float64)\n",
      "#Loss 16 = tensor(178.3521, dtype=torch.float64)\n",
      "#Loss 17 = tensor(163.5837, dtype=torch.float64)\n",
      "#Loss 18 = tensor(149.6106, dtype=torch.float64)\n",
      "#Loss 19 = tensor(137.5745, dtype=torch.float64)\n",
      "#Loss 20 = tensor(128.4794, dtype=torch.float64)\n",
      "#Loss 21 = tensor(120.0636, dtype=torch.float64)\n",
      "#Loss 22 = tensor(109.6913, dtype=torch.float64)\n",
      "#Loss 23 = tensor(100.9316, dtype=torch.float64)\n",
      "#Loss 24 = tensor(92.0312, dtype=torch.float64)\n",
      "#Loss 25 = tensor(84.8979, dtype=torch.float64)\n",
      "#Loss 26 = tensor(78.7401, dtype=torch.float64)\n",
      "#Loss 27 = tensor(73.7700, dtype=torch.float64)\n",
      "#Loss 28 = tensor(68.6338, dtype=torch.float64)\n",
      "#Loss 29 = tensor(64.7617, dtype=torch.float64)\n",
      "#Loss 30 = tensor(61.9329, dtype=torch.float64)\n",
      "#Loss 31 = tensor(59.5345, dtype=torch.float64)\n",
      "#Loss 32 = tensor(56.5331, dtype=torch.float64)\n",
      "#Loss 33 = tensor(53.5803, dtype=torch.float64)\n",
      "#Loss 34 = tensor(51.2594, dtype=torch.float64)\n",
      "#Loss 35 = tensor(48.9734, dtype=torch.float64)\n",
      "#Loss 36 = tensor(47.1492, dtype=torch.float64)\n",
      "#Loss 37 = tensor(45.5162, dtype=torch.float64)\n",
      "#Loss 38 = tensor(43.7000, dtype=torch.float64)\n",
      "#Loss 39 = tensor(42.1245, dtype=torch.float64)\n",
      "#Loss 40 = tensor(40.7182, dtype=torch.float64)\n",
      "#Loss 41 = tensor(39.3221, dtype=torch.float64)\n",
      "#Loss 42 = tensor(38.3600, dtype=torch.float64)\n",
      "#Loss 43 = tensor(37.4320, dtype=torch.float64)\n",
      "#Loss 44 = tensor(36.5884, dtype=torch.float64)\n",
      "#Loss 45 = tensor(35.4267, dtype=torch.float64)\n",
      "#Loss 46 = tensor(34.2426, dtype=torch.float64)\n",
      "#Loss 47 = tensor(33.4369, dtype=torch.float64)\n",
      "#Loss 48 = tensor(32.7040, dtype=torch.float64)\n",
      "#Loss 49 = tensor(31.9016, dtype=torch.float64)\n",
      "#Loss 50 = tensor(30.9569, dtype=torch.float64)\n",
      "#Loss 51 = tensor(30.2595, dtype=torch.float64)\n",
      "#Loss 52 = tensor(29.6964, dtype=torch.float64)\n",
      "#Loss 53 = tensor(28.7871, dtype=torch.float64)\n",
      "#Loss 54 = tensor(28.0372, dtype=torch.float64)\n",
      "#Loss 55 = tensor(27.2715, dtype=torch.float64)\n",
      "#Loss 56 = tensor(26.4908, dtype=torch.float64)\n",
      "#Loss 57 = tensor(26.0315, dtype=torch.float64)\n",
      "#Loss 58 = tensor(25.4739, dtype=torch.float64)\n",
      "#Loss 59 = tensor(24.9349, dtype=torch.float64)\n",
      "#Loss 60 = tensor(24.5454, dtype=torch.float64)\n",
      "#Loss 61 = tensor(24.1760, dtype=torch.float64)\n",
      "#Loss 62 = tensor(23.9884, dtype=torch.float64)\n",
      "#Loss 63 = tensor(23.7785, dtype=torch.float64)\n",
      "#Loss 64 = tensor(23.5932, dtype=torch.float64)\n",
      "#Loss 65 = tensor(23.4955, dtype=torch.float64)\n",
      "#Loss 66 = tensor(23.4125, dtype=torch.float64)\n",
      "#Loss 67 = tensor(23.3388, dtype=torch.float64)\n",
      "#Loss 68 = tensor(23.2678, dtype=torch.float64)\n",
      "#Loss 69 = tensor(22.9885, dtype=torch.float64)\n",
      "#Loss 70 = tensor(22.5855, dtype=torch.float64)\n",
      "#Loss 71 = tensor(22.2816, dtype=torch.float64)\n",
      "#Loss 72 = tensor(22.0459, dtype=torch.float64)\n",
      "#Loss 73 = tensor(21.8730, dtype=torch.float64)\n",
      "#Loss 74 = tensor(21.6773, dtype=torch.float64)\n",
      "#Loss 75 = tensor(21.3964, dtype=torch.float64)\n",
      "#Loss 76 = tensor(21.0488, dtype=torch.float64)\n",
      "#Loss 77 = tensor(20.5107, dtype=torch.float64)\n",
      "#Loss 78 = tensor(20.0892, dtype=torch.float64)\n",
      "#Loss 79 = tensor(19.7826, dtype=torch.float64)\n",
      "#Loss 80 = tensor(19.5744, dtype=torch.float64)\n",
      "#Loss 81 = tensor(19.4132, dtype=torch.float64)\n",
      "#Loss 82 = tensor(19.2834, dtype=torch.float64)\n",
      "#Loss 83 = tensor(19.2126, dtype=torch.float64)\n",
      "#Loss 84 = tensor(19.1265, dtype=torch.float64)\n",
      "#Loss 85 = tensor(18.8177, dtype=torch.float64)\n",
      "#Loss 86 = tensor(18.5207, dtype=torch.float64)\n",
      "#Loss 87 = tensor(18.3304, dtype=torch.float64)\n",
      "#Loss 88 = tensor(18.1233, dtype=torch.float64)\n",
      "#Loss 89 = tensor(17.9733, dtype=torch.float64)\n",
      "#Loss 90 = tensor(17.8806, dtype=torch.float64)\n",
      "#Loss 91 = tensor(17.8109, dtype=torch.float64)\n",
      "#Loss 92 = tensor(17.7142, dtype=torch.float64)\n",
      "#Loss 93 = tensor(17.5340, dtype=torch.float64)\n",
      "#Loss 94 = tensor(17.3790, dtype=torch.float64)\n",
      "#Loss 95 = tensor(17.2899, dtype=torch.float64)\n",
      "#Loss 96 = tensor(17.2397, dtype=torch.float64)\n",
      "#Loss 97 = tensor(17.1932, dtype=torch.float64)\n",
      "#Loss 98 = tensor(17.1467, dtype=torch.float64)\n",
      "#Loss 99 = tensor(17.0828, dtype=torch.float64)\n",
      "#Loss 100 = tensor(17.0559, dtype=torch.float64)\n",
      "#Loss 101 = tensor(17.0318, dtype=torch.float64)\n",
      "#Loss 102 = tensor(17.0158, dtype=torch.float64)\n",
      "#Loss 103 = tensor(16.9160, dtype=torch.float64)\n",
      "#Loss 104 = tensor(16.7912, dtype=torch.float64)\n",
      "#Loss 105 = tensor(16.6717, dtype=torch.float64)\n",
      "#Loss 106 = tensor(16.5686, dtype=torch.float64)\n",
      "#Loss 107 = tensor(16.4762, dtype=torch.float64)\n",
      "#Loss 108 = tensor(16.3137, dtype=torch.float64)\n",
      "#Loss 109 = tensor(16.1339, dtype=torch.float64)\n",
      "#Loss 110 = tensor(16.0009, dtype=torch.float64)\n",
      "#Loss 111 = tensor(15.8885, dtype=torch.float64)\n",
      "#Loss 112 = tensor(15.7468, dtype=torch.float64)\n",
      "#Loss 113 = tensor(15.6477, dtype=torch.float64)\n",
      "#Loss 114 = tensor(15.5438, dtype=torch.float64)\n",
      "#Loss 115 = tensor(15.4763, dtype=torch.float64)\n",
      "#Loss 116 = tensor(15.3861, dtype=torch.float64)\n",
      "#Loss 117 = tensor(15.2671, dtype=torch.float64)\n",
      "#Loss 118 = tensor(15.0100, dtype=torch.float64)\n",
      "#Loss 119 = tensor(14.8746, dtype=torch.float64)\n",
      "#Loss 120 = tensor(14.7260, dtype=torch.float64)\n",
      "#Loss 121 = tensor(14.6088, dtype=torch.float64)\n",
      "#Loss 122 = tensor(14.4877, dtype=torch.float64)\n",
      "#Loss 123 = tensor(14.4488, dtype=torch.float64)\n",
      "#Loss 124 = tensor(14.4139, dtype=torch.float64)\n",
      "#Loss 125 = tensor(14.3671, dtype=torch.float64)\n",
      "#Loss 126 = tensor(14.3095, dtype=torch.float64)\n",
      "#Loss 127 = tensor(14.2236, dtype=torch.float64)\n",
      "#Loss 128 = tensor(14.1364, dtype=torch.float64)\n",
      "#Loss 129 = tensor(14.0776, dtype=torch.float64)\n",
      "#Loss 130 = tensor(14.0192, dtype=torch.float64)\n",
      "#Loss 131 = tensor(13.9853, dtype=torch.float64)\n",
      "#Loss 132 = tensor(13.9554, dtype=torch.float64)\n",
      "#Loss 133 = tensor(13.9392, dtype=torch.float64)\n",
      "#Loss 134 = tensor(13.9346, dtype=torch.float64)\n",
      "#Loss 135 = tensor(13.9339, dtype=torch.float64)\n",
      "#Loss 136 = tensor(13.9338, dtype=torch.float64)\n",
      "#Loss 137 = tensor(13.9338, dtype=torch.float64)\n",
      "#Loss 138 = tensor(13.9338, dtype=torch.float64)\n",
      "#Loss 139 = tensor(13.9338, dtype=torch.float64)\n",
      " 30 300 平均相对误差2： tensor(6.0568, dtype=torch.float64, grad_fn=<NormBackward0>)   30 300 置换矩阵误差： tensor(1.4119, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0646, dtype=torch.float64)   实验回归误差 tensor(0.0465, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(7664.5704, dtype=torch.float64)\n",
      "#Loss 1 = tensor(7355.8008, dtype=torch.float64)\n",
      "#Loss 2 = tensor(870.1778, dtype=torch.float64)\n",
      "#Loss 3 = tensor(545.2179, dtype=torch.float64)\n",
      "#Loss 4 = tensor(487.2233, dtype=torch.float64)\n",
      "#Loss 5 = tensor(456.9321, dtype=torch.float64)\n",
      "#Loss 6 = tensor(428.0600, dtype=torch.float64)\n",
      "#Loss 7 = tensor(399.1555, dtype=torch.float64)\n",
      "#Loss 8 = tensor(371.4261, dtype=torch.float64)\n",
      "#Loss 9 = tensor(341.6710, dtype=torch.float64)\n",
      "#Loss 10 = tensor(312.5758, dtype=torch.float64)\n",
      "#Loss 11 = tensor(285.3971, dtype=torch.float64)\n",
      "#Loss 12 = tensor(257.9092, dtype=torch.float64)\n",
      "#Loss 13 = tensor(233.5264, dtype=torch.float64)\n",
      "#Loss 14 = tensor(208.8951, dtype=torch.float64)\n",
      "#Loss 15 = tensor(187.3099, dtype=torch.float64)\n",
      "#Loss 16 = tensor(164.7596, dtype=torch.float64)\n",
      "#Loss 17 = tensor(146.9897, dtype=torch.float64)\n",
      "#Loss 18 = tensor(129.3542, dtype=torch.float64)\n",
      "#Loss 19 = tensor(115.7444, dtype=torch.float64)\n",
      "#Loss 20 = tensor(103.4426, dtype=torch.float64)\n",
      "#Loss 21 = tensor(93.1798, dtype=torch.float64)\n",
      "#Loss 22 = tensor(85.7909, dtype=torch.float64)\n",
      "#Loss 23 = tensor(78.0500, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 24 = tensor(70.8115, dtype=torch.float64)\n",
      "#Loss 25 = tensor(65.5792, dtype=torch.float64)\n",
      "#Loss 26 = tensor(61.7660, dtype=torch.float64)\n",
      "#Loss 27 = tensor(58.2490, dtype=torch.float64)\n",
      "#Loss 28 = tensor(52.9717, dtype=torch.float64)\n",
      "#Loss 29 = tensor(49.6391, dtype=torch.float64)\n",
      "#Loss 30 = tensor(47.3152, dtype=torch.float64)\n",
      "#Loss 31 = tensor(45.2921, dtype=torch.float64)\n",
      "#Loss 32 = tensor(43.2074, dtype=torch.float64)\n",
      "#Loss 33 = tensor(40.4937, dtype=torch.float64)\n",
      "#Loss 34 = tensor(37.8427, dtype=torch.float64)\n",
      "#Loss 35 = tensor(35.7775, dtype=torch.float64)\n",
      "#Loss 36 = tensor(34.2677, dtype=torch.float64)\n",
      "#Loss 37 = tensor(32.7305, dtype=torch.float64)\n",
      "#Loss 38 = tensor(31.0625, dtype=torch.float64)\n",
      "#Loss 39 = tensor(29.2167, dtype=torch.float64)\n",
      "#Loss 40 = tensor(28.0311, dtype=torch.float64)\n",
      "#Loss 41 = tensor(26.9382, dtype=torch.float64)\n",
      "#Loss 42 = tensor(25.6841, dtype=torch.float64)\n",
      "#Loss 43 = tensor(24.6052, dtype=torch.float64)\n",
      "#Loss 44 = tensor(23.1673, dtype=torch.float64)\n",
      "#Loss 45 = tensor(21.8823, dtype=torch.float64)\n",
      "#Loss 46 = tensor(19.9768, dtype=torch.float64)\n",
      "#Loss 47 = tensor(18.2331, dtype=torch.float64)\n",
      "#Loss 48 = tensor(16.6754, dtype=torch.float64)\n",
      "#Loss 49 = tensor(15.6412, dtype=torch.float64)\n",
      "#Loss 50 = tensor(14.8228, dtype=torch.float64)\n",
      "#Loss 51 = tensor(14.2206, dtype=torch.float64)\n",
      "#Loss 52 = tensor(13.6172, dtype=torch.float64)\n",
      "#Loss 53 = tensor(13.3184, dtype=torch.float64)\n",
      "#Loss 54 = tensor(13.0004, dtype=torch.float64)\n",
      "#Loss 55 = tensor(12.5869, dtype=torch.float64)\n",
      "#Loss 56 = tensor(12.3206, dtype=torch.float64)\n",
      "#Loss 57 = tensor(12.1860, dtype=torch.float64)\n",
      "#Loss 58 = tensor(12.0024, dtype=torch.float64)\n",
      "#Loss 59 = tensor(11.7727, dtype=torch.float64)\n",
      "#Loss 60 = tensor(11.5207, dtype=torch.float64)\n",
      "#Loss 61 = tensor(11.2052, dtype=torch.float64)\n",
      "#Loss 62 = tensor(10.9396, dtype=torch.float64)\n",
      "#Loss 63 = tensor(10.7480, dtype=torch.float64)\n",
      "#Loss 64 = tensor(10.6133, dtype=torch.float64)\n",
      "#Loss 65 = tensor(10.4775, dtype=torch.float64)\n",
      "#Loss 66 = tensor(10.2186, dtype=torch.float64)\n",
      "#Loss 67 = tensor(10.0624, dtype=torch.float64)\n",
      "#Loss 68 = tensor(9.9255, dtype=torch.float64)\n",
      "#Loss 69 = tensor(9.8078, dtype=torch.float64)\n",
      "#Loss 70 = tensor(9.6414, dtype=torch.float64)\n",
      "#Loss 71 = tensor(9.5148, dtype=torch.float64)\n",
      "#Loss 72 = tensor(9.4480, dtype=torch.float64)\n",
      "#Loss 73 = tensor(9.3910, dtype=torch.float64)\n",
      "#Loss 74 = tensor(9.2866, dtype=torch.float64)\n",
      "#Loss 75 = tensor(9.2051, dtype=torch.float64)\n",
      "#Loss 76 = tensor(9.1549, dtype=torch.float64)\n",
      "#Loss 77 = tensor(9.1055, dtype=torch.float64)\n",
      "#Loss 78 = tensor(9.0897, dtype=torch.float64)\n",
      "#Loss 79 = tensor(9.0787, dtype=torch.float64)\n",
      "#Loss 80 = tensor(9.0758, dtype=torch.float64)\n",
      "#Loss 81 = tensor(9.0673, dtype=torch.float64)\n",
      "#Loss 82 = tensor(9.0010, dtype=torch.float64)\n",
      "#Loss 83 = tensor(8.9783, dtype=torch.float64)\n",
      "#Loss 84 = tensor(8.9700, dtype=torch.float64)\n",
      "#Loss 85 = tensor(8.9665, dtype=torch.float64)\n",
      "#Loss 86 = tensor(8.9661, dtype=torch.float64)\n",
      "#Loss 87 = tensor(8.9660, dtype=torch.float64)\n",
      "#Loss 88 = tensor(8.9658, dtype=torch.float64)\n",
      "#Loss 89 = tensor(8.9658, dtype=torch.float64)\n",
      "#Loss 90 = tensor(8.9658, dtype=torch.float64)\n",
      "#Loss 91 = tensor(8.9658, dtype=torch.float64)\n",
      "#Loss 92 = tensor(8.9658, dtype=torch.float64)\n",
      " 30 300 平均相对误差2： tensor(7.3141, dtype=torch.float64, grad_fn=<NormBackward0>)   30 300 置换矩阵误差： tensor(1.4109, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0555, dtype=torch.float64)   实验回归误差 tensor(0.0342, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(6736.0638, dtype=torch.float64)\n",
      "#Loss 1 = tensor(6660.9659, dtype=torch.float64)\n",
      "#Loss 2 = tensor(998.7297, dtype=torch.float64)\n",
      "#Loss 3 = tensor(428.3300, dtype=torch.float64)\n",
      "#Loss 4 = tensor(305.8170, dtype=torch.float64)\n",
      "#Loss 5 = tensor(278.4675, dtype=torch.float64)\n",
      "#Loss 6 = tensor(266.4803, dtype=torch.float64)\n",
      "#Loss 7 = tensor(257.4339, dtype=torch.float64)\n",
      "#Loss 8 = tensor(250.7428, dtype=torch.float64)\n",
      "#Loss 9 = tensor(245.9385, dtype=torch.float64)\n",
      "#Loss 10 = tensor(241.5796, dtype=torch.float64)\n",
      "#Loss 11 = tensor(236.2210, dtype=torch.float64)\n",
      "#Loss 12 = tensor(228.5824, dtype=torch.float64)\n",
      "#Loss 13 = tensor(221.0241, dtype=torch.float64)\n",
      "#Loss 14 = tensor(212.4767, dtype=torch.float64)\n",
      "#Loss 15 = tensor(204.8773, dtype=torch.float64)\n",
      "#Loss 16 = tensor(198.5137, dtype=torch.float64)\n",
      "#Loss 17 = tensor(190.5293, dtype=torch.float64)\n",
      "#Loss 18 = tensor(184.4723, dtype=torch.float64)\n",
      "#Loss 19 = tensor(179.5418, dtype=torch.float64)\n",
      "#Loss 20 = tensor(174.4193, dtype=torch.float64)\n",
      "#Loss 21 = tensor(170.2024, dtype=torch.float64)\n",
      "#Loss 22 = tensor(165.3652, dtype=torch.float64)\n",
      "#Loss 23 = tensor(160.1954, dtype=torch.float64)\n",
      "#Loss 24 = tensor(154.5443, dtype=torch.float64)\n",
      "#Loss 25 = tensor(150.2794, dtype=torch.float64)\n",
      "#Loss 26 = tensor(147.0591, dtype=torch.float64)\n",
      "#Loss 27 = tensor(142.8486, dtype=torch.float64)\n",
      "#Loss 28 = tensor(138.5839, dtype=torch.float64)\n",
      "#Loss 29 = tensor(134.3263, dtype=torch.float64)\n",
      "#Loss 30 = tensor(131.5382, dtype=torch.float64)\n",
      "#Loss 31 = tensor(128.6874, dtype=torch.float64)\n",
      "#Loss 32 = tensor(125.3739, dtype=torch.float64)\n",
      "#Loss 33 = tensor(120.8831, dtype=torch.float64)\n",
      "#Loss 34 = tensor(116.9122, dtype=torch.float64)\n",
      "#Loss 35 = tensor(112.8763, dtype=torch.float64)\n",
      "#Loss 36 = tensor(109.2804, dtype=torch.float64)\n",
      "#Loss 37 = tensor(105.5087, dtype=torch.float64)\n",
      "#Loss 38 = tensor(102.1086, dtype=torch.float64)\n",
      "#Loss 39 = tensor(99.0408, dtype=torch.float64)\n",
      "#Loss 40 = tensor(96.4692, dtype=torch.float64)\n",
      "#Loss 41 = tensor(94.1677, dtype=torch.float64)\n",
      "#Loss 42 = tensor(91.8617, dtype=torch.float64)\n",
      "#Loss 43 = tensor(89.8315, dtype=torch.float64)\n",
      "#Loss 44 = tensor(87.7065, dtype=torch.float64)\n",
      "#Loss 45 = tensor(86.2492, dtype=torch.float64)\n",
      "#Loss 46 = tensor(85.0601, dtype=torch.float64)\n",
      "#Loss 47 = tensor(83.6619, dtype=torch.float64)\n",
      "#Loss 48 = tensor(82.1165, dtype=torch.float64)\n",
      "#Loss 49 = tensor(80.5471, dtype=torch.float64)\n",
      "#Loss 50 = tensor(78.6300, dtype=torch.float64)\n",
      "#Loss 51 = tensor(76.5544, dtype=torch.float64)\n",
      "#Loss 52 = tensor(73.1262, dtype=torch.float64)\n",
      "#Loss 53 = tensor(69.7577, dtype=torch.float64)\n",
      "#Loss 54 = tensor(66.9715, dtype=torch.float64)\n",
      "#Loss 55 = tensor(64.4306, dtype=torch.float64)\n",
      "#Loss 56 = tensor(62.1384, dtype=torch.float64)\n",
      "#Loss 57 = tensor(60.4063, dtype=torch.float64)\n",
      "#Loss 58 = tensor(58.1436, dtype=torch.float64)\n",
      "#Loss 59 = tensor(56.1894, dtype=torch.float64)\n",
      "#Loss 60 = tensor(54.6562, dtype=torch.float64)\n",
      "#Loss 61 = tensor(53.4069, dtype=torch.float64)\n",
      "#Loss 62 = tensor(52.0682, dtype=torch.float64)\n",
      "#Loss 63 = tensor(50.6168, dtype=torch.float64)\n",
      "#Loss 64 = tensor(49.1387, dtype=torch.float64)\n",
      "#Loss 65 = tensor(47.6759, dtype=torch.float64)\n",
      "#Loss 66 = tensor(45.9539, dtype=torch.float64)\n",
      "#Loss 67 = tensor(44.6065, dtype=torch.float64)\n",
      "#Loss 68 = tensor(43.5573, dtype=torch.float64)\n",
      "#Loss 69 = tensor(42.5893, dtype=torch.float64)\n",
      "#Loss 70 = tensor(41.4453, dtype=torch.float64)\n",
      "#Loss 71 = tensor(40.3817, dtype=torch.float64)\n",
      "#Loss 72 = tensor(39.4555, dtype=torch.float64)\n",
      "#Loss 73 = tensor(38.6736, dtype=torch.float64)\n",
      "#Loss 74 = tensor(37.7424, dtype=torch.float64)\n",
      "#Loss 75 = tensor(36.7032, dtype=torch.float64)\n",
      "#Loss 76 = tensor(35.5279, dtype=torch.float64)\n",
      "#Loss 77 = tensor(34.4184, dtype=torch.float64)\n",
      "#Loss 78 = tensor(33.6496, dtype=torch.float64)\n",
      "#Loss 79 = tensor(33.2930, dtype=torch.float64)\n",
      "#Loss 80 = tensor(32.8293, dtype=torch.float64)\n",
      "#Loss 81 = tensor(32.1698, dtype=torch.float64)\n",
      "#Loss 82 = tensor(31.5781, dtype=torch.float64)\n",
      "#Loss 83 = tensor(31.2299, dtype=torch.float64)\n",
      "#Loss 84 = tensor(30.8952, dtype=torch.float64)\n",
      "#Loss 85 = tensor(30.6230, dtype=torch.float64)\n",
      "#Loss 86 = tensor(30.4329, dtype=torch.float64)\n",
      "#Loss 87 = tensor(30.3363, dtype=torch.float64)\n",
      "#Loss 88 = tensor(30.2814, dtype=torch.float64)\n",
      "#Loss 89 = tensor(30.2470, dtype=torch.float64)\n",
      "#Loss 90 = tensor(30.1796, dtype=torch.float64)\n",
      "#Loss 91 = tensor(30.0489, dtype=torch.float64)\n",
      "#Loss 92 = tensor(29.9170, dtype=torch.float64)\n",
      "#Loss 93 = tensor(29.8197, dtype=torch.float64)\n",
      "#Loss 94 = tensor(29.6625, dtype=torch.float64)\n",
      "#Loss 95 = tensor(29.5515, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 96 = tensor(29.4741, dtype=torch.float64)\n",
      "#Loss 97 = tensor(29.4416, dtype=torch.float64)\n",
      "#Loss 98 = tensor(29.4029, dtype=torch.float64)\n",
      "#Loss 99 = tensor(29.3466, dtype=torch.float64)\n",
      "#Loss 100 = tensor(29.2808, dtype=torch.float64)\n",
      "#Loss 101 = tensor(29.2014, dtype=torch.float64)\n",
      "#Loss 102 = tensor(29.1190, dtype=torch.float64)\n",
      "#Loss 103 = tensor(29.0612, dtype=torch.float64)\n",
      "#Loss 104 = tensor(28.9545, dtype=torch.float64)\n",
      "#Loss 105 = tensor(28.8575, dtype=torch.float64)\n",
      "#Loss 106 = tensor(28.7369, dtype=torch.float64)\n",
      "#Loss 107 = tensor(28.5886, dtype=torch.float64)\n",
      "#Loss 108 = tensor(28.4402, dtype=torch.float64)\n",
      "#Loss 109 = tensor(28.2903, dtype=torch.float64)\n",
      "#Loss 110 = tensor(28.1778, dtype=torch.float64)\n",
      "#Loss 111 = tensor(28.0694, dtype=torch.float64)\n",
      "#Loss 112 = tensor(27.9363, dtype=torch.float64)\n",
      "#Loss 113 = tensor(27.7942, dtype=torch.float64)\n",
      "#Loss 114 = tensor(27.6883, dtype=torch.float64)\n",
      "#Loss 115 = tensor(27.5600, dtype=torch.float64)\n",
      "#Loss 116 = tensor(27.4748, dtype=torch.float64)\n",
      "#Loss 117 = tensor(27.4098, dtype=torch.float64)\n",
      "#Loss 118 = tensor(27.3574, dtype=torch.float64)\n",
      "#Loss 119 = tensor(27.2847, dtype=torch.float64)\n",
      "#Loss 120 = tensor(27.2091, dtype=torch.float64)\n",
      "#Loss 121 = tensor(27.1473, dtype=torch.float64)\n",
      "#Loss 122 = tensor(27.1006, dtype=torch.float64)\n",
      "#Loss 123 = tensor(27.0278, dtype=torch.float64)\n",
      "#Loss 124 = tensor(26.9245, dtype=torch.float64)\n",
      "#Loss 125 = tensor(26.8355, dtype=torch.float64)\n",
      "#Loss 126 = tensor(26.7567, dtype=torch.float64)\n",
      "#Loss 127 = tensor(26.6964, dtype=torch.float64)\n",
      "#Loss 128 = tensor(26.6658, dtype=torch.float64)\n",
      "#Loss 129 = tensor(26.6328, dtype=torch.float64)\n",
      "#Loss 130 = tensor(26.6010, dtype=torch.float64)\n",
      "#Loss 131 = tensor(26.5792, dtype=torch.float64)\n",
      "#Loss 132 = tensor(26.5658, dtype=torch.float64)\n",
      "#Loss 133 = tensor(26.5616, dtype=torch.float64)\n",
      "#Loss 134 = tensor(26.5233, dtype=torch.float64)\n",
      "#Loss 135 = tensor(26.5071, dtype=torch.float64)\n",
      "#Loss 136 = tensor(26.4811, dtype=torch.float64)\n",
      "#Loss 137 = tensor(26.4371, dtype=torch.float64)\n",
      "#Loss 138 = tensor(26.4236, dtype=torch.float64)\n",
      "#Loss 139 = tensor(26.4179, dtype=torch.float64)\n",
      "#Loss 140 = tensor(26.4138, dtype=torch.float64)\n",
      "#Loss 141 = tensor(26.4117, dtype=torch.float64)\n",
      "#Loss 142 = tensor(26.4096, dtype=torch.float64)\n",
      "#Loss 143 = tensor(26.4094, dtype=torch.float64)\n",
      "#Loss 144 = tensor(26.4092, dtype=torch.float64)\n",
      "#Loss 145 = tensor(26.4074, dtype=torch.float64)\n",
      "#Loss 146 = tensor(26.4046, dtype=torch.float64)\n",
      "#Loss 147 = tensor(26.3989, dtype=torch.float64)\n",
      "#Loss 148 = tensor(26.3930, dtype=torch.float64)\n",
      "#Loss 149 = tensor(26.3819, dtype=torch.float64)\n",
      "#Loss 150 = tensor(26.3799, dtype=torch.float64)\n",
      "#Loss 151 = tensor(26.3779, dtype=torch.float64)\n",
      "#Loss 152 = tensor(26.3753, dtype=torch.float64)\n",
      "#Loss 153 = tensor(26.3685, dtype=torch.float64)\n",
      "#Loss 154 = tensor(26.3562, dtype=torch.float64)\n",
      "#Loss 155 = tensor(26.3512, dtype=torch.float64)\n",
      "#Loss 156 = tensor(26.3501, dtype=torch.float64)\n",
      "#Loss 157 = tensor(26.3494, dtype=torch.float64)\n",
      "#Loss 158 = tensor(26.3489, dtype=torch.float64)\n",
      "#Loss 159 = tensor(26.3489, dtype=torch.float64)\n",
      "#Loss 160 = tensor(26.3489, dtype=torch.float64)\n",
      "#Loss 161 = tensor(26.3487, dtype=torch.float64)\n",
      "#Loss 162 = tensor(26.3487, dtype=torch.float64)\n",
      "#Loss 163 = tensor(26.3487, dtype=torch.float64)\n",
      "#Loss 164 = tensor(26.3487, dtype=torch.float64)\n",
      " 30 300 平均相对误差2： tensor(7.3911, dtype=torch.float64, grad_fn=<NormBackward0>)   30 300 置换矩阵误差： tensor(1.4142, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0628, dtype=torch.float64)   实验回归误差 tensor(0.0625, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(10996.9586, dtype=torch.float64)\n",
      "#Loss 1 = tensor(10860.1127, dtype=torch.float64)\n",
      "#Loss 2 = tensor(818.3311, dtype=torch.float64)\n",
      "#Loss 3 = tensor(615.9750, dtype=torch.float64)\n",
      "#Loss 4 = tensor(585.3560, dtype=torch.float64)\n",
      "#Loss 5 = tensor(565.6124, dtype=torch.float64)\n",
      "#Loss 6 = tensor(545.7725, dtype=torch.float64)\n",
      "#Loss 7 = tensor(525.6449, dtype=torch.float64)\n",
      "#Loss 8 = tensor(502.4457, dtype=torch.float64)\n",
      "#Loss 9 = tensor(479.9521, dtype=torch.float64)\n",
      "#Loss 10 = tensor(458.3170, dtype=torch.float64)\n",
      "#Loss 11 = tensor(435.2044, dtype=torch.float64)\n",
      "#Loss 12 = tensor(406.4174, dtype=torch.float64)\n",
      "#Loss 13 = tensor(381.8276, dtype=torch.float64)\n",
      "#Loss 14 = tensor(359.0415, dtype=torch.float64)\n",
      "#Loss 15 = tensor(340.6728, dtype=torch.float64)\n",
      "#Loss 16 = tensor(323.3716, dtype=torch.float64)\n",
      "#Loss 17 = tensor(309.4985, dtype=torch.float64)\n",
      "#Loss 18 = tensor(294.4268, dtype=torch.float64)\n",
      "#Loss 19 = tensor(278.6774, dtype=torch.float64)\n",
      "#Loss 20 = tensor(265.3388, dtype=torch.float64)\n",
      "#Loss 21 = tensor(252.5560, dtype=torch.float64)\n",
      "#Loss 22 = tensor(242.2752, dtype=torch.float64)\n",
      "#Loss 23 = tensor(232.3039, dtype=torch.float64)\n",
      "#Loss 24 = tensor(220.5857, dtype=torch.float64)\n",
      "#Loss 25 = tensor(209.3234, dtype=torch.float64)\n",
      "#Loss 26 = tensor(197.5750, dtype=torch.float64)\n",
      "#Loss 27 = tensor(185.0931, dtype=torch.float64)\n",
      "#Loss 28 = tensor(173.5039, dtype=torch.float64)\n",
      "#Loss 29 = tensor(163.9560, dtype=torch.float64)\n",
      "#Loss 30 = tensor(154.4624, dtype=torch.float64)\n",
      "#Loss 31 = tensor(144.6416, dtype=torch.float64)\n",
      "#Loss 32 = tensor(135.6282, dtype=torch.float64)\n",
      "#Loss 33 = tensor(125.8485, dtype=torch.float64)\n",
      "#Loss 34 = tensor(117.3218, dtype=torch.float64)\n",
      "#Loss 35 = tensor(109.0344, dtype=torch.float64)\n",
      "#Loss 36 = tensor(101.1637, dtype=torch.float64)\n",
      "#Loss 37 = tensor(94.4754, dtype=torch.float64)\n",
      "#Loss 38 = tensor(87.2026, dtype=torch.float64)\n",
      "#Loss 39 = tensor(81.4202, dtype=torch.float64)\n",
      "#Loss 40 = tensor(76.5101, dtype=torch.float64)\n",
      "#Loss 41 = tensor(71.4662, dtype=torch.float64)\n",
      "#Loss 42 = tensor(66.0948, dtype=torch.float64)\n",
      "#Loss 43 = tensor(60.3621, dtype=torch.float64)\n",
      "#Loss 44 = tensor(56.0702, dtype=torch.float64)\n",
      "#Loss 45 = tensor(52.4319, dtype=torch.float64)\n",
      "#Loss 46 = tensor(49.3330, dtype=torch.float64)\n",
      "#Loss 47 = tensor(46.5542, dtype=torch.float64)\n",
      "#Loss 48 = tensor(44.0389, dtype=torch.float64)\n",
      "#Loss 49 = tensor(41.7167, dtype=torch.float64)\n",
      "#Loss 50 = tensor(39.0609, dtype=torch.float64)\n",
      "#Loss 51 = tensor(37.3634, dtype=torch.float64)\n",
      "#Loss 52 = tensor(36.1697, dtype=torch.float64)\n",
      "#Loss 53 = tensor(35.0210, dtype=torch.float64)\n",
      "#Loss 54 = tensor(33.7700, dtype=torch.float64)\n",
      "#Loss 55 = tensor(32.2891, dtype=torch.float64)\n",
      "#Loss 56 = tensor(31.0669, dtype=torch.float64)\n",
      "#Loss 57 = tensor(29.9671, dtype=torch.float64)\n",
      "#Loss 58 = tensor(29.1056, dtype=torch.float64)\n",
      "#Loss 59 = tensor(28.2310, dtype=torch.float64)\n",
      "#Loss 60 = tensor(27.0710, dtype=torch.float64)\n",
      "#Loss 61 = tensor(25.4107, dtype=torch.float64)\n",
      "#Loss 62 = tensor(24.2360, dtype=torch.float64)\n",
      "#Loss 63 = tensor(23.1115, dtype=torch.float64)\n",
      "#Loss 64 = tensor(21.9591, dtype=torch.float64)\n",
      "#Loss 65 = tensor(21.0821, dtype=torch.float64)\n",
      "#Loss 66 = tensor(20.5250, dtype=torch.float64)\n",
      "#Loss 67 = tensor(19.8772, dtype=torch.float64)\n",
      "#Loss 68 = tensor(18.9050, dtype=torch.float64)\n",
      "#Loss 69 = tensor(17.2604, dtype=torch.float64)\n",
      "#Loss 70 = tensor(16.1595, dtype=torch.float64)\n",
      "#Loss 71 = tensor(15.0923, dtype=torch.float64)\n",
      "#Loss 72 = tensor(14.3222, dtype=torch.float64)\n",
      "#Loss 73 = tensor(13.3935, dtype=torch.float64)\n",
      "#Loss 74 = tensor(12.3173, dtype=torch.float64)\n",
      "#Loss 75 = tensor(11.4882, dtype=torch.float64)\n",
      "#Loss 76 = tensor(10.8883, dtype=torch.float64)\n",
      "#Loss 77 = tensor(10.3980, dtype=torch.float64)\n",
      "#Loss 78 = tensor(9.9679, dtype=torch.float64)\n",
      "#Loss 79 = tensor(9.6092, dtype=torch.float64)\n",
      "#Loss 80 = tensor(9.4277, dtype=torch.float64)\n",
      "#Loss 81 = tensor(9.3266, dtype=torch.float64)\n",
      "#Loss 82 = tensor(9.1797, dtype=torch.float64)\n",
      "#Loss 83 = tensor(8.9718, dtype=torch.float64)\n",
      "#Loss 84 = tensor(8.8215, dtype=torch.float64)\n",
      "#Loss 85 = tensor(8.7247, dtype=torch.float64)\n",
      "#Loss 86 = tensor(8.6236, dtype=torch.float64)\n",
      "#Loss 87 = tensor(8.4679, dtype=torch.float64)\n",
      "#Loss 88 = tensor(8.3207, dtype=torch.float64)\n",
      "#Loss 89 = tensor(8.2164, dtype=torch.float64)\n",
      "#Loss 90 = tensor(8.1315, dtype=torch.float64)\n",
      "#Loss 91 = tensor(8.0958, dtype=torch.float64)\n",
      "#Loss 92 = tensor(8.0655, dtype=torch.float64)\n",
      "#Loss 93 = tensor(8.0338, dtype=torch.float64)\n",
      "#Loss 94 = tensor(8.0113, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 95 = tensor(7.9916, dtype=torch.float64)\n",
      "#Loss 96 = tensor(7.9885, dtype=torch.float64)\n",
      "#Loss 97 = tensor(7.9877, dtype=torch.float64)\n",
      "#Loss 98 = tensor(7.9875, dtype=torch.float64)\n",
      "#Loss 99 = tensor(7.9874, dtype=torch.float64)\n",
      "#Loss 100 = tensor(7.9874, dtype=torch.float64)\n",
      "#Loss 101 = tensor(7.9874, dtype=torch.float64)\n",
      " 30 300 平均相对误差2： tensor(8.3027, dtype=torch.float64, grad_fn=<NormBackward0>)   30 300 置换矩阵误差： tensor(1.4119, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0492, dtype=torch.float64)   实验回归误差 tensor(0.0270, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(6022.3120, dtype=torch.float64)\n",
      "#Loss 1 = tensor(5866.2707, dtype=torch.float64)\n",
      "#Loss 2 = tensor(308.9416, dtype=torch.float64)\n",
      "#Loss 3 = tensor(253.4899, dtype=torch.float64)\n",
      "#Loss 4 = tensor(236.1863, dtype=torch.float64)\n",
      "#Loss 5 = tensor(221.8701, dtype=torch.float64)\n",
      "#Loss 6 = tensor(209.1237, dtype=torch.float64)\n",
      "#Loss 7 = tensor(198.1352, dtype=torch.float64)\n",
      "#Loss 8 = tensor(187.7298, dtype=torch.float64)\n",
      "#Loss 9 = tensor(178.1115, dtype=torch.float64)\n",
      "#Loss 10 = tensor(170.2938, dtype=torch.float64)\n",
      "#Loss 11 = tensor(162.5379, dtype=torch.float64)\n",
      "#Loss 12 = tensor(154.8568, dtype=torch.float64)\n",
      "#Loss 13 = tensor(146.8933, dtype=torch.float64)\n",
      "#Loss 14 = tensor(138.3168, dtype=torch.float64)\n",
      "#Loss 15 = tensor(128.6310, dtype=torch.float64)\n",
      "#Loss 16 = tensor(121.1029, dtype=torch.float64)\n",
      "#Loss 17 = tensor(113.7198, dtype=torch.float64)\n",
      "#Loss 18 = tensor(105.8335, dtype=torch.float64)\n",
      "#Loss 19 = tensor(96.5377, dtype=torch.float64)\n",
      "#Loss 20 = tensor(87.9873, dtype=torch.float64)\n",
      "#Loss 21 = tensor(79.8713, dtype=torch.float64)\n",
      "#Loss 22 = tensor(74.3220, dtype=torch.float64)\n",
      "#Loss 23 = tensor(68.6269, dtype=torch.float64)\n",
      "#Loss 24 = tensor(63.6100, dtype=torch.float64)\n",
      "#Loss 25 = tensor(59.6524, dtype=torch.float64)\n",
      "#Loss 26 = tensor(56.4256, dtype=torch.float64)\n",
      "#Loss 27 = tensor(52.7272, dtype=torch.float64)\n",
      "#Loss 28 = tensor(49.0541, dtype=torch.float64)\n",
      "#Loss 29 = tensor(45.2143, dtype=torch.float64)\n",
      "#Loss 30 = tensor(41.1018, dtype=torch.float64)\n",
      "#Loss 31 = tensor(37.2833, dtype=torch.float64)\n",
      "#Loss 32 = tensor(34.1845, dtype=torch.float64)\n",
      "#Loss 33 = tensor(31.7118, dtype=torch.float64)\n",
      "#Loss 34 = tensor(29.4651, dtype=torch.float64)\n",
      "#Loss 35 = tensor(27.8189, dtype=torch.float64)\n",
      "#Loss 36 = tensor(26.8033, dtype=torch.float64)\n",
      "#Loss 37 = tensor(25.8265, dtype=torch.float64)\n",
      "#Loss 38 = tensor(24.4965, dtype=torch.float64)\n",
      "#Loss 39 = tensor(23.1012, dtype=torch.float64)\n",
      "#Loss 40 = tensor(21.9921, dtype=torch.float64)\n",
      "#Loss 41 = tensor(20.7561, dtype=torch.float64)\n",
      "#Loss 42 = tensor(19.8427, dtype=torch.float64)\n",
      "#Loss 43 = tensor(18.8199, dtype=torch.float64)\n",
      "#Loss 44 = tensor(17.4578, dtype=torch.float64)\n",
      "#Loss 45 = tensor(16.1865, dtype=torch.float64)\n",
      "#Loss 46 = tensor(15.2571, dtype=torch.float64)\n",
      "#Loss 47 = tensor(14.5947, dtype=torch.float64)\n",
      "#Loss 48 = tensor(13.9466, dtype=torch.float64)\n",
      "#Loss 49 = tensor(13.4786, dtype=torch.float64)\n",
      "#Loss 50 = tensor(13.0160, dtype=torch.float64)\n",
      "#Loss 51 = tensor(12.5578, dtype=torch.float64)\n",
      "#Loss 52 = tensor(12.2616, dtype=torch.float64)\n",
      "#Loss 53 = tensor(11.8530, dtype=torch.float64)\n",
      "#Loss 54 = tensor(11.2658, dtype=torch.float64)\n",
      "#Loss 55 = tensor(10.8172, dtype=torch.float64)\n",
      "#Loss 56 = tensor(10.3876, dtype=torch.float64)\n",
      "#Loss 57 = tensor(10.0638, dtype=torch.float64)\n",
      "#Loss 58 = tensor(9.7750, dtype=torch.float64)\n",
      "#Loss 59 = tensor(9.6028, dtype=torch.float64)\n",
      "#Loss 60 = tensor(9.5166, dtype=torch.float64)\n",
      "#Loss 61 = tensor(9.4276, dtype=torch.float64)\n",
      "#Loss 62 = tensor(9.3815, dtype=torch.float64)\n",
      "#Loss 63 = tensor(9.3302, dtype=torch.float64)\n",
      "#Loss 64 = tensor(9.2458, dtype=torch.float64)\n",
      "#Loss 65 = tensor(9.1858, dtype=torch.float64)\n",
      "#Loss 66 = tensor(9.1271, dtype=torch.float64)\n",
      "#Loss 67 = tensor(9.0600, dtype=torch.float64)\n",
      "#Loss 68 = tensor(9.0073, dtype=torch.float64)\n",
      "#Loss 69 = tensor(8.9851, dtype=torch.float64)\n",
      "#Loss 70 = tensor(8.8731, dtype=torch.float64)\n",
      "#Loss 71 = tensor(8.7574, dtype=torch.float64)\n",
      "#Loss 72 = tensor(8.6768, dtype=torch.float64)\n",
      "#Loss 73 = tensor(8.5983, dtype=torch.float64)\n",
      "#Loss 74 = tensor(8.5152, dtype=torch.float64)\n",
      "#Loss 75 = tensor(8.4599, dtype=torch.float64)\n",
      "#Loss 76 = tensor(8.4051, dtype=torch.float64)\n",
      "#Loss 77 = tensor(8.3687, dtype=torch.float64)\n",
      "#Loss 78 = tensor(8.3478, dtype=torch.float64)\n",
      "#Loss 79 = tensor(8.3420, dtype=torch.float64)\n",
      "#Loss 80 = tensor(8.3337, dtype=torch.float64)\n",
      "#Loss 81 = tensor(8.3163, dtype=torch.float64)\n",
      "#Loss 82 = tensor(8.2846, dtype=torch.float64)\n",
      "#Loss 83 = tensor(8.2687, dtype=torch.float64)\n",
      "#Loss 84 = tensor(8.2509, dtype=torch.float64)\n",
      "#Loss 85 = tensor(8.2419, dtype=torch.float64)\n",
      "#Loss 86 = tensor(8.2375, dtype=torch.float64)\n",
      "#Loss 87 = tensor(8.2364, dtype=torch.float64)\n",
      "#Loss 88 = tensor(8.2362, dtype=torch.float64)\n",
      "#Loss 89 = tensor(8.2358, dtype=torch.float64)\n",
      "#Loss 90 = tensor(8.2357, dtype=torch.float64)\n",
      "#Loss 91 = tensor(8.2357, dtype=torch.float64)\n",
      "#Loss 92 = tensor(8.2357, dtype=torch.float64)\n",
      "#Loss 93 = tensor(8.2357, dtype=torch.float64)\n",
      " 30 300 平均相对误差2： tensor(6.0050, dtype=torch.float64, grad_fn=<NormBackward0>)   30 300 置换矩阵误差： tensor(1.4095, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0688, dtype=torch.float64)   实验回归误差 tensor(0.0370, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(9559.8622, dtype=torch.float64)\n",
      "#Loss 1 = tensor(9534.4731, dtype=torch.float64)\n",
      "#Loss 2 = tensor(1148.9909, dtype=torch.float64)\n",
      "#Loss 3 = tensor(619.7682, dtype=torch.float64)\n",
      "#Loss 4 = tensor(535.9190, dtype=torch.float64)\n",
      "#Loss 5 = tensor(506.9011, dtype=torch.float64)\n",
      "#Loss 6 = tensor(484.7833, dtype=torch.float64)\n",
      "#Loss 7 = tensor(466.7883, dtype=torch.float64)\n",
      "#Loss 8 = tensor(448.5665, dtype=torch.float64)\n",
      "#Loss 9 = tensor(432.2726, dtype=torch.float64)\n",
      "#Loss 10 = tensor(418.5476, dtype=torch.float64)\n",
      "#Loss 11 = tensor(405.1712, dtype=torch.float64)\n",
      "#Loss 12 = tensor(391.3583, dtype=torch.float64)\n",
      "#Loss 13 = tensor(378.5537, dtype=torch.float64)\n",
      "#Loss 14 = tensor(364.9895, dtype=torch.float64)\n",
      "#Loss 15 = tensor(348.7755, dtype=torch.float64)\n",
      "#Loss 16 = tensor(333.5485, dtype=torch.float64)\n",
      "#Loss 17 = tensor(318.9597, dtype=torch.float64)\n",
      "#Loss 18 = tensor(305.1741, dtype=torch.float64)\n",
      "#Loss 19 = tensor(290.8643, dtype=torch.float64)\n",
      "#Loss 20 = tensor(276.8608, dtype=torch.float64)\n",
      "#Loss 21 = tensor(263.1754, dtype=torch.float64)\n",
      "#Loss 22 = tensor(248.6857, dtype=torch.float64)\n",
      "#Loss 23 = tensor(234.8297, dtype=torch.float64)\n",
      "#Loss 24 = tensor(224.1266, dtype=torch.float64)\n",
      "#Loss 25 = tensor(212.7172, dtype=torch.float64)\n",
      "#Loss 26 = tensor(202.4365, dtype=torch.float64)\n",
      "#Loss 27 = tensor(191.5755, dtype=torch.float64)\n",
      "#Loss 28 = tensor(182.2645, dtype=torch.float64)\n",
      "#Loss 29 = tensor(173.6894, dtype=torch.float64)\n",
      "#Loss 30 = tensor(167.4146, dtype=torch.float64)\n",
      "#Loss 31 = tensor(159.9063, dtype=torch.float64)\n",
      "#Loss 32 = tensor(152.7302, dtype=torch.float64)\n",
      "#Loss 33 = tensor(145.8303, dtype=torch.float64)\n",
      "#Loss 34 = tensor(137.4224, dtype=torch.float64)\n",
      "#Loss 35 = tensor(127.1291, dtype=torch.float64)\n",
      "#Loss 36 = tensor(117.9106, dtype=torch.float64)\n",
      "#Loss 37 = tensor(109.4749, dtype=torch.float64)\n",
      "#Loss 38 = tensor(100.6893, dtype=torch.float64)\n",
      "#Loss 39 = tensor(93.5336, dtype=torch.float64)\n",
      "#Loss 40 = tensor(87.2278, dtype=torch.float64)\n",
      "#Loss 41 = tensor(81.1694, dtype=torch.float64)\n",
      "#Loss 42 = tensor(76.9129, dtype=torch.float64)\n",
      "#Loss 43 = tensor(73.3699, dtype=torch.float64)\n",
      "#Loss 44 = tensor(70.6209, dtype=torch.float64)\n",
      "#Loss 45 = tensor(68.7273, dtype=torch.float64)\n",
      "#Loss 46 = tensor(66.9227, dtype=torch.float64)\n",
      "#Loss 47 = tensor(65.0620, dtype=torch.float64)\n",
      "#Loss 48 = tensor(62.6524, dtype=torch.float64)\n",
      "#Loss 49 = tensor(60.2577, dtype=torch.float64)\n",
      "#Loss 50 = tensor(58.9218, dtype=torch.float64)\n",
      "#Loss 51 = tensor(57.7387, dtype=torch.float64)\n",
      "#Loss 52 = tensor(56.4513, dtype=torch.float64)\n",
      "#Loss 53 = tensor(55.4491, dtype=torch.float64)\n",
      "#Loss 54 = tensor(54.4548, dtype=torch.float64)\n",
      "#Loss 55 = tensor(53.4340, dtype=torch.float64)\n",
      "#Loss 56 = tensor(52.4198, dtype=torch.float64)\n",
      "#Loss 57 = tensor(51.1156, dtype=torch.float64)\n",
      "#Loss 58 = tensor(50.1729, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 59 = tensor(49.6676, dtype=torch.float64)\n",
      "#Loss 60 = tensor(49.3491, dtype=torch.float64)\n",
      "#Loss 61 = tensor(49.0783, dtype=torch.float64)\n",
      "#Loss 62 = tensor(48.8889, dtype=torch.float64)\n",
      "#Loss 63 = tensor(48.7710, dtype=torch.float64)\n",
      "#Loss 64 = tensor(48.6093, dtype=torch.float64)\n",
      "#Loss 65 = tensor(48.2533, dtype=torch.float64)\n",
      "#Loss 66 = tensor(48.0805, dtype=torch.float64)\n",
      "#Loss 67 = tensor(47.8893, dtype=torch.float64)\n",
      "#Loss 68 = tensor(47.3811, dtype=torch.float64)\n",
      "#Loss 69 = tensor(47.1046, dtype=torch.float64)\n",
      "#Loss 70 = tensor(46.8050, dtype=torch.float64)\n",
      "#Loss 71 = tensor(46.6171, dtype=torch.float64)\n",
      "#Loss 72 = tensor(46.2457, dtype=torch.float64)\n",
      "#Loss 73 = tensor(45.8073, dtype=torch.float64)\n",
      "#Loss 74 = tensor(45.2731, dtype=torch.float64)\n",
      "#Loss 75 = tensor(44.8335, dtype=torch.float64)\n",
      "#Loss 76 = tensor(44.4593, dtype=torch.float64)\n",
      "#Loss 77 = tensor(44.0713, dtype=torch.float64)\n",
      "#Loss 78 = tensor(43.8288, dtype=torch.float64)\n",
      "#Loss 79 = tensor(43.5725, dtype=torch.float64)\n",
      "#Loss 80 = tensor(43.2616, dtype=torch.float64)\n",
      "#Loss 81 = tensor(42.8654, dtype=torch.float64)\n",
      "#Loss 82 = tensor(42.4787, dtype=torch.float64)\n",
      "#Loss 83 = tensor(42.0443, dtype=torch.float64)\n",
      "#Loss 84 = tensor(41.7798, dtype=torch.float64)\n",
      "#Loss 85 = tensor(41.5585, dtype=torch.float64)\n",
      "#Loss 86 = tensor(41.3004, dtype=torch.float64)\n",
      "#Loss 87 = tensor(41.1063, dtype=torch.float64)\n",
      "#Loss 88 = tensor(40.9391, dtype=torch.float64)\n",
      "#Loss 89 = tensor(40.6904, dtype=torch.float64)\n",
      "#Loss 90 = tensor(40.5569, dtype=torch.float64)\n",
      "#Loss 91 = tensor(40.3241, dtype=torch.float64)\n",
      "#Loss 92 = tensor(40.2048, dtype=torch.float64)\n",
      "#Loss 93 = tensor(40.0371, dtype=torch.float64)\n",
      "#Loss 94 = tensor(39.9013, dtype=torch.float64)\n",
      "#Loss 95 = tensor(39.6763, dtype=torch.float64)\n",
      "#Loss 96 = tensor(39.4259, dtype=torch.float64)\n",
      "#Loss 97 = tensor(39.2172, dtype=torch.float64)\n",
      "#Loss 98 = tensor(39.1305, dtype=torch.float64)\n",
      "#Loss 99 = tensor(39.0115, dtype=torch.float64)\n",
      "#Loss 100 = tensor(38.8453, dtype=torch.float64)\n",
      "#Loss 101 = tensor(38.7556, dtype=torch.float64)\n",
      "#Loss 102 = tensor(38.7078, dtype=torch.float64)\n",
      "#Loss 103 = tensor(38.6818, dtype=torch.float64)\n",
      "#Loss 104 = tensor(38.6451, dtype=torch.float64)\n",
      "#Loss 105 = tensor(38.6010, dtype=torch.float64)\n",
      "#Loss 106 = tensor(38.5213, dtype=torch.float64)\n",
      "#Loss 107 = tensor(38.4296, dtype=torch.float64)\n",
      "#Loss 108 = tensor(38.2872, dtype=torch.float64)\n",
      "#Loss 109 = tensor(38.0824, dtype=torch.float64)\n",
      "#Loss 110 = tensor(37.8527, dtype=torch.float64)\n",
      "#Loss 111 = tensor(37.7225, dtype=torch.float64)\n",
      "#Loss 112 = tensor(37.6293, dtype=torch.float64)\n",
      "#Loss 113 = tensor(37.5602, dtype=torch.float64)\n",
      "#Loss 114 = tensor(37.5097, dtype=torch.float64)\n",
      "#Loss 115 = tensor(37.4757, dtype=torch.float64)\n",
      "#Loss 116 = tensor(37.3533, dtype=torch.float64)\n",
      "#Loss 117 = tensor(37.2791, dtype=torch.float64)\n",
      "#Loss 118 = tensor(37.2212, dtype=torch.float64)\n",
      "#Loss 119 = tensor(37.2002, dtype=torch.float64)\n",
      "#Loss 120 = tensor(37.1922, dtype=torch.float64)\n",
      "#Loss 121 = tensor(37.1801, dtype=torch.float64)\n",
      "#Loss 122 = tensor(37.1739, dtype=torch.float64)\n",
      "#Loss 123 = tensor(37.1607, dtype=torch.float64)\n",
      "#Loss 124 = tensor(37.1483, dtype=torch.float64)\n",
      "#Loss 125 = tensor(37.1338, dtype=torch.float64)\n",
      "#Loss 126 = tensor(37.1272, dtype=torch.float64)\n",
      "#Loss 127 = tensor(37.1122, dtype=torch.float64)\n",
      "#Loss 128 = tensor(37.1005, dtype=torch.float64)\n",
      "#Loss 129 = tensor(37.0862, dtype=torch.float64)\n",
      "#Loss 130 = tensor(37.0753, dtype=torch.float64)\n",
      "#Loss 131 = tensor(37.0482, dtype=torch.float64)\n",
      "#Loss 132 = tensor(37.0379, dtype=torch.float64)\n",
      "#Loss 133 = tensor(37.0108, dtype=torch.float64)\n",
      "#Loss 134 = tensor(36.9924, dtype=torch.float64)\n",
      "#Loss 135 = tensor(36.9730, dtype=torch.float64)\n",
      "#Loss 136 = tensor(36.9529, dtype=torch.float64)\n",
      "#Loss 137 = tensor(36.9354, dtype=torch.float64)\n",
      "#Loss 138 = tensor(36.9311, dtype=torch.float64)\n",
      "#Loss 139 = tensor(36.9300, dtype=torch.float64)\n",
      "#Loss 140 = tensor(36.9294, dtype=torch.float64)\n",
      "#Loss 141 = tensor(36.9290, dtype=torch.float64)\n",
      "#Loss 142 = tensor(36.9289, dtype=torch.float64)\n",
      "#Loss 143 = tensor(36.9289, dtype=torch.float64)\n",
      "#Loss 144 = tensor(36.9289, dtype=torch.float64)\n",
      " 30 300 平均相对误差2： tensor(7.2709, dtype=torch.float64, grad_fn=<NormBackward0>)   30 300 置换矩阵误差： tensor(1.4071, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0571, dtype=torch.float64)   实验回归误差 tensor(0.0622, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(8749.7078, dtype=torch.float64)\n",
      "#Loss 1 = tensor(8657.7145, dtype=torch.float64)\n",
      "#Loss 2 = tensor(784.1317, dtype=torch.float64)\n",
      "#Loss 3 = tensor(725.3775, dtype=torch.float64)\n",
      "#Loss 4 = tensor(671.0781, dtype=torch.float64)\n",
      "#Loss 5 = tensor(612.7558, dtype=torch.float64)\n",
      "#Loss 6 = tensor(558.0607, dtype=torch.float64)\n",
      "#Loss 7 = tensor(506.9297, dtype=torch.float64)\n",
      "#Loss 8 = tensor(461.5616, dtype=torch.float64)\n",
      "#Loss 9 = tensor(421.9874, dtype=torch.float64)\n",
      "#Loss 10 = tensor(386.8209, dtype=torch.float64)\n",
      "#Loss 11 = tensor(348.3192, dtype=torch.float64)\n",
      "#Loss 12 = tensor(308.7148, dtype=torch.float64)\n",
      "#Loss 13 = tensor(270.3623, dtype=torch.float64)\n",
      "#Loss 14 = tensor(233.5309, dtype=torch.float64)\n",
      "#Loss 15 = tensor(204.2915, dtype=torch.float64)\n",
      "#Loss 16 = tensor(179.8065, dtype=torch.float64)\n",
      "#Loss 17 = tensor(159.5244, dtype=torch.float64)\n",
      "#Loss 18 = tensor(141.4204, dtype=torch.float64)\n",
      "#Loss 19 = tensor(126.2392, dtype=torch.float64)\n",
      "#Loss 20 = tensor(112.2891, dtype=torch.float64)\n",
      "#Loss 21 = tensor(100.4039, dtype=torch.float64)\n",
      "#Loss 22 = tensor(90.7281, dtype=torch.float64)\n",
      "#Loss 23 = tensor(77.9466, dtype=torch.float64)\n",
      "#Loss 24 = tensor(67.8460, dtype=torch.float64)\n",
      "#Loss 25 = tensor(59.7152, dtype=torch.float64)\n",
      "#Loss 26 = tensor(52.1589, dtype=torch.float64)\n",
      "#Loss 27 = tensor(46.9153, dtype=torch.float64)\n",
      "#Loss 28 = tensor(42.5226, dtype=torch.float64)\n",
      "#Loss 29 = tensor(39.4175, dtype=torch.float64)\n",
      "#Loss 30 = tensor(36.9851, dtype=torch.float64)\n",
      "#Loss 31 = tensor(35.0314, dtype=torch.float64)\n",
      "#Loss 32 = tensor(33.2572, dtype=torch.float64)\n",
      "#Loss 33 = tensor(31.8380, dtype=torch.float64)\n",
      "#Loss 34 = tensor(30.5060, dtype=torch.float64)\n",
      "#Loss 35 = tensor(29.1785, dtype=torch.float64)\n",
      "#Loss 36 = tensor(27.9891, dtype=torch.float64)\n",
      "#Loss 37 = tensor(26.9259, dtype=torch.float64)\n",
      "#Loss 38 = tensor(26.2326, dtype=torch.float64)\n",
      "#Loss 39 = tensor(25.3291, dtype=torch.float64)\n",
      "#Loss 40 = tensor(23.7666, dtype=torch.float64)\n",
      "#Loss 41 = tensor(21.7425, dtype=torch.float64)\n",
      "#Loss 42 = tensor(20.3256, dtype=torch.float64)\n",
      "#Loss 43 = tensor(19.0957, dtype=torch.float64)\n",
      "#Loss 44 = tensor(18.1197, dtype=torch.float64)\n",
      "#Loss 45 = tensor(17.1724, dtype=torch.float64)\n",
      "#Loss 46 = tensor(16.3104, dtype=torch.float64)\n",
      "#Loss 47 = tensor(15.5246, dtype=torch.float64)\n",
      "#Loss 48 = tensor(14.9197, dtype=torch.float64)\n",
      "#Loss 49 = tensor(14.4182, dtype=torch.float64)\n",
      "#Loss 50 = tensor(13.8756, dtype=torch.float64)\n",
      "#Loss 51 = tensor(13.2388, dtype=torch.float64)\n",
      "#Loss 52 = tensor(12.6962, dtype=torch.float64)\n",
      "#Loss 53 = tensor(12.2447, dtype=torch.float64)\n",
      "#Loss 54 = tensor(11.8417, dtype=torch.float64)\n",
      "#Loss 55 = tensor(11.4706, dtype=torch.float64)\n",
      "#Loss 56 = tensor(11.0974, dtype=torch.float64)\n",
      "#Loss 57 = tensor(10.8160, dtype=torch.float64)\n",
      "#Loss 58 = tensor(10.4333, dtype=torch.float64)\n",
      "#Loss 59 = tensor(10.0957, dtype=torch.float64)\n",
      "#Loss 60 = tensor(9.8943, dtype=torch.float64)\n",
      "#Loss 61 = tensor(9.7513, dtype=torch.float64)\n",
      "#Loss 62 = tensor(9.5176, dtype=torch.float64)\n",
      "#Loss 63 = tensor(9.1967, dtype=torch.float64)\n",
      "#Loss 64 = tensor(8.9366, dtype=torch.float64)\n",
      "#Loss 65 = tensor(8.6525, dtype=torch.float64)\n",
      "#Loss 66 = tensor(8.3843, dtype=torch.float64)\n",
      "#Loss 67 = tensor(8.2099, dtype=torch.float64)\n",
      "#Loss 68 = tensor(8.0637, dtype=torch.float64)\n",
      "#Loss 69 = tensor(7.9577, dtype=torch.float64)\n",
      "#Loss 70 = tensor(7.7351, dtype=torch.float64)\n",
      "#Loss 71 = tensor(7.5873, dtype=torch.float64)\n",
      "#Loss 72 = tensor(7.4849, dtype=torch.float64)\n",
      "#Loss 73 = tensor(7.3427, dtype=torch.float64)\n",
      "#Loss 74 = tensor(7.0060, dtype=torch.float64)\n",
      "#Loss 75 = tensor(6.6526, dtype=torch.float64)\n",
      "#Loss 76 = tensor(6.4837, dtype=torch.float64)\n",
      "#Loss 77 = tensor(6.3632, dtype=torch.float64)\n",
      "#Loss 78 = tensor(6.2750, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 79 = tensor(6.2200, dtype=torch.float64)\n",
      "#Loss 80 = tensor(6.1503, dtype=torch.float64)\n",
      "#Loss 81 = tensor(6.0959, dtype=torch.float64)\n",
      "#Loss 82 = tensor(6.0490, dtype=torch.float64)\n",
      "#Loss 83 = tensor(5.9739, dtype=torch.float64)\n",
      "#Loss 84 = tensor(5.9328, dtype=torch.float64)\n",
      "#Loss 85 = tensor(5.8468, dtype=torch.float64)\n",
      "#Loss 86 = tensor(5.7541, dtype=torch.float64)\n",
      "#Loss 87 = tensor(5.6412, dtype=torch.float64)\n",
      "#Loss 88 = tensor(5.5645, dtype=torch.float64)\n",
      "#Loss 89 = tensor(5.4908, dtype=torch.float64)\n",
      "#Loss 90 = tensor(5.4060, dtype=torch.float64)\n",
      "#Loss 91 = tensor(5.3546, dtype=torch.float64)\n",
      "#Loss 92 = tensor(5.2907, dtype=torch.float64)\n",
      "#Loss 93 = tensor(5.1571, dtype=torch.float64)\n",
      "#Loss 94 = tensor(4.9981, dtype=torch.float64)\n",
      "#Loss 95 = tensor(4.8903, dtype=torch.float64)\n",
      "#Loss 96 = tensor(4.8222, dtype=torch.float64)\n",
      "#Loss 97 = tensor(4.7837, dtype=torch.float64)\n",
      "#Loss 98 = tensor(4.7547, dtype=torch.float64)\n",
      "#Loss 99 = tensor(4.7374, dtype=torch.float64)\n",
      "#Loss 100 = tensor(4.7183, dtype=torch.float64)\n",
      "#Loss 101 = tensor(4.7040, dtype=torch.float64)\n",
      "#Loss 102 = tensor(4.6859, dtype=torch.float64)\n",
      "#Loss 103 = tensor(4.6747, dtype=torch.float64)\n",
      "#Loss 104 = tensor(4.6683, dtype=torch.float64)\n",
      "#Loss 105 = tensor(4.6657, dtype=torch.float64)\n",
      "#Loss 106 = tensor(4.6584, dtype=torch.float64)\n",
      "#Loss 107 = tensor(4.6417, dtype=torch.float64)\n",
      "#Loss 108 = tensor(4.6368, dtype=torch.float64)\n",
      "#Loss 109 = tensor(4.6351, dtype=torch.float64)\n",
      "#Loss 110 = tensor(4.6319, dtype=torch.float64)\n",
      "#Loss 111 = tensor(4.6300, dtype=torch.float64)\n",
      "#Loss 112 = tensor(4.6286, dtype=torch.float64)\n",
      "#Loss 113 = tensor(4.6283, dtype=torch.float64)\n",
      "#Loss 114 = tensor(4.6283, dtype=torch.float64)\n",
      "#Loss 115 = tensor(4.6283, dtype=torch.float64)\n",
      "#Loss 116 = tensor(4.6282, dtype=torch.float64)\n",
      "#Loss 117 = tensor(4.6282, dtype=torch.float64)\n",
      "#Loss 118 = tensor(4.6282, dtype=torch.float64)\n",
      " 30 300 平均相对误差2： tensor(7.8890, dtype=torch.float64, grad_fn=<NormBackward0>)   30 300 置换矩阵误差： tensor(1.4142, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0566, dtype=torch.float64)   实验回归误差 tensor(0.0230, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(11381.6349, dtype=torch.float64)\n",
      "#Loss 1 = tensor(10658.9205, dtype=torch.float64)\n",
      "#Loss 2 = tensor(1225.3030, dtype=torch.float64)\n",
      "#Loss 3 = tensor(474.0421, dtype=torch.float64)\n",
      "#Loss 4 = tensor(342.6964, dtype=torch.float64)\n",
      "#Loss 5 = tensor(307.1840, dtype=torch.float64)\n",
      "#Loss 6 = tensor(287.9961, dtype=torch.float64)\n",
      "#Loss 7 = tensor(264.4402, dtype=torch.float64)\n",
      "#Loss 8 = tensor(250.0781, dtype=torch.float64)\n",
      "#Loss 9 = tensor(237.1682, dtype=torch.float64)\n",
      "#Loss 10 = tensor(225.5284, dtype=torch.float64)\n",
      "#Loss 11 = tensor(213.4502, dtype=torch.float64)\n",
      "#Loss 12 = tensor(202.0202, dtype=torch.float64)\n",
      "#Loss 13 = tensor(189.6800, dtype=torch.float64)\n",
      "#Loss 14 = tensor(180.5425, dtype=torch.float64)\n",
      "#Loss 15 = tensor(171.9216, dtype=torch.float64)\n",
      "#Loss 16 = tensor(164.3719, dtype=torch.float64)\n",
      "#Loss 17 = tensor(158.0831, dtype=torch.float64)\n",
      "#Loss 18 = tensor(152.6055, dtype=torch.float64)\n",
      "#Loss 19 = tensor(146.8606, dtype=torch.float64)\n",
      "#Loss 20 = tensor(141.7316, dtype=torch.float64)\n",
      "#Loss 21 = tensor(135.7326, dtype=torch.float64)\n",
      "#Loss 22 = tensor(130.1982, dtype=torch.float64)\n",
      "#Loss 23 = tensor(124.3198, dtype=torch.float64)\n",
      "#Loss 24 = tensor(118.3251, dtype=torch.float64)\n",
      "#Loss 25 = tensor(113.9256, dtype=torch.float64)\n",
      "#Loss 26 = tensor(109.2014, dtype=torch.float64)\n",
      "#Loss 27 = tensor(105.1203, dtype=torch.float64)\n",
      "#Loss 28 = tensor(101.0352, dtype=torch.float64)\n",
      "#Loss 29 = tensor(96.6527, dtype=torch.float64)\n",
      "#Loss 30 = tensor(93.3009, dtype=torch.float64)\n",
      "#Loss 31 = tensor(90.8319, dtype=torch.float64)\n",
      "#Loss 32 = tensor(88.5126, dtype=torch.float64)\n",
      "#Loss 33 = tensor(86.7785, dtype=torch.float64)\n",
      "#Loss 34 = tensor(84.5670, dtype=torch.float64)\n",
      "#Loss 35 = tensor(82.1877, dtype=torch.float64)\n",
      "#Loss 36 = tensor(80.0116, dtype=torch.float64)\n",
      "#Loss 37 = tensor(78.1387, dtype=torch.float64)\n",
      "#Loss 38 = tensor(76.6486, dtype=torch.float64)\n",
      "#Loss 39 = tensor(75.4678, dtype=torch.float64)\n",
      "#Loss 40 = tensor(74.3744, dtype=torch.float64)\n",
      "#Loss 41 = tensor(73.4601, dtype=torch.float64)\n",
      "#Loss 42 = tensor(72.8113, dtype=torch.float64)\n",
      "#Loss 43 = tensor(72.3763, dtype=torch.float64)\n",
      "#Loss 44 = tensor(71.5482, dtype=torch.float64)\n",
      "#Loss 45 = tensor(70.6347, dtype=torch.float64)\n",
      "#Loss 46 = tensor(70.0045, dtype=torch.float64)\n",
      "#Loss 47 = tensor(69.2703, dtype=torch.float64)\n",
      "#Loss 48 = tensor(68.2627, dtype=torch.float64)\n",
      "#Loss 49 = tensor(67.6890, dtype=torch.float64)\n",
      "#Loss 50 = tensor(66.9382, dtype=torch.float64)\n",
      "#Loss 51 = tensor(65.8065, dtype=torch.float64)\n",
      "#Loss 52 = tensor(64.7264, dtype=torch.float64)\n",
      "#Loss 53 = tensor(63.9223, dtype=torch.float64)\n",
      "#Loss 54 = tensor(63.2326, dtype=torch.float64)\n",
      "#Loss 55 = tensor(62.6328, dtype=torch.float64)\n",
      "#Loss 56 = tensor(61.6899, dtype=torch.float64)\n",
      "#Loss 57 = tensor(60.4941, dtype=torch.float64)\n",
      "#Loss 58 = tensor(59.5251, dtype=torch.float64)\n",
      "#Loss 59 = tensor(58.8306, dtype=torch.float64)\n",
      "#Loss 60 = tensor(57.7279, dtype=torch.float64)\n",
      "#Loss 61 = tensor(56.9826, dtype=torch.float64)\n",
      "#Loss 62 = tensor(56.3358, dtype=torch.float64)\n",
      "#Loss 63 = tensor(55.5789, dtype=torch.float64)\n",
      "#Loss 64 = tensor(54.7857, dtype=torch.float64)\n",
      "#Loss 65 = tensor(53.5807, dtype=torch.float64)\n",
      "#Loss 66 = tensor(52.8218, dtype=torch.float64)\n",
      "#Loss 67 = tensor(52.3549, dtype=torch.float64)\n",
      "#Loss 68 = tensor(51.7865, dtype=torch.float64)\n",
      "#Loss 69 = tensor(51.3562, dtype=torch.float64)\n",
      "#Loss 70 = tensor(50.8137, dtype=torch.float64)\n",
      "#Loss 71 = tensor(50.3688, dtype=torch.float64)\n",
      "#Loss 72 = tensor(49.9385, dtype=torch.float64)\n",
      "#Loss 73 = tensor(49.4886, dtype=torch.float64)\n",
      "#Loss 74 = tensor(49.2068, dtype=torch.float64)\n",
      "#Loss 75 = tensor(48.8749, dtype=torch.float64)\n",
      "#Loss 76 = tensor(48.6510, dtype=torch.float64)\n",
      "#Loss 77 = tensor(48.2650, dtype=torch.float64)\n",
      "#Loss 78 = tensor(47.8651, dtype=torch.float64)\n",
      "#Loss 79 = tensor(47.4703, dtype=torch.float64)\n",
      "#Loss 80 = tensor(46.9610, dtype=torch.float64)\n",
      "#Loss 81 = tensor(46.5907, dtype=torch.float64)\n",
      "#Loss 82 = tensor(46.2065, dtype=torch.float64)\n",
      "#Loss 83 = tensor(45.6515, dtype=torch.float64)\n",
      "#Loss 84 = tensor(45.0914, dtype=torch.float64)\n",
      "#Loss 85 = tensor(44.3899, dtype=torch.float64)\n",
      "#Loss 86 = tensor(43.5145, dtype=torch.float64)\n",
      "#Loss 87 = tensor(42.8657, dtype=torch.float64)\n",
      "#Loss 88 = tensor(42.2962, dtype=torch.float64)\n",
      "#Loss 89 = tensor(41.9270, dtype=torch.float64)\n",
      "#Loss 90 = tensor(41.5667, dtype=torch.float64)\n",
      "#Loss 91 = tensor(41.2522, dtype=torch.float64)\n",
      "#Loss 92 = tensor(40.9582, dtype=torch.float64)\n",
      "#Loss 93 = tensor(40.6764, dtype=torch.float64)\n",
      "#Loss 94 = tensor(40.3689, dtype=torch.float64)\n",
      "#Loss 95 = tensor(40.0898, dtype=torch.float64)\n",
      "#Loss 96 = tensor(39.7900, dtype=torch.float64)\n",
      "#Loss 97 = tensor(39.5832, dtype=torch.float64)\n",
      "#Loss 98 = tensor(39.3323, dtype=torch.float64)\n",
      "#Loss 99 = tensor(39.0548, dtype=torch.float64)\n",
      "#Loss 100 = tensor(38.7837, dtype=torch.float64)\n",
      "#Loss 101 = tensor(38.6189, dtype=torch.float64)\n",
      "#Loss 102 = tensor(38.5333, dtype=torch.float64)\n",
      "#Loss 103 = tensor(38.4550, dtype=torch.float64)\n",
      "#Loss 104 = tensor(38.3878, dtype=torch.float64)\n",
      "#Loss 105 = tensor(38.2337, dtype=torch.float64)\n",
      "#Loss 106 = tensor(38.1081, dtype=torch.float64)\n",
      "#Loss 107 = tensor(38.0153, dtype=torch.float64)\n",
      "#Loss 108 = tensor(37.9488, dtype=torch.float64)\n",
      "#Loss 109 = tensor(37.8913, dtype=torch.float64)\n",
      "#Loss 110 = tensor(37.8248, dtype=torch.float64)\n",
      "#Loss 111 = tensor(37.7929, dtype=torch.float64)\n",
      "#Loss 112 = tensor(37.7527, dtype=torch.float64)\n",
      "#Loss 113 = tensor(37.7150, dtype=torch.float64)\n",
      "#Loss 114 = tensor(37.6711, dtype=torch.float64)\n",
      "#Loss 115 = tensor(37.6440, dtype=torch.float64)\n",
      "#Loss 116 = tensor(37.5966, dtype=torch.float64)\n",
      "#Loss 117 = tensor(37.5171, dtype=torch.float64)\n",
      "#Loss 118 = tensor(37.4732, dtype=torch.float64)\n",
      "#Loss 119 = tensor(37.4402, dtype=torch.float64)\n",
      "#Loss 120 = tensor(37.4099, dtype=torch.float64)\n",
      "#Loss 121 = tensor(37.3653, dtype=torch.float64)\n",
      "#Loss 122 = tensor(36.8044, dtype=torch.float64)\n",
      "#Loss 123 = tensor(36.5602, dtype=torch.float64)\n",
      "#Loss 124 = tensor(36.4651, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 125 = tensor(36.3595, dtype=torch.float64)\n",
      "#Loss 126 = tensor(36.2622, dtype=torch.float64)\n",
      "#Loss 127 = tensor(36.2075, dtype=torch.float64)\n",
      "#Loss 128 = tensor(36.1392, dtype=torch.float64)\n",
      "#Loss 129 = tensor(36.0748, dtype=torch.float64)\n",
      "#Loss 130 = tensor(35.9955, dtype=torch.float64)\n",
      "#Loss 131 = tensor(35.9074, dtype=torch.float64)\n",
      "#Loss 132 = tensor(35.8518, dtype=torch.float64)\n",
      "#Loss 133 = tensor(35.7730, dtype=torch.float64)\n",
      "#Loss 134 = tensor(35.7039, dtype=torch.float64)\n",
      "#Loss 135 = tensor(35.6816, dtype=torch.float64)\n",
      "#Loss 136 = tensor(35.6577, dtype=torch.float64)\n",
      "#Loss 137 = tensor(35.6331, dtype=torch.float64)\n",
      "#Loss 138 = tensor(35.5997, dtype=torch.float64)\n",
      "#Loss 139 = tensor(35.5552, dtype=torch.float64)\n",
      "#Loss 140 = tensor(35.4527, dtype=torch.float64)\n",
      "#Loss 141 = tensor(35.3704, dtype=torch.float64)\n",
      "#Loss 142 = tensor(35.3214, dtype=torch.float64)\n",
      "#Loss 143 = tensor(35.2898, dtype=torch.float64)\n",
      "#Loss 144 = tensor(35.2712, dtype=torch.float64)\n",
      "#Loss 145 = tensor(35.2203, dtype=torch.float64)\n",
      "#Loss 146 = tensor(35.1962, dtype=torch.float64)\n",
      "#Loss 147 = tensor(35.1883, dtype=torch.float64)\n",
      "#Loss 148 = tensor(35.1815, dtype=torch.float64)\n",
      "#Loss 149 = tensor(35.1396, dtype=torch.float64)\n",
      "#Loss 150 = tensor(35.0834, dtype=torch.float64)\n",
      "#Loss 151 = tensor(35.0279, dtype=torch.float64)\n",
      "#Loss 152 = tensor(34.9789, dtype=torch.float64)\n",
      "#Loss 153 = tensor(34.9509, dtype=torch.float64)\n",
      "#Loss 154 = tensor(34.9015, dtype=torch.float64)\n",
      "#Loss 155 = tensor(34.8364, dtype=torch.float64)\n",
      "#Loss 156 = tensor(34.7788, dtype=torch.float64)\n",
      "#Loss 157 = tensor(34.6663, dtype=torch.float64)\n",
      "#Loss 158 = tensor(34.5871, dtype=torch.float64)\n",
      "#Loss 159 = tensor(34.5597, dtype=torch.float64)\n",
      "#Loss 160 = tensor(34.5406, dtype=torch.float64)\n",
      "#Loss 161 = tensor(34.5345, dtype=torch.float64)\n",
      "#Loss 162 = tensor(34.5315, dtype=torch.float64)\n",
      "#Loss 163 = tensor(34.5284, dtype=torch.float64)\n",
      "#Loss 164 = tensor(34.5262, dtype=torch.float64)\n",
      "#Loss 165 = tensor(34.5261, dtype=torch.float64)\n",
      "#Loss 166 = tensor(34.5260, dtype=torch.float64)\n",
      "#Loss 167 = tensor(34.5242, dtype=torch.float64)\n",
      "#Loss 168 = tensor(34.5229, dtype=torch.float64)\n",
      "#Loss 169 = tensor(34.5218, dtype=torch.float64)\n",
      "#Loss 170 = tensor(34.5216, dtype=torch.float64)\n",
      "#Loss 171 = tensor(34.5216, dtype=torch.float64)\n",
      "#Loss 172 = tensor(34.5204, dtype=torch.float64)\n",
      "#Loss 173 = tensor(34.5184, dtype=torch.float64)\n",
      "#Loss 174 = tensor(34.5182, dtype=torch.float64)\n",
      "#Loss 175 = tensor(34.5178, dtype=torch.float64)\n",
      "#Loss 176 = tensor(34.5156, dtype=torch.float64)\n",
      "#Loss 177 = tensor(34.5154, dtype=torch.float64)\n",
      "#Loss 178 = tensor(34.5153, dtype=torch.float64)\n",
      "#Loss 179 = tensor(34.5017, dtype=torch.float64)\n",
      "#Loss 180 = tensor(34.4677, dtype=torch.float64)\n",
      "#Loss 181 = tensor(34.4267, dtype=torch.float64)\n",
      "#Loss 182 = tensor(34.4053, dtype=torch.float64)\n",
      "#Loss 183 = tensor(34.3846, dtype=torch.float64)\n",
      "#Loss 184 = tensor(34.3518, dtype=torch.float64)\n",
      "#Loss 185 = tensor(34.3213, dtype=torch.float64)\n",
      "#Loss 186 = tensor(34.2885, dtype=torch.float64)\n",
      "#Loss 187 = tensor(34.2723, dtype=torch.float64)\n",
      "#Loss 188 = tensor(34.2536, dtype=torch.float64)\n",
      "#Loss 189 = tensor(34.2152, dtype=torch.float64)\n",
      "#Loss 190 = tensor(34.1916, dtype=torch.float64)\n",
      "#Loss 191 = tensor(34.1843, dtype=torch.float64)\n",
      "#Loss 192 = tensor(34.1742, dtype=torch.float64)\n",
      "#Loss 193 = tensor(34.1724, dtype=torch.float64)\n",
      "#Loss 194 = tensor(34.1704, dtype=torch.float64)\n",
      "#Loss 195 = tensor(34.1699, dtype=torch.float64)\n",
      "#Loss 196 = tensor(34.1698, dtype=torch.float64)\n",
      "#Loss 197 = tensor(34.1698, dtype=torch.float64)\n",
      "#Loss 198 = tensor(34.1698, dtype=torch.float64)\n",
      "#Loss 199 = tensor(34.1698, dtype=torch.float64)\n",
      "#Loss 200 = tensor(34.1696, dtype=torch.float64)\n",
      "超过迭代上限\n",
      " 30 300 平均相对误差2： tensor(8.0910, dtype=torch.float64, grad_fn=<NormBackward0>)   30 300 置换矩阵误差： tensor(1.4119, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0504, dtype=torch.float64)   实验回归误差 tensor(0.0548, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(10549.3814, dtype=torch.float64)\n",
      "#Loss 1 = tensor(10446.5653, dtype=torch.float64)\n",
      "#Loss 2 = tensor(935.7535, dtype=torch.float64)\n",
      "#Loss 3 = tensor(787.1607, dtype=torch.float64)\n",
      "#Loss 4 = tensor(707.4281, dtype=torch.float64)\n",
      "#Loss 5 = tensor(633.9519, dtype=torch.float64)\n",
      "#Loss 6 = tensor(563.9263, dtype=torch.float64)\n",
      "#Loss 7 = tensor(504.3986, dtype=torch.float64)\n",
      "#Loss 8 = tensor(453.1587, dtype=torch.float64)\n",
      "#Loss 9 = tensor(402.7998, dtype=torch.float64)\n",
      "#Loss 10 = tensor(351.9806, dtype=torch.float64)\n",
      "#Loss 11 = tensor(310.6725, dtype=torch.float64)\n",
      "#Loss 12 = tensor(273.4810, dtype=torch.float64)\n",
      "#Loss 13 = tensor(240.9089, dtype=torch.float64)\n",
      "#Loss 14 = tensor(213.3252, dtype=torch.float64)\n",
      "#Loss 15 = tensor(189.8721, dtype=torch.float64)\n",
      "#Loss 16 = tensor(167.6537, dtype=torch.float64)\n",
      "#Loss 17 = tensor(146.7907, dtype=torch.float64)\n",
      "#Loss 18 = tensor(126.9731, dtype=torch.float64)\n",
      "#Loss 19 = tensor(110.2577, dtype=torch.float64)\n",
      "#Loss 20 = tensor(95.7373, dtype=torch.float64)\n",
      "#Loss 21 = tensor(84.2228, dtype=torch.float64)\n",
      "#Loss 22 = tensor(75.0903, dtype=torch.float64)\n",
      "#Loss 23 = tensor(66.4061, dtype=torch.float64)\n",
      "#Loss 24 = tensor(59.2740, dtype=torch.float64)\n",
      "#Loss 25 = tensor(53.3277, dtype=torch.float64)\n",
      "#Loss 26 = tensor(48.4828, dtype=torch.float64)\n",
      "#Loss 27 = tensor(44.3314, dtype=torch.float64)\n",
      "#Loss 28 = tensor(40.8760, dtype=torch.float64)\n",
      "#Loss 29 = tensor(37.6640, dtype=torch.float64)\n",
      "#Loss 30 = tensor(34.5056, dtype=torch.float64)\n",
      "#Loss 31 = tensor(31.9322, dtype=torch.float64)\n",
      "#Loss 32 = tensor(29.2892, dtype=torch.float64)\n",
      "#Loss 33 = tensor(26.2533, dtype=torch.float64)\n",
      "#Loss 34 = tensor(24.3220, dtype=torch.float64)\n",
      "#Loss 35 = tensor(23.2181, dtype=torch.float64)\n",
      "#Loss 36 = tensor(22.3846, dtype=torch.float64)\n",
      "#Loss 37 = tensor(21.5187, dtype=torch.float64)\n",
      "#Loss 38 = tensor(20.7414, dtype=torch.float64)\n",
      "#Loss 39 = tensor(20.1946, dtype=torch.float64)\n",
      "#Loss 40 = tensor(19.4891, dtype=torch.float64)\n",
      "#Loss 41 = tensor(18.7672, dtype=torch.float64)\n",
      "#Loss 42 = tensor(18.2158, dtype=torch.float64)\n",
      "#Loss 43 = tensor(17.6871, dtype=torch.float64)\n",
      "#Loss 44 = tensor(17.2961, dtype=torch.float64)\n",
      "#Loss 45 = tensor(16.9590, dtype=torch.float64)\n",
      "#Loss 46 = tensor(16.6744, dtype=torch.float64)\n",
      "#Loss 47 = tensor(16.4163, dtype=torch.float64)\n",
      "#Loss 48 = tensor(16.0575, dtype=torch.float64)\n",
      "#Loss 49 = tensor(15.7575, dtype=torch.float64)\n",
      "#Loss 50 = tensor(15.4739, dtype=torch.float64)\n",
      "#Loss 51 = tensor(15.1855, dtype=torch.float64)\n",
      "#Loss 52 = tensor(14.9391, dtype=torch.float64)\n",
      "#Loss 53 = tensor(14.6700, dtype=torch.float64)\n",
      "#Loss 54 = tensor(14.3353, dtype=torch.float64)\n",
      "#Loss 55 = tensor(14.0624, dtype=torch.float64)\n",
      "#Loss 56 = tensor(13.6904, dtype=torch.float64)\n",
      "#Loss 57 = tensor(13.3294, dtype=torch.float64)\n",
      "#Loss 58 = tensor(13.1564, dtype=torch.float64)\n",
      "#Loss 59 = tensor(13.0342, dtype=torch.float64)\n",
      "#Loss 60 = tensor(12.8233, dtype=torch.float64)\n",
      "#Loss 61 = tensor(12.7512, dtype=torch.float64)\n",
      "#Loss 62 = tensor(12.6769, dtype=torch.float64)\n",
      "#Loss 63 = tensor(12.6131, dtype=torch.float64)\n",
      "#Loss 64 = tensor(12.5467, dtype=torch.float64)\n",
      "#Loss 65 = tensor(12.4634, dtype=torch.float64)\n",
      "#Loss 66 = tensor(12.3475, dtype=torch.float64)\n",
      "#Loss 67 = tensor(11.9780, dtype=torch.float64)\n",
      "#Loss 68 = tensor(11.7041, dtype=torch.float64)\n",
      "#Loss 69 = tensor(11.2950, dtype=torch.float64)\n",
      "#Loss 70 = tensor(11.0975, dtype=torch.float64)\n",
      "#Loss 71 = tensor(10.8959, dtype=torch.float64)\n",
      "#Loss 72 = tensor(10.6037, dtype=torch.float64)\n",
      "#Loss 73 = tensor(10.4353, dtype=torch.float64)\n",
      "#Loss 74 = tensor(10.3568, dtype=torch.float64)\n",
      "#Loss 75 = tensor(10.2932, dtype=torch.float64)\n",
      "#Loss 76 = tensor(10.2321, dtype=torch.float64)\n",
      "#Loss 77 = tensor(10.1551, dtype=torch.float64)\n",
      "#Loss 78 = tensor(10.1062, dtype=torch.float64)\n",
      "#Loss 79 = tensor(10.0171, dtype=torch.float64)\n",
      "#Loss 80 = tensor(9.8816, dtype=torch.float64)\n",
      "#Loss 81 = tensor(9.7662, dtype=torch.float64)\n",
      "#Loss 82 = tensor(9.6850, dtype=torch.float64)\n",
      "#Loss 83 = tensor(9.6457, dtype=torch.float64)\n",
      "#Loss 84 = tensor(9.6220, dtype=torch.float64)\n",
      "#Loss 85 = tensor(9.6063, dtype=torch.float64)\n",
      "#Loss 86 = tensor(9.5719, dtype=torch.float64)\n",
      "#Loss 87 = tensor(9.5431, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 88 = tensor(9.5094, dtype=torch.float64)\n",
      "#Loss 89 = tensor(9.4938, dtype=torch.float64)\n",
      "#Loss 90 = tensor(9.4770, dtype=torch.float64)\n",
      "#Loss 91 = tensor(9.4545, dtype=torch.float64)\n",
      "#Loss 92 = tensor(9.4456, dtype=torch.float64)\n",
      "#Loss 93 = tensor(9.4258, dtype=torch.float64)\n",
      "#Loss 94 = tensor(9.4103, dtype=torch.float64)\n",
      "#Loss 95 = tensor(9.4082, dtype=torch.float64)\n",
      "#Loss 96 = tensor(9.4017, dtype=torch.float64)\n",
      "#Loss 97 = tensor(9.3934, dtype=torch.float64)\n",
      "#Loss 98 = tensor(9.3824, dtype=torch.float64)\n",
      "#Loss 99 = tensor(9.3781, dtype=torch.float64)\n",
      "#Loss 100 = tensor(9.3733, dtype=torch.float64)\n",
      "#Loss 101 = tensor(9.3520, dtype=torch.float64)\n",
      "#Loss 102 = tensor(9.3432, dtype=torch.float64)\n",
      "#Loss 103 = tensor(9.3059, dtype=torch.float64)\n",
      "#Loss 104 = tensor(9.2303, dtype=torch.float64)\n",
      "#Loss 105 = tensor(9.1538, dtype=torch.float64)\n",
      "#Loss 106 = tensor(9.0837, dtype=torch.float64)\n",
      "#Loss 107 = tensor(9.0403, dtype=torch.float64)\n",
      "#Loss 108 = tensor(8.9736, dtype=torch.float64)\n",
      "#Loss 109 = tensor(8.9497, dtype=torch.float64)\n",
      "#Loss 110 = tensor(8.9218, dtype=torch.float64)\n",
      "#Loss 111 = tensor(8.8766, dtype=torch.float64)\n",
      "#Loss 112 = tensor(8.7681, dtype=torch.float64)\n",
      "#Loss 113 = tensor(8.7027, dtype=torch.float64)\n",
      "#Loss 114 = tensor(8.5857, dtype=torch.float64)\n",
      "#Loss 115 = tensor(8.4633, dtype=torch.float64)\n",
      "#Loss 116 = tensor(8.3883, dtype=torch.float64)\n",
      "#Loss 117 = tensor(8.3112, dtype=torch.float64)\n",
      "#Loss 118 = tensor(8.2603, dtype=torch.float64)\n",
      "#Loss 119 = tensor(8.2426, dtype=torch.float64)\n",
      "#Loss 120 = tensor(8.2338, dtype=torch.float64)\n",
      "#Loss 121 = tensor(8.2282, dtype=torch.float64)\n",
      "#Loss 122 = tensor(8.2260, dtype=torch.float64)\n",
      "#Loss 123 = tensor(8.2245, dtype=torch.float64)\n",
      "#Loss 124 = tensor(8.2137, dtype=torch.float64)\n",
      "#Loss 125 = tensor(8.2110, dtype=torch.float64)\n",
      "#Loss 126 = tensor(8.2075, dtype=torch.float64)\n",
      "#Loss 127 = tensor(8.1961, dtype=torch.float64)\n",
      "#Loss 128 = tensor(8.1638, dtype=torch.float64)\n",
      "#Loss 129 = tensor(8.1503, dtype=torch.float64)\n",
      "#Loss 130 = tensor(8.1480, dtype=torch.float64)\n",
      "#Loss 131 = tensor(8.1453, dtype=torch.float64)\n",
      "#Loss 132 = tensor(8.1399, dtype=torch.float64)\n",
      "#Loss 133 = tensor(8.1373, dtype=torch.float64)\n",
      "#Loss 134 = tensor(8.1219, dtype=torch.float64)\n",
      "#Loss 135 = tensor(8.1065, dtype=torch.float64)\n",
      "#Loss 136 = tensor(8.0980, dtype=torch.float64)\n",
      "#Loss 137 = tensor(8.0925, dtype=torch.float64)\n",
      "#Loss 138 = tensor(8.0904, dtype=torch.float64)\n",
      "#Loss 139 = tensor(8.0884, dtype=torch.float64)\n",
      "#Loss 140 = tensor(8.0880, dtype=torch.float64)\n",
      "#Loss 141 = tensor(8.0880, dtype=torch.float64)\n",
      "#Loss 142 = tensor(8.0878, dtype=torch.float64)\n",
      "#Loss 143 = tensor(8.0857, dtype=torch.float64)\n",
      "#Loss 144 = tensor(8.0823, dtype=torch.float64)\n",
      "#Loss 145 = tensor(8.0807, dtype=torch.float64)\n",
      "#Loss 146 = tensor(8.0791, dtype=torch.float64)\n",
      "#Loss 147 = tensor(8.0790, dtype=torch.float64)\n",
      "#Loss 148 = tensor(8.0790, dtype=torch.float64)\n",
      "#Loss 149 = tensor(8.0790, dtype=torch.float64)\n",
      "#Loss 150 = tensor(8.0790, dtype=torch.float64)\n",
      " 30 300 平均相对误差2： tensor(8.4824, dtype=torch.float64, grad_fn=<NormBackward0>)   30 300 置换矩阵误差： tensor(1.4119, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0515, dtype=torch.float64)   实验回归误差 tensor(0.0277, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(6883.8397, dtype=torch.float64)\n",
      "#Loss 1 = tensor(6639.9512, dtype=torch.float64)\n",
      "#Loss 2 = tensor(755.6066, dtype=torch.float64)\n",
      "#Loss 3 = tensor(417.6870, dtype=torch.float64)\n",
      "#Loss 4 = tensor(369.0467, dtype=torch.float64)\n",
      "#Loss 5 = tensor(345.5538, dtype=torch.float64)\n",
      "#Loss 6 = tensor(323.7859, dtype=torch.float64)\n",
      "#Loss 7 = tensor(302.8441, dtype=torch.float64)\n",
      "#Loss 8 = tensor(284.0672, dtype=torch.float64)\n",
      "#Loss 9 = tensor(268.5654, dtype=torch.float64)\n",
      "#Loss 10 = tensor(254.5265, dtype=torch.float64)\n",
      "#Loss 11 = tensor(242.5646, dtype=torch.float64)\n",
      "#Loss 12 = tensor(229.0393, dtype=torch.float64)\n",
      "#Loss 13 = tensor(214.8364, dtype=torch.float64)\n",
      "#Loss 14 = tensor(203.0678, dtype=torch.float64)\n",
      "#Loss 15 = tensor(191.7884, dtype=torch.float64)\n",
      "#Loss 16 = tensor(180.7889, dtype=torch.float64)\n",
      "#Loss 17 = tensor(171.1334, dtype=torch.float64)\n",
      "#Loss 18 = tensor(163.3253, dtype=torch.float64)\n",
      "#Loss 19 = tensor(155.8901, dtype=torch.float64)\n",
      "#Loss 20 = tensor(149.4825, dtype=torch.float64)\n",
      "#Loss 21 = tensor(143.7707, dtype=torch.float64)\n",
      "#Loss 22 = tensor(137.5639, dtype=torch.float64)\n",
      "#Loss 23 = tensor(132.5529, dtype=torch.float64)\n",
      "#Loss 24 = tensor(126.9756, dtype=torch.float64)\n",
      "#Loss 25 = tensor(119.4703, dtype=torch.float64)\n",
      "#Loss 26 = tensor(112.2880, dtype=torch.float64)\n",
      "#Loss 27 = tensor(104.5841, dtype=torch.float64)\n",
      "#Loss 28 = tensor(97.4291, dtype=torch.float64)\n",
      "#Loss 29 = tensor(91.9996, dtype=torch.float64)\n",
      "#Loss 30 = tensor(87.1685, dtype=torch.float64)\n",
      "#Loss 31 = tensor(82.6343, dtype=torch.float64)\n",
      "#Loss 32 = tensor(78.1306, dtype=torch.float64)\n",
      "#Loss 33 = tensor(73.0387, dtype=torch.float64)\n",
      "#Loss 34 = tensor(67.6265, dtype=torch.float64)\n",
      "#Loss 35 = tensor(62.9949, dtype=torch.float64)\n",
      "#Loss 36 = tensor(59.4220, dtype=torch.float64)\n",
      "#Loss 37 = tensor(56.8108, dtype=torch.float64)\n",
      "#Loss 38 = tensor(54.3365, dtype=torch.float64)\n",
      "#Loss 39 = tensor(51.9397, dtype=torch.float64)\n",
      "#Loss 40 = tensor(49.2746, dtype=torch.float64)\n",
      "#Loss 41 = tensor(46.6529, dtype=torch.float64)\n",
      "#Loss 42 = tensor(44.2637, dtype=torch.float64)\n",
      "#Loss 43 = tensor(42.2260, dtype=torch.float64)\n",
      "#Loss 44 = tensor(40.0385, dtype=torch.float64)\n",
      "#Loss 45 = tensor(37.6852, dtype=torch.float64)\n",
      "#Loss 46 = tensor(35.3458, dtype=torch.float64)\n",
      "#Loss 47 = tensor(33.3622, dtype=torch.float64)\n",
      "#Loss 48 = tensor(31.2533, dtype=torch.float64)\n",
      "#Loss 49 = tensor(29.1974, dtype=torch.float64)\n",
      "#Loss 50 = tensor(27.6485, dtype=torch.float64)\n",
      "#Loss 51 = tensor(26.5124, dtype=torch.float64)\n",
      "#Loss 52 = tensor(25.2018, dtype=torch.float64)\n",
      "#Loss 53 = tensor(24.3314, dtype=torch.float64)\n",
      "#Loss 54 = tensor(23.6269, dtype=torch.float64)\n",
      "#Loss 55 = tensor(22.5762, dtype=torch.float64)\n",
      "#Loss 56 = tensor(21.7613, dtype=torch.float64)\n",
      "#Loss 57 = tensor(20.9878, dtype=torch.float64)\n",
      "#Loss 58 = tensor(20.2972, dtype=torch.float64)\n",
      "#Loss 59 = tensor(19.5077, dtype=torch.float64)\n",
      "#Loss 60 = tensor(18.7582, dtype=torch.float64)\n",
      "#Loss 61 = tensor(17.9983, dtype=torch.float64)\n",
      "#Loss 62 = tensor(17.2187, dtype=torch.float64)\n",
      "#Loss 63 = tensor(16.7024, dtype=torch.float64)\n",
      "#Loss 64 = tensor(16.3560, dtype=torch.float64)\n",
      "#Loss 65 = tensor(16.1371, dtype=torch.float64)\n",
      "#Loss 66 = tensor(15.9399, dtype=torch.float64)\n",
      "#Loss 67 = tensor(15.7704, dtype=torch.float64)\n",
      "#Loss 68 = tensor(15.5795, dtype=torch.float64)\n",
      "#Loss 69 = tensor(15.4219, dtype=torch.float64)\n",
      "#Loss 70 = tensor(15.3076, dtype=torch.float64)\n",
      "#Loss 71 = tensor(15.1874, dtype=torch.float64)\n",
      "#Loss 72 = tensor(15.0628, dtype=torch.float64)\n",
      "#Loss 73 = tensor(14.9417, dtype=torch.float64)\n",
      "#Loss 74 = tensor(14.7996, dtype=torch.float64)\n",
      "#Loss 75 = tensor(14.6923, dtype=torch.float64)\n",
      "#Loss 76 = tensor(14.5789, dtype=torch.float64)\n",
      "#Loss 77 = tensor(14.4139, dtype=torch.float64)\n",
      "#Loss 78 = tensor(14.1300, dtype=torch.float64)\n",
      "#Loss 79 = tensor(13.9461, dtype=torch.float64)\n",
      "#Loss 80 = tensor(13.7503, dtype=torch.float64)\n",
      "#Loss 81 = tensor(13.5322, dtype=torch.float64)\n",
      "#Loss 82 = tensor(13.2597, dtype=torch.float64)\n",
      "#Loss 83 = tensor(12.9766, dtype=torch.float64)\n",
      "#Loss 84 = tensor(12.7364, dtype=torch.float64)\n",
      "#Loss 85 = tensor(12.4996, dtype=torch.float64)\n",
      "#Loss 86 = tensor(12.3253, dtype=torch.float64)\n",
      "#Loss 87 = tensor(12.1807, dtype=torch.float64)\n",
      "#Loss 88 = tensor(12.0758, dtype=torch.float64)\n",
      "#Loss 89 = tensor(11.9825, dtype=torch.float64)\n",
      "#Loss 90 = tensor(11.9275, dtype=torch.float64)\n",
      "#Loss 91 = tensor(11.8649, dtype=torch.float64)\n",
      "#Loss 92 = tensor(11.7443, dtype=torch.float64)\n",
      "#Loss 93 = tensor(11.5768, dtype=torch.float64)\n",
      "#Loss 94 = tensor(11.4709, dtype=torch.float64)\n",
      "#Loss 95 = tensor(11.4240, dtype=torch.float64)\n",
      "#Loss 96 = tensor(11.3547, dtype=torch.float64)\n",
      "#Loss 97 = tensor(11.2604, dtype=torch.float64)\n",
      "#Loss 98 = tensor(11.2099, dtype=torch.float64)\n",
      "#Loss 99 = tensor(11.1729, dtype=torch.float64)\n",
      "#Loss 100 = tensor(11.1487, dtype=torch.float64)\n",
      "#Loss 101 = tensor(11.1255, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 102 = tensor(11.1191, dtype=torch.float64)\n",
      "#Loss 103 = tensor(11.1152, dtype=torch.float64)\n",
      "#Loss 104 = tensor(11.1139, dtype=torch.float64)\n",
      "#Loss 105 = tensor(11.1121, dtype=torch.float64)\n",
      "#Loss 106 = tensor(11.1103, dtype=torch.float64)\n",
      "#Loss 107 = tensor(11.1099, dtype=torch.float64)\n",
      "#Loss 108 = tensor(11.1097, dtype=torch.float64)\n",
      "#Loss 109 = tensor(11.1037, dtype=torch.float64)\n",
      "#Loss 110 = tensor(11.0986, dtype=torch.float64)\n",
      "#Loss 111 = tensor(11.0946, dtype=torch.float64)\n",
      "#Loss 112 = tensor(11.0883, dtype=torch.float64)\n",
      "#Loss 113 = tensor(11.0811, dtype=torch.float64)\n",
      "#Loss 114 = tensor(11.0790, dtype=torch.float64)\n",
      "#Loss 115 = tensor(11.0766, dtype=torch.float64)\n",
      "#Loss 116 = tensor(11.0730, dtype=torch.float64)\n",
      "#Loss 117 = tensor(11.0718, dtype=torch.float64)\n",
      "#Loss 118 = tensor(11.0711, dtype=torch.float64)\n",
      "#Loss 119 = tensor(11.0707, dtype=torch.float64)\n",
      "#Loss 120 = tensor(11.0703, dtype=torch.float64)\n",
      "#Loss 121 = tensor(11.0683, dtype=torch.float64)\n",
      "#Loss 122 = tensor(11.0678, dtype=torch.float64)\n",
      "#Loss 123 = tensor(11.0676, dtype=torch.float64)\n",
      "#Loss 124 = tensor(11.0511, dtype=torch.float64)\n",
      "#Loss 125 = tensor(11.0392, dtype=torch.float64)\n",
      "#Loss 126 = tensor(11.0286, dtype=torch.float64)\n",
      "#Loss 127 = tensor(11.0189, dtype=torch.float64)\n",
      "#Loss 128 = tensor(11.0078, dtype=torch.float64)\n",
      "#Loss 129 = tensor(11.0025, dtype=torch.float64)\n",
      "#Loss 130 = tensor(10.9776, dtype=torch.float64)\n",
      "#Loss 131 = tensor(10.9635, dtype=torch.float64)\n",
      "#Loss 132 = tensor(10.9553, dtype=torch.float64)\n",
      "#Loss 133 = tensor(10.9516, dtype=torch.float64)\n",
      "#Loss 134 = tensor(10.9446, dtype=torch.float64)\n",
      "#Loss 135 = tensor(10.9437, dtype=torch.float64)\n",
      "#Loss 136 = tensor(10.9418, dtype=torch.float64)\n",
      "#Loss 137 = tensor(10.9413, dtype=torch.float64)\n",
      "#Loss 138 = tensor(10.9412, dtype=torch.float64)\n",
      "#Loss 139 = tensor(10.9412, dtype=torch.float64)\n",
      "#Loss 140 = tensor(10.9412, dtype=torch.float64)\n",
      "#Loss 141 = tensor(10.9411, dtype=torch.float64)\n",
      "#Loss 142 = tensor(10.9411, dtype=torch.float64)\n",
      "#Loss 143 = tensor(10.9411, dtype=torch.float64)\n",
      "#Loss 144 = tensor(10.9411, dtype=torch.float64)\n",
      " 30 300 平均相对误差2： tensor(5.5019, dtype=torch.float64, grad_fn=<NormBackward0>)   30 300 置换矩阵误差： tensor(1.4142, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0627, dtype=torch.float64)   实验回归误差 tensor(0.0399, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(10616.3622, dtype=torch.float64)\n",
      "#Loss 1 = tensor(10323.5913, dtype=torch.float64)\n",
      "#Loss 2 = tensor(993.8552, dtype=torch.float64)\n",
      "#Loss 3 = tensor(760.8020, dtype=torch.float64)\n",
      "#Loss 4 = tensor(688.9645, dtype=torch.float64)\n",
      "#Loss 5 = tensor(638.7944, dtype=torch.float64)\n",
      "#Loss 6 = tensor(588.4580, dtype=torch.float64)\n",
      "#Loss 7 = tensor(541.9498, dtype=torch.float64)\n",
      "#Loss 8 = tensor(500.7139, dtype=torch.float64)\n",
      "#Loss 9 = tensor(459.9248, dtype=torch.float64)\n",
      "#Loss 10 = tensor(422.1424, dtype=torch.float64)\n",
      "#Loss 11 = tensor(389.9599, dtype=torch.float64)\n",
      "#Loss 12 = tensor(358.8266, dtype=torch.float64)\n",
      "#Loss 13 = tensor(326.6373, dtype=torch.float64)\n",
      "#Loss 14 = tensor(301.0770, dtype=torch.float64)\n",
      "#Loss 15 = tensor(276.8161, dtype=torch.float64)\n",
      "#Loss 16 = tensor(254.9563, dtype=torch.float64)\n",
      "#Loss 17 = tensor(235.3289, dtype=torch.float64)\n",
      "#Loss 18 = tensor(218.4384, dtype=torch.float64)\n",
      "#Loss 19 = tensor(202.5527, dtype=torch.float64)\n",
      "#Loss 20 = tensor(189.7592, dtype=torch.float64)\n",
      "#Loss 21 = tensor(178.7609, dtype=torch.float64)\n",
      "#Loss 22 = tensor(167.6244, dtype=torch.float64)\n",
      "#Loss 23 = tensor(157.4560, dtype=torch.float64)\n",
      "#Loss 24 = tensor(149.4439, dtype=torch.float64)\n",
      "#Loss 25 = tensor(141.1163, dtype=torch.float64)\n",
      "#Loss 26 = tensor(134.6838, dtype=torch.float64)\n",
      "#Loss 27 = tensor(128.0442, dtype=torch.float64)\n",
      "#Loss 28 = tensor(120.7495, dtype=torch.float64)\n",
      "#Loss 29 = tensor(111.0985, dtype=torch.float64)\n",
      "#Loss 30 = tensor(102.7547, dtype=torch.float64)\n",
      "#Loss 31 = tensor(95.8242, dtype=torch.float64)\n",
      "#Loss 32 = tensor(90.7206, dtype=torch.float64)\n",
      "#Loss 33 = tensor(86.1303, dtype=torch.float64)\n",
      "#Loss 34 = tensor(81.7917, dtype=torch.float64)\n",
      "#Loss 35 = tensor(78.6483, dtype=torch.float64)\n",
      "#Loss 36 = tensor(75.6436, dtype=torch.float64)\n",
      "#Loss 37 = tensor(70.3002, dtype=torch.float64)\n",
      "#Loss 38 = tensor(65.9576, dtype=torch.float64)\n",
      "#Loss 39 = tensor(62.6913, dtype=torch.float64)\n",
      "#Loss 40 = tensor(60.1699, dtype=torch.float64)\n",
      "#Loss 41 = tensor(57.4823, dtype=torch.float64)\n",
      "#Loss 42 = tensor(55.6547, dtype=torch.float64)\n",
      "#Loss 43 = tensor(53.4537, dtype=torch.float64)\n",
      "#Loss 44 = tensor(51.5597, dtype=torch.float64)\n",
      "#Loss 45 = tensor(49.7952, dtype=torch.float64)\n",
      "#Loss 46 = tensor(47.8379, dtype=torch.float64)\n",
      "#Loss 47 = tensor(46.3083, dtype=torch.float64)\n",
      "#Loss 48 = tensor(44.5242, dtype=torch.float64)\n",
      "#Loss 49 = tensor(42.9684, dtype=torch.float64)\n",
      "#Loss 50 = tensor(41.4384, dtype=torch.float64)\n",
      "#Loss 51 = tensor(40.1076, dtype=torch.float64)\n",
      "#Loss 52 = tensor(38.7954, dtype=torch.float64)\n",
      "#Loss 53 = tensor(37.7211, dtype=torch.float64)\n",
      "#Loss 54 = tensor(36.5885, dtype=torch.float64)\n",
      "#Loss 55 = tensor(35.5827, dtype=torch.float64)\n",
      "#Loss 56 = tensor(34.8283, dtype=torch.float64)\n",
      "#Loss 57 = tensor(33.9207, dtype=torch.float64)\n",
      "#Loss 58 = tensor(33.1136, dtype=torch.float64)\n",
      "#Loss 59 = tensor(32.2935, dtype=torch.float64)\n",
      "#Loss 60 = tensor(30.9440, dtype=torch.float64)\n",
      "#Loss 61 = tensor(29.6703, dtype=torch.float64)\n",
      "#Loss 62 = tensor(28.7842, dtype=torch.float64)\n",
      "#Loss 63 = tensor(28.0472, dtype=torch.float64)\n",
      "#Loss 64 = tensor(27.5019, dtype=torch.float64)\n",
      "#Loss 65 = tensor(26.9026, dtype=torch.float64)\n",
      "#Loss 66 = tensor(26.5023, dtype=torch.float64)\n",
      "#Loss 67 = tensor(26.2409, dtype=torch.float64)\n",
      "#Loss 68 = tensor(25.9199, dtype=torch.float64)\n",
      "#Loss 69 = tensor(25.7718, dtype=torch.float64)\n",
      "#Loss 70 = tensor(25.6081, dtype=torch.float64)\n",
      "#Loss 71 = tensor(25.2979, dtype=torch.float64)\n",
      "#Loss 72 = tensor(25.0614, dtype=torch.float64)\n",
      "#Loss 73 = tensor(24.9502, dtype=torch.float64)\n",
      "#Loss 74 = tensor(24.8293, dtype=torch.float64)\n",
      "#Loss 75 = tensor(24.6642, dtype=torch.float64)\n",
      "#Loss 76 = tensor(24.4996, dtype=torch.float64)\n",
      "#Loss 77 = tensor(24.4185, dtype=torch.float64)\n",
      "#Loss 78 = tensor(24.3835, dtype=torch.float64)\n",
      "#Loss 79 = tensor(24.3515, dtype=torch.float64)\n",
      "#Loss 80 = tensor(24.3350, dtype=torch.float64)\n",
      "#Loss 81 = tensor(24.3142, dtype=torch.float64)\n",
      "#Loss 82 = tensor(24.2972, dtype=torch.float64)\n",
      "#Loss 83 = tensor(24.2822, dtype=torch.float64)\n",
      "#Loss 84 = tensor(24.2735, dtype=torch.float64)\n",
      "#Loss 85 = tensor(24.2688, dtype=torch.float64)\n",
      "#Loss 86 = tensor(24.2618, dtype=torch.float64)\n",
      "#Loss 87 = tensor(24.2597, dtype=torch.float64)\n",
      "#Loss 88 = tensor(24.2540, dtype=torch.float64)\n",
      "#Loss 89 = tensor(24.2522, dtype=torch.float64)\n",
      "#Loss 90 = tensor(24.2507, dtype=torch.float64)\n",
      "#Loss 91 = tensor(24.2503, dtype=torch.float64)\n",
      "#Loss 92 = tensor(24.2479, dtype=torch.float64)\n",
      "#Loss 93 = tensor(24.2476, dtype=torch.float64)\n",
      "#Loss 94 = tensor(24.2475, dtype=torch.float64)\n",
      "#Loss 95 = tensor(24.2475, dtype=torch.float64)\n",
      "#Loss 96 = tensor(24.2449, dtype=torch.float64)\n",
      "#Loss 97 = tensor(24.2445, dtype=torch.float64)\n",
      "#Loss 98 = tensor(24.2444, dtype=torch.float64)\n",
      "#Loss 99 = tensor(24.2444, dtype=torch.float64)\n",
      "#Loss 100 = tensor(24.2444, dtype=torch.float64)\n",
      "#Loss 101 = tensor(24.2444, dtype=torch.float64)\n",
      "#Loss 102 = tensor(24.2444, dtype=torch.float64)\n",
      " 30 300 平均相对误差2： tensor(9.0799, dtype=torch.float64, grad_fn=<NormBackward0>)   30 300 置换矩阵误差： tensor(1.4119, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0505, dtype=torch.float64)   实验回归误差 tensor(0.0478, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(8682.5501, dtype=torch.float64)\n",
      "#Loss 1 = tensor(8007.9928, dtype=torch.float64)\n",
      "#Loss 2 = tensor(864.5042, dtype=torch.float64)\n",
      "#Loss 3 = tensor(373.2380, dtype=torch.float64)\n",
      "#Loss 4 = tensor(269.3225, dtype=torch.float64)\n",
      "#Loss 5 = tensor(235.7496, dtype=torch.float64)\n",
      "#Loss 6 = tensor(214.5046, dtype=torch.float64)\n",
      "#Loss 7 = tensor(195.6055, dtype=torch.float64)\n",
      "#Loss 8 = tensor(177.0084, dtype=torch.float64)\n",
      "#Loss 9 = tensor(163.1545, dtype=torch.float64)\n",
      "#Loss 10 = tensor(153.4017, dtype=torch.float64)\n",
      "#Loss 11 = tensor(144.6476, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 12 = tensor(135.8597, dtype=torch.float64)\n",
      "#Loss 13 = tensor(128.2197, dtype=torch.float64)\n",
      "#Loss 14 = tensor(122.0367, dtype=torch.float64)\n",
      "#Loss 15 = tensor(115.6406, dtype=torch.float64)\n",
      "#Loss 16 = tensor(109.6098, dtype=torch.float64)\n",
      "#Loss 17 = tensor(103.5276, dtype=torch.float64)\n",
      "#Loss 18 = tensor(96.6904, dtype=torch.float64)\n",
      "#Loss 19 = tensor(89.4378, dtype=torch.float64)\n",
      "#Loss 20 = tensor(83.5717, dtype=torch.float64)\n",
      "#Loss 21 = tensor(78.7817, dtype=torch.float64)\n",
      "#Loss 22 = tensor(74.1214, dtype=torch.float64)\n",
      "#Loss 23 = tensor(71.0910, dtype=torch.float64)\n",
      "#Loss 24 = tensor(68.0862, dtype=torch.float64)\n",
      "#Loss 25 = tensor(65.4293, dtype=torch.float64)\n",
      "#Loss 26 = tensor(62.8540, dtype=torch.float64)\n",
      "#Loss 27 = tensor(60.2099, dtype=torch.float64)\n",
      "#Loss 28 = tensor(57.0714, dtype=torch.float64)\n",
      "#Loss 29 = tensor(54.2349, dtype=torch.float64)\n",
      "#Loss 30 = tensor(51.7109, dtype=torch.float64)\n",
      "#Loss 31 = tensor(49.4328, dtype=torch.float64)\n",
      "#Loss 32 = tensor(47.1041, dtype=torch.float64)\n",
      "#Loss 33 = tensor(45.0426, dtype=torch.float64)\n",
      "#Loss 34 = tensor(43.2526, dtype=torch.float64)\n",
      "#Loss 35 = tensor(41.5561, dtype=torch.float64)\n",
      "#Loss 36 = tensor(39.6466, dtype=torch.float64)\n",
      "#Loss 37 = tensor(37.0890, dtype=torch.float64)\n",
      "#Loss 38 = tensor(34.6777, dtype=torch.float64)\n",
      "#Loss 39 = tensor(32.5669, dtype=torch.float64)\n",
      "#Loss 40 = tensor(30.7189, dtype=torch.float64)\n",
      "#Loss 41 = tensor(29.0969, dtype=torch.float64)\n",
      "#Loss 42 = tensor(27.3882, dtype=torch.float64)\n",
      "#Loss 43 = tensor(25.6323, dtype=torch.float64)\n",
      "#Loss 44 = tensor(24.3784, dtype=torch.float64)\n",
      "#Loss 45 = tensor(23.3447, dtype=torch.float64)\n",
      "#Loss 46 = tensor(22.5882, dtype=torch.float64)\n",
      "#Loss 47 = tensor(21.7303, dtype=torch.float64)\n",
      "#Loss 48 = tensor(21.1722, dtype=torch.float64)\n",
      "#Loss 49 = tensor(20.5900, dtype=torch.float64)\n",
      "#Loss 50 = tensor(20.0949, dtype=torch.float64)\n",
      "#Loss 51 = tensor(19.7993, dtype=torch.float64)\n",
      "#Loss 52 = tensor(19.4158, dtype=torch.float64)\n",
      "#Loss 53 = tensor(19.0822, dtype=torch.float64)\n",
      "#Loss 54 = tensor(18.8114, dtype=torch.float64)\n",
      "#Loss 55 = tensor(18.5007, dtype=torch.float64)\n",
      "#Loss 56 = tensor(18.1878, dtype=torch.float64)\n",
      "#Loss 57 = tensor(17.8662, dtype=torch.float64)\n",
      "#Loss 58 = tensor(17.4461, dtype=torch.float64)\n",
      "#Loss 59 = tensor(17.1904, dtype=torch.float64)\n",
      "#Loss 60 = tensor(16.9686, dtype=torch.float64)\n",
      "#Loss 61 = tensor(16.7070, dtype=torch.float64)\n",
      "#Loss 62 = tensor(16.3402, dtype=torch.float64)\n",
      "#Loss 63 = tensor(16.0295, dtype=torch.float64)\n",
      "#Loss 64 = tensor(15.8072, dtype=torch.float64)\n",
      "#Loss 65 = tensor(15.6150, dtype=torch.float64)\n",
      "#Loss 66 = tensor(15.3793, dtype=torch.float64)\n",
      "#Loss 67 = tensor(15.2249, dtype=torch.float64)\n",
      "#Loss 68 = tensor(14.9693, dtype=torch.float64)\n",
      "#Loss 69 = tensor(14.7371, dtype=torch.float64)\n",
      "#Loss 70 = tensor(14.3853, dtype=torch.float64)\n",
      "#Loss 71 = tensor(14.0364, dtype=torch.float64)\n",
      "#Loss 72 = tensor(13.6160, dtype=torch.float64)\n",
      "#Loss 73 = tensor(13.2208, dtype=torch.float64)\n",
      "#Loss 74 = tensor(12.9181, dtype=torch.float64)\n",
      "#Loss 75 = tensor(12.3994, dtype=torch.float64)\n",
      "#Loss 76 = tensor(11.9238, dtype=torch.float64)\n",
      "#Loss 77 = tensor(11.7266, dtype=torch.float64)\n",
      "#Loss 78 = tensor(11.4857, dtype=torch.float64)\n",
      "#Loss 79 = tensor(11.3561, dtype=torch.float64)\n",
      "#Loss 80 = tensor(11.2810, dtype=torch.float64)\n",
      "#Loss 81 = tensor(11.2071, dtype=torch.float64)\n",
      "#Loss 82 = tensor(11.1446, dtype=torch.float64)\n",
      "#Loss 83 = tensor(11.1007, dtype=torch.float64)\n",
      "#Loss 84 = tensor(10.9343, dtype=torch.float64)\n",
      "#Loss 85 = tensor(10.6162, dtype=torch.float64)\n",
      "#Loss 86 = tensor(10.4525, dtype=torch.float64)\n",
      "#Loss 87 = tensor(10.3823, dtype=torch.float64)\n",
      "#Loss 88 = tensor(10.3426, dtype=torch.float64)\n",
      "#Loss 89 = tensor(10.2808, dtype=torch.float64)\n",
      "#Loss 90 = tensor(10.1811, dtype=torch.float64)\n",
      "#Loss 91 = tensor(10.0955, dtype=torch.float64)\n",
      "#Loss 92 = tensor(10.0530, dtype=torch.float64)\n",
      "#Loss 93 = tensor(9.9974, dtype=torch.float64)\n",
      "#Loss 94 = tensor(9.9840, dtype=torch.float64)\n",
      "#Loss 95 = tensor(9.9727, dtype=torch.float64)\n",
      "#Loss 96 = tensor(9.9521, dtype=torch.float64)\n",
      "#Loss 97 = tensor(9.9284, dtype=torch.float64)\n",
      "#Loss 98 = tensor(9.8665, dtype=torch.float64)\n",
      "#Loss 99 = tensor(9.7385, dtype=torch.float64)\n",
      "#Loss 100 = tensor(9.5325, dtype=torch.float64)\n",
      "#Loss 101 = tensor(9.4070, dtype=torch.float64)\n",
      "#Loss 102 = tensor(9.1659, dtype=torch.float64)\n",
      "#Loss 103 = tensor(8.9142, dtype=torch.float64)\n",
      "#Loss 104 = tensor(8.7029, dtype=torch.float64)\n",
      "#Loss 105 = tensor(8.5207, dtype=torch.float64)\n",
      "#Loss 106 = tensor(8.3458, dtype=torch.float64)\n",
      "#Loss 107 = tensor(8.0888, dtype=torch.float64)\n",
      "#Loss 108 = tensor(7.9032, dtype=torch.float64)\n",
      "#Loss 109 = tensor(7.7311, dtype=torch.float64)\n",
      "#Loss 110 = tensor(7.6483, dtype=torch.float64)\n",
      "#Loss 111 = tensor(7.5666, dtype=torch.float64)\n",
      "#Loss 112 = tensor(7.5131, dtype=torch.float64)\n",
      "#Loss 113 = tensor(7.3534, dtype=torch.float64)\n",
      "#Loss 114 = tensor(7.2747, dtype=torch.float64)\n",
      "#Loss 115 = tensor(7.2137, dtype=torch.float64)\n",
      "#Loss 116 = tensor(7.1410, dtype=torch.float64)\n",
      "#Loss 117 = tensor(7.0997, dtype=torch.float64)\n",
      "#Loss 118 = tensor(7.0764, dtype=torch.float64)\n",
      "#Loss 119 = tensor(7.0474, dtype=torch.float64)\n",
      "#Loss 120 = tensor(7.0175, dtype=torch.float64)\n",
      "#Loss 121 = tensor(6.9963, dtype=torch.float64)\n",
      "#Loss 122 = tensor(6.9791, dtype=torch.float64)\n",
      "#Loss 123 = tensor(6.9602, dtype=torch.float64)\n",
      "#Loss 124 = tensor(6.9391, dtype=torch.float64)\n",
      "#Loss 125 = tensor(6.9284, dtype=torch.float64)\n",
      "#Loss 126 = tensor(6.9143, dtype=torch.float64)\n",
      "#Loss 127 = tensor(6.8925, dtype=torch.float64)\n",
      "#Loss 128 = tensor(6.8816, dtype=torch.float64)\n",
      "#Loss 129 = tensor(6.8661, dtype=torch.float64)\n",
      "#Loss 130 = tensor(6.8556, dtype=torch.float64)\n",
      "#Loss 131 = tensor(6.8126, dtype=torch.float64)\n",
      "#Loss 132 = tensor(6.7355, dtype=torch.float64)\n",
      "#Loss 133 = tensor(6.6562, dtype=torch.float64)\n",
      "#Loss 134 = tensor(6.5800, dtype=torch.float64)\n",
      "#Loss 135 = tensor(6.5458, dtype=torch.float64)\n",
      "#Loss 136 = tensor(6.5280, dtype=torch.float64)\n",
      "#Loss 137 = tensor(6.5056, dtype=torch.float64)\n",
      "#Loss 138 = tensor(6.4409, dtype=torch.float64)\n",
      "#Loss 139 = tensor(6.3810, dtype=torch.float64)\n",
      "#Loss 140 = tensor(6.3314, dtype=torch.float64)\n",
      "#Loss 141 = tensor(6.2589, dtype=torch.float64)\n",
      "#Loss 142 = tensor(6.1757, dtype=torch.float64)\n",
      "#Loss 143 = tensor(6.0384, dtype=torch.float64)\n",
      "#Loss 144 = tensor(5.8931, dtype=torch.float64)\n",
      "#Loss 145 = tensor(5.7768, dtype=torch.float64)\n",
      "#Loss 146 = tensor(5.6073, dtype=torch.float64)\n",
      "#Loss 147 = tensor(5.5195, dtype=torch.float64)\n",
      "#Loss 148 = tensor(5.4686, dtype=torch.float64)\n",
      "#Loss 149 = tensor(5.3791, dtype=torch.float64)\n",
      "#Loss 150 = tensor(5.2768, dtype=torch.float64)\n",
      "#Loss 151 = tensor(5.2206, dtype=torch.float64)\n",
      "#Loss 152 = tensor(5.1668, dtype=torch.float64)\n",
      "#Loss 153 = tensor(5.1213, dtype=torch.float64)\n",
      "#Loss 154 = tensor(5.1001, dtype=torch.float64)\n",
      "#Loss 155 = tensor(5.0752, dtype=torch.float64)\n",
      "#Loss 156 = tensor(5.0046, dtype=torch.float64)\n",
      "#Loss 157 = tensor(4.9738, dtype=torch.float64)\n",
      "#Loss 158 = tensor(4.9449, dtype=torch.float64)\n",
      "#Loss 159 = tensor(4.9297, dtype=torch.float64)\n",
      "#Loss 160 = tensor(4.9205, dtype=torch.float64)\n",
      "#Loss 161 = tensor(4.9173, dtype=torch.float64)\n",
      "#Loss 162 = tensor(4.9160, dtype=torch.float64)\n",
      "#Loss 163 = tensor(4.9151, dtype=torch.float64)\n",
      "#Loss 164 = tensor(4.9150, dtype=torch.float64)\n",
      "#Loss 165 = tensor(4.9148, dtype=torch.float64)\n",
      "#Loss 166 = tensor(4.9147, dtype=torch.float64)\n",
      "#Loss 167 = tensor(4.9147, dtype=torch.float64)\n",
      "#Loss 168 = tensor(4.9147, dtype=torch.float64)\n",
      "#Loss 169 = tensor(4.9147, dtype=torch.float64)\n",
      " 30 300 平均相对误差2： tensor(5.8286, dtype=torch.float64, grad_fn=<NormBackward0>)   30 300 置换矩阵误差： tensor(1.4119, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0599, dtype=torch.float64)   实验回归误差 tensor(0.0238, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(6475.1594, dtype=torch.float64)\n",
      "#Loss 1 = tensor(6194.4440, dtype=torch.float64)\n",
      "#Loss 2 = tensor(364.5244, dtype=torch.float64)\n",
      "#Loss 3 = tensor(309.8323, dtype=torch.float64)\n",
      "#Loss 4 = tensor(292.1764, dtype=torch.float64)\n",
      "#Loss 5 = tensor(276.9837, dtype=torch.float64)\n",
      "#Loss 6 = tensor(262.1072, dtype=torch.float64)\n",
      "#Loss 7 = tensor(247.9328, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 8 = tensor(233.9019, dtype=torch.float64)\n",
      "#Loss 9 = tensor(219.3179, dtype=torch.float64)\n",
      "#Loss 10 = tensor(204.4746, dtype=torch.float64)\n",
      "#Loss 11 = tensor(190.8824, dtype=torch.float64)\n",
      "#Loss 12 = tensor(178.5555, dtype=torch.float64)\n",
      "#Loss 13 = tensor(165.5649, dtype=torch.float64)\n",
      "#Loss 14 = tensor(152.6169, dtype=torch.float64)\n",
      "#Loss 15 = tensor(139.6156, dtype=torch.float64)\n",
      "#Loss 16 = tensor(128.6330, dtype=torch.float64)\n",
      "#Loss 17 = tensor(118.6256, dtype=torch.float64)\n",
      "#Loss 18 = tensor(109.2236, dtype=torch.float64)\n",
      "#Loss 19 = tensor(100.6823, dtype=torch.float64)\n",
      "#Loss 20 = tensor(92.8724, dtype=torch.float64)\n",
      "#Loss 21 = tensor(86.3579, dtype=torch.float64)\n",
      "#Loss 22 = tensor(81.1079, dtype=torch.float64)\n",
      "#Loss 23 = tensor(76.1738, dtype=torch.float64)\n",
      "#Loss 24 = tensor(71.0783, dtype=torch.float64)\n",
      "#Loss 25 = tensor(66.8388, dtype=torch.float64)\n",
      "#Loss 26 = tensor(62.7141, dtype=torch.float64)\n",
      "#Loss 27 = tensor(57.8853, dtype=torch.float64)\n",
      "#Loss 28 = tensor(53.3333, dtype=torch.float64)\n",
      "#Loss 29 = tensor(49.3991, dtype=torch.float64)\n",
      "#Loss 30 = tensor(45.9759, dtype=torch.float64)\n",
      "#Loss 31 = tensor(43.1132, dtype=torch.float64)\n",
      "#Loss 32 = tensor(40.3860, dtype=torch.float64)\n",
      "#Loss 33 = tensor(37.6919, dtype=torch.float64)\n",
      "#Loss 34 = tensor(34.5974, dtype=torch.float64)\n",
      "#Loss 35 = tensor(31.3798, dtype=torch.float64)\n",
      "#Loss 36 = tensor(29.0829, dtype=torch.float64)\n",
      "#Loss 37 = tensor(27.3927, dtype=torch.float64)\n",
      "#Loss 38 = tensor(25.6228, dtype=torch.float64)\n",
      "#Loss 39 = tensor(23.9517, dtype=torch.float64)\n",
      "#Loss 40 = tensor(22.7229, dtype=torch.float64)\n",
      "#Loss 41 = tensor(21.8073, dtype=torch.float64)\n",
      "#Loss 42 = tensor(20.7020, dtype=torch.float64)\n",
      "#Loss 43 = tensor(19.6973, dtype=torch.float64)\n",
      "#Loss 44 = tensor(18.8030, dtype=torch.float64)\n",
      "#Loss 45 = tensor(18.2235, dtype=torch.float64)\n",
      "#Loss 46 = tensor(17.8077, dtype=torch.float64)\n",
      "#Loss 47 = tensor(17.3025, dtype=torch.float64)\n",
      "#Loss 48 = tensor(16.7890, dtype=torch.float64)\n",
      "#Loss 49 = tensor(16.2802, dtype=torch.float64)\n",
      "#Loss 50 = tensor(15.8705, dtype=torch.float64)\n",
      "#Loss 51 = tensor(15.4308, dtype=torch.float64)\n",
      "#Loss 52 = tensor(14.2346, dtype=torch.float64)\n",
      "#Loss 53 = tensor(13.3864, dtype=torch.float64)\n",
      "#Loss 54 = tensor(12.6016, dtype=torch.float64)\n",
      "#Loss 55 = tensor(11.8018, dtype=torch.float64)\n",
      "#Loss 56 = tensor(11.0827, dtype=torch.float64)\n",
      "#Loss 57 = tensor(10.4808, dtype=torch.float64)\n",
      "#Loss 58 = tensor(10.0426, dtype=torch.float64)\n",
      "#Loss 59 = tensor(9.7680, dtype=torch.float64)\n",
      "#Loss 60 = tensor(9.6020, dtype=torch.float64)\n",
      "#Loss 61 = tensor(9.4903, dtype=torch.float64)\n",
      "#Loss 62 = tensor(9.3903, dtype=torch.float64)\n",
      "#Loss 63 = tensor(9.2015, dtype=torch.float64)\n",
      "#Loss 64 = tensor(9.0281, dtype=torch.float64)\n",
      "#Loss 65 = tensor(8.9235, dtype=torch.float64)\n",
      "#Loss 66 = tensor(8.8346, dtype=torch.float64)\n",
      "#Loss 67 = tensor(8.7512, dtype=torch.float64)\n",
      "#Loss 68 = tensor(8.6905, dtype=torch.float64)\n",
      "#Loss 69 = tensor(8.6350, dtype=torch.float64)\n",
      "#Loss 70 = tensor(8.5996, dtype=torch.float64)\n",
      "#Loss 71 = tensor(8.5406, dtype=torch.float64)\n",
      "#Loss 72 = tensor(8.5226, dtype=torch.float64)\n",
      "#Loss 73 = tensor(8.5126, dtype=torch.float64)\n",
      "#Loss 74 = tensor(8.4834, dtype=torch.float64)\n",
      "#Loss 75 = tensor(8.4756, dtype=torch.float64)\n",
      "#Loss 76 = tensor(8.4704, dtype=torch.float64)\n",
      "#Loss 77 = tensor(8.4638, dtype=torch.float64)\n",
      "#Loss 78 = tensor(8.4480, dtype=torch.float64)\n",
      "#Loss 79 = tensor(8.4406, dtype=torch.float64)\n",
      "#Loss 80 = tensor(8.4380, dtype=torch.float64)\n",
      "#Loss 81 = tensor(8.4316, dtype=torch.float64)\n",
      "#Loss 82 = tensor(8.4151, dtype=torch.float64)\n",
      "#Loss 83 = tensor(8.4031, dtype=torch.float64)\n",
      "#Loss 84 = tensor(8.3887, dtype=torch.float64)\n",
      "#Loss 85 = tensor(8.3750, dtype=torch.float64)\n",
      "#Loss 86 = tensor(8.3692, dtype=torch.float64)\n",
      "#Loss 87 = tensor(8.3604, dtype=torch.float64)\n",
      "#Loss 88 = tensor(8.3345, dtype=torch.float64)\n",
      "#Loss 89 = tensor(8.3205, dtype=torch.float64)\n",
      "#Loss 90 = tensor(8.3140, dtype=torch.float64)\n",
      "#Loss 91 = tensor(8.2907, dtype=torch.float64)\n",
      "#Loss 92 = tensor(8.2868, dtype=torch.float64)\n",
      "#Loss 93 = tensor(8.2836, dtype=torch.float64)\n",
      "#Loss 94 = tensor(8.2831, dtype=torch.float64)\n",
      "#Loss 95 = tensor(8.2829, dtype=torch.float64)\n",
      "#Loss 96 = tensor(8.2829, dtype=torch.float64)\n",
      "#Loss 97 = tensor(8.2829, dtype=torch.float64)\n",
      "#Loss 98 = tensor(8.2829, dtype=torch.float64)\n",
      "#Loss 99 = tensor(8.2829, dtype=torch.float64)\n",
      " 30 300 平均相对误差2： tensor(6.2715, dtype=torch.float64, grad_fn=<NormBackward0>)   30 300 置换矩阵误差： tensor(1.4095, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0701, dtype=torch.float64)   实验回归误差 tensor(0.0358, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(6558.5527, dtype=torch.float64)\n",
      "#Loss 1 = tensor(6535.3318, dtype=torch.float64)\n",
      "#Loss 2 = tensor(474.5795, dtype=torch.float64)\n",
      "#Loss 3 = tensor(316.7528, dtype=torch.float64)\n",
      "#Loss 4 = tensor(298.1984, dtype=torch.float64)\n",
      "#Loss 5 = tensor(289.2873, dtype=torch.float64)\n",
      "#Loss 6 = tensor(282.1660, dtype=torch.float64)\n",
      "#Loss 7 = tensor(276.7474, dtype=torch.float64)\n",
      "#Loss 8 = tensor(271.9912, dtype=torch.float64)\n",
      "#Loss 9 = tensor(266.5373, dtype=torch.float64)\n",
      "#Loss 10 = tensor(260.1123, dtype=torch.float64)\n",
      "#Loss 11 = tensor(252.9947, dtype=torch.float64)\n",
      "#Loss 12 = tensor(246.4893, dtype=torch.float64)\n",
      "#Loss 13 = tensor(239.5940, dtype=torch.float64)\n",
      "#Loss 14 = tensor(233.7892, dtype=torch.float64)\n",
      "#Loss 15 = tensor(228.4547, dtype=torch.float64)\n",
      "#Loss 16 = tensor(223.0491, dtype=torch.float64)\n",
      "#Loss 17 = tensor(218.6519, dtype=torch.float64)\n",
      "#Loss 18 = tensor(213.5591, dtype=torch.float64)\n",
      "#Loss 19 = tensor(207.9470, dtype=torch.float64)\n",
      "#Loss 20 = tensor(202.4286, dtype=torch.float64)\n",
      "#Loss 21 = tensor(197.2010, dtype=torch.float64)\n",
      "#Loss 22 = tensor(190.4462, dtype=torch.float64)\n",
      "#Loss 23 = tensor(182.4529, dtype=torch.float64)\n",
      "#Loss 24 = tensor(174.7355, dtype=torch.float64)\n",
      "#Loss 25 = tensor(166.5269, dtype=torch.float64)\n",
      "#Loss 26 = tensor(159.7834, dtype=torch.float64)\n",
      "#Loss 27 = tensor(153.3238, dtype=torch.float64)\n",
      "#Loss 28 = tensor(146.4282, dtype=torch.float64)\n",
      "#Loss 29 = tensor(138.2104, dtype=torch.float64)\n",
      "#Loss 30 = tensor(130.5636, dtype=torch.float64)\n",
      "#Loss 31 = tensor(124.8901, dtype=torch.float64)\n",
      "#Loss 32 = tensor(120.1155, dtype=torch.float64)\n",
      "#Loss 33 = tensor(115.5056, dtype=torch.float64)\n",
      "#Loss 34 = tensor(110.1197, dtype=torch.float64)\n",
      "#Loss 35 = tensor(105.1416, dtype=torch.float64)\n",
      "#Loss 36 = tensor(101.1517, dtype=torch.float64)\n",
      "#Loss 37 = tensor(96.7204, dtype=torch.float64)\n",
      "#Loss 38 = tensor(91.9673, dtype=torch.float64)\n",
      "#Loss 39 = tensor(86.4020, dtype=torch.float64)\n",
      "#Loss 40 = tensor(81.5226, dtype=torch.float64)\n",
      "#Loss 41 = tensor(77.8332, dtype=torch.float64)\n",
      "#Loss 42 = tensor(74.5510, dtype=torch.float64)\n",
      "#Loss 43 = tensor(71.4435, dtype=torch.float64)\n",
      "#Loss 44 = tensor(68.8174, dtype=torch.float64)\n",
      "#Loss 45 = tensor(66.5496, dtype=torch.float64)\n",
      "#Loss 46 = tensor(64.3482, dtype=torch.float64)\n",
      "#Loss 47 = tensor(61.7065, dtype=torch.float64)\n",
      "#Loss 48 = tensor(59.1028, dtype=torch.float64)\n",
      "#Loss 49 = tensor(56.4603, dtype=torch.float64)\n",
      "#Loss 50 = tensor(53.4529, dtype=torch.float64)\n",
      "#Loss 51 = tensor(50.7503, dtype=torch.float64)\n",
      "#Loss 52 = tensor(48.8754, dtype=torch.float64)\n",
      "#Loss 53 = tensor(46.3715, dtype=torch.float64)\n",
      "#Loss 54 = tensor(43.7916, dtype=torch.float64)\n",
      "#Loss 55 = tensor(41.8118, dtype=torch.float64)\n",
      "#Loss 56 = tensor(40.3129, dtype=torch.float64)\n",
      "#Loss 57 = tensor(39.0306, dtype=torch.float64)\n",
      "#Loss 58 = tensor(38.2338, dtype=torch.float64)\n",
      "#Loss 59 = tensor(37.2526, dtype=torch.float64)\n",
      "#Loss 60 = tensor(36.2494, dtype=torch.float64)\n",
      "#Loss 61 = tensor(35.4241, dtype=torch.float64)\n",
      "#Loss 62 = tensor(34.7244, dtype=torch.float64)\n",
      "#Loss 63 = tensor(33.9569, dtype=torch.float64)\n",
      "#Loss 64 = tensor(32.9483, dtype=torch.float64)\n",
      "#Loss 65 = tensor(32.2742, dtype=torch.float64)\n",
      "#Loss 66 = tensor(31.7785, dtype=torch.float64)\n",
      "#Loss 67 = tensor(31.1056, dtype=torch.float64)\n",
      "#Loss 68 = tensor(30.5148, dtype=torch.float64)\n",
      "#Loss 69 = tensor(30.0259, dtype=torch.float64)\n",
      "#Loss 70 = tensor(29.5672, dtype=torch.float64)\n",
      "#Loss 71 = tensor(28.4680, dtype=torch.float64)\n",
      "#Loss 72 = tensor(27.3079, dtype=torch.float64)\n",
      "#Loss 73 = tensor(26.1517, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 74 = tensor(25.1619, dtype=torch.float64)\n",
      "#Loss 75 = tensor(24.2111, dtype=torch.float64)\n",
      "#Loss 76 = tensor(23.3084, dtype=torch.float64)\n",
      "#Loss 77 = tensor(22.4393, dtype=torch.float64)\n",
      "#Loss 78 = tensor(21.7583, dtype=torch.float64)\n",
      "#Loss 79 = tensor(21.1994, dtype=torch.float64)\n",
      "#Loss 80 = tensor(20.7395, dtype=torch.float64)\n",
      "#Loss 81 = tensor(20.3642, dtype=torch.float64)\n",
      "#Loss 82 = tensor(19.9277, dtype=torch.float64)\n",
      "#Loss 83 = tensor(19.5760, dtype=torch.float64)\n",
      "#Loss 84 = tensor(19.0271, dtype=torch.float64)\n",
      "#Loss 85 = tensor(18.6195, dtype=torch.float64)\n",
      "#Loss 86 = tensor(17.9477, dtype=torch.float64)\n",
      "#Loss 87 = tensor(17.4430, dtype=torch.float64)\n",
      "#Loss 88 = tensor(16.9138, dtype=torch.float64)\n",
      "#Loss 89 = tensor(16.5402, dtype=torch.float64)\n",
      "#Loss 90 = tensor(16.1863, dtype=torch.float64)\n",
      "#Loss 91 = tensor(15.8185, dtype=torch.float64)\n",
      "#Loss 92 = tensor(15.5515, dtype=torch.float64)\n",
      "#Loss 93 = tensor(15.2906, dtype=torch.float64)\n",
      "#Loss 94 = tensor(15.0232, dtype=torch.float64)\n",
      "#Loss 95 = tensor(14.6979, dtype=torch.float64)\n",
      "#Loss 96 = tensor(14.4618, dtype=torch.float64)\n",
      "#Loss 97 = tensor(14.2812, dtype=torch.float64)\n",
      "#Loss 98 = tensor(14.1495, dtype=torch.float64)\n",
      "#Loss 99 = tensor(13.9791, dtype=torch.float64)\n",
      "#Loss 100 = tensor(13.8312, dtype=torch.float64)\n",
      "#Loss 101 = tensor(13.6889, dtype=torch.float64)\n",
      "#Loss 102 = tensor(13.4672, dtype=torch.float64)\n",
      "#Loss 103 = tensor(13.3695, dtype=torch.float64)\n",
      "#Loss 104 = tensor(13.2994, dtype=torch.float64)\n",
      "#Loss 105 = tensor(13.2163, dtype=torch.float64)\n",
      "#Loss 106 = tensor(13.1248, dtype=torch.float64)\n",
      "#Loss 107 = tensor(13.0107, dtype=torch.float64)\n",
      "#Loss 108 = tensor(12.9020, dtype=torch.float64)\n",
      "#Loss 109 = tensor(12.7859, dtype=torch.float64)\n",
      "#Loss 110 = tensor(12.6149, dtype=torch.float64)\n",
      "#Loss 111 = tensor(12.5176, dtype=torch.float64)\n",
      "#Loss 112 = tensor(12.4448, dtype=torch.float64)\n",
      "#Loss 113 = tensor(12.3996, dtype=torch.float64)\n",
      "#Loss 114 = tensor(12.2918, dtype=torch.float64)\n",
      "#Loss 115 = tensor(12.1517, dtype=torch.float64)\n",
      "#Loss 116 = tensor(12.0741, dtype=torch.float64)\n",
      "#Loss 117 = tensor(11.9121, dtype=torch.float64)\n",
      "#Loss 118 = tensor(11.7220, dtype=torch.float64)\n",
      "#Loss 119 = tensor(11.5054, dtype=torch.float64)\n",
      "#Loss 120 = tensor(11.1070, dtype=torch.float64)\n",
      "#Loss 121 = tensor(10.6061, dtype=torch.float64)\n",
      "#Loss 122 = tensor(10.3513, dtype=torch.float64)\n",
      "#Loss 123 = tensor(10.2274, dtype=torch.float64)\n",
      "#Loss 124 = tensor(10.1434, dtype=torch.float64)\n",
      "#Loss 125 = tensor(10.0552, dtype=torch.float64)\n",
      "#Loss 126 = tensor(9.8738, dtype=torch.float64)\n",
      "#Loss 127 = tensor(9.7282, dtype=torch.float64)\n",
      "#Loss 128 = tensor(9.6243, dtype=torch.float64)\n",
      "#Loss 129 = tensor(9.4749, dtype=torch.float64)\n",
      "#Loss 130 = tensor(9.3416, dtype=torch.float64)\n",
      "#Loss 131 = tensor(9.2872, dtype=torch.float64)\n",
      "#Loss 132 = tensor(9.2528, dtype=torch.float64)\n",
      "#Loss 133 = tensor(9.2375, dtype=torch.float64)\n",
      "#Loss 134 = tensor(9.2141, dtype=torch.float64)\n",
      "#Loss 135 = tensor(9.1895, dtype=torch.float64)\n",
      "#Loss 136 = tensor(9.0925, dtype=torch.float64)\n",
      "#Loss 137 = tensor(9.0379, dtype=torch.float64)\n",
      "#Loss 138 = tensor(8.9763, dtype=torch.float64)\n",
      "#Loss 139 = tensor(8.9493, dtype=torch.float64)\n",
      "#Loss 140 = tensor(8.9304, dtype=torch.float64)\n",
      "#Loss 141 = tensor(8.9229, dtype=torch.float64)\n",
      "#Loss 142 = tensor(8.9195, dtype=torch.float64)\n",
      "#Loss 143 = tensor(8.9151, dtype=torch.float64)\n",
      "#Loss 144 = tensor(8.9128, dtype=torch.float64)\n",
      "#Loss 145 = tensor(8.9125, dtype=torch.float64)\n",
      "#Loss 146 = tensor(8.9124, dtype=torch.float64)\n",
      "#Loss 147 = tensor(8.9124, dtype=torch.float64)\n",
      "#Loss 148 = tensor(8.9124, dtype=torch.float64)\n",
      "#Loss 149 = tensor(8.9118, dtype=torch.float64)\n",
      "#Loss 150 = tensor(8.9086, dtype=torch.float64)\n",
      "#Loss 151 = tensor(8.9039, dtype=torch.float64)\n",
      "#Loss 152 = tensor(8.9027, dtype=torch.float64)\n",
      "#Loss 153 = tensor(8.9025, dtype=torch.float64)\n",
      "#Loss 154 = tensor(8.9025, dtype=torch.float64)\n",
      "#Loss 155 = tensor(8.9025, dtype=torch.float64)\n",
      "#Loss 156 = tensor(8.9022, dtype=torch.float64)\n",
      "#Loss 157 = tensor(8.9021, dtype=torch.float64)\n",
      "#Loss 158 = tensor(8.9021, dtype=torch.float64)\n",
      "#Loss 159 = tensor(8.9021, dtype=torch.float64)\n",
      "#Loss 160 = tensor(8.9021, dtype=torch.float64)\n",
      " 30 300 平均相对误差2： tensor(6.4445, dtype=torch.float64, grad_fn=<NormBackward0>)   30 300 置换矩阵误差： tensor(1.4119, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0628, dtype=torch.float64)   实验回归误差 tensor(0.0368, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(10677.6010, dtype=torch.float64)\n",
      "#Loss 1 = tensor(10488.3773, dtype=torch.float64)\n",
      "#Loss 2 = tensor(681.7728, dtype=torch.float64)\n",
      "#Loss 3 = tensor(630.8515, dtype=torch.float64)\n",
      "#Loss 4 = tensor(589.1563, dtype=torch.float64)\n",
      "#Loss 5 = tensor(550.0644, dtype=torch.float64)\n",
      "#Loss 6 = tensor(510.0851, dtype=torch.float64)\n",
      "#Loss 7 = tensor(473.9521, dtype=torch.float64)\n",
      "#Loss 8 = tensor(446.0486, dtype=torch.float64)\n",
      "#Loss 9 = tensor(422.6071, dtype=torch.float64)\n",
      "#Loss 10 = tensor(395.8385, dtype=torch.float64)\n",
      "#Loss 11 = tensor(370.7548, dtype=torch.float64)\n",
      "#Loss 12 = tensor(342.8011, dtype=torch.float64)\n",
      "#Loss 13 = tensor(320.4570, dtype=torch.float64)\n",
      "#Loss 14 = tensor(296.4138, dtype=torch.float64)\n",
      "#Loss 15 = tensor(273.9503, dtype=torch.float64)\n",
      "#Loss 16 = tensor(256.5443, dtype=torch.float64)\n",
      "#Loss 17 = tensor(239.1219, dtype=torch.float64)\n",
      "#Loss 18 = tensor(220.3587, dtype=torch.float64)\n",
      "#Loss 19 = tensor(203.5515, dtype=torch.float64)\n",
      "#Loss 20 = tensor(188.8413, dtype=torch.float64)\n",
      "#Loss 21 = tensor(176.1273, dtype=torch.float64)\n",
      "#Loss 22 = tensor(164.0504, dtype=torch.float64)\n",
      "#Loss 23 = tensor(153.1787, dtype=torch.float64)\n",
      "#Loss 24 = tensor(141.5992, dtype=torch.float64)\n",
      "#Loss 25 = tensor(128.9435, dtype=torch.float64)\n",
      "#Loss 26 = tensor(117.4840, dtype=torch.float64)\n",
      "#Loss 27 = tensor(107.8534, dtype=torch.float64)\n",
      "#Loss 28 = tensor(99.6823, dtype=torch.float64)\n",
      "#Loss 29 = tensor(92.3011, dtype=torch.float64)\n",
      "#Loss 30 = tensor(84.9008, dtype=torch.float64)\n",
      "#Loss 31 = tensor(77.6354, dtype=torch.float64)\n",
      "#Loss 32 = tensor(71.4918, dtype=torch.float64)\n",
      "#Loss 33 = tensor(65.0531, dtype=torch.float64)\n",
      "#Loss 34 = tensor(59.0761, dtype=torch.float64)\n",
      "#Loss 35 = tensor(55.0488, dtype=torch.float64)\n",
      "#Loss 36 = tensor(51.3621, dtype=torch.float64)\n",
      "#Loss 37 = tensor(47.6445, dtype=torch.float64)\n",
      "#Loss 38 = tensor(44.5538, dtype=torch.float64)\n",
      "#Loss 39 = tensor(41.3392, dtype=torch.float64)\n",
      "#Loss 40 = tensor(38.8946, dtype=torch.float64)\n",
      "#Loss 41 = tensor(37.6296, dtype=torch.float64)\n",
      "#Loss 42 = tensor(36.2257, dtype=torch.float64)\n",
      "#Loss 43 = tensor(34.7854, dtype=torch.float64)\n",
      "#Loss 44 = tensor(33.1829, dtype=torch.float64)\n",
      "#Loss 45 = tensor(31.7443, dtype=torch.float64)\n",
      "#Loss 46 = tensor(30.9385, dtype=torch.float64)\n",
      "#Loss 47 = tensor(30.2953, dtype=torch.float64)\n",
      "#Loss 48 = tensor(29.7314, dtype=torch.float64)\n",
      "#Loss 49 = tensor(29.3425, dtype=torch.float64)\n",
      "#Loss 50 = tensor(28.8365, dtype=torch.float64)\n",
      "#Loss 51 = tensor(28.2766, dtype=torch.float64)\n",
      "#Loss 52 = tensor(27.6081, dtype=torch.float64)\n",
      "#Loss 53 = tensor(26.6932, dtype=torch.float64)\n",
      "#Loss 54 = tensor(25.9501, dtype=torch.float64)\n",
      "#Loss 55 = tensor(25.2221, dtype=torch.float64)\n",
      "#Loss 56 = tensor(24.4834, dtype=torch.float64)\n",
      "#Loss 57 = tensor(23.5405, dtype=torch.float64)\n",
      "#Loss 58 = tensor(22.7098, dtype=torch.float64)\n",
      "#Loss 59 = tensor(21.9931, dtype=torch.float64)\n",
      "#Loss 60 = tensor(21.5569, dtype=torch.float64)\n",
      "#Loss 61 = tensor(21.1852, dtype=torch.float64)\n",
      "#Loss 62 = tensor(20.7832, dtype=torch.float64)\n",
      "#Loss 63 = tensor(20.3635, dtype=torch.float64)\n",
      "#Loss 64 = tensor(20.0947, dtype=torch.float64)\n",
      "#Loss 65 = tensor(19.7130, dtype=torch.float64)\n",
      "#Loss 66 = tensor(19.0376, dtype=torch.float64)\n",
      "#Loss 67 = tensor(18.5584, dtype=torch.float64)\n",
      "#Loss 68 = tensor(18.0256, dtype=torch.float64)\n",
      "#Loss 69 = tensor(17.5834, dtype=torch.float64)\n",
      "#Loss 70 = tensor(17.2163, dtype=torch.float64)\n",
      "#Loss 71 = tensor(16.9077, dtype=torch.float64)\n",
      "#Loss 72 = tensor(16.4511, dtype=torch.float64)\n",
      "#Loss 73 = tensor(16.1596, dtype=torch.float64)\n",
      "#Loss 74 = tensor(15.6011, dtype=torch.float64)\n",
      "#Loss 75 = tensor(15.1851, dtype=torch.float64)\n",
      "#Loss 76 = tensor(14.9253, dtype=torch.float64)\n",
      "#Loss 77 = tensor(14.7385, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 78 = tensor(14.5823, dtype=torch.float64)\n",
      "#Loss 79 = tensor(14.3934, dtype=torch.float64)\n",
      "#Loss 80 = tensor(14.2096, dtype=torch.float64)\n",
      "#Loss 81 = tensor(13.9846, dtype=torch.float64)\n",
      "#Loss 82 = tensor(13.8817, dtype=torch.float64)\n",
      "#Loss 83 = tensor(13.7006, dtype=torch.float64)\n",
      "#Loss 84 = tensor(13.5207, dtype=torch.float64)\n",
      "#Loss 85 = tensor(13.4353, dtype=torch.float64)\n",
      "#Loss 86 = tensor(13.3824, dtype=torch.float64)\n",
      "#Loss 87 = tensor(13.3516, dtype=torch.float64)\n",
      "#Loss 88 = tensor(13.3339, dtype=torch.float64)\n",
      "#Loss 89 = tensor(13.3013, dtype=torch.float64)\n",
      "#Loss 90 = tensor(13.2718, dtype=torch.float64)\n",
      "#Loss 91 = tensor(13.2363, dtype=torch.float64)\n",
      "#Loss 92 = tensor(13.2001, dtype=torch.float64)\n",
      "#Loss 93 = tensor(13.1655, dtype=torch.float64)\n",
      "#Loss 94 = tensor(13.1345, dtype=torch.float64)\n",
      "#Loss 95 = tensor(13.1005, dtype=torch.float64)\n",
      "#Loss 96 = tensor(13.0001, dtype=torch.float64)\n",
      "#Loss 97 = tensor(12.8397, dtype=torch.float64)\n",
      "#Loss 98 = tensor(12.7510, dtype=torch.float64)\n",
      "#Loss 99 = tensor(12.6816, dtype=torch.float64)\n",
      "#Loss 100 = tensor(12.5744, dtype=torch.float64)\n",
      "#Loss 101 = tensor(12.4200, dtype=torch.float64)\n",
      "#Loss 102 = tensor(12.2128, dtype=torch.float64)\n",
      "#Loss 103 = tensor(12.0383, dtype=torch.float64)\n",
      "#Loss 104 = tensor(11.9547, dtype=torch.float64)\n",
      "#Loss 105 = tensor(11.9075, dtype=torch.float64)\n",
      "#Loss 106 = tensor(11.8527, dtype=torch.float64)\n",
      "#Loss 107 = tensor(11.7941, dtype=torch.float64)\n",
      "#Loss 108 = tensor(11.7273, dtype=torch.float64)\n",
      "#Loss 109 = tensor(11.6569, dtype=torch.float64)\n",
      "#Loss 110 = tensor(11.5898, dtype=torch.float64)\n",
      "#Loss 111 = tensor(11.5400, dtype=torch.float64)\n",
      "#Loss 112 = tensor(11.4963, dtype=torch.float64)\n",
      "#Loss 113 = tensor(11.4458, dtype=torch.float64)\n",
      "#Loss 114 = tensor(11.3290, dtype=torch.float64)\n",
      "#Loss 115 = tensor(11.2089, dtype=torch.float64)\n",
      "#Loss 116 = tensor(11.1444, dtype=torch.float64)\n",
      "#Loss 117 = tensor(11.1081, dtype=torch.float64)\n",
      "#Loss 118 = tensor(11.0775, dtype=torch.float64)\n",
      "#Loss 119 = tensor(11.0590, dtype=torch.float64)\n",
      "#Loss 120 = tensor(11.0386, dtype=torch.float64)\n",
      "#Loss 121 = tensor(11.0271, dtype=torch.float64)\n",
      "#Loss 122 = tensor(11.0114, dtype=torch.float64)\n",
      "#Loss 123 = tensor(11.0036, dtype=torch.float64)\n",
      "#Loss 124 = tensor(11.0022, dtype=torch.float64)\n",
      "#Loss 125 = tensor(11.0019, dtype=torch.float64)\n",
      "#Loss 126 = tensor(10.9994, dtype=torch.float64)\n",
      "#Loss 127 = tensor(10.9990, dtype=torch.float64)\n",
      "#Loss 128 = tensor(10.9990, dtype=torch.float64)\n",
      "#Loss 129 = tensor(10.9990, dtype=torch.float64)\n",
      "#Loss 130 = tensor(10.9990, dtype=torch.float64)\n",
      "#Loss 131 = tensor(10.9990, dtype=torch.float64)\n",
      " 30 300 平均相对误差2： tensor(8.5188, dtype=torch.float64, grad_fn=<NormBackward0>)   30 300 置换矩阵误差： tensor(1.4142, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0505, dtype=torch.float64)   实验回归误差 tensor(0.0321, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(12636.7715, dtype=torch.float64)\n",
      "#Loss 1 = tensor(12215.0082, dtype=torch.float64)\n",
      "#Loss 2 = tensor(1774.8696, dtype=torch.float64)\n",
      "#Loss 3 = tensor(1078.8725, dtype=torch.float64)\n",
      "#Loss 4 = tensor(921.8278, dtype=torch.float64)\n",
      "#Loss 5 = tensor(844.8104, dtype=torch.float64)\n",
      "#Loss 6 = tensor(784.2390, dtype=torch.float64)\n",
      "#Loss 7 = tensor(725.5785, dtype=torch.float64)\n",
      "#Loss 8 = tensor(665.0869, dtype=torch.float64)\n",
      "#Loss 9 = tensor(597.2297, dtype=torch.float64)\n",
      "#Loss 10 = tensor(525.6899, dtype=torch.float64)\n",
      "#Loss 11 = tensor(459.8571, dtype=torch.float64)\n",
      "#Loss 12 = tensor(406.5502, dtype=torch.float64)\n",
      "#Loss 13 = tensor(361.5884, dtype=torch.float64)\n",
      "#Loss 14 = tensor(317.5067, dtype=torch.float64)\n",
      "#Loss 15 = tensor(273.9414, dtype=torch.float64)\n",
      "#Loss 16 = tensor(241.4002, dtype=torch.float64)\n",
      "#Loss 17 = tensor(215.0282, dtype=torch.float64)\n",
      "#Loss 18 = tensor(190.6119, dtype=torch.float64)\n",
      "#Loss 19 = tensor(165.4889, dtype=torch.float64)\n",
      "#Loss 20 = tensor(144.3899, dtype=torch.float64)\n",
      "#Loss 21 = tensor(124.8846, dtype=torch.float64)\n",
      "#Loss 22 = tensor(104.9574, dtype=torch.float64)\n",
      "#Loss 23 = tensor(88.8551, dtype=torch.float64)\n",
      "#Loss 24 = tensor(78.3697, dtype=torch.float64)\n",
      "#Loss 25 = tensor(71.0906, dtype=torch.float64)\n",
      "#Loss 26 = tensor(63.5905, dtype=torch.float64)\n",
      "#Loss 27 = tensor(56.5106, dtype=torch.float64)\n",
      "#Loss 28 = tensor(50.2984, dtype=torch.float64)\n",
      "#Loss 29 = tensor(45.9773, dtype=torch.float64)\n",
      "#Loss 30 = tensor(42.8884, dtype=torch.float64)\n",
      "#Loss 31 = tensor(41.0919, dtype=torch.float64)\n",
      "#Loss 32 = tensor(39.7485, dtype=torch.float64)\n",
      "#Loss 33 = tensor(38.6253, dtype=torch.float64)\n",
      "#Loss 34 = tensor(37.4334, dtype=torch.float64)\n",
      "#Loss 35 = tensor(36.3950, dtype=torch.float64)\n",
      "#Loss 36 = tensor(35.3997, dtype=torch.float64)\n",
      "#Loss 37 = tensor(34.7535, dtype=torch.float64)\n",
      "#Loss 38 = tensor(34.2414, dtype=torch.float64)\n",
      "#Loss 39 = tensor(33.8396, dtype=torch.float64)\n",
      "#Loss 40 = tensor(33.5417, dtype=torch.float64)\n",
      "#Loss 41 = tensor(33.2519, dtype=torch.float64)\n",
      "#Loss 42 = tensor(32.9409, dtype=torch.float64)\n",
      "#Loss 43 = tensor(32.6337, dtype=torch.float64)\n",
      "#Loss 44 = tensor(32.4500, dtype=torch.float64)\n",
      "#Loss 45 = tensor(32.1913, dtype=torch.float64)\n",
      "#Loss 46 = tensor(31.5848, dtype=torch.float64)\n",
      "#Loss 47 = tensor(30.7917, dtype=torch.float64)\n",
      "#Loss 48 = tensor(29.9466, dtype=torch.float64)\n",
      "#Loss 49 = tensor(29.3562, dtype=torch.float64)\n",
      "#Loss 50 = tensor(29.0065, dtype=torch.float64)\n",
      "#Loss 51 = tensor(28.7284, dtype=torch.float64)\n",
      "#Loss 52 = tensor(28.5021, dtype=torch.float64)\n",
      "#Loss 53 = tensor(28.3497, dtype=torch.float64)\n",
      "#Loss 54 = tensor(28.1456, dtype=torch.float64)\n",
      "#Loss 55 = tensor(28.0715, dtype=torch.float64)\n",
      "#Loss 56 = tensor(28.0269, dtype=torch.float64)\n",
      "#Loss 57 = tensor(27.9676, dtype=torch.float64)\n",
      "#Loss 58 = tensor(27.7527, dtype=torch.float64)\n",
      "#Loss 59 = tensor(27.6233, dtype=torch.float64)\n",
      "#Loss 60 = tensor(27.5383, dtype=torch.float64)\n",
      "#Loss 61 = tensor(27.4281, dtype=torch.float64)\n",
      "#Loss 62 = tensor(27.2476, dtype=torch.float64)\n",
      "#Loss 63 = tensor(27.1047, dtype=torch.float64)\n",
      "#Loss 64 = tensor(26.8500, dtype=torch.float64)\n",
      "#Loss 65 = tensor(26.5182, dtype=torch.float64)\n",
      "#Loss 66 = tensor(26.2500, dtype=torch.float64)\n",
      "#Loss 67 = tensor(25.9654, dtype=torch.float64)\n",
      "#Loss 68 = tensor(25.7912, dtype=torch.float64)\n",
      "#Loss 69 = tensor(25.6884, dtype=torch.float64)\n",
      "#Loss 70 = tensor(25.6064, dtype=torch.float64)\n",
      "#Loss 71 = tensor(25.5214, dtype=torch.float64)\n",
      "#Loss 72 = tensor(25.1690, dtype=torch.float64)\n",
      "#Loss 73 = tensor(24.7841, dtype=torch.float64)\n",
      "#Loss 74 = tensor(24.5007, dtype=torch.float64)\n",
      "#Loss 75 = tensor(24.2863, dtype=torch.float64)\n",
      "#Loss 76 = tensor(24.0121, dtype=torch.float64)\n",
      "#Loss 77 = tensor(23.7923, dtype=torch.float64)\n",
      "#Loss 78 = tensor(23.6452, dtype=torch.float64)\n",
      "#Loss 79 = tensor(23.4804, dtype=torch.float64)\n",
      "#Loss 80 = tensor(23.3500, dtype=torch.float64)\n",
      "#Loss 81 = tensor(23.2881, dtype=torch.float64)\n",
      "#Loss 82 = tensor(23.2212, dtype=torch.float64)\n",
      "#Loss 83 = tensor(23.0884, dtype=torch.float64)\n",
      "#Loss 84 = tensor(22.9233, dtype=torch.float64)\n",
      "#Loss 85 = tensor(22.8111, dtype=torch.float64)\n",
      "#Loss 86 = tensor(22.6709, dtype=torch.float64)\n",
      "#Loss 87 = tensor(22.5539, dtype=torch.float64)\n",
      "#Loss 88 = tensor(22.4861, dtype=torch.float64)\n",
      "#Loss 89 = tensor(22.4518, dtype=torch.float64)\n",
      "#Loss 90 = tensor(22.3846, dtype=torch.float64)\n",
      "#Loss 91 = tensor(22.2777, dtype=torch.float64)\n",
      "#Loss 92 = tensor(22.1813, dtype=torch.float64)\n",
      "#Loss 93 = tensor(22.1286, dtype=torch.float64)\n",
      "#Loss 94 = tensor(22.0275, dtype=torch.float64)\n",
      "#Loss 95 = tensor(21.9342, dtype=torch.float64)\n",
      "#Loss 96 = tensor(21.7988, dtype=torch.float64)\n",
      "#Loss 97 = tensor(21.6843, dtype=torch.float64)\n",
      "#Loss 98 = tensor(21.5709, dtype=torch.float64)\n",
      "#Loss 99 = tensor(21.5305, dtype=torch.float64)\n",
      "#Loss 100 = tensor(21.5159, dtype=torch.float64)\n",
      "#Loss 101 = tensor(21.5069, dtype=torch.float64)\n",
      "#Loss 102 = tensor(21.4923, dtype=torch.float64)\n",
      "#Loss 103 = tensor(21.4818, dtype=torch.float64)\n",
      "#Loss 104 = tensor(21.4768, dtype=torch.float64)\n",
      "#Loss 105 = tensor(21.4716, dtype=torch.float64)\n",
      "#Loss 106 = tensor(21.4704, dtype=torch.float64)\n",
      "#Loss 107 = tensor(21.4700, dtype=torch.float64)\n",
      "#Loss 108 = tensor(21.4688, dtype=torch.float64)\n",
      "#Loss 109 = tensor(21.4680, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 110 = tensor(21.4679, dtype=torch.float64)\n",
      "#Loss 111 = tensor(21.4679, dtype=torch.float64)\n",
      "#Loss 112 = tensor(21.4676, dtype=torch.float64)\n",
      "#Loss 113 = tensor(21.4675, dtype=torch.float64)\n",
      "#Loss 114 = tensor(21.4675, dtype=torch.float64)\n",
      "#Loss 115 = tensor(21.4675, dtype=torch.float64)\n",
      " 30 300 平均相对误差2： tensor(8.7769, dtype=torch.float64, grad_fn=<NormBackward0>)   30 300 置换矩阵误差： tensor(1.4119, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0474, dtype=torch.float64)   实验回归误差 tensor(0.0412, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(9504.1245, dtype=torch.float64)\n",
      "#Loss 1 = tensor(9490.6690, dtype=torch.float64)\n",
      "#Loss 2 = tensor(877.1140, dtype=torch.float64)\n",
      "#Loss 3 = tensor(682.5623, dtype=torch.float64)\n",
      "#Loss 4 = tensor(630.5892, dtype=torch.float64)\n",
      "#Loss 5 = tensor(591.7579, dtype=torch.float64)\n",
      "#Loss 6 = tensor(548.6166, dtype=torch.float64)\n",
      "#Loss 7 = tensor(512.3615, dtype=torch.float64)\n",
      "#Loss 8 = tensor(480.9077, dtype=torch.float64)\n",
      "#Loss 9 = tensor(450.7389, dtype=torch.float64)\n",
      "#Loss 10 = tensor(426.6357, dtype=torch.float64)\n",
      "#Loss 11 = tensor(405.6518, dtype=torch.float64)\n",
      "#Loss 12 = tensor(381.0284, dtype=torch.float64)\n",
      "#Loss 13 = tensor(353.3213, dtype=torch.float64)\n",
      "#Loss 14 = tensor(329.5599, dtype=torch.float64)\n",
      "#Loss 15 = tensor(305.9127, dtype=torch.float64)\n",
      "#Loss 16 = tensor(279.5930, dtype=torch.float64)\n",
      "#Loss 17 = tensor(255.7128, dtype=torch.float64)\n",
      "#Loss 18 = tensor(235.4355, dtype=torch.float64)\n",
      "#Loss 19 = tensor(216.7106, dtype=torch.float64)\n",
      "#Loss 20 = tensor(197.6138, dtype=torch.float64)\n",
      "#Loss 21 = tensor(177.1750, dtype=torch.float64)\n",
      "#Loss 22 = tensor(160.2181, dtype=torch.float64)\n",
      "#Loss 23 = tensor(146.4269, dtype=torch.float64)\n",
      "#Loss 24 = tensor(132.1654, dtype=torch.float64)\n",
      "#Loss 25 = tensor(119.4059, dtype=torch.float64)\n",
      "#Loss 26 = tensor(107.1261, dtype=torch.float64)\n",
      "#Loss 27 = tensor(97.1260, dtype=torch.float64)\n",
      "#Loss 28 = tensor(86.7755, dtype=torch.float64)\n",
      "#Loss 29 = tensor(78.4921, dtype=torch.float64)\n",
      "#Loss 30 = tensor(72.3841, dtype=torch.float64)\n",
      "#Loss 31 = tensor(65.7600, dtype=torch.float64)\n",
      "#Loss 32 = tensor(59.9546, dtype=torch.float64)\n",
      "#Loss 33 = tensor(55.3474, dtype=torch.float64)\n",
      "#Loss 34 = tensor(51.5904, dtype=torch.float64)\n",
      "#Loss 35 = tensor(48.5301, dtype=torch.float64)\n",
      "#Loss 36 = tensor(45.0996, dtype=torch.float64)\n",
      "#Loss 37 = tensor(41.8584, dtype=torch.float64)\n",
      "#Loss 38 = tensor(38.7943, dtype=torch.float64)\n",
      "#Loss 39 = tensor(36.0457, dtype=torch.float64)\n",
      "#Loss 40 = tensor(33.8674, dtype=torch.float64)\n",
      "#Loss 41 = tensor(32.3038, dtype=torch.float64)\n",
      "#Loss 42 = tensor(31.2002, dtype=torch.float64)\n",
      "#Loss 43 = tensor(30.3196, dtype=torch.float64)\n",
      "#Loss 44 = tensor(29.5124, dtype=torch.float64)\n",
      "#Loss 45 = tensor(28.8494, dtype=torch.float64)\n",
      "#Loss 46 = tensor(28.2365, dtype=torch.float64)\n",
      "#Loss 47 = tensor(27.6575, dtype=torch.float64)\n",
      "#Loss 48 = tensor(27.1183, dtype=torch.float64)\n",
      "#Loss 49 = tensor(26.5649, dtype=torch.float64)\n",
      "#Loss 50 = tensor(25.6673, dtype=torch.float64)\n",
      "#Loss 51 = tensor(24.8442, dtype=torch.float64)\n",
      "#Loss 52 = tensor(24.3379, dtype=torch.float64)\n",
      "#Loss 53 = tensor(23.7724, dtype=torch.float64)\n",
      "#Loss 54 = tensor(23.3125, dtype=torch.float64)\n",
      "#Loss 55 = tensor(22.7310, dtype=torch.float64)\n",
      "#Loss 56 = tensor(22.0635, dtype=torch.float64)\n",
      "#Loss 57 = tensor(21.3157, dtype=torch.float64)\n",
      "#Loss 58 = tensor(20.6788, dtype=torch.float64)\n",
      "#Loss 59 = tensor(20.2872, dtype=torch.float64)\n",
      "#Loss 60 = tensor(19.8256, dtype=torch.float64)\n",
      "#Loss 61 = tensor(19.4617, dtype=torch.float64)\n",
      "#Loss 62 = tensor(19.1183, dtype=torch.float64)\n",
      "#Loss 63 = tensor(18.8603, dtype=torch.float64)\n",
      "#Loss 64 = tensor(18.6644, dtype=torch.float64)\n",
      "#Loss 65 = tensor(18.4006, dtype=torch.float64)\n",
      "#Loss 66 = tensor(18.1411, dtype=torch.float64)\n",
      "#Loss 67 = tensor(17.9551, dtype=torch.float64)\n",
      "#Loss 68 = tensor(17.5282, dtype=torch.float64)\n",
      "#Loss 69 = tensor(17.3060, dtype=torch.float64)\n",
      "#Loss 70 = tensor(17.1628, dtype=torch.float64)\n",
      "#Loss 71 = tensor(16.9996, dtype=torch.float64)\n",
      "#Loss 72 = tensor(16.8269, dtype=torch.float64)\n",
      "#Loss 73 = tensor(16.6085, dtype=torch.float64)\n",
      "#Loss 74 = tensor(16.3034, dtype=torch.float64)\n",
      "#Loss 75 = tensor(15.9825, dtype=torch.float64)\n",
      "#Loss 76 = tensor(15.7955, dtype=torch.float64)\n",
      "#Loss 77 = tensor(15.6587, dtype=torch.float64)\n",
      "#Loss 78 = tensor(15.5578, dtype=torch.float64)\n",
      "#Loss 79 = tensor(15.4895, dtype=torch.float64)\n",
      "#Loss 80 = tensor(15.3749, dtype=torch.float64)\n",
      "#Loss 81 = tensor(15.2697, dtype=torch.float64)\n",
      "#Loss 82 = tensor(15.1362, dtype=torch.float64)\n",
      "#Loss 83 = tensor(15.0135, dtype=torch.float64)\n",
      "#Loss 84 = tensor(14.7256, dtype=torch.float64)\n",
      "#Loss 85 = tensor(14.3884, dtype=torch.float64)\n",
      "#Loss 86 = tensor(14.1882, dtype=torch.float64)\n",
      "#Loss 87 = tensor(14.0193, dtype=torch.float64)\n",
      "#Loss 88 = tensor(13.8965, dtype=torch.float64)\n",
      "#Loss 89 = tensor(13.8261, dtype=torch.float64)\n",
      "#Loss 90 = tensor(13.7571, dtype=torch.float64)\n",
      "#Loss 91 = tensor(13.7041, dtype=torch.float64)\n",
      "#Loss 92 = tensor(13.6016, dtype=torch.float64)\n",
      "#Loss 93 = tensor(13.4730, dtype=torch.float64)\n",
      "#Loss 94 = tensor(13.1842, dtype=torch.float64)\n",
      "#Loss 95 = tensor(13.0368, dtype=torch.float64)\n",
      "#Loss 96 = tensor(12.8891, dtype=torch.float64)\n",
      "#Loss 97 = tensor(12.7292, dtype=torch.float64)\n",
      "#Loss 98 = tensor(12.4545, dtype=torch.float64)\n",
      "#Loss 99 = tensor(12.2954, dtype=torch.float64)\n",
      "#Loss 100 = tensor(12.1012, dtype=torch.float64)\n",
      "#Loss 101 = tensor(11.8227, dtype=torch.float64)\n",
      "#Loss 102 = tensor(11.5342, dtype=torch.float64)\n",
      "#Loss 103 = tensor(11.3510, dtype=torch.float64)\n",
      "#Loss 104 = tensor(11.2187, dtype=torch.float64)\n",
      "#Loss 105 = tensor(10.9465, dtype=torch.float64)\n",
      "#Loss 106 = tensor(10.5102, dtype=torch.float64)\n",
      "#Loss 107 = tensor(10.0951, dtype=torch.float64)\n",
      "#Loss 108 = tensor(9.8332, dtype=torch.float64)\n",
      "#Loss 109 = tensor(9.6402, dtype=torch.float64)\n",
      "#Loss 110 = tensor(9.4387, dtype=torch.float64)\n",
      "#Loss 111 = tensor(9.1831, dtype=torch.float64)\n",
      "#Loss 112 = tensor(8.8867, dtype=torch.float64)\n",
      "#Loss 113 = tensor(8.7065, dtype=torch.float64)\n",
      "#Loss 114 = tensor(8.5348, dtype=torch.float64)\n",
      "#Loss 115 = tensor(8.3928, dtype=torch.float64)\n",
      "#Loss 116 = tensor(8.2840, dtype=torch.float64)\n",
      "#Loss 117 = tensor(8.2393, dtype=torch.float64)\n",
      "#Loss 118 = tensor(8.2115, dtype=torch.float64)\n",
      "#Loss 119 = tensor(8.1541, dtype=torch.float64)\n",
      "#Loss 120 = tensor(8.1139, dtype=torch.float64)\n",
      "#Loss 121 = tensor(8.0713, dtype=torch.float64)\n",
      "#Loss 122 = tensor(8.0532, dtype=torch.float64)\n",
      "#Loss 123 = tensor(8.0332, dtype=torch.float64)\n",
      "#Loss 124 = tensor(8.0195, dtype=torch.float64)\n",
      "#Loss 125 = tensor(8.0001, dtype=torch.float64)\n",
      "#Loss 126 = tensor(7.9589, dtype=torch.float64)\n",
      "#Loss 127 = tensor(7.8826, dtype=torch.float64)\n",
      "#Loss 128 = tensor(7.8306, dtype=torch.float64)\n",
      "#Loss 129 = tensor(7.7394, dtype=torch.float64)\n",
      "#Loss 130 = tensor(7.6579, dtype=torch.float64)\n",
      "#Loss 131 = tensor(7.4707, dtype=torch.float64)\n",
      "#Loss 132 = tensor(7.3652, dtype=torch.float64)\n",
      "#Loss 133 = tensor(7.3400, dtype=torch.float64)\n",
      "#Loss 134 = tensor(7.3098, dtype=torch.float64)\n",
      "#Loss 135 = tensor(7.2642, dtype=torch.float64)\n",
      "#Loss 136 = tensor(7.2087, dtype=torch.float64)\n",
      "#Loss 137 = tensor(7.1580, dtype=torch.float64)\n",
      "#Loss 138 = tensor(7.0922, dtype=torch.float64)\n",
      "#Loss 139 = tensor(7.0002, dtype=torch.float64)\n",
      "#Loss 140 = tensor(6.9060, dtype=torch.float64)\n",
      "#Loss 141 = tensor(6.8319, dtype=torch.float64)\n",
      "#Loss 142 = tensor(6.7642, dtype=torch.float64)\n",
      "#Loss 143 = tensor(6.7291, dtype=torch.float64)\n",
      "#Loss 144 = tensor(6.6886, dtype=torch.float64)\n",
      "#Loss 145 = tensor(6.6538, dtype=torch.float64)\n",
      "#Loss 146 = tensor(6.6338, dtype=torch.float64)\n",
      "#Loss 147 = tensor(6.6000, dtype=torch.float64)\n",
      "#Loss 148 = tensor(6.5300, dtype=torch.float64)\n",
      "#Loss 149 = tensor(6.4790, dtype=torch.float64)\n",
      "#Loss 150 = tensor(6.3144, dtype=torch.float64)\n",
      "#Loss 151 = tensor(6.1982, dtype=torch.float64)\n",
      "#Loss 152 = tensor(6.1243, dtype=torch.float64)\n",
      "#Loss 153 = tensor(6.0678, dtype=torch.float64)\n",
      "#Loss 154 = tensor(6.0484, dtype=torch.float64)\n",
      "#Loss 155 = tensor(6.0426, dtype=torch.float64)\n",
      "#Loss 156 = tensor(6.0209, dtype=torch.float64)\n",
      "#Loss 157 = tensor(6.0102, dtype=torch.float64)\n",
      "#Loss 158 = tensor(6.0017, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 159 = tensor(5.9967, dtype=torch.float64)\n",
      "#Loss 160 = tensor(5.9937, dtype=torch.float64)\n",
      "#Loss 161 = tensor(5.9887, dtype=torch.float64)\n",
      "#Loss 162 = tensor(5.9821, dtype=torch.float64)\n",
      "#Loss 163 = tensor(5.9530, dtype=torch.float64)\n",
      "#Loss 164 = tensor(5.8513, dtype=torch.float64)\n",
      "#Loss 165 = tensor(5.7197, dtype=torch.float64)\n",
      "#Loss 166 = tensor(5.6341, dtype=torch.float64)\n",
      "#Loss 167 = tensor(5.5757, dtype=torch.float64)\n",
      "#Loss 168 = tensor(5.5158, dtype=torch.float64)\n",
      "#Loss 169 = tensor(5.4759, dtype=torch.float64)\n",
      "#Loss 170 = tensor(5.4519, dtype=torch.float64)\n",
      "#Loss 171 = tensor(5.4437, dtype=torch.float64)\n",
      "#Loss 172 = tensor(5.4406, dtype=torch.float64)\n",
      "#Loss 173 = tensor(5.4379, dtype=torch.float64)\n",
      "#Loss 174 = tensor(5.4367, dtype=torch.float64)\n",
      "#Loss 175 = tensor(5.4365, dtype=torch.float64)\n",
      "#Loss 176 = tensor(5.4362, dtype=torch.float64)\n",
      "#Loss 177 = tensor(5.4361, dtype=torch.float64)\n",
      "#Loss 178 = tensor(5.4361, dtype=torch.float64)\n",
      "#Loss 179 = tensor(5.4361, dtype=torch.float64)\n",
      "#Loss 180 = tensor(5.4361, dtype=torch.float64)\n",
      " 30 300 平均相对误差2： tensor(7.3626, dtype=torch.float64, grad_fn=<NormBackward0>)   30 300 置换矩阵误差： tensor(1.4142, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0525, dtype=torch.float64)   实验回归误差 tensor(0.0239, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(7363.8848, dtype=torch.float64)\n",
      "#Loss 1 = tensor(7007.9796, dtype=torch.float64)\n",
      "#Loss 2 = tensor(787.8735, dtype=torch.float64)\n",
      "#Loss 3 = tensor(404.5435, dtype=torch.float64)\n",
      "#Loss 4 = tensor(323.9257, dtype=torch.float64)\n",
      "#Loss 5 = tensor(291.7741, dtype=torch.float64)\n",
      "#Loss 6 = tensor(268.9641, dtype=torch.float64)\n",
      "#Loss 7 = tensor(249.5025, dtype=torch.float64)\n",
      "#Loss 8 = tensor(231.0017, dtype=torch.float64)\n",
      "#Loss 9 = tensor(214.4081, dtype=torch.float64)\n",
      "#Loss 10 = tensor(199.1417, dtype=torch.float64)\n",
      "#Loss 11 = tensor(182.0964, dtype=torch.float64)\n",
      "#Loss 12 = tensor(164.7983, dtype=torch.float64)\n",
      "#Loss 13 = tensor(148.3603, dtype=torch.float64)\n",
      "#Loss 14 = tensor(135.4576, dtype=torch.float64)\n",
      "#Loss 15 = tensor(123.0002, dtype=torch.float64)\n",
      "#Loss 16 = tensor(111.0951, dtype=torch.float64)\n",
      "#Loss 17 = tensor(100.8077, dtype=torch.float64)\n",
      "#Loss 18 = tensor(92.0096, dtype=torch.float64)\n",
      "#Loss 19 = tensor(84.3945, dtype=torch.float64)\n",
      "#Loss 20 = tensor(78.4147, dtype=torch.float64)\n",
      "#Loss 21 = tensor(71.1459, dtype=torch.float64)\n",
      "#Loss 22 = tensor(64.6078, dtype=torch.float64)\n",
      "#Loss 23 = tensor(59.9070, dtype=torch.float64)\n",
      "#Loss 24 = tensor(55.4973, dtype=torch.float64)\n",
      "#Loss 25 = tensor(50.8604, dtype=torch.float64)\n",
      "#Loss 26 = tensor(46.7130, dtype=torch.float64)\n",
      "#Loss 27 = tensor(41.3018, dtype=torch.float64)\n",
      "#Loss 28 = tensor(37.0876, dtype=torch.float64)\n",
      "#Loss 29 = tensor(34.2478, dtype=torch.float64)\n",
      "#Loss 30 = tensor(32.3279, dtype=torch.float64)\n",
      "#Loss 31 = tensor(29.8602, dtype=torch.float64)\n",
      "#Loss 32 = tensor(27.6374, dtype=torch.float64)\n",
      "#Loss 33 = tensor(26.2806, dtype=torch.float64)\n",
      "#Loss 34 = tensor(25.1169, dtype=torch.float64)\n",
      "#Loss 35 = tensor(24.1176, dtype=torch.float64)\n",
      "#Loss 36 = tensor(22.7666, dtype=torch.float64)\n",
      "#Loss 37 = tensor(21.5553, dtype=torch.float64)\n",
      "#Loss 38 = tensor(20.7223, dtype=torch.float64)\n",
      "#Loss 39 = tensor(19.7966, dtype=torch.float64)\n",
      "#Loss 40 = tensor(19.0098, dtype=torch.float64)\n",
      "#Loss 41 = tensor(18.4092, dtype=torch.float64)\n",
      "#Loss 42 = tensor(17.6013, dtype=torch.float64)\n",
      "#Loss 43 = tensor(17.0007, dtype=torch.float64)\n",
      "#Loss 44 = tensor(16.4084, dtype=torch.float64)\n",
      "#Loss 45 = tensor(15.8439, dtype=torch.float64)\n",
      "#Loss 46 = tensor(15.3177, dtype=torch.float64)\n",
      "#Loss 47 = tensor(14.9534, dtype=torch.float64)\n",
      "#Loss 48 = tensor(14.8128, dtype=torch.float64)\n",
      "#Loss 49 = tensor(14.6879, dtype=torch.float64)\n",
      "#Loss 50 = tensor(14.4874, dtype=torch.float64)\n",
      "#Loss 51 = tensor(14.3053, dtype=torch.float64)\n",
      "#Loss 52 = tensor(14.0372, dtype=torch.float64)\n",
      "#Loss 53 = tensor(13.7924, dtype=torch.float64)\n",
      "#Loss 54 = tensor(13.5743, dtype=torch.float64)\n",
      "#Loss 55 = tensor(13.3285, dtype=torch.float64)\n",
      "#Loss 56 = tensor(12.9391, dtype=torch.float64)\n",
      "#Loss 57 = tensor(12.5706, dtype=torch.float64)\n",
      "#Loss 58 = tensor(12.1951, dtype=torch.float64)\n",
      "#Loss 59 = tensor(12.0375, dtype=torch.float64)\n",
      "#Loss 60 = tensor(11.8482, dtype=torch.float64)\n",
      "#Loss 61 = tensor(11.6019, dtype=torch.float64)\n",
      "#Loss 62 = tensor(11.3542, dtype=torch.float64)\n",
      "#Loss 63 = tensor(10.9768, dtype=torch.float64)\n",
      "#Loss 64 = tensor(10.6865, dtype=torch.float64)\n",
      "#Loss 65 = tensor(10.5496, dtype=torch.float64)\n",
      "#Loss 66 = tensor(10.4895, dtype=torch.float64)\n",
      "#Loss 67 = tensor(10.4217, dtype=torch.float64)\n",
      "#Loss 68 = tensor(10.3642, dtype=torch.float64)\n",
      "#Loss 69 = tensor(10.3059, dtype=torch.float64)\n",
      "#Loss 70 = tensor(10.2618, dtype=torch.float64)\n",
      "#Loss 71 = tensor(10.1914, dtype=torch.float64)\n",
      "#Loss 72 = tensor(10.0671, dtype=torch.float64)\n",
      "#Loss 73 = tensor(9.9728, dtype=torch.float64)\n",
      "#Loss 74 = tensor(9.8827, dtype=torch.float64)\n",
      "#Loss 75 = tensor(9.8116, dtype=torch.float64)\n",
      "#Loss 76 = tensor(9.7234, dtype=torch.float64)\n",
      "#Loss 77 = tensor(9.6885, dtype=torch.float64)\n",
      "#Loss 78 = tensor(9.6604, dtype=torch.float64)\n",
      "#Loss 79 = tensor(9.6277, dtype=torch.float64)\n",
      "#Loss 80 = tensor(9.6117, dtype=torch.float64)\n",
      "#Loss 81 = tensor(9.5992, dtype=torch.float64)\n",
      "#Loss 82 = tensor(9.5806, dtype=torch.float64)\n",
      "#Loss 83 = tensor(9.5521, dtype=torch.float64)\n",
      "#Loss 84 = tensor(9.5335, dtype=torch.float64)\n",
      "#Loss 85 = tensor(9.5230, dtype=torch.float64)\n",
      "#Loss 86 = tensor(9.5161, dtype=torch.float64)\n",
      "#Loss 87 = tensor(9.4855, dtype=torch.float64)\n",
      "#Loss 88 = tensor(9.4728, dtype=torch.float64)\n",
      "#Loss 89 = tensor(9.4625, dtype=torch.float64)\n",
      "#Loss 90 = tensor(9.4594, dtype=torch.float64)\n",
      "#Loss 91 = tensor(9.4587, dtype=torch.float64)\n",
      "#Loss 92 = tensor(9.4576, dtype=torch.float64)\n",
      "#Loss 93 = tensor(9.4574, dtype=torch.float64)\n",
      "#Loss 94 = tensor(9.4573, dtype=torch.float64)\n",
      "#Loss 95 = tensor(9.4554, dtype=torch.float64)\n",
      "#Loss 96 = tensor(9.4544, dtype=torch.float64)\n",
      "#Loss 97 = tensor(9.4542, dtype=torch.float64)\n",
      "#Loss 98 = tensor(9.4542, dtype=torch.float64)\n",
      "#Loss 99 = tensor(9.4542, dtype=torch.float64)\n",
      "#Loss 100 = tensor(9.4541, dtype=torch.float64)\n",
      "#Loss 101 = tensor(9.4541, dtype=torch.float64)\n",
      " 30 300 平均相对误差2： tensor(6.1540, dtype=torch.float64, grad_fn=<NormBackward0>)   30 300 置换矩阵误差： tensor(1.4119, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0625, dtype=torch.float64)   实验回归误差 tensor(0.0358, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(7978.0514, dtype=torch.float64)\n",
      "#Loss 1 = tensor(7906.7680, dtype=torch.float64)\n",
      "#Loss 2 = tensor(907.9049, dtype=torch.float64)\n",
      "#Loss 3 = tensor(687.5941, dtype=torch.float64)\n",
      "#Loss 4 = tensor(638.9812, dtype=torch.float64)\n",
      "#Loss 5 = tensor(602.9724, dtype=torch.float64)\n",
      "#Loss 6 = tensor(564.8242, dtype=torch.float64)\n",
      "#Loss 7 = tensor(523.0358, dtype=torch.float64)\n",
      "#Loss 8 = tensor(484.2857, dtype=torch.float64)\n",
      "#Loss 9 = tensor(450.4373, dtype=torch.float64)\n",
      "#Loss 10 = tensor(420.5536, dtype=torch.float64)\n",
      "#Loss 11 = tensor(392.0590, dtype=torch.float64)\n",
      "#Loss 12 = tensor(368.7016, dtype=torch.float64)\n",
      "#Loss 13 = tensor(345.2809, dtype=torch.float64)\n",
      "#Loss 14 = tensor(320.7293, dtype=torch.float64)\n",
      "#Loss 15 = tensor(295.7573, dtype=torch.float64)\n",
      "#Loss 16 = tensor(267.9393, dtype=torch.float64)\n",
      "#Loss 17 = tensor(241.4149, dtype=torch.float64)\n",
      "#Loss 18 = tensor(217.7430, dtype=torch.float64)\n",
      "#Loss 19 = tensor(197.2815, dtype=torch.float64)\n",
      "#Loss 20 = tensor(176.5483, dtype=torch.float64)\n",
      "#Loss 21 = tensor(157.1789, dtype=torch.float64)\n",
      "#Loss 22 = tensor(139.6208, dtype=torch.float64)\n",
      "#Loss 23 = tensor(124.0856, dtype=torch.float64)\n",
      "#Loss 24 = tensor(111.2018, dtype=torch.float64)\n",
      "#Loss 25 = tensor(101.4679, dtype=torch.float64)\n",
      "#Loss 26 = tensor(90.1032, dtype=torch.float64)\n",
      "#Loss 27 = tensor(80.6406, dtype=torch.float64)\n",
      "#Loss 28 = tensor(70.9770, dtype=torch.float64)\n",
      "#Loss 29 = tensor(63.7340, dtype=torch.float64)\n",
      "#Loss 30 = tensor(58.4727, dtype=torch.float64)\n",
      "#Loss 31 = tensor(52.5895, dtype=torch.float64)\n",
      "#Loss 32 = tensor(48.0400, dtype=torch.float64)\n",
      "#Loss 33 = tensor(43.9322, dtype=torch.float64)\n",
      "#Loss 34 = tensor(40.5026, dtype=torch.float64)\n",
      "#Loss 35 = tensor(36.9655, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 36 = tensor(33.6624, dtype=torch.float64)\n",
      "#Loss 37 = tensor(30.4922, dtype=torch.float64)\n",
      "#Loss 38 = tensor(28.4410, dtype=torch.float64)\n",
      "#Loss 39 = tensor(26.7894, dtype=torch.float64)\n",
      "#Loss 40 = tensor(25.5235, dtype=torch.float64)\n",
      "#Loss 41 = tensor(24.3746, dtype=torch.float64)\n",
      "#Loss 42 = tensor(23.5967, dtype=torch.float64)\n",
      "#Loss 43 = tensor(22.9295, dtype=torch.float64)\n",
      "#Loss 44 = tensor(22.1658, dtype=torch.float64)\n",
      "#Loss 45 = tensor(21.4300, dtype=torch.float64)\n",
      "#Loss 46 = tensor(20.6932, dtype=torch.float64)\n",
      "#Loss 47 = tensor(19.8374, dtype=torch.float64)\n",
      "#Loss 48 = tensor(19.2970, dtype=torch.float64)\n",
      "#Loss 49 = tensor(18.7915, dtype=torch.float64)\n",
      "#Loss 50 = tensor(18.3586, dtype=torch.float64)\n",
      "#Loss 51 = tensor(17.9253, dtype=torch.float64)\n",
      "#Loss 52 = tensor(17.3923, dtype=torch.float64)\n",
      "#Loss 53 = tensor(16.8619, dtype=torch.float64)\n",
      "#Loss 54 = tensor(16.4980, dtype=torch.float64)\n",
      "#Loss 55 = tensor(16.2429, dtype=torch.float64)\n",
      "#Loss 56 = tensor(16.0414, dtype=torch.float64)\n",
      "#Loss 57 = tensor(15.7895, dtype=torch.float64)\n",
      "#Loss 58 = tensor(15.5893, dtype=torch.float64)\n",
      "#Loss 59 = tensor(15.2074, dtype=torch.float64)\n",
      "#Loss 60 = tensor(14.9984, dtype=torch.float64)\n",
      "#Loss 61 = tensor(14.8469, dtype=torch.float64)\n",
      "#Loss 62 = tensor(14.7168, dtype=torch.float64)\n",
      "#Loss 63 = tensor(14.5855, dtype=torch.float64)\n",
      "#Loss 64 = tensor(14.4954, dtype=torch.float64)\n",
      "#Loss 65 = tensor(14.4520, dtype=torch.float64)\n",
      "#Loss 66 = tensor(14.4033, dtype=torch.float64)\n",
      "#Loss 67 = tensor(14.3437, dtype=torch.float64)\n",
      "#Loss 68 = tensor(14.2958, dtype=torch.float64)\n",
      "#Loss 69 = tensor(14.2556, dtype=torch.float64)\n",
      "#Loss 70 = tensor(14.2293, dtype=torch.float64)\n",
      "#Loss 71 = tensor(14.1643, dtype=torch.float64)\n",
      "#Loss 72 = tensor(14.1321, dtype=torch.float64)\n",
      "#Loss 73 = tensor(14.0892, dtype=torch.float64)\n",
      "#Loss 74 = tensor(14.0658, dtype=torch.float64)\n",
      "#Loss 75 = tensor(14.0144, dtype=torch.float64)\n",
      "#Loss 76 = tensor(13.9856, dtype=torch.float64)\n",
      "#Loss 77 = tensor(13.9261, dtype=torch.float64)\n",
      "#Loss 78 = tensor(13.8632, dtype=torch.float64)\n",
      "#Loss 79 = tensor(13.8328, dtype=torch.float64)\n",
      "#Loss 80 = tensor(13.8109, dtype=torch.float64)\n",
      "#Loss 81 = tensor(13.7931, dtype=torch.float64)\n",
      "#Loss 82 = tensor(13.7805, dtype=torch.float64)\n",
      "#Loss 83 = tensor(13.7697, dtype=torch.float64)\n",
      "#Loss 84 = tensor(13.7679, dtype=torch.float64)\n",
      "#Loss 85 = tensor(13.7675, dtype=torch.float64)\n",
      "#Loss 86 = tensor(13.7672, dtype=torch.float64)\n",
      "#Loss 87 = tensor(13.7656, dtype=torch.float64)\n",
      "#Loss 88 = tensor(13.7654, dtype=torch.float64)\n",
      "#Loss 89 = tensor(13.7654, dtype=torch.float64)\n",
      "#Loss 90 = tensor(13.7654, dtype=torch.float64)\n",
      "#Loss 91 = tensor(13.7654, dtype=torch.float64)\n",
      " 30 300 平均相对误差2： tensor(7.3106, dtype=torch.float64, grad_fn=<NormBackward0>)   30 300 置换矩阵误差： tensor(1.4119, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0590, dtype=torch.float64)   实验回归误差 tensor(0.0415, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(4319.9426, dtype=torch.float64)\n",
      "#Loss 1 = tensor(4284.2377, dtype=torch.float64)\n",
      "#Loss 2 = tensor(462.3645, dtype=torch.float64)\n",
      "#Loss 3 = tensor(412.6035, dtype=torch.float64)\n",
      "#Loss 4 = tensor(384.7022, dtype=torch.float64)\n",
      "#Loss 5 = tensor(357.4898, dtype=torch.float64)\n",
      "#Loss 6 = tensor(332.8338, dtype=torch.float64)\n",
      "#Loss 7 = tensor(309.2920, dtype=torch.float64)\n",
      "#Loss 8 = tensor(283.9415, dtype=torch.float64)\n",
      "#Loss 9 = tensor(257.2345, dtype=torch.float64)\n",
      "#Loss 10 = tensor(229.0329, dtype=torch.float64)\n",
      "#Loss 11 = tensor(205.9412, dtype=torch.float64)\n",
      "#Loss 12 = tensor(185.1185, dtype=torch.float64)\n",
      "#Loss 13 = tensor(166.0536, dtype=torch.float64)\n",
      "#Loss 14 = tensor(147.5585, dtype=torch.float64)\n",
      "#Loss 15 = tensor(130.5341, dtype=torch.float64)\n",
      "#Loss 16 = tensor(116.0191, dtype=torch.float64)\n",
      "#Loss 17 = tensor(104.9664, dtype=torch.float64)\n",
      "#Loss 18 = tensor(95.2956, dtype=torch.float64)\n",
      "#Loss 19 = tensor(85.8188, dtype=torch.float64)\n",
      "#Loss 20 = tensor(76.9181, dtype=torch.float64)\n",
      "#Loss 21 = tensor(68.9749, dtype=torch.float64)\n",
      "#Loss 22 = tensor(62.0392, dtype=torch.float64)\n",
      "#Loss 23 = tensor(56.5222, dtype=torch.float64)\n",
      "#Loss 24 = tensor(51.9033, dtype=torch.float64)\n",
      "#Loss 25 = tensor(48.6666, dtype=torch.float64)\n",
      "#Loss 26 = tensor(46.0759, dtype=torch.float64)\n",
      "#Loss 27 = tensor(43.4202, dtype=torch.float64)\n",
      "#Loss 28 = tensor(40.5699, dtype=torch.float64)\n",
      "#Loss 29 = tensor(38.1571, dtype=torch.float64)\n",
      "#Loss 30 = tensor(35.5856, dtype=torch.float64)\n",
      "#Loss 31 = tensor(33.5449, dtype=torch.float64)\n",
      "#Loss 32 = tensor(32.2752, dtype=torch.float64)\n",
      "#Loss 33 = tensor(31.2053, dtype=torch.float64)\n",
      "#Loss 34 = tensor(30.2763, dtype=torch.float64)\n",
      "#Loss 35 = tensor(29.5448, dtype=torch.float64)\n",
      "#Loss 36 = tensor(28.8906, dtype=torch.float64)\n",
      "#Loss 37 = tensor(28.3010, dtype=torch.float64)\n",
      "#Loss 38 = tensor(27.7913, dtype=torch.float64)\n",
      "#Loss 39 = tensor(27.3674, dtype=torch.float64)\n",
      "#Loss 40 = tensor(27.0368, dtype=torch.float64)\n",
      "#Loss 41 = tensor(26.7781, dtype=torch.float64)\n",
      "#Loss 42 = tensor(26.4444, dtype=torch.float64)\n",
      "#Loss 43 = tensor(26.1436, dtype=torch.float64)\n",
      "#Loss 44 = tensor(25.8763, dtype=torch.float64)\n",
      "#Loss 45 = tensor(25.6055, dtype=torch.float64)\n",
      "#Loss 46 = tensor(25.3554, dtype=torch.float64)\n",
      "#Loss 47 = tensor(25.1567, dtype=torch.float64)\n",
      "#Loss 48 = tensor(25.0006, dtype=torch.float64)\n",
      "#Loss 49 = tensor(24.8740, dtype=torch.float64)\n",
      "#Loss 50 = tensor(24.7168, dtype=torch.float64)\n",
      "#Loss 51 = tensor(24.5605, dtype=torch.float64)\n",
      "#Loss 52 = tensor(24.4466, dtype=torch.float64)\n",
      "#Loss 53 = tensor(24.2744, dtype=torch.float64)\n",
      "#Loss 54 = tensor(24.1051, dtype=torch.float64)\n",
      "#Loss 55 = tensor(23.8863, dtype=torch.float64)\n",
      "#Loss 56 = tensor(23.4154, dtype=torch.float64)\n",
      "#Loss 57 = tensor(23.0412, dtype=torch.float64)\n",
      "#Loss 58 = tensor(22.8203, dtype=torch.float64)\n",
      "#Loss 59 = tensor(22.6215, dtype=torch.float64)\n",
      "#Loss 60 = tensor(22.3761, dtype=torch.float64)\n",
      "#Loss 61 = tensor(22.0538, dtype=torch.float64)\n",
      "#Loss 62 = tensor(21.5967, dtype=torch.float64)\n",
      "#Loss 63 = tensor(21.2533, dtype=torch.float64)\n",
      "#Loss 64 = tensor(20.7318, dtype=torch.float64)\n",
      "#Loss 65 = tensor(20.2798, dtype=torch.float64)\n",
      "#Loss 66 = tensor(19.8834, dtype=torch.float64)\n",
      "#Loss 67 = tensor(19.3626, dtype=torch.float64)\n",
      "#Loss 68 = tensor(18.5325, dtype=torch.float64)\n",
      "#Loss 69 = tensor(17.9116, dtype=torch.float64)\n",
      "#Loss 70 = tensor(17.3360, dtype=torch.float64)\n",
      "#Loss 71 = tensor(16.9977, dtype=torch.float64)\n",
      "#Loss 72 = tensor(16.7317, dtype=torch.float64)\n",
      "#Loss 73 = tensor(16.4593, dtype=torch.float64)\n",
      "#Loss 74 = tensor(16.2443, dtype=torch.float64)\n",
      "#Loss 75 = tensor(15.3521, dtype=torch.float64)\n",
      "#Loss 76 = tensor(14.6802, dtype=torch.float64)\n",
      "#Loss 77 = tensor(14.3803, dtype=torch.float64)\n",
      "#Loss 78 = tensor(14.0977, dtype=torch.float64)\n",
      "#Loss 79 = tensor(13.8151, dtype=torch.float64)\n",
      "#Loss 80 = tensor(13.2190, dtype=torch.float64)\n",
      "#Loss 81 = tensor(12.8334, dtype=torch.float64)\n",
      "#Loss 82 = tensor(12.4787, dtype=torch.float64)\n",
      "#Loss 83 = tensor(12.1604, dtype=torch.float64)\n",
      "#Loss 84 = tensor(11.9109, dtype=torch.float64)\n",
      "#Loss 85 = tensor(11.6439, dtype=torch.float64)\n",
      "#Loss 86 = tensor(11.4003, dtype=torch.float64)\n",
      "#Loss 87 = tensor(11.2071, dtype=torch.float64)\n",
      "#Loss 88 = tensor(11.0459, dtype=torch.float64)\n",
      "#Loss 89 = tensor(10.9156, dtype=torch.float64)\n",
      "#Loss 90 = tensor(10.7545, dtype=torch.float64)\n",
      "#Loss 91 = tensor(10.5836, dtype=torch.float64)\n",
      "#Loss 92 = tensor(10.4039, dtype=torch.float64)\n",
      "#Loss 93 = tensor(10.2674, dtype=torch.float64)\n",
      "#Loss 94 = tensor(10.1556, dtype=torch.float64)\n",
      "#Loss 95 = tensor(10.0427, dtype=torch.float64)\n",
      "#Loss 96 = tensor(9.8335, dtype=torch.float64)\n",
      "#Loss 97 = tensor(9.6360, dtype=torch.float64)\n",
      "#Loss 98 = tensor(9.4136, dtype=torch.float64)\n",
      "#Loss 99 = tensor(9.2831, dtype=torch.float64)\n",
      "#Loss 100 = tensor(9.1934, dtype=torch.float64)\n",
      "#Loss 101 = tensor(9.0905, dtype=torch.float64)\n",
      "#Loss 102 = tensor(8.9969, dtype=torch.float64)\n",
      "#Loss 103 = tensor(8.9395, dtype=torch.float64)\n",
      "#Loss 104 = tensor(8.8873, dtype=torch.float64)\n",
      "#Loss 105 = tensor(8.8416, dtype=torch.float64)\n",
      "#Loss 106 = tensor(8.8087, dtype=torch.float64)\n",
      "#Loss 107 = tensor(8.7886, dtype=torch.float64)\n",
      "#Loss 108 = tensor(8.7747, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 109 = tensor(8.7590, dtype=torch.float64)\n",
      "#Loss 110 = tensor(8.6956, dtype=torch.float64)\n",
      "#Loss 111 = tensor(8.6168, dtype=torch.float64)\n",
      "#Loss 112 = tensor(8.5834, dtype=torch.float64)\n",
      "#Loss 113 = tensor(8.5585, dtype=torch.float64)\n",
      "#Loss 114 = tensor(8.5448, dtype=torch.float64)\n",
      "#Loss 115 = tensor(8.5362, dtype=torch.float64)\n",
      "#Loss 116 = tensor(8.5275, dtype=torch.float64)\n",
      "#Loss 117 = tensor(8.5212, dtype=torch.float64)\n",
      "#Loss 118 = tensor(8.5183, dtype=torch.float64)\n",
      "#Loss 119 = tensor(8.5171, dtype=torch.float64)\n",
      "#Loss 120 = tensor(8.5005, dtype=torch.float64)\n",
      "#Loss 121 = tensor(8.4688, dtype=torch.float64)\n",
      "#Loss 122 = tensor(8.4241, dtype=torch.float64)\n",
      "#Loss 123 = tensor(8.3973, dtype=torch.float64)\n",
      "#Loss 124 = tensor(8.3744, dtype=torch.float64)\n",
      "#Loss 125 = tensor(8.3599, dtype=torch.float64)\n",
      "#Loss 126 = tensor(8.3553, dtype=torch.float64)\n",
      "#Loss 127 = tensor(8.3450, dtype=torch.float64)\n",
      "#Loss 128 = tensor(8.3355, dtype=torch.float64)\n",
      "#Loss 129 = tensor(8.3177, dtype=torch.float64)\n",
      "#Loss 130 = tensor(8.2932, dtype=torch.float64)\n",
      "#Loss 131 = tensor(8.2659, dtype=torch.float64)\n",
      "#Loss 132 = tensor(8.2507, dtype=torch.float64)\n",
      "#Loss 133 = tensor(8.2477, dtype=torch.float64)\n",
      "#Loss 134 = tensor(8.2471, dtype=torch.float64)\n",
      "#Loss 135 = tensor(8.2470, dtype=torch.float64)\n",
      "#Loss 136 = tensor(8.2469, dtype=torch.float64)\n",
      "#Loss 137 = tensor(8.2449, dtype=torch.float64)\n",
      "#Loss 138 = tensor(8.2444, dtype=torch.float64)\n",
      "#Loss 139 = tensor(8.2432, dtype=torch.float64)\n",
      "#Loss 140 = tensor(8.2302, dtype=torch.float64)\n",
      "#Loss 141 = tensor(8.2038, dtype=torch.float64)\n",
      "#Loss 142 = tensor(8.1724, dtype=torch.float64)\n",
      "#Loss 143 = tensor(8.1234, dtype=torch.float64)\n",
      "#Loss 144 = tensor(8.0951, dtype=torch.float64)\n",
      "#Loss 145 = tensor(8.0692, dtype=torch.float64)\n",
      "#Loss 146 = tensor(8.0413, dtype=torch.float64)\n",
      "#Loss 147 = tensor(7.9951, dtype=torch.float64)\n",
      "#Loss 148 = tensor(7.9343, dtype=torch.float64)\n",
      "#Loss 149 = tensor(7.8972, dtype=torch.float64)\n",
      "#Loss 150 = tensor(7.8696, dtype=torch.float64)\n",
      "#Loss 151 = tensor(7.8460, dtype=torch.float64)\n",
      "#Loss 152 = tensor(7.8408, dtype=torch.float64)\n",
      "#Loss 153 = tensor(7.8392, dtype=torch.float64)\n",
      "#Loss 154 = tensor(7.8377, dtype=torch.float64)\n",
      "#Loss 155 = tensor(7.8343, dtype=torch.float64)\n",
      "#Loss 156 = tensor(7.8321, dtype=torch.float64)\n",
      "#Loss 157 = tensor(7.8294, dtype=torch.float64)\n",
      "#Loss 158 = tensor(7.8262, dtype=torch.float64)\n",
      "#Loss 159 = tensor(7.8242, dtype=torch.float64)\n",
      "#Loss 160 = tensor(7.8199, dtype=torch.float64)\n",
      "#Loss 161 = tensor(7.7957, dtype=torch.float64)\n",
      "#Loss 162 = tensor(7.7802, dtype=torch.float64)\n",
      "#Loss 163 = tensor(7.7604, dtype=torch.float64)\n",
      "#Loss 164 = tensor(7.7520, dtype=torch.float64)\n",
      "#Loss 165 = tensor(7.7459, dtype=torch.float64)\n",
      "#Loss 166 = tensor(7.7223, dtype=torch.float64)\n",
      "#Loss 167 = tensor(7.7174, dtype=torch.float64)\n",
      "#Loss 168 = tensor(7.7058, dtype=torch.float64)\n",
      "#Loss 169 = tensor(7.6777, dtype=torch.float64)\n",
      "#Loss 170 = tensor(7.6556, dtype=torch.float64)\n",
      "#Loss 171 = tensor(7.6370, dtype=torch.float64)\n",
      "#Loss 172 = tensor(7.6231, dtype=torch.float64)\n",
      "#Loss 173 = tensor(7.6149, dtype=torch.float64)\n",
      "#Loss 174 = tensor(7.6108, dtype=torch.float64)\n",
      "#Loss 175 = tensor(7.6066, dtype=torch.float64)\n",
      "#Loss 176 = tensor(7.6005, dtype=torch.float64)\n",
      "#Loss 177 = tensor(7.5975, dtype=torch.float64)\n",
      "#Loss 178 = tensor(7.5968, dtype=torch.float64)\n",
      "#Loss 179 = tensor(7.5958, dtype=torch.float64)\n",
      "#Loss 180 = tensor(7.5949, dtype=torch.float64)\n",
      "#Loss 181 = tensor(7.5940, dtype=torch.float64)\n",
      "#Loss 182 = tensor(7.5939, dtype=torch.float64)\n",
      "#Loss 183 = tensor(7.5938, dtype=torch.float64)\n",
      "#Loss 184 = tensor(7.5938, dtype=torch.float64)\n",
      "#Loss 185 = tensor(7.5938, dtype=torch.float64)\n",
      "#Loss 186 = tensor(7.5938, dtype=torch.float64)\n",
      "#Loss 187 = tensor(7.5938, dtype=torch.float64)\n",
      " 30 300 平均相对误差2： tensor(5.7101, dtype=torch.float64, grad_fn=<NormBackward0>)   30 300 置换矩阵误差： tensor(1.4142, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0800, dtype=torch.float64)   实验回归误差 tensor(0.0419, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(5777.2044, dtype=torch.float64)\n",
      "#Loss 1 = tensor(5518.0880, dtype=torch.float64)\n",
      "#Loss 2 = tensor(610.5043, dtype=torch.float64)\n",
      "#Loss 3 = tensor(329.1959, dtype=torch.float64)\n",
      "#Loss 4 = tensor(272.7570, dtype=torch.float64)\n",
      "#Loss 5 = tensor(241.7322, dtype=torch.float64)\n",
      "#Loss 6 = tensor(216.7712, dtype=torch.float64)\n",
      "#Loss 7 = tensor(196.5850, dtype=torch.float64)\n",
      "#Loss 8 = tensor(177.8440, dtype=torch.float64)\n",
      "#Loss 9 = tensor(161.3276, dtype=torch.float64)\n",
      "#Loss 10 = tensor(146.5842, dtype=torch.float64)\n",
      "#Loss 11 = tensor(136.0560, dtype=torch.float64)\n",
      "#Loss 12 = tensor(124.7860, dtype=torch.float64)\n",
      "#Loss 13 = tensor(114.5703, dtype=torch.float64)\n",
      "#Loss 14 = tensor(105.0414, dtype=torch.float64)\n",
      "#Loss 15 = tensor(95.5734, dtype=torch.float64)\n",
      "#Loss 16 = tensor(88.1357, dtype=torch.float64)\n",
      "#Loss 17 = tensor(82.5881, dtype=torch.float64)\n",
      "#Loss 18 = tensor(77.7028, dtype=torch.float64)\n",
      "#Loss 19 = tensor(71.7559, dtype=torch.float64)\n",
      "#Loss 20 = tensor(67.0669, dtype=torch.float64)\n",
      "#Loss 21 = tensor(62.6129, dtype=torch.float64)\n",
      "#Loss 22 = tensor(58.8065, dtype=torch.float64)\n",
      "#Loss 23 = tensor(55.0926, dtype=torch.float64)\n",
      "#Loss 24 = tensor(51.8042, dtype=torch.float64)\n",
      "#Loss 25 = tensor(47.9785, dtype=torch.float64)\n",
      "#Loss 26 = tensor(44.2869, dtype=torch.float64)\n",
      "#Loss 27 = tensor(40.9153, dtype=torch.float64)\n",
      "#Loss 28 = tensor(38.2891, dtype=torch.float64)\n",
      "#Loss 29 = tensor(36.0281, dtype=torch.float64)\n",
      "#Loss 30 = tensor(33.9240, dtype=torch.float64)\n",
      "#Loss 31 = tensor(32.3668, dtype=torch.float64)\n",
      "#Loss 32 = tensor(30.6302, dtype=torch.float64)\n",
      "#Loss 33 = tensor(29.4489, dtype=torch.float64)\n",
      "#Loss 34 = tensor(28.4344, dtype=torch.float64)\n",
      "#Loss 35 = tensor(27.4970, dtype=torch.float64)\n",
      "#Loss 36 = tensor(26.3864, dtype=torch.float64)\n",
      "#Loss 37 = tensor(25.3815, dtype=torch.float64)\n",
      "#Loss 38 = tensor(24.1421, dtype=torch.float64)\n",
      "#Loss 39 = tensor(23.0819, dtype=torch.float64)\n",
      "#Loss 40 = tensor(22.3873, dtype=torch.float64)\n",
      "#Loss 41 = tensor(21.6910, dtype=torch.float64)\n",
      "#Loss 42 = tensor(20.7238, dtype=torch.float64)\n",
      "#Loss 43 = tensor(19.4209, dtype=torch.float64)\n",
      "#Loss 44 = tensor(17.8784, dtype=torch.float64)\n",
      "#Loss 45 = tensor(16.8280, dtype=torch.float64)\n",
      "#Loss 46 = tensor(15.9450, dtype=torch.float64)\n",
      "#Loss 47 = tensor(15.3757, dtype=torch.float64)\n",
      "#Loss 48 = tensor(14.6940, dtype=torch.float64)\n",
      "#Loss 49 = tensor(13.7111, dtype=torch.float64)\n",
      "#Loss 50 = tensor(13.0686, dtype=torch.float64)\n",
      "#Loss 51 = tensor(12.4771, dtype=torch.float64)\n",
      "#Loss 52 = tensor(11.8056, dtype=torch.float64)\n",
      "#Loss 53 = tensor(10.9572, dtype=torch.float64)\n",
      "#Loss 54 = tensor(10.2211, dtype=torch.float64)\n",
      "#Loss 55 = tensor(9.3657, dtype=torch.float64)\n",
      "#Loss 56 = tensor(8.5924, dtype=torch.float64)\n",
      "#Loss 57 = tensor(8.0814, dtype=torch.float64)\n",
      "#Loss 58 = tensor(7.8231, dtype=torch.float64)\n",
      "#Loss 59 = tensor(7.5742, dtype=torch.float64)\n",
      "#Loss 60 = tensor(7.3699, dtype=torch.float64)\n",
      "#Loss 61 = tensor(7.1749, dtype=torch.float64)\n",
      "#Loss 62 = tensor(7.0624, dtype=torch.float64)\n",
      "#Loss 63 = tensor(6.9553, dtype=torch.float64)\n",
      "#Loss 64 = tensor(6.7775, dtype=torch.float64)\n",
      "#Loss 65 = tensor(6.6780, dtype=torch.float64)\n",
      "#Loss 66 = tensor(6.6183, dtype=torch.float64)\n",
      "#Loss 67 = tensor(6.5757, dtype=torch.float64)\n",
      "#Loss 68 = tensor(6.5188, dtype=torch.float64)\n",
      "#Loss 69 = tensor(6.3420, dtype=torch.float64)\n",
      "#Loss 70 = tensor(6.2379, dtype=torch.float64)\n",
      "#Loss 71 = tensor(6.1556, dtype=torch.float64)\n",
      "#Loss 72 = tensor(6.0460, dtype=torch.float64)\n",
      "#Loss 73 = tensor(5.9405, dtype=torch.float64)\n",
      "#Loss 74 = tensor(5.8599, dtype=torch.float64)\n",
      "#Loss 75 = tensor(5.7673, dtype=torch.float64)\n",
      "#Loss 76 = tensor(5.6931, dtype=torch.float64)\n",
      "#Loss 77 = tensor(5.6279, dtype=torch.float64)\n",
      "#Loss 78 = tensor(5.5729, dtype=torch.float64)\n",
      "#Loss 79 = tensor(5.5202, dtype=torch.float64)\n",
      "#Loss 80 = tensor(5.4898, dtype=torch.float64)\n",
      "#Loss 81 = tensor(5.4336, dtype=torch.float64)\n",
      "#Loss 82 = tensor(5.3550, dtype=torch.float64)\n",
      "#Loss 83 = tensor(5.2492, dtype=torch.float64)\n",
      "#Loss 84 = tensor(5.1830, dtype=torch.float64)\n",
      "#Loss 85 = tensor(5.1473, dtype=torch.float64)\n",
      "#Loss 86 = tensor(5.1313, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 87 = tensor(5.1274, dtype=torch.float64)\n",
      "#Loss 88 = tensor(5.1243, dtype=torch.float64)\n",
      "#Loss 89 = tensor(5.1224, dtype=torch.float64)\n",
      "#Loss 90 = tensor(5.1222, dtype=torch.float64)\n",
      "#Loss 91 = tensor(5.1215, dtype=torch.float64)\n",
      "#Loss 92 = tensor(5.1213, dtype=torch.float64)\n",
      "#Loss 93 = tensor(5.1213, dtype=torch.float64)\n",
      "#Loss 4 = tensor(723.2613, dtype=torch.float64)\n",
      "#Loss 5 = tensor(681.9732, dtype=torch.float64)\n",
      "#Loss 6 = tensor(641.5343, dtype=torch.float64)\n",
      "#Loss 7 = tensor(604.1947, dtype=torch.float64)\n",
      "#Loss 8 = tensor(567.9806, dtype=torch.float64)\n",
      "#Loss 9 = tensor(533.5700, dtype=torch.float64)\n",
      "#Loss 10 = tensor(499.2694, dtype=torch.float64)\n",
      "#Loss 11 = tensor(463.6460, dtype=torch.float64)\n",
      "#Loss 12 = tensor(427.9526, dtype=torch.float64)\n",
      "#Loss 13 = tensor(392.3084, dtype=torch.float64)\n",
      "#Loss 14 = tensor(359.0053, dtype=torch.float64)\n",
      "#Loss 15 = tensor(326.8051, dtype=torch.float64)\n",
      "#Loss 16 = tensor(296.6282, dtype=torch.float64)\n",
      "#Loss 17 = tensor(267.7028, dtype=torch.float64)\n",
      "#Loss 18 = tensor(238.1781, dtype=torch.float64)\n",
      "#Loss 19 = tensor(210.8901, dtype=torch.float64)\n",
      "#Loss 20 = tensor(187.2629, dtype=torch.float64)\n",
      "#Loss 21 = tensor(165.9125, dtype=torch.float64)\n",
      "#Loss 22 = tensor(145.6211, dtype=torch.float64)\n",
      "#Loss 23 = tensor(127.5310, dtype=torch.float64)\n",
      "#Loss 24 = tensor(111.6323, dtype=torch.float64)\n",
      "#Loss 25 = tensor(99.2123, dtype=torch.float64)\n",
      "#Loss 26 = tensor(88.5919, dtype=torch.float64)\n",
      "#Loss 27 = tensor(79.3839, dtype=torch.float64)\n",
      "#Loss 28 = tensor(71.7742, dtype=torch.float64)\n",
      "#Loss 29 = tensor(65.8148, dtype=torch.float64)\n",
      "#Loss 30 = tensor(61.1046, dtype=torch.float64)\n",
      "#Loss 31 = tensor(57.1309, dtype=torch.float64)\n",
      "#Loss 32 = tensor(52.9179, dtype=torch.float64)\n",
      "#Loss 33 = tensor(48.8493, dtype=torch.float64)\n",
      "#Loss 34 = tensor(45.3481, dtype=torch.float64)\n",
      "#Loss 35 = tensor(42.0344, dtype=torch.float64)\n",
      "#Loss 36 = tensor(39.1249, dtype=torch.float64)\n",
      "#Loss 37 = tensor(37.2546, dtype=torch.float64)\n",
      "#Loss 38 = tensor(34.5434, dtype=torch.float64)\n",
      "#Loss 39 = tensor(31.7482, dtype=torch.float64)\n",
      "#Loss 40 = tensor(29.7448, dtype=torch.float64)\n",
      "#Loss 41 = tensor(27.8773, dtype=torch.float64)\n",
      "#Loss 42 = tensor(25.9220, dtype=torch.float64)\n",
      "#Loss 43 = tensor(24.0894, dtype=torch.float64)\n",
      "#Loss 44 = tensor(22.6439, dtype=torch.float64)\n",
      "#Loss 45 = tensor(21.2165, dtype=torch.float64)\n",
      "#Loss 46 = tensor(19.8367, dtype=torch.float64)\n",
      "#Loss 47 = tensor(18.7200, dtype=torch.float64)\n",
      "#Loss 48 = tensor(17.8281, dtype=torch.float64)\n",
      "#Loss 49 = tensor(17.1179, dtype=torch.float64)\n",
      "#Loss 50 = tensor(16.4081, dtype=torch.float64)\n",
      "#Loss 51 = tensor(15.7834, dtype=torch.float64)\n",
      "#Loss 52 = tensor(15.1837, dtype=torch.float64)\n",
      "#Loss 53 = tensor(14.5652, dtype=torch.float64)\n",
      "#Loss 54 = tensor(14.0793, dtype=torch.float64)\n",
      "#Loss 55 = tensor(13.7745, dtype=torch.float64)\n",
      "#Loss 56 = tensor(13.4970, dtype=torch.float64)\n",
      "#Loss 57 = tensor(13.2804, dtype=torch.float64)\n",
      "#Loss 58 = tensor(13.0593, dtype=torch.float64)\n",
      "#Loss 59 = tensor(12.8636, dtype=torch.float64)\n",
      "#Loss 60 = tensor(12.6242, dtype=torch.float64)\n",
      "#Loss 61 = tensor(12.5221, dtype=torch.float64)\n",
      "#Loss 62 = tensor(12.4653, dtype=torch.float64)\n",
      "#Loss 63 = tensor(12.3657, dtype=torch.float64)\n",
      "#Loss 64 = tensor(12.1789, dtype=torch.float64)\n",
      "#Loss 65 = tensor(12.0476, dtype=torch.float64)\n",
      "#Loss 66 = tensor(11.9634, dtype=torch.float64)\n",
      "#Loss 67 = tensor(11.9348, dtype=torch.float64)\n",
      "#Loss 68 = tensor(11.9179, dtype=torch.float64)\n",
      "#Loss 69 = tensor(11.9135, dtype=torch.float64)\n",
      "#Loss 70 = tensor(11.9089, dtype=torch.float64)\n",
      "#Loss 71 = tensor(11.9074, dtype=torch.float64)\n",
      "#Loss 72 = tensor(11.9071, dtype=torch.float64)\n",
      "#Loss 73 = tensor(11.9069, dtype=torch.float64)\n",
      "#Loss 74 = tensor(11.9066, dtype=torch.float64)\n",
      "#Loss 75 = tensor(11.9066, dtype=torch.float64)\n",
      "#Loss 76 = tensor(11.9066, dtype=torch.float64)\n",
      "#Loss 77 = tensor(11.9066, dtype=torch.float64)\n",
      "#Loss 78 = tensor(11.9066, dtype=torch.float64)\n",
      " 30 300 平均相对误差2： tensor(6.3720, dtype=torch.float64, grad_fn=<NormBackward0>)   30 300 置换矩阵误差： tensor(1.4095, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0534, dtype=torch.float64)   实验回归误差 tensor(0.0351, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(7628.6245, dtype=torch.float64)\n",
      "#Loss 1 = tensor(7235.0531, dtype=torch.float64)\n",
      "#Loss 2 = tensor(401.2034, dtype=torch.float64)\n",
      "#Loss 3 = tensor(332.2243, dtype=torch.float64)\n",
      "#Loss 4 = tensor(319.0723, dtype=torch.float64)\n",
      "#Loss 5 = tensor(307.6065, dtype=torch.float64)\n",
      "#Loss 6 = tensor(296.6335, dtype=torch.float64)\n",
      "#Loss 7 = tensor(283.7937, dtype=torch.float64)\n",
      "#Loss 8 = tensor(270.6844, dtype=torch.float64)\n",
      "#Loss 9 = tensor(255.9609, dtype=torch.float64)\n",
      "#Loss 10 = tensor(244.6571, dtype=torch.float64)\n",
      "#Loss 11 = tensor(230.9490, dtype=torch.float64)\n",
      "#Loss 12 = tensor(218.3508, dtype=torch.float64)\n",
      "#Loss 13 = tensor(206.9829, dtype=torch.float64)\n",
      "#Loss 14 = tensor(197.1230, dtype=torch.float64)\n",
      "#Loss 15 = tensor(186.3920, dtype=torch.float64)\n",
      "#Loss 16 = tensor(175.3192, dtype=torch.float64)\n",
      "#Loss 17 = tensor(165.0521, dtype=torch.float64)\n",
      "#Loss 18 = tensor(157.0850, dtype=torch.float64)\n",
      "#Loss 19 = tensor(149.1999, dtype=torch.float64)\n",
      "#Loss 20 = tensor(141.9466, dtype=torch.float64)\n",
      "#Loss 21 = tensor(135.3638, dtype=torch.float64)\n",
      "#Loss 22 = tensor(130.1609, dtype=torch.float64)\n",
      "#Loss 23 = tensor(124.5064, dtype=torch.float64)\n",
      "#Loss 24 = tensor(117.1952, dtype=torch.float64)\n",
      "#Loss 25 = tensor(110.5579, dtype=torch.float64)\n",
      "#Loss 26 = tensor(104.4736, dtype=torch.float64)\n",
      "#Loss 27 = tensor(97.9163, dtype=torch.float64)\n",
      "#Loss 28 = tensor(90.4121, dtype=torch.float64)\n",
      "#Loss 29 = tensor(84.3153, dtype=torch.float64)\n",
      "#Loss 30 = tensor(79.0501, dtype=torch.float64)\n",
      "#Loss 31 = tensor(74.5569, dtype=torch.float64)\n",
      "#Loss 32 = tensor(70.9654, dtype=torch.float64)\n",
      "#Loss 33 = tensor(66.9910, dtype=torch.float64)\n",
      "#Loss 34 = tensor(63.8289, dtype=torch.float64)\n",
      "#Loss 35 = tensor(61.0034, dtype=torch.float64)\n",
      "#Loss 36 = tensor(58.8096, dtype=torch.float64)\n",
      "#Loss 37 = tensor(56.8873, dtype=torch.float64)\n",
      "#Loss 38 = tensor(54.9466, dtype=torch.float64)\n",
      "#Loss 39 = tensor(52.8700, dtype=torch.float64)\n",
      "#Loss 40 = tensor(50.8485, dtype=torch.float64)\n",
      "#Loss 41 = tensor(48.9444, dtype=torch.float64)\n",
      "#Loss 42 = tensor(47.3181, dtype=torch.float64)\n",
      "#Loss 43 = tensor(44.9308, dtype=torch.float64)\n",
      "#Loss 44 = tensor(43.1665, dtype=torch.float64)\n",
      "#Loss 45 = tensor(41.2392, dtype=torch.float64)\n",
      "#Loss 46 = tensor(39.3821, dtype=torch.float64)\n",
      "#Loss 47 = tensor(37.6907, dtype=torch.float64)\n",
      "#Loss 48 = tensor(35.9062, dtype=torch.float64)\n",
      "#Loss 49 = tensor(34.2523, dtype=torch.float64)\n",
      "#Loss 50 = tensor(32.2084, dtype=torch.float64)\n",
      "#Loss 51 = tensor(30.2483, dtype=torch.float64)\n",
      "#Loss 52 = tensor(28.4111, dtype=torch.float64)\n",
      "#Loss 53 = tensor(27.0901, dtype=torch.float64)\n",
      "#Loss 54 = tensor(25.3974, dtype=torch.float64)\n",
      "#Loss 55 = tensor(23.8698, dtype=torch.float64)\n",
      "#Loss 56 = tensor(22.3754, dtype=torch.float64)\n",
      "#Loss 57 = tensor(21.0232, dtype=torch.float64)\n",
      "#Loss 58 = tensor(19.4623, dtype=torch.float64)\n",
      "#Loss 59 = tensor(18.5454, dtype=torch.float64)\n",
      "#Loss 60 = tensor(17.8613, dtype=torch.float64)\n",
      "#Loss 61 = tensor(17.3911, dtype=torch.float64)\n",
      "#Loss 62 = tensor(16.9153, dtype=torch.float64)\n",
      "#Loss 63 = tensor(16.6221, dtype=torch.float64)\n",
      "#Loss 64 = tensor(16.4345, dtype=torch.float64)\n",
      "#Loss 65 = tensor(16.2261, dtype=torch.float64)\n",
      "#Loss 66 = tensor(15.9066, dtype=torch.float64)\n",
      "#Loss 67 = tensor(15.6254, dtype=torch.float64)\n",
      "#Loss 68 = tensor(15.0502, dtype=torch.float64)\n",
      "#Loss 69 = tensor(14.5289, dtype=torch.float64)\n",
      "#Loss 70 = tensor(14.0980, dtype=torch.float64)\n",
      "#Loss 71 = tensor(13.8276, dtype=torch.float64)\n",
      "#Loss 72 = tensor(13.6112, dtype=torch.float64)\n",
      "#Loss 73 = tensor(13.4158, dtype=torch.float64)\n",
      "#Loss 74 = tensor(13.0893, dtype=torch.float64)\n",
      "#Loss 75 = tensor(12.8959, dtype=torch.float64)\n",
      "#Loss 76 = tensor(12.7259, dtype=torch.float64)\n",
      "#Loss 77 = tensor(12.6134, dtype=torch.float64)\n",
      "#Loss 78 = tensor(12.4593, dtype=torch.float64)\n",
      "#Loss 79 = tensor(12.3004, dtype=torch.float64)\n",
      "#Loss 80 = tensor(12.1031, dtype=torch.float64)\n",
      "#Loss 81 = tensor(11.8787, dtype=torch.float64)\n",
      "#Loss 82 = tensor(11.5463, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 83 = tensor(11.3353, dtype=torch.float64)\n",
      "#Loss 84 = tensor(11.1643, dtype=torch.float64)\n",
      "#Loss 85 = tensor(11.0188, dtype=torch.float64)\n",
      "#Loss 86 = tensor(10.8787, dtype=torch.float64)\n",
      "#Loss 87 = tensor(10.5923, dtype=torch.float64)\n",
      "#Loss 88 = tensor(10.3096, dtype=torch.float64)\n",
      "#Loss 89 = tensor(10.1370, dtype=torch.float64)\n",
      "#Loss 90 = tensor(10.0096, dtype=torch.float64)\n",
      "#Loss 91 = tensor(9.9040, dtype=torch.float64)\n",
      "#Loss 92 = tensor(9.8223, dtype=torch.float64)\n",
      "#Loss 93 = tensor(9.7634, dtype=torch.float64)\n",
      "#Loss 94 = tensor(9.7369, dtype=torch.float64)\n",
      "#Loss 95 = tensor(9.6979, dtype=torch.float64)\n",
      "#Loss 96 = tensor(9.6478, dtype=torch.float64)\n",
      "#Loss 97 = tensor(9.6264, dtype=torch.float64)\n",
      "#Loss 98 = tensor(9.6061, dtype=torch.float64)\n",
      "#Loss 99 = tensor(9.5413, dtype=torch.float64)\n",
      "#Loss 100 = tensor(9.4725, dtype=torch.float64)\n",
      "#Loss 101 = tensor(9.3622, dtype=torch.float64)\n",
      "#Loss 102 = tensor(9.1872, dtype=torch.float64)\n",
      "#Loss 103 = tensor(9.0400, dtype=torch.float64)\n",
      "#Loss 104 = tensor(8.9418, dtype=torch.float64)\n",
      "#Loss 105 = tensor(8.8198, dtype=torch.float64)\n",
      "#Loss 106 = tensor(8.6867, dtype=torch.float64)\n",
      "#Loss 107 = tensor(8.6130, dtype=torch.float64)\n",
      "#Loss 108 = tensor(8.5553, dtype=torch.float64)\n",
      "#Loss 109 = tensor(8.2836, dtype=torch.float64)\n",
      "#Loss 110 = tensor(7.9190, dtype=torch.float64)\n",
      "#Loss 111 = tensor(7.7824, dtype=torch.float64)\n",
      "#Loss 112 = tensor(7.6754, dtype=torch.float64)\n",
      "#Loss 113 = tensor(7.5884, dtype=torch.float64)\n",
      "#Loss 114 = tensor(7.4909, dtype=torch.float64)\n",
      "#Loss 115 = tensor(7.4241, dtype=torch.float64)\n",
      "#Loss 116 = tensor(7.3611, dtype=torch.float64)\n",
      "#Loss 117 = tensor(7.3199, dtype=torch.float64)\n",
      "#Loss 118 = tensor(7.2945, dtype=torch.float64)\n",
      "#Loss 119 = tensor(7.2793, dtype=torch.float64)\n",
      "#Loss 120 = tensor(7.2610, dtype=torch.float64)\n",
      "#Loss 121 = tensor(7.2400, dtype=torch.float64)\n",
      "#Loss 122 = tensor(7.2187, dtype=torch.float64)\n",
      "#Loss 123 = tensor(7.1941, dtype=torch.float64)\n",
      "#Loss 124 = tensor(7.1615, dtype=torch.float64)\n",
      "#Loss 125 = tensor(7.1019, dtype=torch.float64)\n",
      "#Loss 126 = tensor(7.0823, dtype=torch.float64)\n",
      "#Loss 127 = tensor(7.0545, dtype=torch.float64)\n",
      "#Loss 128 = tensor(7.0289, dtype=torch.float64)\n",
      "#Loss 129 = tensor(7.0162, dtype=torch.float64)\n",
      "#Loss 130 = tensor(7.0104, dtype=torch.float64)\n",
      "#Loss 131 = tensor(7.0080, dtype=torch.float64)\n",
      "#Loss 132 = tensor(7.0058, dtype=torch.float64)\n",
      "#Loss 133 = tensor(7.0051, dtype=torch.float64)\n",
      "#Loss 134 = tensor(7.0051, dtype=torch.float64)\n",
      "#Loss 135 = tensor(7.0051, dtype=torch.float64)\n",
      "#Loss 136 = tensor(7.0051, dtype=torch.float64)\n",
      "#Loss 137 = tensor(7.0051, dtype=torch.float64)\n",
      " 30 300 平均相对误差2： tensor(6.7102, dtype=torch.float64, grad_fn=<NormBackward0>)   30 300 置换矩阵误差： tensor(1.4119, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0647, dtype=torch.float64)   实验回归误差 tensor(0.0303, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(5868.1619, dtype=torch.float64)\n",
      "#Loss 1 = tensor(5633.6737, dtype=torch.float64)\n",
      "#Loss 2 = tensor(457.3871, dtype=torch.float64)\n",
      "#Loss 3 = tensor(418.9576, dtype=torch.float64)\n",
      "#Loss 4 = tensor(397.4836, dtype=torch.float64)\n",
      "#Loss 5 = tensor(375.8940, dtype=torch.float64)\n",
      "#Loss 6 = tensor(352.2490, dtype=torch.float64)\n",
      "#Loss 7 = tensor(329.3039, dtype=torch.float64)\n",
      "#Loss 8 = tensor(306.4864, dtype=torch.float64)\n",
      "#Loss 9 = tensor(282.5114, dtype=torch.float64)\n",
      "#Loss 10 = tensor(260.6219, dtype=torch.float64)\n",
      "#Loss 11 = tensor(241.3226, dtype=torch.float64)\n",
      "#Loss 12 = tensor(220.6327, dtype=torch.float64)\n",
      "#Loss 13 = tensor(201.8597, dtype=torch.float64)\n",
      "#Loss 14 = tensor(185.7717, dtype=torch.float64)\n",
      "#Loss 15 = tensor(169.8179, dtype=torch.float64)\n",
      "#Loss 16 = tensor(153.5375, dtype=torch.float64)\n",
      "#Loss 17 = tensor(137.0254, dtype=torch.float64)\n",
      "#Loss 18 = tensor(122.0320, dtype=torch.float64)\n",
      "#Loss 19 = tensor(110.4862, dtype=torch.float64)\n",
      "#Loss 20 = tensor(100.6367, dtype=torch.float64)\n",
      "#Loss 21 = tensor(91.9095, dtype=torch.float64)\n",
      "#Loss 22 = tensor(85.1035, dtype=torch.float64)\n",
      "#Loss 23 = tensor(78.2959, dtype=torch.float64)\n",
      "#Loss 24 = tensor(71.1687, dtype=torch.float64)\n",
      "#Loss 25 = tensor(64.4764, dtype=torch.float64)\n",
      "#Loss 26 = tensor(58.3440, dtype=torch.float64)\n",
      "#Loss 27 = tensor(52.5345, dtype=torch.float64)\n",
      "#Loss 28 = tensor(47.6967, dtype=torch.float64)\n",
      "#Loss 29 = tensor(44.3456, dtype=torch.float64)\n",
      "#Loss 30 = tensor(41.7046, dtype=torch.float64)\n",
      "#Loss 31 = tensor(39.6567, dtype=torch.float64)\n",
      "#Loss 32 = tensor(38.0275, dtype=torch.float64)\n",
      "#Loss 33 = tensor(36.4606, dtype=torch.float64)\n",
      "#Loss 34 = tensor(35.5474, dtype=torch.float64)\n",
      "#Loss 35 = tensor(34.4850, dtype=torch.float64)\n",
      "#Loss 36 = tensor(33.4643, dtype=torch.float64)\n",
      "#Loss 37 = tensor(32.4786, dtype=torch.float64)\n",
      "#Loss 38 = tensor(31.7853, dtype=torch.float64)\n",
      "#Loss 39 = tensor(31.1034, dtype=torch.float64)\n",
      "#Loss 40 = tensor(30.5407, dtype=torch.float64)\n",
      "#Loss 41 = tensor(29.8556, dtype=torch.float64)\n",
      "#Loss 42 = tensor(29.3117, dtype=torch.float64)\n",
      "#Loss 43 = tensor(28.7950, dtype=torch.float64)\n",
      "#Loss 44 = tensor(28.1377, dtype=torch.float64)\n",
      "#Loss 45 = tensor(27.6094, dtype=torch.float64)\n",
      "#Loss 46 = tensor(26.9133, dtype=torch.float64)\n",
      "#Loss 47 = tensor(26.4039, dtype=torch.float64)\n",
      "#Loss 48 = tensor(25.9620, dtype=torch.float64)\n",
      "#Loss 49 = tensor(25.4025, dtype=torch.float64)\n",
      "#Loss 50 = tensor(25.0216, dtype=torch.float64)\n",
      "#Loss 51 = tensor(24.7446, dtype=torch.float64)\n",
      "#Loss 52 = tensor(24.5672, dtype=torch.float64)\n",
      "#Loss 53 = tensor(24.4427, dtype=torch.float64)\n",
      "#Loss 54 = tensor(24.3045, dtype=torch.float64)\n",
      "#Loss 55 = tensor(24.0514, dtype=torch.float64)\n",
      "#Loss 56 = tensor(23.8656, dtype=torch.float64)\n",
      "#Loss 57 = tensor(23.7444, dtype=torch.float64)\n",
      "#Loss 58 = tensor(23.6452, dtype=torch.float64)\n",
      "#Loss 62 = tensor(22.6293, dtype=torch.float64)\n",
      "#Loss 63 = tensor(22.4330, dtype=torch.float64)\n",
      "#Loss 64 = tensor(22.1953, dtype=torch.float64)\n",
      "#Loss 65 = tensor(21.9944, dtype=torch.float64)\n",
      "#Loss 66 = tensor(21.8238, dtype=torch.float64)\n",
      "#Loss 67 = tensor(21.6524, dtype=torch.float64)\n",
      "#Loss 68 = tensor(21.4742, dtype=torch.float64)\n",
      "#Loss 69 = tensor(21.2964, dtype=torch.float64)\n",
      "#Loss 70 = tensor(21.1910, dtype=torch.float64)\n",
      "#Loss 71 = tensor(21.0418, dtype=torch.float64)\n",
      "#Loss 72 = tensor(20.9149, dtype=torch.float64)\n",
      "#Loss 73 = tensor(20.7088, dtype=torch.float64)\n",
      "#Loss 74 = tensor(20.5650, dtype=torch.float64)\n",
      "#Loss 75 = tensor(20.4953, dtype=torch.float64)\n",
      "#Loss 76 = tensor(20.3927, dtype=torch.float64)\n",
      "#Loss 77 = tensor(20.3186, dtype=torch.float64)\n",
      "#Loss 78 = tensor(20.2764, dtype=torch.float64)\n",
      "#Loss 79 = tensor(20.2328, dtype=torch.float64)\n",
      "#Loss 80 = tensor(20.1729, dtype=torch.float64)\n",
      "#Loss 81 = tensor(20.1087, dtype=torch.float64)\n",
      "#Loss 82 = tensor(20.0816, dtype=torch.float64)\n",
      "#Loss 83 = tensor(20.0708, dtype=torch.float64)\n",
      "#Loss 84 = tensor(20.0212, dtype=torch.float64)\n",
      "#Loss 85 = tensor(19.9783, dtype=torch.float64)\n",
      "#Loss 86 = tensor(19.9199, dtype=torch.float64)\n",
      "#Loss 87 = tensor(19.8635, dtype=torch.float64)\n",
      "#Loss 88 = tensor(19.8313, dtype=torch.float64)\n",
      "#Loss 89 = tensor(19.8016, dtype=torch.float64)\n",
      "#Loss 90 = tensor(19.7855, dtype=torch.float64)\n",
      "#Loss 91 = tensor(19.7751, dtype=torch.float64)\n",
      "#Loss 92 = tensor(19.7648, dtype=torch.float64)\n",
      "#Loss 93 = tensor(19.7542, dtype=torch.float64)\n",
      "#Loss 94 = tensor(19.7335, dtype=torch.float64)\n",
      "#Loss 95 = tensor(19.7035, dtype=torch.float64)\n",
      "#Loss 96 = tensor(19.6775, dtype=torch.float64)\n",
      "#Loss 97 = tensor(19.6463, dtype=torch.float64)\n",
      "#Loss 98 = tensor(19.6094, dtype=torch.float64)\n",
      "#Loss 99 = tensor(19.5840, dtype=torch.float64)\n",
      "#Loss 100 = tensor(19.5704, dtype=torch.float64)\n",
      "#Loss 101 = tensor(19.5567, dtype=torch.float64)\n",
      "#Loss 102 = tensor(19.5407, dtype=torch.float64)\n",
      "#Loss 103 = tensor(19.5212, dtype=torch.float64)\n",
      "#Loss 104 = tensor(19.5015, dtype=torch.float64)\n",
      "#Loss 105 = tensor(19.4765, dtype=torch.float64)\n",
      "#Loss 106 = tensor(19.4511, dtype=torch.float64)\n",
      "#Loss 107 = tensor(19.4063, dtype=torch.float64)\n",
      "#Loss 108 = tensor(19.3837, dtype=torch.float64)\n",
      "#Loss 109 = tensor(19.3580, dtype=torch.float64)\n",
      "#Loss 110 = tensor(19.3456, dtype=torch.float64)\n",
      "#Loss 111 = tensor(19.3327, dtype=torch.float64)\n",
      "#Loss 112 = tensor(19.3136, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 113 = tensor(19.2930, dtype=torch.float64)\n",
      "#Loss 114 = tensor(19.2825, dtype=torch.float64)\n",
      "#Loss 115 = tensor(19.2769, dtype=torch.float64)\n",
      "#Loss 116 = tensor(19.2681, dtype=torch.float64)\n",
      "#Loss 117 = tensor(19.2609, dtype=torch.float64)\n",
      "#Loss 118 = tensor(19.2577, dtype=torch.float64)\n",
      "#Loss 119 = tensor(19.2563, dtype=torch.float64)\n",
      "#Loss 120 = tensor(19.2551, dtype=torch.float64)\n",
      "#Loss 121 = tensor(19.2550, dtype=torch.float64)\n",
      "#Loss 122 = tensor(19.2550, dtype=torch.float64)\n",
      "#Loss 123 = tensor(19.2550, dtype=torch.float64)\n",
      "#Loss 124 = tensor(19.2550, dtype=torch.float64)\n",
      " 30 300 平均相对误差2： tensor(6.2552, dtype=torch.float64, grad_fn=<NormBackward0>)   30 300 置换矩阵误差： tensor(1.4119, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0641, dtype=torch.float64)   实验回归误差 tensor(0.0573, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(8746.9308, dtype=torch.float64)\n",
      "#Loss 1 = tensor(8328.6036, dtype=torch.float64)\n",
      "#Loss 2 = tensor(579.6663, dtype=torch.float64)\n",
      "#Loss 3 = tensor(423.1741, dtype=torch.float64)\n",
      "#Loss 4 = tensor(391.6663, dtype=torch.float64)\n",
      "#Loss 5 = tensor(367.0078, dtype=torch.float64)\n",
      "#Loss 6 = tensor(344.5271, dtype=torch.float64)\n",
      "#Loss 7 = tensor(322.7924, dtype=torch.float64)\n",
      "#Loss 8 = tensor(300.7331, dtype=torch.float64)\n",
      "#Loss 9 = tensor(278.0022, dtype=torch.float64)\n",
      "#Loss 10 = tensor(254.7332, dtype=torch.float64)\n",
      "#Loss 11 = tensor(232.4176, dtype=torch.float64)\n",
      "#Loss 12 = tensor(212.0896, dtype=torch.float64)\n",
      "#Loss 13 = tensor(194.4900, dtype=torch.float64)\n",
      "#Loss 14 = tensor(177.7572, dtype=torch.float64)\n",
      "#Loss 15 = tensor(162.9979, dtype=torch.float64)\n",
      "#Loss 16 = tensor(149.8425, dtype=torch.float64)\n",
      "#Loss 17 = tensor(139.8751, dtype=torch.float64)\n",
      "#Loss 18 = tensor(129.5714, dtype=torch.float64)\n",
      "#Loss 19 = tensor(120.0050, dtype=torch.float64)\n",
      "#Loss 20 = tensor(111.8838, dtype=torch.float64)\n",
      "#Loss 21 = tensor(103.1586, dtype=torch.float64)\n",
      "#Loss 22 = tensor(92.5965, dtype=torch.float64)\n",
      "#Loss 23 = tensor(82.4451, dtype=torch.float64)\n",
      "#Loss 24 = tensor(73.4106, dtype=torch.float64)\n",
      "#Loss 25 = tensor(64.7780, dtype=torch.float64)\n",
      "#Loss 26 = tensor(57.2770, dtype=torch.float64)\n",
      "#Loss 27 = tensor(50.4942, dtype=torch.float64)\n",
      "#Loss 28 = tensor(43.8547, dtype=torch.float64)\n",
      "#Loss 29 = tensor(39.1807, dtype=torch.float64)\n",
      "#Loss 30 = tensor(36.1716, dtype=torch.float64)\n",
      "#Loss 31 = tensor(33.3135, dtype=torch.float64)\n",
      "#Loss 32 = tensor(31.3997, dtype=torch.float64)\n",
      "#Loss 33 = tensor(29.9174, dtype=torch.float64)\n",
      "#Loss 34 = tensor(28.6598, dtype=torch.float64)\n",
      "#Loss 35 = tensor(27.3821, dtype=torch.float64)\n",
      "#Loss 36 = tensor(25.9526, dtype=torch.float64)\n",
      "#Loss 37 = tensor(24.5251, dtype=torch.float64)\n",
      "#Loss 38 = tensor(22.7566, dtype=torch.float64)\n",
      "#Loss 39 = tensor(21.4842, dtype=torch.float64)\n",
      "#Loss 40 = tensor(20.6036, dtype=torch.float64)\n",
      "#Loss 41 = tensor(19.8927, dtype=torch.float64)\n",
      "#Loss 42 = tensor(19.4231, dtype=torch.float64)\n",
      "#Loss 43 = tensor(18.9387, dtype=torch.float64)\n",
      "#Loss 44 = tensor(18.6256, dtype=torch.float64)\n",
      "#Loss 45 = tensor(18.3908, dtype=torch.float64)\n",
      "#Loss 46 = tensor(18.1393, dtype=torch.float64)\n",
      "#Loss 47 = tensor(17.9254, dtype=torch.float64)\n",
      "#Loss 48 = tensor(17.5865, dtype=torch.float64)\n",
      "#Loss 49 = tensor(17.1776, dtype=torch.float64)\n",
      "#Loss 50 = tensor(16.7339, dtype=torch.float64)\n",
      "#Loss 51 = tensor(16.1743, dtype=torch.float64)\n",
      "#Loss 52 = tensor(15.7030, dtype=torch.float64)\n",
      "#Loss 53 = tensor(15.4246, dtype=torch.float64)\n",
      "#Loss 54 = tensor(15.2258, dtype=torch.float64)\n",
      "#Loss 55 = tensor(14.8829, dtype=torch.float64)\n",
      "#Loss 56 = tensor(14.5137, dtype=torch.float64)\n",
      "#Loss 57 = tensor(14.1966, dtype=torch.float64)\n",
      "#Loss 58 = tensor(13.9441, dtype=torch.float64)\n",
      "#Loss 59 = tensor(13.7595, dtype=torch.float64)\n",
      "#Loss 60 = tensor(13.5978, dtype=torch.float64)\n",
      "#Loss 61 = tensor(13.3577, dtype=torch.float64)\n",
      "#Loss 62 = tensor(12.9547, dtype=torch.float64)\n",
      "#Loss 63 = tensor(12.6324, dtype=torch.float64)\n",
      "#Loss 64 = tensor(12.4106, dtype=torch.float64)\n",
      "#Loss 65 = tensor(12.2682, dtype=torch.float64)\n",
      "#Loss 66 = tensor(12.0414, dtype=torch.float64)\n",
      "#Loss 67 = tensor(11.8559, dtype=torch.float64)\n",
      "#Loss 68 = tensor(11.7171, dtype=torch.float64)\n",
      "#Loss 69 = tensor(11.6143, dtype=torch.float64)\n",
      "#Loss 70 = tensor(11.5459, dtype=torch.float64)\n",
      "#Loss 71 = tensor(11.5033, dtype=torch.float64)\n",
      "#Loss 72 = tensor(11.4605, dtype=torch.float64)\n",
      "#Loss 73 = tensor(11.4289, dtype=torch.float64)\n",
      "#Loss 74 = tensor(11.4038, dtype=torch.float64)\n",
      "#Loss 75 = tensor(11.3731, dtype=torch.float64)\n",
      "#Loss 76 = tensor(11.3320, dtype=torch.float64)\n",
      "#Loss 77 = tensor(11.2671, dtype=torch.float64)\n",
      "#Loss 78 = tensor(11.2209, dtype=torch.float64)\n",
      "#Loss 79 = tensor(11.1847, dtype=torch.float64)\n",
      "#Loss 80 = tensor(11.1026, dtype=torch.float64)\n",
      "#Loss 81 = tensor(11.0085, dtype=torch.float64)\n",
      "#Loss 82 = tensor(10.9282, dtype=torch.float64)\n",
      "#Loss 83 = tensor(10.8784, dtype=torch.float64)\n",
      "#Loss 84 = tensor(10.8469, dtype=torch.float64)\n",
      "#Loss 85 = tensor(10.8280, dtype=torch.float64)\n",
      "#Loss 86 = tensor(10.8177, dtype=torch.float64)\n",
      "#Loss 87 = tensor(10.8138, dtype=torch.float64)\n",
      "#Loss 88 = tensor(10.8080, dtype=torch.float64)\n",
      "#Loss 89 = tensor(10.8004, dtype=torch.float64)\n",
      "#Loss 90 = tensor(10.7913, dtype=torch.float64)\n",
      "#Loss 91 = tensor(10.7743, dtype=torch.float64)\n",
      "#Loss 92 = tensor(10.7481, dtype=torch.float64)\n",
      "#Loss 93 = tensor(10.7406, dtype=torch.float64)\n",
      "#Loss 94 = tensor(10.7221, dtype=torch.float64)\n",
      "#Loss 95 = tensor(10.7018, dtype=torch.float64)\n",
      "#Loss 96 = tensor(10.6924, dtype=torch.float64)\n",
      "#Loss 97 = tensor(10.6852, dtype=torch.float64)\n",
      "#Loss 98 = tensor(10.6710, dtype=torch.float64)\n",
      "#Loss 99 = tensor(10.5785, dtype=torch.float64)\n",
      "#Loss 100 = tensor(10.5390, dtype=torch.float64)\n",
      "#Loss 101 = tensor(10.4932, dtype=torch.float64)\n",
      "#Loss 102 = tensor(10.4434, dtype=torch.float64)\n",
      "#Loss 103 = tensor(10.3749, dtype=torch.float64)\n",
      "#Loss 104 = tensor(10.3227, dtype=torch.float64)\n",
      "#Loss 105 = tensor(10.2881, dtype=torch.float64)\n",
      "#Loss 106 = tensor(10.1940, dtype=torch.float64)\n",
      "#Loss 107 = tensor(10.1457, dtype=torch.float64)\n",
      "#Loss 108 = tensor(10.0999, dtype=torch.float64)\n",
      "#Loss 109 = tensor(9.9980, dtype=torch.float64)\n",
      "#Loss 110 = tensor(9.9365, dtype=torch.float64)\n",
      "#Loss 111 = tensor(9.9160, dtype=torch.float64)\n",
      "#Loss 112 = tensor(9.8867, dtype=torch.float64)\n",
      "#Loss 113 = tensor(9.8370, dtype=torch.float64)\n",
      "#Loss 114 = tensor(9.7493, dtype=torch.float64)\n",
      "#Loss 115 = tensor(9.7403, dtype=torch.float64)\n",
      "#Loss 116 = tensor(9.7333, dtype=torch.float64)\n",
      "#Loss 117 = tensor(9.7297, dtype=torch.float64)\n",
      "#Loss 118 = tensor(9.7279, dtype=torch.float64)\n",
      "#Loss 119 = tensor(9.7277, dtype=torch.float64)\n",
      "#Loss 120 = tensor(9.7276, dtype=torch.float64)\n",
      "#Loss 121 = tensor(9.7276, dtype=torch.float64)\n",
      "#Loss 122 = tensor(9.7276, dtype=torch.float64)\n",
      "#Loss 123 = tensor(9.7276, dtype=torch.float64)\n",
      "#Loss 124 = tensor(9.7276, dtype=torch.float64)\n",
      " 30 300 平均相对误差2： tensor(6.4500, dtype=torch.float64, grad_fn=<NormBackward0>)   30 300 置换矩阵误差： tensor(1.4071, dtype=torch.float64, grad_fn=<DivBackward0>)   真实回归误差 tensor(0.0576, dtype=torch.float64)   实验回归误差 tensor(0.0333, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Loss 0 = tensor(9471.0593, dtype=torch.float64)\n",
      "#Loss 1 = tensor(9158.9867, dtype=torch.float64)\n",
      "#Loss 2 = tensor(744.1543, dtype=torch.float64)\n",
      "#Loss 3 = tensor(380.8851, dtype=torch.float64)\n",
      "#Loss 4 = tensor(341.2048, dtype=torch.float64)\n",
      "#Loss 5 = tensor(329.0872, dtype=torch.float64)\n",
      "#Loss 6 = tensor(319.9960, dtype=torch.float64)\n",
      "#Loss 7 = tensor(312.3253, dtype=torch.float64)\n",
      "#Loss 8 = tensor(304.1162, dtype=torch.float64)\n",
      "#Loss 9 = tensor(297.4022, dtype=torch.float64)\n",
      "#Loss 10 = tensor(291.2147, dtype=torch.float64)\n",
      "#Loss 11 = tensor(285.1697, dtype=torch.float64)\n",
      "#Loss 12 = tensor(279.1159, dtype=torch.float64)\n",
      "#Loss 13 = tensor(271.4400, dtype=torch.float64)\n",
      "#Loss 14 = tensor(262.9778, dtype=torch.float64)\n",
      "#Loss 15 = tensor(252.9749, dtype=torch.float64)\n",
      "#Loss 16 = tensor(245.4683, dtype=torch.float64)\n",
      "#Loss 19 = tensor(224.3727, dtype=torch.float64)\n",
      "#Loss 20 = tensor(215.8314, dtype=torch.float64)\n",
      "#Loss 21 = tensor(206.8796, dtype=torch.float64)\n",
      "#Loss 22 = tensor(196.7124, dtype=torch.float64)\n",
      "#Loss 23 = tensor(185.4725, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loss 24 = tensor(176.8347, dtype=torch.float64)\n",
      "#Loss 25 = tensor(168.0725, dtype=torch.float64)\n",
      "#Loss 26 = tensor(160.5893, dtype=torch.float64)\n",
      "#Loss 27 = tensor(154.8102, dtype=torch.float64)\n",
      "#Loss 28 = tensor(150.0830, dtype=torch.float64)\n",
      "#Loss 29 = tensor(144.5480, dtype=torch.float64)\n",
      "#Loss 30 = tensor(137.6120, dtype=torch.float64)\n",
      "#Loss 31 = tensor(131.0662, dtype=torch.float64)\n",
      "#Loss 32 = tensor(124.7288, dtype=torch.float64)\n",
      "#Loss 33 = tensor(118.4424, dtype=torch.float64)\n",
      "#Loss 34 = tensor(113.2261, dtype=torch.float64)\n",
      "#Loss 35 = tensor(108.7405, dtype=torch.float64)\n",
      "#Loss 36 = tensor(105.4770, dtype=torch.float64)\n",
      "#Loss 37 = tensor(101.6928, dtype=torch.float64)\n",
      "#Loss 38 = tensor(97.1948, dtype=torch.float64)\n",
      "#Loss 39 = tensor(92.4838, dtype=torch.float64)\n",
      "#Loss 40 = tensor(87.8815, dtype=torch.float64)\n",
      "#Loss 41 = tensor(84.1832, dtype=torch.float64)\n",
      "#Loss 42 = tensor(80.5854, dtype=torch.float64)\n",
      "#Loss 43 = tensor(77.4445, dtype=torch.float64)\n",
      "#Loss 44 = tensor(75.0243, dtype=torch.float64)\n",
      "#Loss 45 = tensor(72.5079, dtype=torch.float64)\n",
      "#Loss 46 = tensor(70.3065, dtype=torch.float64)\n",
      "#Loss 47 = tensor(68.1840, dtype=torch.float64)\n",
      "#Loss 48 = tensor(66.8774, dtype=torch.float64)\n",
      "#Loss 49 = tensor(65.4618, dtype=torch.float64)\n",
      "#Loss 50 = tensor(64.1927, dtype=torch.float64)\n",
      "#Loss 51 = tensor(62.5413, dtype=torch.float64)\n",
      "#Loss 52 = tensor(60.9446, dtype=torch.float64)\n",
      "#Loss 53 = tensor(59.4321, dtype=torch.float64)\n",
      "#Loss 54 = tensor(57.7495, dtype=torch.float64)\n",
      "#Loss 55 = tensor(56.1288, dtype=torch.float64)\n",
      "#Loss 56 = tensor(54.5440, dtype=torch.float64)\n",
      "#Loss 57 = tensor(52.9821, dtype=torch.float64)\n",
      "#Loss 58 = tensor(51.7781, dtype=torch.float64)\n",
      "#Loss 59 = tensor(50.5787, dtype=torch.float64)\n",
      "#Loss 60 = tensor(49.4737, dtype=torch.float64)\n",
      "#Loss 61 = tensor(48.6326, dtype=torch.float64)\n",
      "#Loss 62 = tensor(47.8006, dtype=torch.float64)\n",
      "#Loss 63 = tensor(46.9326, dtype=torch.float64)\n",
      "#Loss 64 = tensor(45.7563, dtype=torch.float64)\n",
      "#Loss 65 = tensor(44.9418, dtype=torch.float64)\n",
      "#Loss 66 = tensor(44.0508, dtype=torch.float64)\n",
      "#Loss 67 = tensor(43.1509, dtype=torch.float64)\n",
      "#Loss 68 = tensor(42.1347, dtype=torch.float64)\n",
      "#Loss 69 = tensor(41.0429, dtype=torch.float64)\n",
      "#Loss 70 = tensor(39.7359, dtype=torch.float64)\n",
      "#Loss 71 = tensor(38.8799, dtype=torch.float64)\n",
      "#Loss 72 = tensor(37.9747, dtype=torch.float64)\n",
      "#"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-cb149303df9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mLoss\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                         \u001b[0mLoss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0;31m#                         results_Loss.append(Loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m#                         for i_ in range(num_X1features):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gama_=1\n",
    "eta=0\n",
    "starts=1\n",
    "for i_____ in range(5):\n",
    "    for num_example in range(300,301,100): \n",
    "        for num_X2feature in [30]:\n",
    "            for i____ in range(10):\n",
    "                (y_,X2_,true_w2,true_P,error_reg1)=generatedata(noise=0.3)\n",
    "                y=y_\n",
    "                X2=X2_\n",
    "                results_Loss = []\n",
    "                results_w2=[]\n",
    "                results_error=[]\n",
    "                for i__ in range(starts):\n",
    "    #                     P_array=np.random.permutation(num_example)\n",
    "    #                     P=torch.zeros(num_example,num_example,dtype=torch.float64)\n",
    "    #                     for i in range(num_example):\n",
    "    #                         P[i][P_array[i]]=1\n",
    "    #                     X_=torch.cat([X1,X2],1)\n",
    "    #                     X=torch.mm(P,X_)\n",
    "    #                     w=torch.mm(torch.mm(torch.tensor(np.linalg.inv(torch.mm(X.transpose(1,0),X))),X.transpose(1,0)),y)\n",
    "    #                     w1,w2=w.split([num_X1feature,num_X2feature],dim=0)\n",
    "    #                     w1=torch.from_numpy(np.random.normal(0, 0,(num_X1feature,1)))\n",
    "    #                     w2=torch.from_numpy(np.random.normal(0, 0,(num_X2feature,1)))\n",
    "                    w2=generateinitialw(method='zeros')\n",
    "                    #w2=true_w2\n",
    "                    w2.requires_grad_(requires_grad=True)\n",
    "    #                 results_Loss = []\n",
    "                    lr=0.0016\n",
    "                    results_S=[]\n",
    "                    t=0\n",
    "                    before1=0\n",
    "                    while True:\n",
    "                        #start=time()\n",
    "                        Y1=y\n",
    "                        Y2=torch.mm(X2,w2)\n",
    "                        C=torch.zeros(num_example,num_example,dtype=torch.float64)\n",
    "                        for i in range(num_example):\n",
    "                            for j in range(num_example):\n",
    "                                C[i][j]=(Y1[i]-Y2[j])**2            \n",
    "\n",
    "                        #S=SinkhornIPOT(C)\n",
    "                        a=torch.ones(num_example,1,dtype=torch.float64)\n",
    "                        b=torch.ones(num_example,1,dtype=torch.float64)\n",
    "                        S=sinkhorn_epsilon_scaling(a, b, C, 0.00000001)\n",
    "                        #print(S.transpose(1,0).half())\n",
    "                        #results_S.append(S)\n",
    "                        #if t>0:\n",
    "                            #print('        S变化',(torch.norm(results_S[t]-results_S[t-1]))/(torch.norm(results_S[t-1])))\n",
    "                        #Loss=torch.sum(S*C)\n",
    "                        Loss=torch.norm(Y1-torch.mm(S,Y2))**2\n",
    "                        if Loss<1e-2:\n",
    "                            break\n",
    "                        Loss.backward()\n",
    "    #                         results_Loss.append(Loss)\n",
    "    #                         for i_ in range(num_X1features):\n",
    "    #                             results_w1[t][i_]=(w1[i_].data)\n",
    "    #                         for i_ in range(num_X2features):\n",
    "    #                             results_w2[t][i_]=(w2[i_].data)\n",
    "                        w2.data-=lr*(w2.grad+np.random.normal(0,np.sqrt(eta/(1+t)**gama_)))\n",
    "                        #print(w2.grad)\n",
    "    #                     if t==num_epochs-1:\n",
    "    #                         print('最终w1梯度：',w1.grad)\n",
    "    #                         print('最终w2梯度：',w2.grad)\n",
    "                        w2.grad.data.zero_() \n",
    "                        print('Loss',t,'=',Loss.data)\n",
    "    #                     if t%6==0:\n",
    "    #                         if torch.norm(Loss-before1)<1e-4:\n",
    "    #                             break\n",
    "    #                         before1=Loss\n",
    "                        if torch.norm(Loss-before1)/before1<1e-7:\n",
    "                            break\n",
    "                        before1=Loss\n",
    "                        if t>=200:\n",
    "                            print('超过迭代上限')\n",
    "                            break\n",
    "                        if math.isnan(Loss):\n",
    "                            break\n",
    "                        t+=1\n",
    "                        print('#',end='')\n",
    "                        #print(time()-start)\n",
    "\n",
    "\n",
    "\n",
    "                    print(' ',end='')\n",
    "                    error_each=(torch.norm(w2-true_w2))\n",
    "                    results_error.append(error_each)\n",
    "                    #results_Loss.append(Loss)\n",
    "                    #results_w1.append(w1.data)\n",
    "                    #results_w2.append(w2.data)\n",
    "\n",
    "\n",
    "                #w1=results_w1[results_Loss.index(min(results_Loss))]\n",
    "                #w2=results_w2[results_Loss.index(min(results_Loss))]\n",
    "\n",
    "    #                     for i_ in range(starts):\n",
    "    #                         results_w1[i_]=(w1[i_].data)\n",
    "    #                     for i_ in range(starts):\n",
    "    #                         results_w2[i_]=(w2[i_].data)\n",
    "\n",
    "\n",
    "                #error_w=((torch.norm(w1-true_w1))/(torch.norm(true_w1))+(torch.norm(w2-true_w2))/(torch.norm(true_w2)))/2\n",
    "                #print(num_X1feature,num_X2feature,num_example,'平均相对误差1：',error_w)\n",
    "                print(num_X2feature,num_example,'平均相对误差2：',np.min(results_error),end='   ')\n",
    "\n",
    "                #print('真实置换矩阵为：',true_P)\n",
    "                error_P=(torch.norm(S.transpose(1,0)-true_P))/(torch.norm(true_P))\n",
    "                print(num_X2feature,num_example,'置换矩阵误差：',error_P,end='   ')\n",
    "                error_reg2=(torch.norm(y_-torch.mm(torch.mm(S,X2_),w2))/torch.norm(y_))\n",
    "                print('真实回归误差',error_reg1,end='   ')\n",
    "                print('实验回归误差',error_reg2)\n",
    "                #print('双随机矩阵S为：',S.transpose(1,0).half())\n",
    "                #print(results)\n",
    "    #                 plt.figure(figsize=(6,6))\n",
    "    #                 plt.plot(results_w1_0,results_Loss, '-o',label='$w1[0]$')\n",
    "    #                 plt.plot(results_w1_1,results_Loss, '-o',label='$w1[1]$')\n",
    "    #                 plt.plot(results_w1_2,results_Loss, '-o',label='$w1[2]$')\n",
    "    #                 plt.plot(results_w2_0,results_Loss, '-o',label='$w2[0]$')\n",
    "    #                 plt.plot(results_w2_1,results_Loss, '-o',label='$w2[1]$')\n",
    "    #                 plt.plot(results_w2_2,results_Loss, '-o',label='$w2[2]$')\n",
    "    #                 plt.legend()\n",
    "    #                 plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
